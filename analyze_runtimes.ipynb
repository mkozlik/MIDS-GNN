{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import random\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import torch\n",
    "import torch_geometric.utils as tg_utils\n",
    "from tqdm.notebook import tqdm, trange\n",
    "from MIDS_dataset import MIDSDataset, MIDSLabelsDataset, MIDSProbabilitiesDataset\n",
    "from MIDS_script import generate_model\n",
    "from my_graphs_dataset import GraphDataset\n",
    "from torch_geometric.loader import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(root):\n",
    "    # Set up parameters.\n",
    "    seed = 42\n",
    "    selected_graph_sizes = {\n",
    "        \"03-25_mix_750\": -1,\n",
    "    }\n",
    "    split = (0.6, 0.2)\n",
    "    batch_size = 1\n",
    "\n",
    "    # Get the dataset.\n",
    "    loader = GraphDataset(selection=selected_graph_sizes, seed=seed)\n",
    "    prob_dataset = MIDSProbabilitiesDataset(root / \"Dataset\", loader)\n",
    "    labels_dataset = MIDSLabelsDataset(root / \"Dataset\", loader, selected_extra_feature=\"predicted_probability\")\n",
    "\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    prob_dataset, perm = prob_dataset.shuffle(return_perm=True)\n",
    "    labels_dataset = labels_dataset.index_select(perm) # type: ignore\n",
    "    assert isinstance(prob_dataset, MIDSDataset)\n",
    "    assert isinstance(labels_dataset, MIDSDataset)\n",
    "\n",
    "    # Flexible dataset splitting. Can be split to train/test or train/val/test.\n",
    "    if isinstance(split, tuple):\n",
    "        train_size, val_size = split\n",
    "        train_size = round(train_size * len(prob_dataset))\n",
    "        val_size = round(val_size * len(prob_dataset))\n",
    "    else:\n",
    "        train_size = round(split * len(prob_dataset))\n",
    "        val_size = len(prob_dataset) - train_size\n",
    "\n",
    "    test_probs = prob_dataset[train_size + val_size:]\n",
    "    test_labels = labels_dataset[train_size + val_size:]\n",
    "\n",
    "    # Batch and load data.\n",
    "    prob_loader = DataLoader(test_probs, batch_size, shuffle=False)  # type: ignore\n",
    "    labels_loader = DataLoader(test_labels, batch_size, shuffle=False)  # type: ignore\n",
    "    prob_data = [test_batch for test_batch in prob_loader]\n",
    "    labels_data = [test_batch for test_batch in labels_loader]\n",
    "\n",
    "    return prob_data, labels_data, labels_dataset.num_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definitions for testing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_GNN(root, prob_data, label_data, num_features):\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "    # Load the probability model.\n",
    "    prob_model = torch.load(root / \"Models\" / \"prob_model_best.pth\")\n",
    "    prob_model.to(device)\n",
    "    prob_model.eval()\n",
    "\n",
    "    # Load the best results csv file.\n",
    "    load_path = root / \"Results\" / \"labels_all_best.csv\"\n",
    "    best_df = pd.read_csv(load_path, index_col=0)\n",
    "    selected_df = best_df[best_df['selected_extra_feature'] == 'predicted_probability']\n",
    "\n",
    "    # Perform the experiment over models and data examples.\n",
    "    records = []\n",
    "    for _, row in tqdm(selected_df.iterrows(), total=len(selected_df)):\n",
    "        # Load the model.\n",
    "        model_kwargs = {}\n",
    "        if row[\"architecture\"] == \"GIN\":\n",
    "            model_kwargs = {\"train_eps\": True}\n",
    "        elif row[\"architecture\"] == \"GAT\":\n",
    "            model_kwargs = {\"v2\": True}\n",
    "\n",
    "        label_model = generate_model(\n",
    "            row[\"architecture\"],\n",
    "            num_features,\n",
    "            row[\"hidden_channels\"],\n",
    "            row[\"gnn_layers\"],\n",
    "            act=row[\"activation\"],\n",
    "            jk=row[\"jk\"] if row[\"jk\"] != \"none\" else None,\n",
    "            **model_kwargs\n",
    "        )\n",
    "        saved_model_dict = torch.load(root / \"Models\" / f\"{row['id']}_best_model.pth\", weights_only=False)\n",
    "        label_model.load_state_dict(saved_model_dict[\"model_state_dict\"])\n",
    "        label_model.to(device)\n",
    "        label_model.eval()\n",
    "\n",
    "        # Calculate the execution time on each data example\n",
    "        for i in trange(len(prob_data), leave=False, desc=row[\"architecture\"]):\n",
    "            start = time.perf_counter()\n",
    "            # First, predict probabilities.\n",
    "            example = prob_data[i].to(device)\n",
    "            out = prob_model(example.x, example.edge_index)\n",
    "\n",
    "            # Second, predict labels.\n",
    "            example = label_data[i].to(device)\n",
    "            out = label_model(example.x, example.edge_index)\n",
    "\n",
    "            end = time.perf_counter()\n",
    "            records.append({\n",
    "                \"model\": row[\"architecture\"],\n",
    "                \"num_nodes\": example.num_nodes,\n",
    "                \"num_edges\": example.num_edges,\n",
    "                \"execution_time\": (end - start) * 1000\n",
    "            })\n",
    "\n",
    "    return pd.DataFrame(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Utilities.baselines import optimize_Gurobi\n",
    "\n",
    "def run_Gurobi(label_data):\n",
    "    records = []\n",
    "\n",
    "    for i in trange(len(label_data)):\n",
    "        nx_graph = tg_utils.to_networkx(label_data[i], to_undirected=True)\n",
    "        sol, execution_time, details = optimize_Gurobi(nx_graph, \"MIDS\", goal=\"D\", outputFlag=0, single_cpu=False)\n",
    "        records.append({\n",
    "            \"model\": \"Gurobi\",\n",
    "            \"num_nodes\": nx_graph.number_of_nodes(),\n",
    "            \"num_edges\": nx_graph.number_of_edges(),\n",
    "            \"execution_time\": execution_time\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Utilities.mids_utils import find_MIDS\n",
    "\n",
    "def run_BK(label_data):\n",
    "    records = []\n",
    "\n",
    "    for i in trange(len(label_data)):\n",
    "        nx_graph = tg_utils.to_networkx(label_data[i], to_undirected=True)\n",
    "        start = time.perf_counter()\n",
    "        sol = find_MIDS(nx_graph)\n",
    "        end = time.perf_counter()\n",
    "        records.append({\n",
    "            \"model\": \"Bron-Kerbosch\",\n",
    "            \"num_nodes\": nx_graph.number_of_nodes(),\n",
    "            \"num_edges\": nx_graph.number_of_edges(),\n",
    "            \"execution_time\": (end - start) * 1000\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(records)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definitions for processing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_results(results):\n",
    "    # Average and standard deviation of execution time for each model over all data examples.\n",
    "    overall = results.groupby(\"model\")\n",
    "    overall_avg = overall[\"execution_time\"].mean()\n",
    "    overall_std = overall[\"execution_time\"].std()\n",
    "\n",
    "    # Average and standard deviation of execution time for each model over all data examples with the same number of nodes.\n",
    "    by_nodesize = results.groupby([\"model\", \"num_nodes\"])\n",
    "    by_nodesize_avg = by_nodesize[\"execution_time\"].mean()\n",
    "    by_nodesize_std = by_nodesize[\"execution_time\"].std()\n",
    "\n",
    "    return (pd.DataFrame({\"avg\": overall_avg, \"std\": overall_std}),\n",
    "            pd.DataFrame({\"avg\": by_nodesize_avg, \"std\": by_nodesize_std}))\n",
    "\n",
    "\n",
    "def final_analysis(overall_results, by_nodesize_results):\n",
    "    # Join overall results\n",
    "    overall_results = pd.concat(overall_results, axis=0, keys=overall_results.keys())\n",
    "    overall_results = overall_results.droplevel(0)\n",
    "    print(overall_results)\n",
    "\n",
    "    # Join by_nodesize results\n",
    "    by_nodesize_results = pd.concat(by_nodesize_results, axis=0, keys=by_nodesize_results.keys())\n",
    "\n",
    "    # Reset index for easier manipulation\n",
    "    by_nodesize_results = by_nodesize_results.reset_index()\n",
    "    by_nodesize_results = by_nodesize_results.drop(columns=\"level_0\")\n",
    "\n",
    "    # Pivot the data to create a matrix for the heatmap\n",
    "    heatmap_data = by_nodesize_results.pivot_table(\n",
    "        index=\"num_nodes\", columns=[\"model\"], values=\"avg\"\n",
    "    )\n",
    "\n",
    "    # Add hover data for \"avg\" and \"std\"\n",
    "    hover_data = []\n",
    "    for model in by_nodesize_results[\"model\"].unique():\n",
    "        for size in by_nodesize_results[\"num_nodes\"].unique():\n",
    "            avg_time = by_nodesize_results[\n",
    "                (by_nodesize_results[\"model\"] == model) & (by_nodesize_results[\"num_nodes\"] == size)\n",
    "            ][\"avg\"].values[0]\n",
    "            std_dev = by_nodesize_results[\n",
    "                (by_nodesize_results[\"model\"] == model) & (by_nodesize_results[\"num_nodes\"] == size)\n",
    "            ][\"std\"].values[0]\n",
    "            hover_data.append((size, model, f\"{avg_time:.3f} ± {std_dev:.3f}\"))\n",
    "\n",
    "    hover_df = pd.DataFrame(hover_data, columns=[\"num_nodes\", \"model\", \"hover\"])\n",
    "    hover_matrix = hover_df.pivot(index=\"num_nodes\", columns=\"model\", values=\"hover\")\n",
    "    hover_matrix = hover_matrix.loc[:, list(heatmap_data.columns)]\n",
    "\n",
    "    # Plot the heatmap\n",
    "    fig = px.imshow(\n",
    "        heatmap_data,\n",
    "        title=\"Average Execution Time by Node Size and Model\",\n",
    "        labels={\"color\": \"Execution Time (ms)\"},\n",
    "        color_continuous_scale=px.colors.sequential.Viridis[::-1]\n",
    "    )\n",
    "\n",
    "    # Add custom hover template\n",
    "    fig.update_traces(text=hover_matrix.values, hovertemplate=\"%{text}\")\n",
    "    fig.update_layout(\n",
    "        xaxis=dict(tickmode='array', tickvals=heatmap_data.columns, ticktext=heatmap_data.columns),\n",
    "        yaxis=dict(tickmode='array', tickvals=heatmap_data.index, ticktext=heatmap_data.index)\n",
    "    )\n",
    "\n",
    "    fig.show()\n",
    "    fig.write_html(\"heatmap.html\")\n",
    "\n",
    "    return overall_results, by_nodesize_results\n",
    "\n",
    "\n",
    "def make_latex_table(overall_results, by_nodesize_results):\n",
    "    # Remove index from overall_results\n",
    "    overall_results = overall_results.reset_index()\n",
    "\n",
    "    # Combine avg and std columns into a single column with ± sign\n",
    "    overall_results[\"execution_time\"] = overall_results[\"avg\"].round(3).astype(str) + \" ± \" + overall_results[\"std\"].round(3).astype(str)\n",
    "    overall_results = overall_results.drop(columns=[\"avg\", \"std\"])\n",
    "    overall_results = overall_results.rename(columns={\"execution_time\": \"Execution Time (ms)\", \"model\": \"Method\"})\n",
    "\n",
    "    # Sort rows with a specified order\n",
    "    model_order = [\"Gurobi\", \"Bron-Kerbosch\", \"MLP\", \"GCN\", \"GIN\", \"GraphSAGE\", \"GAT\", \"GATLinNet\"]\n",
    "    overall_results[\"Method\"] = pd.Categorical(overall_results[\"Method\"], categories=model_order, ordered=True)\n",
    "    overall_results = overall_results.sort_values(\"Method\")\n",
    "\n",
    "    # Generate LaTeX table for overall results\n",
    "    overall_latex = overall_results.to_latex(index=False, header=True, column_format=\"l|l\", escape=False)\n",
    "\n",
    "    return overall_latex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = pathlib.Path().cwd()  # For Jupyter notebook.\n",
    "\n",
    "# Load the dataset.\n",
    "prob_data, label_data, num_features = load_dataset(root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_results = dict()\n",
    "by_nodesize_results = dict()\n",
    "\n",
    "# Experiment for GNN models\n",
    "print(\"Running GNN models\")\n",
    "GNN_results = run_GNN(root, prob_data, label_data, num_features)\n",
    "overall_results[\"GNN\"], by_nodesize_results[\"GNN\"] = process_results(GNN_results)\n",
    "\n",
    "# Experiment for Gurobi\n",
    "print(\"Running Gurobi\")\n",
    "Gurobi_results = run_Gurobi(label_data)\n",
    "overall_results[\"Gurobi\"], by_nodesize_results[\"Gurobi\"] = process_results(Gurobi_results)\n",
    "\n",
    "# Repeat the experiment for Bron-Kerbosch\n",
    "print(\"Running Bron-Kerbosch\")\n",
    "BK_results = run_BK(label_data)\n",
    "overall_results[\"BK\"], by_nodesize_results[\"BK\"] = process_results(BK_results)\n",
    "\n",
    "# Repeat the experiment for something else"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze the results\n",
    "overall_concat, by_nodesize_concat = final_analysis(overall_results, by_nodesize_results)\n",
    "\n",
    "# Make a latex table\n",
    "overall_latex = make_latex_table(overall_concat, by_nodesize_concat)\n",
    "print(overall_latex)\n",
    "\n",
    "# Save the results\n",
    "overall_concat.to_csv(root / \"Results\" / \"overall_execution_time.csv\")\n",
    "by_nodesize_concat.to_csv(root / \"Results\" / \"by_nodesize_execution_time.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graphs_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
