{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "!pip install torch torchvision torchaudio\n",
    "\n",
    "import torch\n",
    "os.environ['TORCH'] = torch.__version__\n",
    "print(torch.__version__)\n",
    "\n",
    "#!pip install torch-sparse #-f https://data.pyg.org/whl/torch-${TORCH}.html\n",
    "#!pip install torch-scatter #-f https://data.pyg.org/whl/torch-${TORCH}.html\n",
    "#!pip install torch-sparse -f https://data.pyg.org/whl/torch-2.3.0+cu121.html\n",
    "#!pip install torch-scatter -f https://data.pyg.org/whl/torch-2.3.0+cu121.html\n",
    "\n",
    "!pip uninstall torch-scatter torch-sparse torch-geometric torch-cluster  --y\n",
    "!pip install torch-scatter -f https://data.pyg.org/whl/torch-{torch.__version__}.html\n",
    "!pip install torch-sparse -f https://data.pyg.org/whl/torch-{torch.__version__}.html\n",
    "#!pip install torch-cluster -f https://data.pyg.org/whl/torch-{torch.__version__}.html\n",
    "!pip install git+https://github.com/pyg-team/pytorch_geometric.git\n",
    "\n",
    "!pip install torch-geometric\n",
    "!pip install codetiming\n",
    "!pip install wandb\n",
    "!pip install plotly\n",
    "!pip install line-profiler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.0+cu124\n",
      "Loaded torch. Using *cuda* device.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pathlib\n",
    "\n",
    "import codetiming\n",
    "import numpy as np\n",
    "import torch\n",
    "import wandb\n",
    "\n",
    "print(torch.__version__)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Loaded torch. Using *{device}* device.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graphs_03.txt\n",
      "graphs_04.txt\n",
      "graphs_05.txt\n",
      "graphs_06.txt\n",
      "graphs_07.txt\n",
      "graphs_08.txt\n",
      "graphs_09.txt\n",
      "graphs_10.txt\n",
      "graphs_11.txt\n",
      "graphs_12.txt\n",
      "graphs_13.txt\n",
      "graphs_14.txt\n",
      "graphs_15.txt\n",
      "graphs_20.txt\n",
      "graphs_30.txt\n",
      "graphs_40.txt\n",
      "graphs_50.txt\n",
      "graphs_10.txt\n",
      "graphs_20.txt\n",
      "Elapsed time: 0.0028 seconds\n",
      "\n",
      "Dataset: MIDSdataset(992):\n",
      "====================\n",
      "Number of graphs: 992\n",
      "Number of features: 7\n",
      "Number of classes: 2\n",
      "\n",
      "Data(edge_index=[2, 18], x=[7, 7], y=[7])\n",
      "=============================================================\n",
      "Number of nodes: 7\n",
      "Number of edges: 18\n",
      "Average node degree: 2.57\n",
      "Has isolated nodes: False\n",
      "Has self-loops: False\n",
      "Is undirected: True\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%run -i '/home/jovyan/MIDS-GNN/pyg_dataset.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graphs_03.txt\n",
      "graphs_04.txt\n",
      "graphs_05.txt\n",
      "graphs_06.txt\n",
      "graphs_07.txt\n",
      "graphs_08.txt\n",
      "graphs_09.txt\n",
      "graphs_10.txt\n",
      "graphs_11.txt\n",
      "graphs_12.txt\n",
      "graphs_13.txt\n",
      "graphs_14.txt\n",
      "graphs_15.txt\n",
      "graphs_20.txt\n",
      "graphs_30.txt\n",
      "graphs_40.txt\n",
      "graphs_50.txt\n",
      "graphs_04.txt\n",
      "graphs_05.txt\n",
      "graphs_06.txt\n",
      "graphs_07.txt\n",
      "\n",
      "Dataset: MIDSdataset(992):\n",
      "====================\n",
      "Number of graphs: 992\n",
      "Number of features: 7\n",
      "\n",
      "Number of training graphs: 794\n",
      "Number of test graphs: 198\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.loader import DataLoader\n",
    "from my_graphs_dataset import GraphDataset\n",
    "\n",
    "# Set up dataset.\n",
    "selected_graph_sizes = {\n",
    "    #3: -1,\n",
    "    4: -1,\n",
    "    5: -1,\n",
    "    6: -1,\n",
    "    7: -1,\n",
    "    #8: -1,\n",
    "    #9:  10000,\n",
    "    #10: 1000,\n",
    "    #11: 1000,\n",
    "    #12: 1000,\n",
    "    #13: 1000,\n",
    "    #14: 1000,\n",
    "    #15: 1000,\n",
    "    #20: 2000,\n",
    "    #30: 10000,\n",
    "}\n",
    "dataset_config = {\n",
    "    \"name\": \"MIDSdataset\",\n",
    "    \"selected_graphs\": str(selected_graph_sizes),\n",
    "    \"split\": 0.8,\n",
    "    \"batch_size\": 6000,\n",
    "}\n",
    "\n",
    "# Load the dataset.\n",
    "root = \"/home/jovyan/MIDS-GNN/Dataset\"\n",
    "graphs_loader = GraphDataset(selection=selected_graph_sizes)\n",
    "dataset = MIDSdataset(root, graphs_loader)\n",
    "\n",
    "# General information\n",
    "print()\n",
    "print(f\"Dataset: {dataset}:\")\n",
    "print(\"====================\")\n",
    "print(f\"Number of graphs: {len(dataset)}\")\n",
    "print(f\"Number of features: {dataset.num_features}\")\n",
    "\n",
    "# Store information about the dataset.\n",
    "dataset_config.update({\"num_graphs\": len(dataset)})#, \"features\": dataset.feature_functions})\n",
    "\n",
    "# Shuffle and split the dataset.\n",
    "torch.manual_seed(seed := 42)\n",
    "dataset = dataset.shuffle()\n",
    "\n",
    "train_size = round(dataset_config[\"split\"] * len(dataset))\n",
    "train_dataset = dataset[:train_size]\n",
    "test_dataset = dataset[train_size:]\n",
    "\n",
    "print()\n",
    "print(f\"Number of training graphs: {len(train_dataset)}\")\n",
    "print(f\"Number of test graphs: {len(test_dataset)}\")\n",
    "\n",
    "# Batch and load data.\n",
    "# TODO: Batch size?\n",
    "batch_size = dataset_config[\"batch_size\"] if dataset_config[\"batch_size\"] > 0 else len(train_dataset)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "train_batch = None\n",
    "test_batch = None\n",
    "# If the whole dataset fits in memory, we can use the following lines to get a single large batch.\n",
    "#train_batch = next(iter(train_loader))\n",
    "#test_batch = next(iter(test_loader))\n",
    "\n",
    "#train_dataset = train_batch if train_batch is not None else train_loader\n",
    "#test_dataset = test_batch if test_batch is not None else test_loader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import GATConv\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = GATConv(train_dataset.num_features, hidden_channels, heads=4)\n",
    "        self.lin1 = torch.nn.Linear(train_dataset.num_features, 4 * hidden_channels)\n",
    "        self.conv2 = GATConv(4 * hidden_channels, hidden_channels, heads=4)\n",
    "        self.lin2 = torch.nn.Linear(4 * hidden_channels, 4 * hidden_channels)\n",
    "        self.conv3 = GATConv(4 * hidden_channels, hidden_channels, heads=4)\n",
    "        self.lin3 = torch.nn.Linear(4 * hidden_channels, 4 * hidden_channels)\n",
    "        self.conv5 = GATConv(4 * hidden_channels, hidden_channels, heads=4)\n",
    "        self.lin5 = torch.nn.Linear(4 * hidden_channels, 4 * hidden_channels)\n",
    "        self.conv4 = GATConv(4 * hidden_channels, 1, heads=6,\n",
    "                             concat=False)\n",
    "        self.lin4 = torch.nn.Linear(4 * hidden_channels, 1)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = F.elu(self.conv1(x, edge_index) + self.lin1(x))\n",
    "        x = F.elu(self.conv2(x, edge_index) + self.lin2(x))\n",
    "        x = F.elu(self.conv3(x, edge_index) + self.lin3(x))\n",
    "        #x = F.elu(self.conv5(x, edge_index) + self.lin5(x))\n",
    "        x = self.conv4(x, edge_index) + self.lin4(x)\n",
    "        return x.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import GATConv, GINConv, GCNConv, GATv2Conv, ARMAConv\n",
    "from torch_geometric.nn import global_mean_pool\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = GATv2Conv(train_dataset.num_features, hidden_channels)\n",
    "        self.conv2 = GATv2Conv(hidden_channels, hidden_channels)\n",
    "        self.conv3 = ARMAConv(hidden_channels, hidden_channels)\n",
    "        self.conv4 = GATv2Conv(hidden_channels, hidden_channels)\n",
    "        self.lin1 = torch.nn.Linear(hidden_channels, hidden_channels)\n",
    "        self.lin2 = torch.nn.Linear(hidden_channels, hidden_channels)\n",
    "        self.lin3 = torch.nn.Linear(hidden_channels, hidden_channels)\n",
    "        self.lin = torch.nn.Linear(hidden_channels, 1)\n",
    "        self.conv_last = GCNConv(hidden_channels, 1)\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = self.lin1(x)\n",
    "        x = x.relu()\n",
    "        x = self.conv3(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = self.lin2(x)\n",
    "        x = x.relu()\n",
    "        x = self.conv4(x, edge_index)\n",
    "\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.lin(x)\n",
    "        return x.squeeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training & Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import Data\n",
    "from torch.nn.modules.loss import _Loss\n",
    "import torch.nn.functional as F\n",
    "from torch import Tensor\n",
    "\n",
    "from torch_sparse import SparseTensor\n",
    "\n",
    "class CustomLossFunction(torch.nn.BCEWithLogitsLoss):\n",
    "    \"\"\"Custom loss function based on BCEWithLogitsLoss\"\"\"\n",
    "    def forward(self, input: Tensor, target: Tensor) -> Tensor:\n",
    "        tens = torch.split(target, input.size(dim=0))[0]\n",
    "        loss = F.binary_cross_entropy_with_logits(input, tens, self.weight, pos_weight=self.pos_weight, reduction=self.reduction)\n",
    "      \n",
    "        for tens in torch.split(target, input.size(dim=0)):\n",
    "            new = F.binary_cross_entropy_with_logits(input, tens, self.weight, pos_weight=self.pos_weight, reduction=self.reduction)\n",
    "            if new.item() < loss.item():\n",
    "                loss = new\n",
    "        return loss\n",
    "\n",
    "\n",
    "class UnsupervisedLossFunction(torch.nn.BCEWithLogitsLoss):\n",
    "\n",
    "    def forward(self, A, candidate, target_value) -> Tensor:\n",
    "        n = len(candidate)\n",
    "        loss = torch.tensor(0.0, requires_grad=True)\n",
    "    \n",
    "        # loss for MIDS size\n",
    "        loss = torch.add(loss, abs(sum(candidate) - target_value))\n",
    "    \n",
    "        # loss for domination\n",
    "        for el in ((A + np.eye(n)) @ candidate):\n",
    "            if el < 1: \n",
    "                loss = torch.add(loss, 1/n) # devide by factor (size)\n",
    "    \n",
    "        # loss for independance\n",
    "        for i in range(n):\n",
    "            for j in range(i+1, n):\n",
    "                if candidate[i] and candidate[j] and A[i,j]:\n",
    "                    loss = torch.add(loss, 1/n) # devide by factsor (size)\n",
    "        return loss\n",
    "\n",
    "def check_accuracy_unsupervised(data, out, criterion):\n",
    "    pred = torch.where(out > 0, 1.0, 0.0)\n",
    "    num_nodes = data.num_nodes \n",
    "    adjacency = SparseTensor(row=data.edge_index[0], col=data.edge_index[1], sparse_sizes=(num_nodes, num_nodes))\n",
    "    adjacency_matrix = adjacency.to_dense()\n",
    "    return criterion(adjacency_matrix.cpu().numpy(),\n",
    "                                              out.detach().cpu().numpy(),\n",
    "                                              sum(torch.split(data.y, data.num_nodes)[0].cpu().numpy()))\n",
    "\n",
    "\n",
    "'''\n",
    "def UnsupervisedLossFunction(A, candidate, target_value):\n",
    "    n = len(candidate)\n",
    "    loss = 0\n",
    "\n",
    "    # loss for MIDS size\n",
    "    loss += abs(sum(candidate) - target_value) \n",
    "\n",
    "    # loss for domination\n",
    "    for el in ((A + np.eye(n)) @ candidate):\n",
    "        if el < 1: \n",
    "            loss += 1/n # devide by factor (size)\n",
    "\n",
    "    # loss for independance\n",
    "    for i in range(n):\n",
    "        for j in range(i+1, n):\n",
    "            if candidate[i] and candidate[j] and A[i,j]:\n",
    "                loss += 1/n # devide by factsor (size)\n",
    "                \n",
    "    return torch.tensor(loss, requires_grad=True)\n",
    "'''\n",
    "\n",
    "def check_MIDS(A, candidate, target_value):\n",
    "    n = len(candidate)\n",
    "\n",
    "    # Candidate set is larger than MIDS size\n",
    "    if sum(candidate) > target_value:\n",
    "        return False\n",
    "        \n",
    "    # Candidate set is not dominating\n",
    "    if not all((A + np.eye(n)) @ candidate >= 1):\n",
    "        return False\n",
    "\n",
    "    # Candidate set is not independent\n",
    "    for i in range(n):\n",
    "        for j in range(i+1, n):\n",
    "            if candidate[i] and candidate[j] and A[i,j]:\n",
    "                return False\n",
    "\n",
    "    #This case should never happen\n",
    "    if sum(candidate) < target_value:\n",
    "        print(f\"Somehow we found an even smaller MIDS: {sum(candidate)}, {target_value}\")\n",
    "        pass\n",
    "\n",
    "    return True\n",
    "\n",
    "def generate_model(hidden_channels):\n",
    "    \"\"\"Generate a Neural Network model based on the architecture and hyperparameters.\"\"\"\n",
    "    model = Net(hidden_channels=hidden_channels).to(device)\n",
    "    return model\n",
    "\n",
    "def generate_optimizer(model, optimizer, lr):\n",
    "    \"\"\"Generate optimizer object based on the model and hyperparameters.\"\"\"\n",
    "    if optimizer == \"adam\":\n",
    "        return torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    else:\n",
    "        raise ValueError(\"Only Adam optimizer is currently supported.\")\n",
    "\n",
    "\n",
    "def training_pass(model, batch, optimizer, criterion):\n",
    "    \"\"\"Perofrm a single training pass over the batch.\"\"\"\n",
    "    data = batch.to(device)\n",
    "    optimizer.zero_grad()  # Clear gradients.\n",
    "    out = model(data.x.type(torch.FloatTensor).to(device), data.edge_index, data.batch)  # Perform a single forward pass.\n",
    "    loss = criterion(out, data.y)  # Compute the loss.\n",
    "    #loss = check_accuracy_unsupervised(batch, out, criterion)\n",
    "    loss.backward()  # Derive gradients.\n",
    "    optimizer.step()  # Update parameters based on gradients.\n",
    "\n",
    "def check_accuracy(data, out):\n",
    "    pred = torch.where(out > 0, 1.0, 0.0)\n",
    "    num_nodes = data.num_nodes \n",
    "    adjacency = SparseTensor(row=data.edge_index[0], col=data.edge_index[1], sparse_sizes=(num_nodes, num_nodes))\n",
    "    adjacency_matrix = adjacency.to_dense()\n",
    "    return int(check_MIDS(adjacency_matrix.cpu().numpy(),\n",
    "                                              pred.cpu().numpy(),\n",
    "                                              sum(torch.split(data.y, data.num_nodes)[0].cpu().numpy())))\n",
    "\n",
    "\n",
    "def testing_pass(model, batch, criterion):\n",
    "    \"\"\"Perform a single testing pass over the batch.\"\"\"\n",
    "    with torch.no_grad():\n",
    "        data = batch.to(device)\n",
    "        out = model(data.x.type(torch.FloatTensor).to(device), data.edge_index, data.batch)\n",
    "        loss = criterion(out, data.y).item()  # Compute the loss.\n",
    "        #loss = check_accuracy_unsupervised(data, out, criterion).item()\n",
    "        acc = check_accuracy(data,out)\n",
    "    return loss, acc\n",
    "\n",
    "\n",
    "def do_train(model, data, optimizer, criterion):\n",
    "    \"\"\"Train the model on individual batches or the entire dataset.\"\"\"\n",
    "    model.train()\n",
    "\n",
    "    for batch in data:  # Iterate in batches over the training dataset.\n",
    "        training_pass(model, batch, optimizer, criterion)\n",
    "\n",
    "\n",
    "def do_test(model, data, criterion):\n",
    "    \"\"\"Test the model on individual batches or the entire dataset.\"\"\"\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    losses = 0\n",
    "    for batch in data:\n",
    "        loss, acc = testing_pass(model, batch, criterion)\n",
    "        correct += acc \n",
    "        losses += loss\n",
    "    return losses/len(data), correct/len(data)*100\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "def train(model, optimizer, criterion, num_epochs=200, is_sweep=False):\n",
    "    # GLOBALS: device, dataset, train_dataset, train_dataset\n",
    "\n",
    "    # Prepare for training.\n",
    "    train_losses = np.zeros(num_epochs)\n",
    "    test_losses = np.zeros(num_epochs)\n",
    "\n",
    "    # Start the training loop with timer.\n",
    "    training_timer = codetiming.Timer(logger=None)\n",
    "    epoch_timer = codetiming.Timer(logger=None)\n",
    "    training_timer.start()\n",
    "    epoch_timer.start()\n",
    "    train_loss = 0\n",
    "    train_acc = 0\n",
    "    test_loss = 0\n",
    "    test_acc = 0\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        # Perform one pass over the training set and then test on both sets.\n",
    "        do_train(model, train_loader, optimizer, criterion)\n",
    "        if epoch % 100 == 1 or epoch == 10000:\n",
    "            train_loss, train_acc = do_test(model, train_dataset, criterion)\n",
    "            test_loss, test_acc = do_test(model, test_dataset, criterion)\n",
    "\n",
    "        # Store the losses.\n",
    "        train_losses[epoch - 1] = train_loss\n",
    "        test_losses[epoch - 1] = test_loss\n",
    "\n",
    "        dur = epoch_timer.stop()\n",
    "        print(\n",
    "            f\"Epoch: {epoch:03d}, \"\n",
    "            f\"Train Loss: {train_loss:.4f}, \"\n",
    "            f\"Test Loss: {test_loss:.4f}, \"\n",
    "            f\"Train Accuracy: {train_acc:.4f}, \"\n",
    "            f\"Test Accuracy: {test_acc:.4f}, \"\n",
    "            f\"Avg. duration: {dur:.4f} s\"\n",
    "        )\n",
    "        wandb.log({\"train_loss\": train_loss, \"test_loss\": test_loss,\n",
    "                    \"train_acc\": train_acc, \"test_acc\": test_acc,\n",
    "                    \"train_loss_scaled\": train_loss/0.8, \"test_loss_scaled\": test_loss/0.2,\n",
    "                    \"epoch_time\": dur})\n",
    "        epoch_timer.start()\n",
    "    epoch_timer.stop()\n",
    "    duration = training_timer.stop()\n",
    "\n",
    "    results = {\"train_losses\": train_losses, \"test_losses\": test_losses, \"duration\": duration}\n",
    "    return results, model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from utils import create_graph_wandb, extract_graphs_from_batch, graphs_to_tuple\n",
    "\n",
    "\n",
    "def plot_training_curves(num_epochs, train_losses, test_losses, criterion):\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Scatter(x=list(range(1, num_epochs + 1)), y=train_losses, mode=\"lines\", name=\"Train Loss\"))\n",
    "    fig.add_trace(go.Scatter(x=list(range(1, num_epochs + 1)), y=test_losses, mode=\"lines\", name=\"Test Loss\"))\n",
    "    fig.update_layout(title=\"Training and Test Loss\", xaxis_title=\"Epoch\", yaxis_title=criterion)\n",
    "    fig.show()\n",
    "\n",
    "\n",
    "def evaluate(model, plot_graphs=False, is_sweep=False):\n",
    "    # GLOBALS: dataset_config, train_loader, test_loader\n",
    "\n",
    "    df = pd.DataFrame()\n",
    "\n",
    "    # Evaluate the model on the test set.\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:  # Iterate in batches over the training/test dataset.\n",
    "            # Make predictions.\n",
    "            data = data.to(device)\n",
    "            out = model(data.x.type(torch.FloatTensor).to(device), data.edge_index)\n",
    "            predictions = out.cpu().numpy().squeeze()\n",
    "            ground_truth = data.y.cpu().numpy()\n",
    "\n",
    "            # Extract graphs and create visualizations.\n",
    "            nx_graphs = extract_graphs_from_batch(data)\n",
    "            graphs, node_nums, edge_nums = zip(*graphs_to_tuple(nx_graphs))\n",
    "            # FIXME: This is the only way to parallelize in Jupyter but runs out of memory.\n",
    "            # with concurrent.futures.ProcessPoolExecutor(4) as executor:\n",
    "            #     graph_visuals = executor.map(create_graph_wandb, nx_graphs, chunksize=10)\n",
    "            if plot_graphs:\n",
    "                graph_visuals = [create_graph_wandb(g) for g in nx_graphs]\n",
    "            else:\n",
    "                graph_visuals = [\"N/A\"] * len(nx_graphs)\n",
    "\n",
    "            # Store to pandas DataFrame.\n",
    "            df = pd.concat(\n",
    "                [\n",
    "                    df,\n",
    "                    pd.DataFrame(\n",
    "                        {\n",
    "                            \"GraphVis\": graph_visuals,\n",
    "                            \"Graph\": graphs,\n",
    "                            \"Nodes\": node_nums,\n",
    "                            \"Edges\": edge_nums,\n",
    "                            \"True\": ground_truth,\n",
    "                            \"Predicted\": predictions,\n",
    "                        }\n",
    "                    ),\n",
    "                ]\n",
    "            )\n",
    "\n",
    "    # Calculate the statistics.\n",
    "    df[\"Error\"] = df[\"True\"] - df[\"Predicted\"]\n",
    "    df[\"Error %\"] = 100 * df[\"Error\"] / df[\"True\"]\n",
    "    df[\"abs(Error)\"] = np.abs(df[\"Error\"])\n",
    "    err_mean = np.mean(df[\"abs(Error)\"])\n",
    "    err_stddev = np.std(df[\"abs(Error)\"])\n",
    "\n",
    "    # Create a W&B table.\n",
    "    table = wandb.Table(dataframe=df)\n",
    "\n",
    "    # Print and plot.\n",
    "    # df = df.sort_values(by=\"abs(Error)\")\n",
    "    fig_abs_err = px.histogram(df, x=\"Error\")\n",
    "    fig_rel_err = px.histogram(df, x=\"Error %\")\n",
    "\n",
    "    if not is_sweep:\n",
    "        print(f\"Mean error: {err_mean:.4f}\\n\" f\"Std. dev.: {err_stddev:.4f}\\n\")\n",
    "        fig_abs_err.show()\n",
    "        fig_rel_err.show()\n",
    "        df = df.sort_values(by=\"Nodes\")\n",
    "        print(df)\n",
    "\n",
    "    results = {\n",
    "        \"mean_err\": err_mean,\n",
    "        \"stddev_err\": err_stddev,\n",
    "        \"fig_abs_err\": fig_abs_err,\n",
    "        \"fig_rel_err\": fig_rel_err,\n",
    "        \"table\": table,\n",
    "    }\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Main definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "def main(config=None, skip_evaluation=False):\n",
    "    # GLOBALS: device, dataset, train_dataset, test_dataset\n",
    "\n",
    "    is_sweep = config is None\n",
    "\n",
    "    # Set up the run\n",
    "    run = wandb.init(project=\"GNN_MIDS\", config=config)\n",
    "    config = wandb.config\n",
    "    if is_sweep:\n",
    "        print(f\"Running sweep with config: {config}...\")\n",
    "\n",
    "    # Set up the model, optimizer, and criterion.\n",
    "    model = generate_model(config[\"hidden_channels\"])\n",
    "    optimizer = generate_optimizer(model, config[\"optimizer\"], config[\"learning_rate\"])\n",
    "    criterion = CustomLossFunction()\n",
    "    criterion = torch.nn.BCEWithLogitsLoss()\n",
    "    #criterion = UnsupervisedLossFunction()\n",
    "\n",
    "    # Run training.\n",
    "    print(\"Training started\")\n",
    "    train_results, model = train(model, optimizer, criterion, config[\"epochs\"], is_sweep=is_sweep)\n",
    "    run.summary[\"best_train_loss\"] = min(train_results[\"train_losses\"])\n",
    "    run.summary[\"best_test_loss\"] = min(train_results[\"test_losses\"])\n",
    "    run.summary[\"duration\"] = train_results[\"duration\"]\n",
    "    if not is_sweep:\n",
    "        plot_training_curves(\n",
    "            config[\"epochs\"], train_results[\"train_losses\"], train_results[\"test_losses\"], type(criterion).__name__\n",
    "        )\n",
    "\n",
    "    return run, model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Standard run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:60hrab4r) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch_time</td><td>▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>test_acc</td><td>▁▁▅▅▆▆▇▇▇▇▇▇▇▇▇▆▇▇▇▇███▇▇▇▆▆▆▆▆▆▇▇▇▇▇▆▆▆</td></tr><tr><td>test_loss</td><td>████▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▂▃▃▂▂▃▃▃▃▃▄▄▄▄</td></tr><tr><td>test_loss_scaled</td><td>██▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▂▂▂▂▃▂▂▃▃▃▃▃▃▃▃▃▃▃▄▄</td></tr><tr><td>train_acc</td><td>▁▁▁▅▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇██▇██▇███████████████</td></tr><tr><td>train_loss</td><td>██▄▄▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_scaled</td><td>█▄▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▂▂▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_test_loss</td><td>0.2922</td></tr><tr><td>best_train_loss</td><td>0.16111</td></tr><tr><td>duration</td><td>186.89037</td></tr><tr><td>epoch_time</td><td>0.02781</td></tr><tr><td>test_acc</td><td>55.55556</td></tr><tr><td>test_loss</td><td>0.43903</td></tr><tr><td>test_loss_scaled</td><td>2.19514</td></tr><tr><td>train_acc</td><td>69.14358</td></tr><tr><td>train_loss</td><td>0.16111</td></tr><tr><td>train_loss_scaled</td><td>0.20139</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">divine-universe-136</strong> at: <a href='https://wandb.ai/markokoz/GNN_MIDS/runs/60hrab4r' target=\"_blank\">https://wandb.ai/markokoz/GNN_MIDS/runs/60hrab4r</a><br/> View project at: <a href='https://wandb.ai/markokoz/GNN_MIDS' target=\"_blank\">https://wandb.ai/markokoz/GNN_MIDS</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20241028_145124-60hrab4r/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:60hrab4r). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/jovyan/MIDS-GNN/wandb/run-20241028_145451-sjpblu9i</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/markokoz/GNN_MIDS/runs/sjpblu9i' target=\"_blank\">lilac-meadow-137</a></strong> to <a href='https://wandb.ai/markokoz/GNN_MIDS' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/markokoz/GNN_MIDS' target=\"_blank\">https://wandb.ai/markokoz/GNN_MIDS</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/markokoz/GNN_MIDS/runs/sjpblu9i' target=\"_blank\">https://wandb.ai/markokoz/GNN_MIDS/runs/sjpblu9i</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training started\n",
      "Epoch: 001, Train Loss: 0.6857, Test Loss: 0.6857, Train Accuracy: 0.0000, Test Accuracy: 0.0000, Avg. duration: 2.7301 s\n",
      "Epoch: 002, Train Loss: 0.6857, Test Loss: 0.6857, Train Accuracy: 0.0000, Test Accuracy: 0.0000, Avg. duration: 0.0284 s\n",
      "Epoch: 003, Train Loss: 0.6857, Test Loss: 0.6857, Train Accuracy: 0.0000, Test Accuracy: 0.0000, Avg. duration: 0.0276 s\n",
      "Epoch: 004, Train Loss: 0.6857, Test Loss: 0.6857, Train Accuracy: 0.0000, Test Accuracy: 0.0000, Avg. duration: 0.0274 s\n",
      "Epoch: 005, Train Loss: 0.6857, Test Loss: 0.6857, Train Accuracy: 0.0000, Test Accuracy: 0.0000, Avg. duration: 0.0273 s\n",
      "Epoch: 006, Train Loss: 0.6857, Test Loss: 0.6857, Train Accuracy: 0.0000, Test Accuracy: 0.0000, Avg. duration: 0.0268 s\n",
      "Epoch: 007, Train Loss: 0.6857, Test Loss: 0.6857, Train Accuracy: 0.0000, Test Accuracy: 0.0000, Avg. duration: 0.0275 s\n",
      "Epoch: 008, Train Loss: 0.6857, Test Loss: 0.6857, Train Accuracy: 0.0000, Test Accuracy: 0.0000, Avg. duration: 0.0272 s\n",
      "Epoch: 009, Train Loss: 0.6857, Test Loss: 0.6857, Train Accuracy: 0.0000, Test Accuracy: 0.0000, Avg. duration: 0.0278 s\n",
      "Epoch: 010, Train Loss: 0.6857, Test Loss: 0.6857, Train Accuracy: 0.0000, Test Accuracy: 0.0000, Avg. duration: 0.0278 s\n",
      "Epoch: 011, Train Loss: 0.6857, Test Loss: 0.6857, Train Accuracy: 0.0000, Test Accuracy: 0.0000, Avg. duration: 0.0274 s\n",
      "Epoch: 012, Train Loss: 0.6857, Test Loss: 0.6857, Train Accuracy: 0.0000, Test Accuracy: 0.0000, Avg. duration: 0.0271 s\n",
      "Epoch: 013, Train Loss: 0.6857, Test Loss: 0.6857, Train Accuracy: 0.0000, Test Accuracy: 0.0000, Avg. duration: 0.0268 s\n",
      "Epoch: 014, Train Loss: 0.6857, Test Loss: 0.6857, Train Accuracy: 0.0000, Test Accuracy: 0.0000, Avg. duration: 0.0270 s\n",
      "Epoch: 015, Train Loss: 0.6857, Test Loss: 0.6857, Train Accuracy: 0.0000, Test Accuracy: 0.0000, Avg. duration: 0.0274 s\n",
      "Epoch: 016, Train Loss: 0.6857, Test Loss: 0.6857, Train Accuracy: 0.0000, Test Accuracy: 0.0000, Avg. duration: 0.0272 s\n",
      "Epoch: 017, Train Loss: 0.6857, Test Loss: 0.6857, Train Accuracy: 0.0000, Test Accuracy: 0.0000, Avg. duration: 0.0277 s\n",
      "Epoch: 018, Train Loss: 0.6857, Test Loss: 0.6857, Train Accuracy: 0.0000, Test Accuracy: 0.0000, Avg. duration: 0.0272 s\n",
      "Epoch: 019, Train Loss: 0.6857, Test Loss: 0.6857, Train Accuracy: 0.0000, Test Accuracy: 0.0000, Avg. duration: 0.0270 s\n",
      "Epoch: 020, Train Loss: 0.6857, Test Loss: 0.6857, Train Accuracy: 0.0000, Test Accuracy: 0.0000, Avg. duration: 0.0273 s\n",
      "Epoch: 021, Train Loss: 0.6857, Test Loss: 0.6857, Train Accuracy: 0.0000, Test Accuracy: 0.0000, Avg. duration: 0.0271 s\n",
      "Epoch: 022, Train Loss: 0.6857, Test Loss: 0.6857, Train Accuracy: 0.0000, Test Accuracy: 0.0000, Avg. duration: 0.0275 s\n",
      "Epoch: 023, Train Loss: 0.6857, Test Loss: 0.6857, Train Accuracy: 0.0000, Test Accuracy: 0.0000, Avg. duration: 0.0275 s\n",
      "Epoch: 024, Train Loss: 0.6857, Test Loss: 0.6857, Train Accuracy: 0.0000, Test Accuracy: 0.0000, Avg. duration: 0.0270 s\n",
      "Epoch: 025, Train Loss: 0.6857, Test Loss: 0.6857, Train Accuracy: 0.0000, Test Accuracy: 0.0000, Avg. duration: 0.0274 s\n",
      "Epoch: 026, Train Loss: 0.6857, Test Loss: 0.6857, Train Accuracy: 0.0000, Test Accuracy: 0.0000, Avg. duration: 0.0271 s\n",
      "Epoch: 027, Train Loss: 0.6857, Test Loss: 0.6857, Train Accuracy: 0.0000, Test Accuracy: 0.0000, Avg. duration: 0.0274 s\n",
      "Epoch: 028, Train Loss: 0.6857, Test Loss: 0.6857, Train Accuracy: 0.0000, Test Accuracy: 0.0000, Avg. duration: 0.0278 s\n",
      "Epoch: 029, Train Loss: 0.6857, Test Loss: 0.6857, Train Accuracy: 0.0000, Test Accuracy: 0.0000, Avg. duration: 0.0272 s\n",
      "Epoch: 030, Train Loss: 0.6857, Test Loss: 0.6857, Train Accuracy: 0.0000, Test Accuracy: 0.0000, Avg. duration: 0.0272 s\n",
      "Epoch: 031, Train Loss: 0.6857, Test Loss: 0.6857, Train Accuracy: 0.0000, Test Accuracy: 0.0000, Avg. duration: 0.0270 s\n",
      "Epoch: 032, Train Loss: 0.6857, Test Loss: 0.6857, Train Accuracy: 0.0000, Test Accuracy: 0.0000, Avg. duration: 0.0276 s\n",
      "Epoch: 033, Train Loss: 0.6857, Test Loss: 0.6857, Train Accuracy: 0.0000, Test Accuracy: 0.0000, Avg. duration: 0.0278 s\n",
      "Epoch: 034, Train Loss: 0.6857, Test Loss: 0.6857, Train Accuracy: 0.0000, Test Accuracy: 0.0000, Avg. duration: 0.3176 s\n",
      "Epoch: 035, Train Loss: 0.6857, Test Loss: 0.6857, Train Accuracy: 0.0000, Test Accuracy: 0.0000, Avg. duration: 0.0281 s\n",
      "Epoch: 036, Train Loss: 0.6857, Test Loss: 0.6857, Train Accuracy: 0.0000, Test Accuracy: 0.0000, Avg. duration: 0.0278 s\n",
      "Epoch: 037, Train Loss: 0.6857, Test Loss: 0.6857, Train Accuracy: 0.0000, Test Accuracy: 0.0000, Avg. duration: 0.0277 s\n",
      "Epoch: 038, Train Loss: 0.6857, Test Loss: 0.6857, Train Accuracy: 0.0000, Test Accuracy: 0.0000, Avg. duration: 0.0269 s\n",
      "Epoch: 039, Train Loss: 0.6857, Test Loss: 0.6857, Train Accuracy: 0.0000, Test Accuracy: 0.0000, Avg. duration: 0.0274 s\n",
      "Epoch: 040, Train Loss: 0.6857, Test Loss: 0.6857, Train Accuracy: 0.0000, Test Accuracy: 0.0000, Avg. duration: 0.0279 s\n",
      "Epoch: 041, Train Loss: 0.6857, Test Loss: 0.6857, Train Accuracy: 0.0000, Test Accuracy: 0.0000, Avg. duration: 0.0270 s\n",
      "Epoch: 042, Train Loss: 0.6857, Test Loss: 0.6857, Train Accuracy: 0.0000, Test Accuracy: 0.0000, Avg. duration: 0.0275 s\n",
      "Epoch: 043, Train Loss: 0.6857, Test Loss: 0.6857, Train Accuracy: 0.0000, Test Accuracy: 0.0000, Avg. duration: 0.0267 s\n",
      "Epoch: 044, Train Loss: 0.6857, Test Loss: 0.6857, Train Accuracy: 0.0000, Test Accuracy: 0.0000, Avg. duration: 0.0271 s\n",
      "Epoch: 045, Train Loss: 0.6857, Test Loss: 0.6857, Train Accuracy: 0.0000, Test Accuracy: 0.0000, Avg. duration: 0.0273 s\n",
      "Epoch: 046, Train Loss: 0.6857, Test Loss: 0.6857, Train Accuracy: 0.0000, Test Accuracy: 0.0000, Avg. duration: 0.0275 s\n",
      "Epoch: 047, Train Loss: 0.6857, Test Loss: 0.6857, Train Accuracy: 0.0000, Test Accuracy: 0.0000, Avg. duration: 0.0267 s\n",
      "Epoch: 048, Train Loss: 0.6857, Test Loss: 0.6857, Train Accuracy: 0.0000, Test Accuracy: 0.0000, Avg. duration: 0.0271 s\n",
      "Epoch: 049, Train Loss: 0.6857, Test Loss: 0.6857, Train Accuracy: 0.0000, Test Accuracy: 0.0000, Avg. duration: 0.0271 s\n",
      "Epoch: 050, Train Loss: 0.6857, Test Loss: 0.6857, Train Accuracy: 0.0000, Test Accuracy: 0.0000, Avg. duration: 0.0282 s\n",
      "Epoch: 051, Train Loss: 0.6857, Test Loss: 0.6857, Train Accuracy: 0.0000, Test Accuracy: 0.0000, Avg. duration: 0.0275 s\n",
      "Epoch: 052, Train Loss: 0.6857, Test Loss: 0.6857, Train Accuracy: 0.0000, Test Accuracy: 0.0000, Avg. duration: 0.0279 s\n",
      "Epoch: 053, Train Loss: 0.6857, Test Loss: 0.6857, Train Accuracy: 0.0000, Test Accuracy: 0.0000, Avg. duration: 0.0270 s\n",
      "Epoch: 054, Train Loss: 0.6857, Test Loss: 0.6857, Train Accuracy: 0.0000, Test Accuracy: 0.0000, Avg. duration: 0.0273 s\n",
      "Epoch: 055, Train Loss: 0.6857, Test Loss: 0.6857, Train Accuracy: 0.0000, Test Accuracy: 0.0000, Avg. duration: 0.0272 s\n",
      "Epoch: 056, Train Loss: 0.6857, Test Loss: 0.6857, Train Accuracy: 0.0000, Test Accuracy: 0.0000, Avg. duration: 0.0273 s\n",
      "Epoch: 057, Train Loss: 0.6857, Test Loss: 0.6857, Train Accuracy: 0.0000, Test Accuracy: 0.0000, Avg. duration: 0.0274 s\n",
      "Epoch: 058, Train Loss: 0.6857, Test Loss: 0.6857, Train Accuracy: 0.0000, Test Accuracy: 0.0000, Avg. duration: 0.0281 s\n",
      "Epoch: 059, Train Loss: 0.6857, Test Loss: 0.6857, Train Accuracy: 0.0000, Test Accuracy: 0.0000, Avg. duration: 0.0275 s\n",
      "Epoch: 060, Train Loss: 0.6857, Test Loss: 0.6857, Train Accuracy: 0.0000, Test Accuracy: 0.0000, Avg. duration: 0.0278 s\n",
      "Epoch: 061, Train Loss: 0.6857, Test Loss: 0.6857, Train Accuracy: 0.0000, Test Accuracy: 0.0000, Avg. duration: 0.0278 s\n",
      "Epoch: 062, Train Loss: 0.6857, Test Loss: 0.6857, Train Accuracy: 0.0000, Test Accuracy: 0.0000, Avg. duration: 0.0277 s\n",
      "Epoch: 063, Train Loss: 0.6857, Test Loss: 0.6857, Train Accuracy: 0.0000, Test Accuracy: 0.0000, Avg. duration: 0.0273 s\n",
      "Epoch: 064, Train Loss: 0.6857, Test Loss: 0.6857, Train Accuracy: 0.0000, Test Accuracy: 0.0000, Avg. duration: 0.0276 s\n",
      "Epoch: 065, Train Loss: 0.6857, Test Loss: 0.6857, Train Accuracy: 0.0000, Test Accuracy: 0.0000, Avg. duration: 0.0273 s\n",
      "Epoch: 066, Train Loss: 0.6857, Test Loss: 0.6857, Train Accuracy: 0.0000, Test Accuracy: 0.0000, Avg. duration: 0.0278 s\n",
      "Epoch: 067, Train Loss: 0.6857, Test Loss: 0.6857, Train Accuracy: 0.0000, Test Accuracy: 0.0000, Avg. duration: 0.0274 s\n",
      "Epoch: 068, Train Loss: 0.6857, Test Loss: 0.6857, Train Accuracy: 0.0000, Test Accuracy: 0.0000, Avg. duration: 0.0273 s\n",
      "Epoch: 069, Train Loss: 0.6857, Test Loss: 0.6857, Train Accuracy: 0.0000, Test Accuracy: 0.0000, Avg. duration: 0.0273 s\n",
      "Epoch: 070, Train Loss: 0.6857, Test Loss: 0.6857, Train Accuracy: 0.0000, Test Accuracy: 0.0000, Avg. duration: 0.0278 s\n",
      "Epoch: 071, Train Loss: 0.6857, Test Loss: 0.6857, Train Accuracy: 0.0000, Test Accuracy: 0.0000, Avg. duration: 0.0274 s\n",
      "Epoch: 072, Train Loss: 0.6857, Test Loss: 0.6857, Train Accuracy: 0.0000, Test Accuracy: 0.0000, Avg. duration: 0.0273 s\n",
      "Epoch: 073, Train Loss: 0.6857, Test Loss: 0.6857, Train Accuracy: 0.0000, Test Accuracy: 0.0000, Avg. duration: 0.0278 s\n",
      "Epoch: 074, Train Loss: 0.6857, Test Loss: 0.6857, Train Accuracy: 0.0000, Test Accuracy: 0.0000, Avg. duration: 0.0276 s\n",
      "Epoch: 075, Train Loss: 0.6857, Test Loss: 0.6857, Train Accuracy: 0.0000, Test Accuracy: 0.0000, Avg. duration: 0.0279 s\n",
      "Epoch: 076, Train Loss: 0.6857, Test Loss: 0.6857, Train Accuracy: 0.0000, Test Accuracy: 0.0000, Avg. duration: 0.0278 s\n",
      "Epoch: 077, Train Loss: 0.6857, Test Loss: 0.6857, Train Accuracy: 0.0000, Test Accuracy: 0.0000, Avg. duration: 0.0276 s\n",
      "Epoch: 078, Train Loss: 0.6857, Test Loss: 0.6857, Train Accuracy: 0.0000, Test Accuracy: 0.0000, Avg. duration: 0.0275 s\n",
      "Epoch: 079, Train Loss: 0.6857, Test Loss: 0.6857, Train Accuracy: 0.0000, Test Accuracy: 0.0000, Avg. duration: 0.0275 s\n",
      "Epoch: 080, Train Loss: 0.6857, Test Loss: 0.6857, Train Accuracy: 0.0000, Test Accuracy: 0.0000, Avg. duration: 0.0274 s\n",
      "Epoch: 081, Train Loss: 0.6857, Test Loss: 0.6857, Train Accuracy: 0.0000, Test Accuracy: 0.0000, Avg. duration: 0.0276 s\n",
      "Epoch: 082, Train Loss: 0.6857, Test Loss: 0.6857, Train Accuracy: 0.0000, Test Accuracy: 0.0000, Avg. duration: 0.0286 s\n",
      "Epoch: 083, Train Loss: 0.6857, Test Loss: 0.6857, Train Accuracy: 0.0000, Test Accuracy: 0.0000, Avg. duration: 0.0274 s\n",
      "Epoch: 084, Train Loss: 0.6857, Test Loss: 0.6857, Train Accuracy: 0.0000, Test Accuracy: 0.0000, Avg. duration: 0.0279 s\n",
      "Epoch: 085, Train Loss: 0.6857, Test Loss: 0.6857, Train Accuracy: 0.0000, Test Accuracy: 0.0000, Avg. duration: 0.0275 s\n",
      "Epoch: 086, Train Loss: 0.6857, Test Loss: 0.6857, Train Accuracy: 0.0000, Test Accuracy: 0.0000, Avg. duration: 0.0277 s\n",
      "Epoch: 087, Train Loss: 0.6857, Test Loss: 0.6857, Train Accuracy: 0.0000, Test Accuracy: 0.0000, Avg. duration: 0.0275 s\n",
      "Epoch: 088, Train Loss: 0.6857, Test Loss: 0.6857, Train Accuracy: 0.0000, Test Accuracy: 0.0000, Avg. duration: 0.0283 s\n",
      "Epoch: 089, Train Loss: 0.6857, Test Loss: 0.6857, Train Accuracy: 0.0000, Test Accuracy: 0.0000, Avg. duration: 0.0276 s\n",
      "Epoch: 090, Train Loss: 0.6857, Test Loss: 0.6857, Train Accuracy: 0.0000, Test Accuracy: 0.0000, Avg. duration: 0.0279 s\n",
      "Epoch: 091, Train Loss: 0.6857, Test Loss: 0.6857, Train Accuracy: 0.0000, Test Accuracy: 0.0000, Avg. duration: 0.0278 s\n",
      "Epoch: 092, Train Loss: 0.6857, Test Loss: 0.6857, Train Accuracy: 0.0000, Test Accuracy: 0.0000, Avg. duration: 0.0278 s\n",
      "Epoch: 093, Train Loss: 0.6857, Test Loss: 0.6857, Train Accuracy: 0.0000, Test Accuracy: 0.0000, Avg. duration: 0.0279 s\n",
      "Epoch: 094, Train Loss: 0.6857, Test Loss: 0.6857, Train Accuracy: 0.0000, Test Accuracy: 0.0000, Avg. duration: 0.0277 s\n",
      "Epoch: 095, Train Loss: 0.6857, Test Loss: 0.6857, Train Accuracy: 0.0000, Test Accuracy: 0.0000, Avg. duration: 0.0272 s\n",
      "Epoch: 096, Train Loss: 0.6857, Test Loss: 0.6857, Train Accuracy: 0.0000, Test Accuracy: 0.0000, Avg. duration: 0.0271 s\n",
      "Epoch: 097, Train Loss: 0.6857, Test Loss: 0.6857, Train Accuracy: 0.0000, Test Accuracy: 0.0000, Avg. duration: 0.0277 s\n",
      "Epoch: 098, Train Loss: 0.6857, Test Loss: 0.6857, Train Accuracy: 0.0000, Test Accuracy: 0.0000, Avg. duration: 0.0281 s\n",
      "Epoch: 099, Train Loss: 0.6857, Test Loss: 0.6857, Train Accuracy: 0.0000, Test Accuracy: 0.0000, Avg. duration: 0.0278 s\n",
      "Epoch: 100, Train Loss: 0.6857, Test Loss: 0.6857, Train Accuracy: 0.0000, Test Accuracy: 0.0000, Avg. duration: 0.0274 s\n",
      "Epoch: 101, Train Loss: 0.5353, Test Loss: 0.5383, Train Accuracy: 0.0000, Test Accuracy: 0.0000, Avg. duration: 2.7189 s\n",
      "Epoch: 102, Train Loss: 0.5353, Test Loss: 0.5383, Train Accuracy: 0.0000, Test Accuracy: 0.0000, Avg. duration: 0.0284 s\n",
      "Epoch: 103, Train Loss: 0.5353, Test Loss: 0.5383, Train Accuracy: 0.0000, Test Accuracy: 0.0000, Avg. duration: 0.0270 s\n",
      "Epoch: 104, Train Loss: 0.5353, Test Loss: 0.5383, Train Accuracy: 0.0000, Test Accuracy: 0.0000, Avg. duration: 0.0273 s\n",
      "Epoch: 105, Train Loss: 0.5353, Test Loss: 0.5383, Train Accuracy: 0.0000, Test Accuracy: 0.0000, Avg. duration: 0.0272 s\n",
      "Epoch: 106, Train Loss: 0.5353, Test Loss: 0.5383, Train Accuracy: 0.0000, Test Accuracy: 0.0000, Avg. duration: 0.0275 s\n",
      "Epoch: 107, Train Loss: 0.5353, Test Loss: 0.5383, Train Accuracy: 0.0000, Test Accuracy: 0.0000, Avg. duration: 0.0269 s\n",
      "Epoch: 108, Train Loss: 0.5353, Test Loss: 0.5383, Train Accuracy: 0.0000, Test Accuracy: 0.0000, Avg. duration: 0.0269 s\n",
      "Epoch: 109, Train Loss: 0.5353, Test Loss: 0.5383, Train Accuracy: 0.0000, Test Accuracy: 0.0000, Avg. duration: 0.0276 s\n",
      "Epoch: 110, Train Loss: 0.5353, Test Loss: 0.5383, Train Accuracy: 0.0000, Test Accuracy: 0.0000, Avg. duration: 0.3235 s\n",
      "Epoch: 111, Train Loss: 0.5353, Test Loss: 0.5383, Train Accuracy: 0.0000, Test Accuracy: 0.0000, Avg. duration: 0.0283 s\n",
      "Epoch: 112, Train Loss: 0.5353, Test Loss: 0.5383, Train Accuracy: 0.0000, Test Accuracy: 0.0000, Avg. duration: 0.0278 s\n",
      "Epoch: 113, Train Loss: 0.5353, Test Loss: 0.5383, Train Accuracy: 0.0000, Test Accuracy: 0.0000, Avg. duration: 0.0276 s\n",
      "Epoch: 114, Train Loss: 0.5353, Test Loss: 0.5383, Train Accuracy: 0.0000, Test Accuracy: 0.0000, Avg. duration: 0.0271 s\n",
      "Epoch: 115, Train Loss: 0.5353, Test Loss: 0.5383, Train Accuracy: 0.0000, Test Accuracy: 0.0000, Avg. duration: 0.0270 s\n",
      "Epoch: 116, Train Loss: 0.5353, Test Loss: 0.5383, Train Accuracy: 0.0000, Test Accuracy: 0.0000, Avg. duration: 0.0271 s\n",
      "Epoch: 117, Train Loss: 0.5353, Test Loss: 0.5383, Train Accuracy: 0.0000, Test Accuracy: 0.0000, Avg. duration: 0.0275 s\n",
      "Epoch: 118, Train Loss: 0.5353, Test Loss: 0.5383, Train Accuracy: 0.0000, Test Accuracy: 0.0000, Avg. duration: 0.0281 s\n",
      "Epoch: 119, Train Loss: 0.5353, Test Loss: 0.5383, Train Accuracy: 0.0000, Test Accuracy: 0.0000, Avg. duration: 0.0276 s\n",
      "Epoch: 120, Train Loss: 0.5353, Test Loss: 0.5383, Train Accuracy: 0.0000, Test Accuracy: 0.0000, Avg. duration: 0.0270 s\n",
      "Epoch: 121, Train Loss: 0.5353, Test Loss: 0.5383, Train Accuracy: 0.0000, Test Accuracy: 0.0000, Avg. duration: 0.0273 s\n",
      "Epoch: 122, Train Loss: 0.5353, Test Loss: 0.5383, Train Accuracy: 0.0000, Test Accuracy: 0.0000, Avg. duration: 0.0271 s\n",
      "Epoch: 123, Train Loss: 0.5353, Test Loss: 0.5383, Train Accuracy: 0.0000, Test Accuracy: 0.0000, Avg. duration: 0.0272 s\n",
      "Epoch: 124, Train Loss: 0.5353, Test Loss: 0.5383, Train Accuracy: 0.0000, Test Accuracy: 0.0000, Avg. duration: 0.0273 s\n",
      "Epoch: 125, Train Loss: 0.5353, Test Loss: 0.5383, Train Accuracy: 0.0000, Test Accuracy: 0.0000, Avg. duration: 0.0269 s\n",
      "Epoch: 126, Train Loss: 0.5353, Test Loss: 0.5383, Train Accuracy: 0.0000, Test Accuracy: 0.0000, Avg. duration: 0.0272 s\n",
      "Epoch: 127, Train Loss: 0.5353, Test Loss: 0.5383, Train Accuracy: 0.0000, Test Accuracy: 0.0000, Avg. duration: 0.0269 s\n",
      "Epoch: 128, Train Loss: 0.5353, Test Loss: 0.5383, Train Accuracy: 0.0000, Test Accuracy: 0.0000, Avg. duration: 0.0275 s\n",
      "Epoch: 129, Train Loss: 0.5353, Test Loss: 0.5383, Train Accuracy: 0.0000, Test Accuracy: 0.0000, Avg. duration: 0.0276 s\n",
      "Epoch: 130, Train Loss: 0.5353, Test Loss: 0.5383, Train Accuracy: 0.0000, Test Accuracy: 0.0000, Avg. duration: 0.0274 s\n",
      "Epoch: 131, Train Loss: 0.5353, Test Loss: 0.5383, Train Accuracy: 0.0000, Test Accuracy: 0.0000, Avg. duration: 0.0269 s\n",
      "Epoch: 132, Train Loss: 0.5353, Test Loss: 0.5383, Train Accuracy: 0.0000, Test Accuracy: 0.0000, Avg. duration: 0.0270 s\n",
      "Epoch: 133, Train Loss: 0.5353, Test Loss: 0.5383, Train Accuracy: 0.0000, Test Accuracy: 0.0000, Avg. duration: 0.0271 s\n",
      "Epoch: 134, Train Loss: 0.5353, Test Loss: 0.5383, Train Accuracy: 0.0000, Test Accuracy: 0.0000, Avg. duration: 0.0274 s\n",
      "Epoch: 135, Train Loss: 0.5353, Test Loss: 0.5383, Train Accuracy: 0.0000, Test Accuracy: 0.0000, Avg. duration: 0.0275 s\n",
      "Epoch: 136, Train Loss: 0.5353, Test Loss: 0.5383, Train Accuracy: 0.0000, Test Accuracy: 0.0000, Avg. duration: 0.0277 s\n",
      "Epoch: 137, Train Loss: 0.5353, Test Loss: 0.5383, Train Accuracy: 0.0000, Test Accuracy: 0.0000, Avg. duration: 0.0268 s\n",
      "Epoch: 138, Train Loss: 0.5353, Test Loss: 0.5383, Train Accuracy: 0.0000, Test Accuracy: 0.0000, Avg. duration: 0.0269 s\n",
      "Epoch: 139, Train Loss: 0.5353, Test Loss: 0.5383, Train Accuracy: 0.0000, Test Accuracy: 0.0000, Avg. duration: 0.0272 s\n",
      "Epoch: 140, Train Loss: 0.5353, Test Loss: 0.5383, Train Accuracy: 0.0000, Test Accuracy: 0.0000, Avg. duration: 0.0272 s\n",
      "Epoch: 141, Train Loss: 0.5353, Test Loss: 0.5383, Train Accuracy: 0.0000, Test Accuracy: 0.0000, Avg. duration: 0.0275 s\n",
      "Epoch: 142, Train Loss: 0.5353, Test Loss: 0.5383, Train Accuracy: 0.0000, Test Accuracy: 0.0000, Avg. duration: 0.0274 s\n",
      "Epoch: 143, Train Loss: 0.5353, Test Loss: 0.5383, Train Accuracy: 0.0000, Test Accuracy: 0.0000, Avg. duration: 0.0271 s\n",
      "Epoch: 144, Train Loss: 0.5353, Test Loss: 0.5383, Train Accuracy: 0.0000, Test Accuracy: 0.0000, Avg. duration: 0.0268 s\n",
      "Epoch: 145, Train Loss: 0.5353, Test Loss: 0.5383, Train Accuracy: 0.0000, Test Accuracy: 0.0000, Avg. duration: 0.0278 s\n",
      "Epoch: 146, Train Loss: 0.5353, Test Loss: 0.5383, Train Accuracy: 0.0000, Test Accuracy: 0.0000, Avg. duration: 0.0271 s\n",
      "Epoch: 147, Train Loss: 0.5353, Test Loss: 0.5383, Train Accuracy: 0.0000, Test Accuracy: 0.0000, Avg. duration: 0.0275 s\n",
      "Epoch: 148, Train Loss: 0.5353, Test Loss: 0.5383, Train Accuracy: 0.0000, Test Accuracy: 0.0000, Avg. duration: 0.0272 s\n",
      "Epoch: 149, Train Loss: 0.5353, Test Loss: 0.5383, Train Accuracy: 0.0000, Test Accuracy: 0.0000, Avg. duration: 0.0272 s\n",
      "Epoch: 150, Train Loss: 0.5353, Test Loss: 0.5383, Train Accuracy: 0.0000, Test Accuracy: 0.0000, Avg. duration: 0.0276 s\n",
      "Epoch: 151, Train Loss: 0.5353, Test Loss: 0.5383, Train Accuracy: 0.0000, Test Accuracy: 0.0000, Avg. duration: 0.0274 s\n",
      "Epoch: 152, Train Loss: 0.5353, Test Loss: 0.5383, Train Accuracy: 0.0000, Test Accuracy: 0.0000, Avg. duration: 0.0276 s\n",
      "Epoch: 153, Train Loss: 0.5353, Test Loss: 0.5383, Train Accuracy: 0.0000, Test Accuracy: 0.0000, Avg. duration: 0.0277 s\n",
      "Epoch: 154, Train Loss: 0.5353, Test Loss: 0.5383, Train Accuracy: 0.0000, Test Accuracy: 0.0000, Avg. duration: 0.0276 s\n",
      "Epoch: 155, Train Loss: 0.5353, Test Loss: 0.5383, Train Accuracy: 0.0000, Test Accuracy: 0.0000, Avg. duration: 0.0272 s\n",
      "Epoch: 156, Train Loss: 0.5353, Test Loss: 0.5383, Train Accuracy: 0.0000, Test Accuracy: 0.0000, Avg. duration: 0.0276 s\n",
      "Epoch: 157, Train Loss: 0.5353, Test Loss: 0.5383, Train Accuracy: 0.0000, Test Accuracy: 0.0000, Avg. duration: 0.0278 s\n",
      "Epoch: 158, Train Loss: 0.5353, Test Loss: 0.5383, Train Accuracy: 0.0000, Test Accuracy: 0.0000, Avg. duration: 0.0279 s\n",
      "Epoch: 159, Train Loss: 0.5353, Test Loss: 0.5383, Train Accuracy: 0.0000, Test Accuracy: 0.0000, Avg. duration: 0.0278 s\n",
      "Epoch: 160, Train Loss: 0.5353, Test Loss: 0.5383, Train Accuracy: 0.0000, Test Accuracy: 0.0000, Avg. duration: 0.0277 s\n",
      "Epoch: 161, Train Loss: 0.5353, Test Loss: 0.5383, Train Accuracy: 0.0000, Test Accuracy: 0.0000, Avg. duration: 0.0276 s\n",
      "Epoch: 162, Train Loss: 0.5353, Test Loss: 0.5383, Train Accuracy: 0.0000, Test Accuracy: 0.0000, Avg. duration: 0.0271 s\n",
      "Epoch: 163, Train Loss: 0.5353, Test Loss: 0.5383, Train Accuracy: 0.0000, Test Accuracy: 0.0000, Avg. duration: 0.0274 s\n",
      "Epoch: 164, Train Loss: 0.5353, Test Loss: 0.5383, Train Accuracy: 0.0000, Test Accuracy: 0.0000, Avg. duration: 0.0278 s\n",
      "Epoch: 165, Train Loss: 0.5353, Test Loss: 0.5383, Train Accuracy: 0.0000, Test Accuracy: 0.0000, Avg. duration: 0.0278 s\n",
      "Epoch: 166, Train Loss: 0.5353, Test Loss: 0.5383, Train Accuracy: 0.0000, Test Accuracy: 0.0000, Avg. duration: 0.0279 s\n",
      "Epoch: 167, Train Loss: 0.5353, Test Loss: 0.5383, Train Accuracy: 0.0000, Test Accuracy: 0.0000, Avg. duration: 0.0274 s\n",
      "Epoch: 168, Train Loss: 0.5353, Test Loss: 0.5383, Train Accuracy: 0.0000, Test Accuracy: 0.0000, Avg. duration: 0.0275 s\n",
      "Epoch: 169, Train Loss: 0.5353, Test Loss: 0.5383, Train Accuracy: 0.0000, Test Accuracy: 0.0000, Avg. duration: 0.0275 s\n",
      "Epoch: 170, Train Loss: 0.5353, Test Loss: 0.5383, Train Accuracy: 0.0000, Test Accuracy: 0.0000, Avg. duration: 0.0277 s\n",
      "Epoch: 171, Train Loss: 0.5353, Test Loss: 0.5383, Train Accuracy: 0.0000, Test Accuracy: 0.0000, Avg. duration: 0.0280 s\n",
      "Epoch: 172, Train Loss: 0.5353, Test Loss: 0.5383, Train Accuracy: 0.0000, Test Accuracy: 0.0000, Avg. duration: 0.0279 s\n",
      "Epoch: 173, Train Loss: 0.5353, Test Loss: 0.5383, Train Accuracy: 0.0000, Test Accuracy: 0.0000, Avg. duration: 0.0277 s\n",
      "Epoch: 174, Train Loss: 0.5353, Test Loss: 0.5383, Train Accuracy: 0.0000, Test Accuracy: 0.0000, Avg. duration: 0.0279 s\n",
      "Epoch: 175, Train Loss: 0.5353, Test Loss: 0.5383, Train Accuracy: 0.0000, Test Accuracy: 0.0000, Avg. duration: 0.0277 s\n",
      "Epoch: 176, Train Loss: 0.5353, Test Loss: 0.5383, Train Accuracy: 0.0000, Test Accuracy: 0.0000, Avg. duration: 0.0278 s\n",
      "Epoch: 177, Train Loss: 0.5353, Test Loss: 0.5383, Train Accuracy: 0.0000, Test Accuracy: 0.0000, Avg. duration: 0.3184 s\n",
      "Epoch: 178, Train Loss: 0.5353, Test Loss: 0.5383, Train Accuracy: 0.0000, Test Accuracy: 0.0000, Avg. duration: 0.0284 s\n",
      "Epoch: 179, Train Loss: 0.5353, Test Loss: 0.5383, Train Accuracy: 0.0000, Test Accuracy: 0.0000, Avg. duration: 0.0280 s\n",
      "Epoch: 180, Train Loss: 0.5353, Test Loss: 0.5383, Train Accuracy: 0.0000, Test Accuracy: 0.0000, Avg. duration: 0.0282 s\n",
      "Epoch: 181, Train Loss: 0.5353, Test Loss: 0.5383, Train Accuracy: 0.0000, Test Accuracy: 0.0000, Avg. duration: 0.0277 s\n",
      "Epoch: 182, Train Loss: 0.5353, Test Loss: 0.5383, Train Accuracy: 0.0000, Test Accuracy: 0.0000, Avg. duration: 0.0278 s\n",
      "Epoch: 183, Train Loss: 0.5353, Test Loss: 0.5383, Train Accuracy: 0.0000, Test Accuracy: 0.0000, Avg. duration: 0.0282 s\n",
      "Epoch: 184, Train Loss: 0.5353, Test Loss: 0.5383, Train Accuracy: 0.0000, Test Accuracy: 0.0000, Avg. duration: 0.0276 s\n",
      "Epoch: 185, Train Loss: 0.5353, Test Loss: 0.5383, Train Accuracy: 0.0000, Test Accuracy: 0.0000, Avg. duration: 0.0282 s\n",
      "Epoch: 186, Train Loss: 0.5353, Test Loss: 0.5383, Train Accuracy: 0.0000, Test Accuracy: 0.0000, Avg. duration: 0.0275 s\n",
      "Epoch: 187, Train Loss: 0.5353, Test Loss: 0.5383, Train Accuracy: 0.0000, Test Accuracy: 0.0000, Avg. duration: 0.0279 s\n",
      "Epoch: 188, Train Loss: 0.5353, Test Loss: 0.5383, Train Accuracy: 0.0000, Test Accuracy: 0.0000, Avg. duration: 0.0276 s\n",
      "Epoch: 189, Train Loss: 0.5353, Test Loss: 0.5383, Train Accuracy: 0.0000, Test Accuracy: 0.0000, Avg. duration: 0.0280 s\n",
      "Epoch: 190, Train Loss: 0.5353, Test Loss: 0.5383, Train Accuracy: 0.0000, Test Accuracy: 0.0000, Avg. duration: 0.0277 s\n",
      "Epoch: 191, Train Loss: 0.5353, Test Loss: 0.5383, Train Accuracy: 0.0000, Test Accuracy: 0.0000, Avg. duration: 0.0277 s\n",
      "Epoch: 192, Train Loss: 0.5353, Test Loss: 0.5383, Train Accuracy: 0.0000, Test Accuracy: 0.0000, Avg. duration: 0.0276 s\n",
      "Epoch: 193, Train Loss: 0.5353, Test Loss: 0.5383, Train Accuracy: 0.0000, Test Accuracy: 0.0000, Avg. duration: 0.0280 s\n",
      "Epoch: 194, Train Loss: 0.5353, Test Loss: 0.5383, Train Accuracy: 0.0000, Test Accuracy: 0.0000, Avg. duration: 0.0280 s\n",
      "Epoch: 195, Train Loss: 0.5353, Test Loss: 0.5383, Train Accuracy: 0.0000, Test Accuracy: 0.0000, Avg. duration: 0.0282 s\n",
      "Epoch: 196, Train Loss: 0.5353, Test Loss: 0.5383, Train Accuracy: 0.0000, Test Accuracy: 0.0000, Avg. duration: 0.0277 s\n",
      "Epoch: 197, Train Loss: 0.5353, Test Loss: 0.5383, Train Accuracy: 0.0000, Test Accuracy: 0.0000, Avg. duration: 0.0277 s\n",
      "Epoch: 198, Train Loss: 0.5353, Test Loss: 0.5383, Train Accuracy: 0.0000, Test Accuracy: 0.0000, Avg. duration: 0.0276 s\n",
      "Epoch: 199, Train Loss: 0.5353, Test Loss: 0.5383, Train Accuracy: 0.0000, Test Accuracy: 0.0000, Avg. duration: 0.0278 s\n",
      "Epoch: 200, Train Loss: 0.5353, Test Loss: 0.5383, Train Accuracy: 0.0000, Test Accuracy: 0.0000, Avg. duration: 0.0280 s\n",
      "Epoch: 201, Train Loss: 0.3424, Test Loss: 0.3551, Train Accuracy: 44.8363, Test Accuracy: 44.4444, Avg. duration: 2.7339 s\n",
      "Epoch: 202, Train Loss: 0.3424, Test Loss: 0.3551, Train Accuracy: 44.8363, Test Accuracy: 44.4444, Avg. duration: 0.0287 s\n",
      "Epoch: 203, Train Loss: 0.3424, Test Loss: 0.3551, Train Accuracy: 44.8363, Test Accuracy: 44.4444, Avg. duration: 0.0273 s\n",
      "Epoch: 204, Train Loss: 0.3424, Test Loss: 0.3551, Train Accuracy: 44.8363, Test Accuracy: 44.4444, Avg. duration: 0.0276 s\n",
      "Epoch: 205, Train Loss: 0.3424, Test Loss: 0.3551, Train Accuracy: 44.8363, Test Accuracy: 44.4444, Avg. duration: 0.0270 s\n",
      "Epoch: 206, Train Loss: 0.3424, Test Loss: 0.3551, Train Accuracy: 44.8363, Test Accuracy: 44.4444, Avg. duration: 0.0270 s\n",
      "Epoch: 207, Train Loss: 0.3424, Test Loss: 0.3551, Train Accuracy: 44.8363, Test Accuracy: 44.4444, Avg. duration: 0.0273 s\n",
      "Epoch: 208, Train Loss: 0.3424, Test Loss: 0.3551, Train Accuracy: 44.8363, Test Accuracy: 44.4444, Avg. duration: 0.0269 s\n",
      "Epoch: 209, Train Loss: 0.3424, Test Loss: 0.3551, Train Accuracy: 44.8363, Test Accuracy: 44.4444, Avg. duration: 0.0276 s\n",
      "Epoch: 210, Train Loss: 0.3424, Test Loss: 0.3551, Train Accuracy: 44.8363, Test Accuracy: 44.4444, Avg. duration: 0.0267 s\n",
      "Epoch: 211, Train Loss: 0.3424, Test Loss: 0.3551, Train Accuracy: 44.8363, Test Accuracy: 44.4444, Avg. duration: 0.0273 s\n",
      "Epoch: 212, Train Loss: 0.3424, Test Loss: 0.3551, Train Accuracy: 44.8363, Test Accuracy: 44.4444, Avg. duration: 0.0269 s\n",
      "Epoch: 213, Train Loss: 0.3424, Test Loss: 0.3551, Train Accuracy: 44.8363, Test Accuracy: 44.4444, Avg. duration: 0.0272 s\n",
      "Epoch: 214, Train Loss: 0.3424, Test Loss: 0.3551, Train Accuracy: 44.8363, Test Accuracy: 44.4444, Avg. duration: 0.0268 s\n",
      "Epoch: 215, Train Loss: 0.3424, Test Loss: 0.3551, Train Accuracy: 44.8363, Test Accuracy: 44.4444, Avg. duration: 0.0273 s\n",
      "Epoch: 216, Train Loss: 0.3424, Test Loss: 0.3551, Train Accuracy: 44.8363, Test Accuracy: 44.4444, Avg. duration: 0.0272 s\n",
      "Epoch: 217, Train Loss: 0.3424, Test Loss: 0.3551, Train Accuracy: 44.8363, Test Accuracy: 44.4444, Avg. duration: 0.0282 s\n",
      "Epoch: 218, Train Loss: 0.3424, Test Loss: 0.3551, Train Accuracy: 44.8363, Test Accuracy: 44.4444, Avg. duration: 0.0271 s\n",
      "Epoch: 219, Train Loss: 0.3424, Test Loss: 0.3551, Train Accuracy: 44.8363, Test Accuracy: 44.4444, Avg. duration: 0.0273 s\n",
      "Epoch: 220, Train Loss: 0.3424, Test Loss: 0.3551, Train Accuracy: 44.8363, Test Accuracy: 44.4444, Avg. duration: 0.0268 s\n",
      "Epoch: 221, Train Loss: 0.3424, Test Loss: 0.3551, Train Accuracy: 44.8363, Test Accuracy: 44.4444, Avg. duration: 0.0270 s\n",
      "Epoch: 222, Train Loss: 0.3424, Test Loss: 0.3551, Train Accuracy: 44.8363, Test Accuracy: 44.4444, Avg. duration: 0.0267 s\n",
      "Epoch: 223, Train Loss: 0.3424, Test Loss: 0.3551, Train Accuracy: 44.8363, Test Accuracy: 44.4444, Avg. duration: 0.0273 s\n",
      "Epoch: 224, Train Loss: 0.3424, Test Loss: 0.3551, Train Accuracy: 44.8363, Test Accuracy: 44.4444, Avg. duration: 0.0276 s\n",
      "Epoch: 225, Train Loss: 0.3424, Test Loss: 0.3551, Train Accuracy: 44.8363, Test Accuracy: 44.4444, Avg. duration: 0.0274 s\n",
      "Epoch: 226, Train Loss: 0.3424, Test Loss: 0.3551, Train Accuracy: 44.8363, Test Accuracy: 44.4444, Avg. duration: 0.0272 s\n",
      "Epoch: 227, Train Loss: 0.3424, Test Loss: 0.3551, Train Accuracy: 44.8363, Test Accuracy: 44.4444, Avg. duration: 0.0266 s\n",
      "Epoch: 228, Train Loss: 0.3424, Test Loss: 0.3551, Train Accuracy: 44.8363, Test Accuracy: 44.4444, Avg. duration: 0.0273 s\n",
      "Epoch: 229, Train Loss: 0.3424, Test Loss: 0.3551, Train Accuracy: 44.8363, Test Accuracy: 44.4444, Avg. duration: 0.0270 s\n",
      "Epoch: 230, Train Loss: 0.3424, Test Loss: 0.3551, Train Accuracy: 44.8363, Test Accuracy: 44.4444, Avg. duration: 0.0271 s\n",
      "Epoch: 231, Train Loss: 0.3424, Test Loss: 0.3551, Train Accuracy: 44.8363, Test Accuracy: 44.4444, Avg. duration: 0.0273 s\n",
      "Epoch: 232, Train Loss: 0.3424, Test Loss: 0.3551, Train Accuracy: 44.8363, Test Accuracy: 44.4444, Avg. duration: 0.0270 s\n",
      "Epoch: 233, Train Loss: 0.3424, Test Loss: 0.3551, Train Accuracy: 44.8363, Test Accuracy: 44.4444, Avg. duration: 0.0269 s\n",
      "Epoch: 234, Train Loss: 0.3424, Test Loss: 0.3551, Train Accuracy: 44.8363, Test Accuracy: 44.4444, Avg. duration: 0.0271 s\n",
      "Epoch: 235, Train Loss: 0.3424, Test Loss: 0.3551, Train Accuracy: 44.8363, Test Accuracy: 44.4444, Avg. duration: 0.0271 s\n",
      "Epoch: 236, Train Loss: 0.3424, Test Loss: 0.3551, Train Accuracy: 44.8363, Test Accuracy: 44.4444, Avg. duration: 0.0277 s\n",
      "Epoch: 237, Train Loss: 0.3424, Test Loss: 0.3551, Train Accuracy: 44.8363, Test Accuracy: 44.4444, Avg. duration: 0.0278 s\n",
      "Epoch: 238, Train Loss: 0.3424, Test Loss: 0.3551, Train Accuracy: 44.8363, Test Accuracy: 44.4444, Avg. duration: 0.0269 s\n",
      "Epoch: 239, Train Loss: 0.3424, Test Loss: 0.3551, Train Accuracy: 44.8363, Test Accuracy: 44.4444, Avg. duration: 0.0268 s\n",
      "Epoch: 240, Train Loss: 0.3424, Test Loss: 0.3551, Train Accuracy: 44.8363, Test Accuracy: 44.4444, Avg. duration: 0.0276 s\n",
      "Epoch: 241, Train Loss: 0.3424, Test Loss: 0.3551, Train Accuracy: 44.8363, Test Accuracy: 44.4444, Avg. duration: 0.0278 s\n",
      "Epoch: 242, Train Loss: 0.3424, Test Loss: 0.3551, Train Accuracy: 44.8363, Test Accuracy: 44.4444, Avg. duration: 0.0275 s\n",
      "Epoch: 243, Train Loss: 0.3424, Test Loss: 0.3551, Train Accuracy: 44.8363, Test Accuracy: 44.4444, Avg. duration: 0.0277 s\n",
      "Epoch: 244, Train Loss: 0.3424, Test Loss: 0.3551, Train Accuracy: 44.8363, Test Accuracy: 44.4444, Avg. duration: 0.0270 s\n",
      "Epoch: 245, Train Loss: 0.3424, Test Loss: 0.3551, Train Accuracy: 44.8363, Test Accuracy: 44.4444, Avg. duration: 0.0268 s\n",
      "Epoch: 246, Train Loss: 0.3424, Test Loss: 0.3551, Train Accuracy: 44.8363, Test Accuracy: 44.4444, Avg. duration: 0.0268 s\n",
      "Epoch: 247, Train Loss: 0.3424, Test Loss: 0.3551, Train Accuracy: 44.8363, Test Accuracy: 44.4444, Avg. duration: 0.0277 s\n",
      "Epoch: 248, Train Loss: 0.3424, Test Loss: 0.3551, Train Accuracy: 44.8363, Test Accuracy: 44.4444, Avg. duration: 0.0277 s\n",
      "Epoch: 249, Train Loss: 0.3424, Test Loss: 0.3551, Train Accuracy: 44.8363, Test Accuracy: 44.4444, Avg. duration: 0.0280 s\n",
      "Epoch: 250, Train Loss: 0.3424, Test Loss: 0.3551, Train Accuracy: 44.8363, Test Accuracy: 44.4444, Avg. duration: 0.0274 s\n",
      "Epoch: 251, Train Loss: 0.3424, Test Loss: 0.3551, Train Accuracy: 44.8363, Test Accuracy: 44.4444, Avg. duration: 0.0271 s\n",
      "Epoch: 252, Train Loss: 0.3424, Test Loss: 0.3551, Train Accuracy: 44.8363, Test Accuracy: 44.4444, Avg. duration: 0.0276 s\n",
      "Epoch: 253, Train Loss: 0.3424, Test Loss: 0.3551, Train Accuracy: 44.8363, Test Accuracy: 44.4444, Avg. duration: 0.3146 s\n",
      "Epoch: 254, Train Loss: 0.3424, Test Loss: 0.3551, Train Accuracy: 44.8363, Test Accuracy: 44.4444, Avg. duration: 0.0287 s\n",
      "Epoch: 255, Train Loss: 0.3424, Test Loss: 0.3551, Train Accuracy: 44.8363, Test Accuracy: 44.4444, Avg. duration: 0.0280 s\n",
      "Epoch: 256, Train Loss: 0.3424, Test Loss: 0.3551, Train Accuracy: 44.8363, Test Accuracy: 44.4444, Avg. duration: 0.0272 s\n",
      "Epoch: 257, Train Loss: 0.3424, Test Loss: 0.3551, Train Accuracy: 44.8363, Test Accuracy: 44.4444, Avg. duration: 0.0274 s\n",
      "Epoch: 258, Train Loss: 0.3424, Test Loss: 0.3551, Train Accuracy: 44.8363, Test Accuracy: 44.4444, Avg. duration: 0.0277 s\n",
      "Epoch: 259, Train Loss: 0.3424, Test Loss: 0.3551, Train Accuracy: 44.8363, Test Accuracy: 44.4444, Avg. duration: 0.0277 s\n",
      "Epoch: 260, Train Loss: 0.3424, Test Loss: 0.3551, Train Accuracy: 44.8363, Test Accuracy: 44.4444, Avg. duration: 0.0279 s\n",
      "Epoch: 261, Train Loss: 0.3424, Test Loss: 0.3551, Train Accuracy: 44.8363, Test Accuracy: 44.4444, Avg. duration: 0.0280 s\n",
      "Epoch: 262, Train Loss: 0.3424, Test Loss: 0.3551, Train Accuracy: 44.8363, Test Accuracy: 44.4444, Avg. duration: 0.0276 s\n",
      "Epoch: 263, Train Loss: 0.3424, Test Loss: 0.3551, Train Accuracy: 44.8363, Test Accuracy: 44.4444, Avg. duration: 0.0276 s\n",
      "Epoch: 264, Train Loss: 0.3424, Test Loss: 0.3551, Train Accuracy: 44.8363, Test Accuracy: 44.4444, Avg. duration: 0.0274 s\n",
      "Epoch: 265, Train Loss: 0.3424, Test Loss: 0.3551, Train Accuracy: 44.8363, Test Accuracy: 44.4444, Avg. duration: 0.0276 s\n",
      "Epoch: 266, Train Loss: 0.3424, Test Loss: 0.3551, Train Accuracy: 44.8363, Test Accuracy: 44.4444, Avg. duration: 0.0281 s\n",
      "Epoch: 267, Train Loss: 0.3424, Test Loss: 0.3551, Train Accuracy: 44.8363, Test Accuracy: 44.4444, Avg. duration: 0.0276 s\n",
      "Epoch: 268, Train Loss: 0.3424, Test Loss: 0.3551, Train Accuracy: 44.8363, Test Accuracy: 44.4444, Avg. duration: 0.0271 s\n",
      "Epoch: 269, Train Loss: 0.3424, Test Loss: 0.3551, Train Accuracy: 44.8363, Test Accuracy: 44.4444, Avg. duration: 0.0277 s\n",
      "Epoch: 270, Train Loss: 0.3424, Test Loss: 0.3551, Train Accuracy: 44.8363, Test Accuracy: 44.4444, Avg. duration: 0.0275 s\n",
      "Epoch: 271, Train Loss: 0.3424, Test Loss: 0.3551, Train Accuracy: 44.8363, Test Accuracy: 44.4444, Avg. duration: 0.0275 s\n",
      "Epoch: 272, Train Loss: 0.3424, Test Loss: 0.3551, Train Accuracy: 44.8363, Test Accuracy: 44.4444, Avg. duration: 0.0278 s\n",
      "Epoch: 273, Train Loss: 0.3424, Test Loss: 0.3551, Train Accuracy: 44.8363, Test Accuracy: 44.4444, Avg. duration: 0.0277 s\n",
      "Epoch: 274, Train Loss: 0.3424, Test Loss: 0.3551, Train Accuracy: 44.8363, Test Accuracy: 44.4444, Avg. duration: 0.0270 s\n",
      "Epoch: 275, Train Loss: 0.3424, Test Loss: 0.3551, Train Accuracy: 44.8363, Test Accuracy: 44.4444, Avg. duration: 0.0278 s\n",
      "Epoch: 276, Train Loss: 0.3424, Test Loss: 0.3551, Train Accuracy: 44.8363, Test Accuracy: 44.4444, Avg. duration: 0.0276 s\n",
      "Epoch: 277, Train Loss: 0.3424, Test Loss: 0.3551, Train Accuracy: 44.8363, Test Accuracy: 44.4444, Avg. duration: 0.0281 s\n",
      "Epoch: 278, Train Loss: 0.3424, Test Loss: 0.3551, Train Accuracy: 44.8363, Test Accuracy: 44.4444, Avg. duration: 0.0275 s\n",
      "Epoch: 279, Train Loss: 0.3424, Test Loss: 0.3551, Train Accuracy: 44.8363, Test Accuracy: 44.4444, Avg. duration: 0.0276 s\n",
      "Epoch: 280, Train Loss: 0.3424, Test Loss: 0.3551, Train Accuracy: 44.8363, Test Accuracy: 44.4444, Avg. duration: 0.0275 s\n",
      "Epoch: 281, Train Loss: 0.3424, Test Loss: 0.3551, Train Accuracy: 44.8363, Test Accuracy: 44.4444, Avg. duration: 0.0275 s\n",
      "Epoch: 282, Train Loss: 0.3424, Test Loss: 0.3551, Train Accuracy: 44.8363, Test Accuracy: 44.4444, Avg. duration: 0.0275 s\n",
      "Epoch: 283, Train Loss: 0.3424, Test Loss: 0.3551, Train Accuracy: 44.8363, Test Accuracy: 44.4444, Avg. duration: 0.0314 s\n",
      "Epoch: 284, Train Loss: 0.3424, Test Loss: 0.3551, Train Accuracy: 44.8363, Test Accuracy: 44.4444, Avg. duration: 0.0285 s\n",
      "Epoch: 285, Train Loss: 0.3424, Test Loss: 0.3551, Train Accuracy: 44.8363, Test Accuracy: 44.4444, Avg. duration: 0.0284 s\n",
      "Epoch: 286, Train Loss: 0.3424, Test Loss: 0.3551, Train Accuracy: 44.8363, Test Accuracy: 44.4444, Avg. duration: 0.0277 s\n",
      "Epoch: 287, Train Loss: 0.3424, Test Loss: 0.3551, Train Accuracy: 44.8363, Test Accuracy: 44.4444, Avg. duration: 0.0279 s\n",
      "Epoch: 288, Train Loss: 0.3424, Test Loss: 0.3551, Train Accuracy: 44.8363, Test Accuracy: 44.4444, Avg. duration: 0.0277 s\n",
      "Epoch: 289, Train Loss: 0.3424, Test Loss: 0.3551, Train Accuracy: 44.8363, Test Accuracy: 44.4444, Avg. duration: 0.0279 s\n",
      "Epoch: 290, Train Loss: 0.3424, Test Loss: 0.3551, Train Accuracy: 44.8363, Test Accuracy: 44.4444, Avg. duration: 0.0278 s\n",
      "Epoch: 291, Train Loss: 0.3424, Test Loss: 0.3551, Train Accuracy: 44.8363, Test Accuracy: 44.4444, Avg. duration: 0.0274 s\n",
      "Epoch: 292, Train Loss: 0.3424, Test Loss: 0.3551, Train Accuracy: 44.8363, Test Accuracy: 44.4444, Avg. duration: 0.0273 s\n",
      "Epoch: 293, Train Loss: 0.3424, Test Loss: 0.3551, Train Accuracy: 44.8363, Test Accuracy: 44.4444, Avg. duration: 0.0284 s\n",
      "Epoch: 294, Train Loss: 0.3424, Test Loss: 0.3551, Train Accuracy: 44.8363, Test Accuracy: 44.4444, Avg. duration: 0.0277 s\n",
      "Epoch: 295, Train Loss: 0.3424, Test Loss: 0.3551, Train Accuracy: 44.8363, Test Accuracy: 44.4444, Avg. duration: 0.0272 s\n",
      "Epoch: 296, Train Loss: 0.3424, Test Loss: 0.3551, Train Accuracy: 44.8363, Test Accuracy: 44.4444, Avg. duration: 0.0277 s\n",
      "Epoch: 297, Train Loss: 0.3424, Test Loss: 0.3551, Train Accuracy: 44.8363, Test Accuracy: 44.4444, Avg. duration: 0.0279 s\n",
      "Epoch: 298, Train Loss: 0.3424, Test Loss: 0.3551, Train Accuracy: 44.8363, Test Accuracy: 44.4444, Avg. duration: 0.0272 s\n",
      "Epoch: 299, Train Loss: 0.3424, Test Loss: 0.3551, Train Accuracy: 44.8363, Test Accuracy: 44.4444, Avg. duration: 0.0276 s\n",
      "Epoch: 300, Train Loss: 0.3424, Test Loss: 0.3551, Train Accuracy: 44.8363, Test Accuracy: 44.4444, Avg. duration: 0.0277 s\n",
      "Epoch: 301, Train Loss: 0.3148, Test Loss: 0.3460, Train Accuracy: 50.6297, Test Accuracy: 48.9899, Avg. duration: 2.7287 s\n",
      "Epoch: 302, Train Loss: 0.3148, Test Loss: 0.3460, Train Accuracy: 50.6297, Test Accuracy: 48.9899, Avg. duration: 0.0288 s\n",
      "Epoch: 303, Train Loss: 0.3148, Test Loss: 0.3460, Train Accuracy: 50.6297, Test Accuracy: 48.9899, Avg. duration: 0.0277 s\n",
      "Epoch: 304, Train Loss: 0.3148, Test Loss: 0.3460, Train Accuracy: 50.6297, Test Accuracy: 48.9899, Avg. duration: 0.0271 s\n",
      "Epoch: 305, Train Loss: 0.3148, Test Loss: 0.3460, Train Accuracy: 50.6297, Test Accuracy: 48.9899, Avg. duration: 0.0272 s\n",
      "Epoch: 306, Train Loss: 0.3148, Test Loss: 0.3460, Train Accuracy: 50.6297, Test Accuracy: 48.9899, Avg. duration: 0.0272 s\n",
      "Epoch: 307, Train Loss: 0.3148, Test Loss: 0.3460, Train Accuracy: 50.6297, Test Accuracy: 48.9899, Avg. duration: 0.0271 s\n",
      "Epoch: 308, Train Loss: 0.3148, Test Loss: 0.3460, Train Accuracy: 50.6297, Test Accuracy: 48.9899, Avg. duration: 0.0272 s\n",
      "Epoch: 309, Train Loss: 0.3148, Test Loss: 0.3460, Train Accuracy: 50.6297, Test Accuracy: 48.9899, Avg. duration: 0.0274 s\n",
      "Epoch: 310, Train Loss: 0.3148, Test Loss: 0.3460, Train Accuracy: 50.6297, Test Accuracy: 48.9899, Avg. duration: 0.0270 s\n",
      "Epoch: 311, Train Loss: 0.3148, Test Loss: 0.3460, Train Accuracy: 50.6297, Test Accuracy: 48.9899, Avg. duration: 0.0268 s\n",
      "Epoch: 312, Train Loss: 0.3148, Test Loss: 0.3460, Train Accuracy: 50.6297, Test Accuracy: 48.9899, Avg. duration: 0.0271 s\n",
      "Epoch: 313, Train Loss: 0.3148, Test Loss: 0.3460, Train Accuracy: 50.6297, Test Accuracy: 48.9899, Avg. duration: 0.0271 s\n",
      "Epoch: 314, Train Loss: 0.3148, Test Loss: 0.3460, Train Accuracy: 50.6297, Test Accuracy: 48.9899, Avg. duration: 0.0271 s\n",
      "Epoch: 315, Train Loss: 0.3148, Test Loss: 0.3460, Train Accuracy: 50.6297, Test Accuracy: 48.9899, Avg. duration: 0.0272 s\n",
      "Epoch: 316, Train Loss: 0.3148, Test Loss: 0.3460, Train Accuracy: 50.6297, Test Accuracy: 48.9899, Avg. duration: 0.0270 s\n",
      "Epoch: 317, Train Loss: 0.3148, Test Loss: 0.3460, Train Accuracy: 50.6297, Test Accuracy: 48.9899, Avg. duration: 0.0272 s\n",
      "Epoch: 318, Train Loss: 0.3148, Test Loss: 0.3460, Train Accuracy: 50.6297, Test Accuracy: 48.9899, Avg. duration: 0.0271 s\n",
      "Epoch: 319, Train Loss: 0.3148, Test Loss: 0.3460, Train Accuracy: 50.6297, Test Accuracy: 48.9899, Avg. duration: 0.0272 s\n",
      "Epoch: 320, Train Loss: 0.3148, Test Loss: 0.3460, Train Accuracy: 50.6297, Test Accuracy: 48.9899, Avg. duration: 0.3150 s\n",
      "Epoch: 321, Train Loss: 0.3148, Test Loss: 0.3460, Train Accuracy: 50.6297, Test Accuracy: 48.9899, Avg. duration: 0.0277 s\n",
      "Epoch: 322, Train Loss: 0.3148, Test Loss: 0.3460, Train Accuracy: 50.6297, Test Accuracy: 48.9899, Avg. duration: 0.0274 s\n",
      "Epoch: 323, Train Loss: 0.3148, Test Loss: 0.3460, Train Accuracy: 50.6297, Test Accuracy: 48.9899, Avg. duration: 0.0271 s\n",
      "Epoch: 324, Train Loss: 0.3148, Test Loss: 0.3460, Train Accuracy: 50.6297, Test Accuracy: 48.9899, Avg. duration: 0.0275 s\n",
      "Epoch: 325, Train Loss: 0.3148, Test Loss: 0.3460, Train Accuracy: 50.6297, Test Accuracy: 48.9899, Avg. duration: 0.0275 s\n",
      "Epoch: 326, Train Loss: 0.3148, Test Loss: 0.3460, Train Accuracy: 50.6297, Test Accuracy: 48.9899, Avg. duration: 0.0273 s\n",
      "Epoch: 327, Train Loss: 0.3148, Test Loss: 0.3460, Train Accuracy: 50.6297, Test Accuracy: 48.9899, Avg. duration: 0.0272 s\n",
      "Epoch: 328, Train Loss: 0.3148, Test Loss: 0.3460, Train Accuracy: 50.6297, Test Accuracy: 48.9899, Avg. duration: 0.0278 s\n",
      "Epoch: 329, Train Loss: 0.3148, Test Loss: 0.3460, Train Accuracy: 50.6297, Test Accuracy: 48.9899, Avg. duration: 0.0271 s\n",
      "Epoch: 330, Train Loss: 0.3148, Test Loss: 0.3460, Train Accuracy: 50.6297, Test Accuracy: 48.9899, Avg. duration: 0.0271 s\n",
      "Epoch: 331, Train Loss: 0.3148, Test Loss: 0.3460, Train Accuracy: 50.6297, Test Accuracy: 48.9899, Avg. duration: 0.0272 s\n",
      "Epoch: 332, Train Loss: 0.3148, Test Loss: 0.3460, Train Accuracy: 50.6297, Test Accuracy: 48.9899, Avg. duration: 0.0272 s\n",
      "Epoch: 333, Train Loss: 0.3148, Test Loss: 0.3460, Train Accuracy: 50.6297, Test Accuracy: 48.9899, Avg. duration: 0.0269 s\n",
      "Epoch: 334, Train Loss: 0.3148, Test Loss: 0.3460, Train Accuracy: 50.6297, Test Accuracy: 48.9899, Avg. duration: 0.0267 s\n",
      "Epoch: 335, Train Loss: 0.3148, Test Loss: 0.3460, Train Accuracy: 50.6297, Test Accuracy: 48.9899, Avg. duration: 0.0270 s\n",
      "Epoch: 336, Train Loss: 0.3148, Test Loss: 0.3460, Train Accuracy: 50.6297, Test Accuracy: 48.9899, Avg. duration: 0.0276 s\n",
      "Epoch: 337, Train Loss: 0.3148, Test Loss: 0.3460, Train Accuracy: 50.6297, Test Accuracy: 48.9899, Avg. duration: 0.0275 s\n",
      "Epoch: 338, Train Loss: 0.3148, Test Loss: 0.3460, Train Accuracy: 50.6297, Test Accuracy: 48.9899, Avg. duration: 0.0271 s\n",
      "Epoch: 339, Train Loss: 0.3148, Test Loss: 0.3460, Train Accuracy: 50.6297, Test Accuracy: 48.9899, Avg. duration: 0.0267 s\n",
      "Epoch: 340, Train Loss: 0.3148, Test Loss: 0.3460, Train Accuracy: 50.6297, Test Accuracy: 48.9899, Avg. duration: 0.0271 s\n",
      "Epoch: 341, Train Loss: 0.3148, Test Loss: 0.3460, Train Accuracy: 50.6297, Test Accuracy: 48.9899, Avg. duration: 0.0270 s\n",
      "Epoch: 342, Train Loss: 0.3148, Test Loss: 0.3460, Train Accuracy: 50.6297, Test Accuracy: 48.9899, Avg. duration: 0.0268 s\n",
      "Epoch: 343, Train Loss: 0.3148, Test Loss: 0.3460, Train Accuracy: 50.6297, Test Accuracy: 48.9899, Avg. duration: 0.0271 s\n",
      "Epoch: 344, Train Loss: 0.3148, Test Loss: 0.3460, Train Accuracy: 50.6297, Test Accuracy: 48.9899, Avg. duration: 0.0279 s\n",
      "Epoch: 345, Train Loss: 0.3148, Test Loss: 0.3460, Train Accuracy: 50.6297, Test Accuracy: 48.9899, Avg. duration: 0.0271 s\n",
      "Epoch: 346, Train Loss: 0.3148, Test Loss: 0.3460, Train Accuracy: 50.6297, Test Accuracy: 48.9899, Avg. duration: 0.0268 s\n",
      "Epoch: 347, Train Loss: 0.3148, Test Loss: 0.3460, Train Accuracy: 50.6297, Test Accuracy: 48.9899, Avg. duration: 0.0268 s\n",
      "Epoch: 348, Train Loss: 0.3148, Test Loss: 0.3460, Train Accuracy: 50.6297, Test Accuracy: 48.9899, Avg. duration: 0.0269 s\n",
      "Epoch: 349, Train Loss: 0.3148, Test Loss: 0.3460, Train Accuracy: 50.6297, Test Accuracy: 48.9899, Avg. duration: 0.0273 s\n",
      "Epoch: 350, Train Loss: 0.3148, Test Loss: 0.3460, Train Accuracy: 50.6297, Test Accuracy: 48.9899, Avg. duration: 0.0277 s\n",
      "Epoch: 351, Train Loss: 0.3148, Test Loss: 0.3460, Train Accuracy: 50.6297, Test Accuracy: 48.9899, Avg. duration: 0.0270 s\n",
      "Epoch: 352, Train Loss: 0.3148, Test Loss: 0.3460, Train Accuracy: 50.6297, Test Accuracy: 48.9899, Avg. duration: 0.0272 s\n",
      "Epoch: 353, Train Loss: 0.3148, Test Loss: 0.3460, Train Accuracy: 50.6297, Test Accuracy: 48.9899, Avg. duration: 0.0272 s\n",
      "Epoch: 354, Train Loss: 0.3148, Test Loss: 0.3460, Train Accuracy: 50.6297, Test Accuracy: 48.9899, Avg. duration: 0.0272 s\n",
      "Epoch: 355, Train Loss: 0.3148, Test Loss: 0.3460, Train Accuracy: 50.6297, Test Accuracy: 48.9899, Avg. duration: 0.0277 s\n",
      "Epoch: 356, Train Loss: 0.3148, Test Loss: 0.3460, Train Accuracy: 50.6297, Test Accuracy: 48.9899, Avg. duration: 0.0276 s\n",
      "Epoch: 357, Train Loss: 0.3148, Test Loss: 0.3460, Train Accuracy: 50.6297, Test Accuracy: 48.9899, Avg. duration: 0.0269 s\n",
      "Epoch: 358, Train Loss: 0.3148, Test Loss: 0.3460, Train Accuracy: 50.6297, Test Accuracy: 48.9899, Avg. duration: 0.0271 s\n",
      "Epoch: 359, Train Loss: 0.3148, Test Loss: 0.3460, Train Accuracy: 50.6297, Test Accuracy: 48.9899, Avg. duration: 0.0275 s\n",
      "Epoch: 360, Train Loss: 0.3148, Test Loss: 0.3460, Train Accuracy: 50.6297, Test Accuracy: 48.9899, Avg. duration: 0.0279 s\n",
      "Epoch: 361, Train Loss: 0.3148, Test Loss: 0.3460, Train Accuracy: 50.6297, Test Accuracy: 48.9899, Avg. duration: 0.0277 s\n",
      "Epoch: 362, Train Loss: 0.3148, Test Loss: 0.3460, Train Accuracy: 50.6297, Test Accuracy: 48.9899, Avg. duration: 0.0276 s\n",
      "Epoch: 363, Train Loss: 0.3148, Test Loss: 0.3460, Train Accuracy: 50.6297, Test Accuracy: 48.9899, Avg. duration: 0.0268 s\n",
      "Epoch: 364, Train Loss: 0.3148, Test Loss: 0.3460, Train Accuracy: 50.6297, Test Accuracy: 48.9899, Avg. duration: 0.0276 s\n",
      "Epoch: 365, Train Loss: 0.3148, Test Loss: 0.3460, Train Accuracy: 50.6297, Test Accuracy: 48.9899, Avg. duration: 0.0272 s\n",
      "Epoch: 366, Train Loss: 0.3148, Test Loss: 0.3460, Train Accuracy: 50.6297, Test Accuracy: 48.9899, Avg. duration: 0.0275 s\n",
      "Epoch: 367, Train Loss: 0.3148, Test Loss: 0.3460, Train Accuracy: 50.6297, Test Accuracy: 48.9899, Avg. duration: 0.0276 s\n",
      "Epoch: 368, Train Loss: 0.3148, Test Loss: 0.3460, Train Accuracy: 50.6297, Test Accuracy: 48.9899, Avg. duration: 0.0279 s\n",
      "Epoch: 369, Train Loss: 0.3148, Test Loss: 0.3460, Train Accuracy: 50.6297, Test Accuracy: 48.9899, Avg. duration: 0.0275 s\n",
      "Epoch: 370, Train Loss: 0.3148, Test Loss: 0.3460, Train Accuracy: 50.6297, Test Accuracy: 48.9899, Avg. duration: 0.0277 s\n",
      "Epoch: 371, Train Loss: 0.3148, Test Loss: 0.3460, Train Accuracy: 50.6297, Test Accuracy: 48.9899, Avg. duration: 0.0276 s\n",
      "Epoch: 372, Train Loss: 0.3148, Test Loss: 0.3460, Train Accuracy: 50.6297, Test Accuracy: 48.9899, Avg. duration: 0.0275 s\n",
      "Epoch: 373, Train Loss: 0.3148, Test Loss: 0.3460, Train Accuracy: 50.6297, Test Accuracy: 48.9899, Avg. duration: 0.0275 s\n",
      "Epoch: 374, Train Loss: 0.3148, Test Loss: 0.3460, Train Accuracy: 50.6297, Test Accuracy: 48.9899, Avg. duration: 0.0277 s\n",
      "Epoch: 375, Train Loss: 0.3148, Test Loss: 0.3460, Train Accuracy: 50.6297, Test Accuracy: 48.9899, Avg. duration: 0.0273 s\n",
      "Epoch: 376, Train Loss: 0.3148, Test Loss: 0.3460, Train Accuracy: 50.6297, Test Accuracy: 48.9899, Avg. duration: 0.0277 s\n",
      "Epoch: 377, Train Loss: 0.3148, Test Loss: 0.3460, Train Accuracy: 50.6297, Test Accuracy: 48.9899, Avg. duration: 0.0276 s\n",
      "Epoch: 378, Train Loss: 0.3148, Test Loss: 0.3460, Train Accuracy: 50.6297, Test Accuracy: 48.9899, Avg. duration: 0.0275 s\n",
      "Epoch: 379, Train Loss: 0.3148, Test Loss: 0.3460, Train Accuracy: 50.6297, Test Accuracy: 48.9899, Avg. duration: 0.0278 s\n",
      "Epoch: 380, Train Loss: 0.3148, Test Loss: 0.3460, Train Accuracy: 50.6297, Test Accuracy: 48.9899, Avg. duration: 0.0279 s\n",
      "Epoch: 381, Train Loss: 0.3148, Test Loss: 0.3460, Train Accuracy: 50.6297, Test Accuracy: 48.9899, Avg. duration: 0.0270 s\n",
      "Epoch: 382, Train Loss: 0.3148, Test Loss: 0.3460, Train Accuracy: 50.6297, Test Accuracy: 48.9899, Avg. duration: 0.0273 s\n",
      "Epoch: 383, Train Loss: 0.3148, Test Loss: 0.3460, Train Accuracy: 50.6297, Test Accuracy: 48.9899, Avg. duration: 0.0279 s\n",
      "Epoch: 384, Train Loss: 0.3148, Test Loss: 0.3460, Train Accuracy: 50.6297, Test Accuracy: 48.9899, Avg. duration: 0.0280 s\n",
      "Epoch: 385, Train Loss: 0.3148, Test Loss: 0.3460, Train Accuracy: 50.6297, Test Accuracy: 48.9899, Avg. duration: 0.0277 s\n",
      "Epoch: 386, Train Loss: 0.3148, Test Loss: 0.3460, Train Accuracy: 50.6297, Test Accuracy: 48.9899, Avg. duration: 0.0275 s\n",
      "Epoch: 387, Train Loss: 0.3148, Test Loss: 0.3460, Train Accuracy: 50.6297, Test Accuracy: 48.9899, Avg. duration: 0.0270 s\n",
      "Epoch: 388, Train Loss: 0.3148, Test Loss: 0.3460, Train Accuracy: 50.6297, Test Accuracy: 48.9899, Avg. duration: 0.0275 s\n",
      "Epoch: 389, Train Loss: 0.3148, Test Loss: 0.3460, Train Accuracy: 50.6297, Test Accuracy: 48.9899, Avg. duration: 0.0276 s\n",
      "Epoch: 390, Train Loss: 0.3148, Test Loss: 0.3460, Train Accuracy: 50.6297, Test Accuracy: 48.9899, Avg. duration: 0.0275 s\n",
      "Epoch: 391, Train Loss: 0.3148, Test Loss: 0.3460, Train Accuracy: 50.6297, Test Accuracy: 48.9899, Avg. duration: 0.0277 s\n",
      "Epoch: 392, Train Loss: 0.3148, Test Loss: 0.3460, Train Accuracy: 50.6297, Test Accuracy: 48.9899, Avg. duration: 0.0281 s\n",
      "Epoch: 393, Train Loss: 0.3148, Test Loss: 0.3460, Train Accuracy: 50.6297, Test Accuracy: 48.9899, Avg. duration: 0.0275 s\n",
      "Epoch: 394, Train Loss: 0.3148, Test Loss: 0.3460, Train Accuracy: 50.6297, Test Accuracy: 48.9899, Avg. duration: 0.0271 s\n",
      "Epoch: 395, Train Loss: 0.3148, Test Loss: 0.3460, Train Accuracy: 50.6297, Test Accuracy: 48.9899, Avg. duration: 0.0273 s\n",
      "Epoch: 396, Train Loss: 0.3148, Test Loss: 0.3460, Train Accuracy: 50.6297, Test Accuracy: 48.9899, Avg. duration: 0.3096 s\n",
      "Epoch: 397, Train Loss: 0.3148, Test Loss: 0.3460, Train Accuracy: 50.6297, Test Accuracy: 48.9899, Avg. duration: 0.0283 s\n",
      "Epoch: 398, Train Loss: 0.3148, Test Loss: 0.3460, Train Accuracy: 50.6297, Test Accuracy: 48.9899, Avg. duration: 0.0278 s\n",
      "Epoch: 399, Train Loss: 0.3148, Test Loss: 0.3460, Train Accuracy: 50.6297, Test Accuracy: 48.9899, Avg. duration: 0.0277 s\n",
      "Epoch: 400, Train Loss: 0.3148, Test Loss: 0.3460, Train Accuracy: 50.6297, Test Accuracy: 48.9899, Avg. duration: 0.0276 s\n",
      "Epoch: 401, Train Loss: 0.3038, Test Loss: 0.3450, Train Accuracy: 52.5189, Test Accuracy: 50.5051, Avg. duration: 2.7277 s\n",
      "Epoch: 402, Train Loss: 0.3038, Test Loss: 0.3450, Train Accuracy: 52.5189, Test Accuracy: 50.5051, Avg. duration: 0.0288 s\n",
      "Epoch: 403, Train Loss: 0.3038, Test Loss: 0.3450, Train Accuracy: 52.5189, Test Accuracy: 50.5051, Avg. duration: 0.0277 s\n",
      "Epoch: 404, Train Loss: 0.3038, Test Loss: 0.3450, Train Accuracy: 52.5189, Test Accuracy: 50.5051, Avg. duration: 0.0275 s\n",
      "Epoch: 405, Train Loss: 0.3038, Test Loss: 0.3450, Train Accuracy: 52.5189, Test Accuracy: 50.5051, Avg. duration: 0.0269 s\n",
      "Epoch: 406, Train Loss: 0.3038, Test Loss: 0.3450, Train Accuracy: 52.5189, Test Accuracy: 50.5051, Avg. duration: 0.0272 s\n",
      "Epoch: 407, Train Loss: 0.3038, Test Loss: 0.3450, Train Accuracy: 52.5189, Test Accuracy: 50.5051, Avg. duration: 0.0272 s\n",
      "Epoch: 408, Train Loss: 0.3038, Test Loss: 0.3450, Train Accuracy: 52.5189, Test Accuracy: 50.5051, Avg. duration: 0.0274 s\n",
      "Epoch: 409, Train Loss: 0.3038, Test Loss: 0.3450, Train Accuracy: 52.5189, Test Accuracy: 50.5051, Avg. duration: 0.0276 s\n",
      "Epoch: 410, Train Loss: 0.3038, Test Loss: 0.3450, Train Accuracy: 52.5189, Test Accuracy: 50.5051, Avg. duration: 0.0272 s\n",
      "Epoch: 411, Train Loss: 0.3038, Test Loss: 0.3450, Train Accuracy: 52.5189, Test Accuracy: 50.5051, Avg. duration: 0.0271 s\n",
      "Epoch: 412, Train Loss: 0.3038, Test Loss: 0.3450, Train Accuracy: 52.5189, Test Accuracy: 50.5051, Avg. duration: 0.0270 s\n",
      "Epoch: 413, Train Loss: 0.3038, Test Loss: 0.3450, Train Accuracy: 52.5189, Test Accuracy: 50.5051, Avg. duration: 0.0271 s\n",
      "Epoch: 414, Train Loss: 0.3038, Test Loss: 0.3450, Train Accuracy: 52.5189, Test Accuracy: 50.5051, Avg. duration: 0.0274 s\n",
      "Epoch: 415, Train Loss: 0.3038, Test Loss: 0.3450, Train Accuracy: 52.5189, Test Accuracy: 50.5051, Avg. duration: 0.0271 s\n",
      "Epoch: 416, Train Loss: 0.3038, Test Loss: 0.3450, Train Accuracy: 52.5189, Test Accuracy: 50.5051, Avg. duration: 0.0274 s\n",
      "Epoch: 417, Train Loss: 0.3038, Test Loss: 0.3450, Train Accuracy: 52.5189, Test Accuracy: 50.5051, Avg. duration: 0.0280 s\n",
      "Epoch: 418, Train Loss: 0.3038, Test Loss: 0.3450, Train Accuracy: 52.5189, Test Accuracy: 50.5051, Avg. duration: 0.0273 s\n",
      "Epoch: 419, Train Loss: 0.3038, Test Loss: 0.3450, Train Accuracy: 52.5189, Test Accuracy: 50.5051, Avg. duration: 0.0272 s\n",
      "Epoch: 420, Train Loss: 0.3038, Test Loss: 0.3450, Train Accuracy: 52.5189, Test Accuracy: 50.5051, Avg. duration: 0.0272 s\n",
      "Epoch: 421, Train Loss: 0.3038, Test Loss: 0.3450, Train Accuracy: 52.5189, Test Accuracy: 50.5051, Avg. duration: 0.0272 s\n",
      "Epoch: 422, Train Loss: 0.3038, Test Loss: 0.3450, Train Accuracy: 52.5189, Test Accuracy: 50.5051, Avg. duration: 0.0273 s\n",
      "Epoch: 423, Train Loss: 0.3038, Test Loss: 0.3450, Train Accuracy: 52.5189, Test Accuracy: 50.5051, Avg. duration: 0.0270 s\n",
      "Epoch: 424, Train Loss: 0.3038, Test Loss: 0.3450, Train Accuracy: 52.5189, Test Accuracy: 50.5051, Avg. duration: 0.0269 s\n",
      "Epoch: 425, Train Loss: 0.3038, Test Loss: 0.3450, Train Accuracy: 52.5189, Test Accuracy: 50.5051, Avg. duration: 0.0273 s\n",
      "Epoch: 426, Train Loss: 0.3038, Test Loss: 0.3450, Train Accuracy: 52.5189, Test Accuracy: 50.5051, Avg. duration: 0.0271 s\n",
      "Epoch: 427, Train Loss: 0.3038, Test Loss: 0.3450, Train Accuracy: 52.5189, Test Accuracy: 50.5051, Avg. duration: 0.0277 s\n",
      "Epoch: 428, Train Loss: 0.3038, Test Loss: 0.3450, Train Accuracy: 52.5189, Test Accuracy: 50.5051, Avg. duration: 0.0277 s\n",
      "Epoch: 429, Train Loss: 0.3038, Test Loss: 0.3450, Train Accuracy: 52.5189, Test Accuracy: 50.5051, Avg. duration: 0.0268 s\n",
      "Epoch: 430, Train Loss: 0.3038, Test Loss: 0.3450, Train Accuracy: 52.5189, Test Accuracy: 50.5051, Avg. duration: 0.0269 s\n",
      "Epoch: 431, Train Loss: 0.3038, Test Loss: 0.3450, Train Accuracy: 52.5189, Test Accuracy: 50.5051, Avg. duration: 0.0272 s\n",
      "Epoch: 432, Train Loss: 0.3038, Test Loss: 0.3450, Train Accuracy: 52.5189, Test Accuracy: 50.5051, Avg. duration: 0.0272 s\n",
      "Epoch: 433, Train Loss: 0.3038, Test Loss: 0.3450, Train Accuracy: 52.5189, Test Accuracy: 50.5051, Avg. duration: 0.0276 s\n",
      "Epoch: 434, Train Loss: 0.3038, Test Loss: 0.3450, Train Accuracy: 52.5189, Test Accuracy: 50.5051, Avg. duration: 0.0278 s\n",
      "Epoch: 435, Train Loss: 0.3038, Test Loss: 0.3450, Train Accuracy: 52.5189, Test Accuracy: 50.5051, Avg. duration: 0.0268 s\n",
      "Epoch: 436, Train Loss: 0.3038, Test Loss: 0.3450, Train Accuracy: 52.5189, Test Accuracy: 50.5051, Avg. duration: 0.0272 s\n",
      "Epoch: 437, Train Loss: 0.3038, Test Loss: 0.3450, Train Accuracy: 52.5189, Test Accuracy: 50.5051, Avg. duration: 0.0269 s\n",
      "Epoch: 438, Train Loss: 0.3038, Test Loss: 0.3450, Train Accuracy: 52.5189, Test Accuracy: 50.5051, Avg. duration: 0.0271 s\n",
      "Epoch: 439, Train Loss: 0.3038, Test Loss: 0.3450, Train Accuracy: 52.5189, Test Accuracy: 50.5051, Avg. duration: 0.0273 s\n",
      "Epoch: 440, Train Loss: 0.3038, Test Loss: 0.3450, Train Accuracy: 52.5189, Test Accuracy: 50.5051, Avg. duration: 0.0273 s\n",
      "Epoch: 441, Train Loss: 0.3038, Test Loss: 0.3450, Train Accuracy: 52.5189, Test Accuracy: 50.5051, Avg. duration: 0.0274 s\n",
      "Epoch: 442, Train Loss: 0.3038, Test Loss: 0.3450, Train Accuracy: 52.5189, Test Accuracy: 50.5051, Avg. duration: 0.0274 s\n",
      "Epoch: 443, Train Loss: 0.3038, Test Loss: 0.3450, Train Accuracy: 52.5189, Test Accuracy: 50.5051, Avg. duration: 0.0271 s\n",
      "Epoch: 444, Train Loss: 0.3038, Test Loss: 0.3450, Train Accuracy: 52.5189, Test Accuracy: 50.5051, Avg. duration: 0.0276 s\n",
      "Epoch: 445, Train Loss: 0.3038, Test Loss: 0.3450, Train Accuracy: 52.5189, Test Accuracy: 50.5051, Avg. duration: 0.0272 s\n",
      "Epoch: 446, Train Loss: 0.3038, Test Loss: 0.3450, Train Accuracy: 52.5189, Test Accuracy: 50.5051, Avg. duration: 0.0273 s\n",
      "Epoch: 447, Train Loss: 0.3038, Test Loss: 0.3450, Train Accuracy: 52.5189, Test Accuracy: 50.5051, Avg. duration: 0.0267 s\n",
      "Epoch: 448, Train Loss: 0.3038, Test Loss: 0.3450, Train Accuracy: 52.5189, Test Accuracy: 50.5051, Avg. duration: 0.0268 s\n",
      "Epoch: 449, Train Loss: 0.3038, Test Loss: 0.3450, Train Accuracy: 52.5189, Test Accuracy: 50.5051, Avg. duration: 0.0272 s\n",
      "Epoch: 450, Train Loss: 0.3038, Test Loss: 0.3450, Train Accuracy: 52.5189, Test Accuracy: 50.5051, Avg. duration: 0.0272 s\n",
      "Epoch: 451, Train Loss: 0.3038, Test Loss: 0.3450, Train Accuracy: 52.5189, Test Accuracy: 50.5051, Avg. duration: 0.0276 s\n",
      "Epoch: 452, Train Loss: 0.3038, Test Loss: 0.3450, Train Accuracy: 52.5189, Test Accuracy: 50.5051, Avg. duration: 0.0271 s\n",
      "Epoch: 453, Train Loss: 0.3038, Test Loss: 0.3450, Train Accuracy: 52.5189, Test Accuracy: 50.5051, Avg. duration: 0.0271 s\n",
      "Epoch: 454, Train Loss: 0.3038, Test Loss: 0.3450, Train Accuracy: 52.5189, Test Accuracy: 50.5051, Avg. duration: 0.0267 s\n",
      "Epoch: 455, Train Loss: 0.3038, Test Loss: 0.3450, Train Accuracy: 52.5189, Test Accuracy: 50.5051, Avg. duration: 0.0270 s\n",
      "Epoch: 456, Train Loss: 0.3038, Test Loss: 0.3450, Train Accuracy: 52.5189, Test Accuracy: 50.5051, Avg. duration: 0.0276 s\n",
      "Epoch: 457, Train Loss: 0.3038, Test Loss: 0.3450, Train Accuracy: 52.5189, Test Accuracy: 50.5051, Avg. duration: 0.0278 s\n",
      "Epoch: 458, Train Loss: 0.3038, Test Loss: 0.3450, Train Accuracy: 52.5189, Test Accuracy: 50.5051, Avg. duration: 0.0275 s\n",
      "Epoch: 459, Train Loss: 0.3038, Test Loss: 0.3450, Train Accuracy: 52.5189, Test Accuracy: 50.5051, Avg. duration: 0.0270 s\n",
      "Epoch: 460, Train Loss: 0.3038, Test Loss: 0.3450, Train Accuracy: 52.5189, Test Accuracy: 50.5051, Avg. duration: 0.0271 s\n",
      "Epoch: 461, Train Loss: 0.3038, Test Loss: 0.3450, Train Accuracy: 52.5189, Test Accuracy: 50.5051, Avg. duration: 0.0270 s\n",
      "Epoch: 462, Train Loss: 0.3038, Test Loss: 0.3450, Train Accuracy: 52.5189, Test Accuracy: 50.5051, Avg. duration: 0.0273 s\n",
      "Epoch: 463, Train Loss: 0.3038, Test Loss: 0.3450, Train Accuracy: 52.5189, Test Accuracy: 50.5051, Avg. duration: 0.3175 s\n",
      "Epoch: 464, Train Loss: 0.3038, Test Loss: 0.3450, Train Accuracy: 52.5189, Test Accuracy: 50.5051, Avg. duration: 0.0284 s\n",
      "Epoch: 465, Train Loss: 0.3038, Test Loss: 0.3450, Train Accuracy: 52.5189, Test Accuracy: 50.5051, Avg. duration: 0.0277 s\n",
      "Epoch: 466, Train Loss: 0.3038, Test Loss: 0.3450, Train Accuracy: 52.5189, Test Accuracy: 50.5051, Avg. duration: 0.0275 s\n",
      "Epoch: 467, Train Loss: 0.3038, Test Loss: 0.3450, Train Accuracy: 52.5189, Test Accuracy: 50.5051, Avg. duration: 0.0277 s\n",
      "Epoch: 468, Train Loss: 0.3038, Test Loss: 0.3450, Train Accuracy: 52.5189, Test Accuracy: 50.5051, Avg. duration: 0.0279 s\n",
      "Epoch: 469, Train Loss: 0.3038, Test Loss: 0.3450, Train Accuracy: 52.5189, Test Accuracy: 50.5051, Avg. duration: 0.0277 s\n",
      "Epoch: 470, Train Loss: 0.3038, Test Loss: 0.3450, Train Accuracy: 52.5189, Test Accuracy: 50.5051, Avg. duration: 0.0277 s\n",
      "Epoch: 471, Train Loss: 0.3038, Test Loss: 0.3450, Train Accuracy: 52.5189, Test Accuracy: 50.5051, Avg. duration: 0.0277 s\n",
      "Epoch: 472, Train Loss: 0.3038, Test Loss: 0.3450, Train Accuracy: 52.5189, Test Accuracy: 50.5051, Avg. duration: 0.0274 s\n",
      "Epoch: 473, Train Loss: 0.3038, Test Loss: 0.3450, Train Accuracy: 52.5189, Test Accuracy: 50.5051, Avg. duration: 0.0277 s\n",
      "Epoch: 474, Train Loss: 0.3038, Test Loss: 0.3450, Train Accuracy: 52.5189, Test Accuracy: 50.5051, Avg. duration: 0.0279 s\n",
      "Epoch: 475, Train Loss: 0.3038, Test Loss: 0.3450, Train Accuracy: 52.5189, Test Accuracy: 50.5051, Avg. duration: 0.0280 s\n",
      "Epoch: 476, Train Loss: 0.3038, Test Loss: 0.3450, Train Accuracy: 52.5189, Test Accuracy: 50.5051, Avg. duration: 0.0275 s\n",
      "Epoch: 477, Train Loss: 0.3038, Test Loss: 0.3450, Train Accuracy: 52.5189, Test Accuracy: 50.5051, Avg. duration: 0.0271 s\n",
      "Epoch: 478, Train Loss: 0.3038, Test Loss: 0.3450, Train Accuracy: 52.5189, Test Accuracy: 50.5051, Avg. duration: 0.0275 s\n",
      "Epoch: 479, Train Loss: 0.3038, Test Loss: 0.3450, Train Accuracy: 52.5189, Test Accuracy: 50.5051, Avg. duration: 0.0281 s\n",
      "Epoch: 480, Train Loss: 0.3038, Test Loss: 0.3450, Train Accuracy: 52.5189, Test Accuracy: 50.5051, Avg. duration: 0.0277 s\n",
      "Epoch: 481, Train Loss: 0.3038, Test Loss: 0.3450, Train Accuracy: 52.5189, Test Accuracy: 50.5051, Avg. duration: 0.0276 s\n",
      "Epoch: 482, Train Loss: 0.3038, Test Loss: 0.3450, Train Accuracy: 52.5189, Test Accuracy: 50.5051, Avg. duration: 0.0278 s\n",
      "Epoch: 483, Train Loss: 0.3038, Test Loss: 0.3450, Train Accuracy: 52.5189, Test Accuracy: 50.5051, Avg. duration: 0.0273 s\n",
      "Epoch: 484, Train Loss: 0.3038, Test Loss: 0.3450, Train Accuracy: 52.5189, Test Accuracy: 50.5051, Avg. duration: 0.0275 s\n",
      "Epoch: 485, Train Loss: 0.3038, Test Loss: 0.3450, Train Accuracy: 52.5189, Test Accuracy: 50.5051, Avg. duration: 0.0274 s\n",
      "Epoch: 486, Train Loss: 0.3038, Test Loss: 0.3450, Train Accuracy: 52.5189, Test Accuracy: 50.5051, Avg. duration: 0.0275 s\n",
      "Epoch: 487, Train Loss: 0.3038, Test Loss: 0.3450, Train Accuracy: 52.5189, Test Accuracy: 50.5051, Avg. duration: 0.0283 s\n",
      "Epoch: 488, Train Loss: 0.3038, Test Loss: 0.3450, Train Accuracy: 52.5189, Test Accuracy: 50.5051, Avg. duration: 0.0273 s\n",
      "Epoch: 489, Train Loss: 0.3038, Test Loss: 0.3450, Train Accuracy: 52.5189, Test Accuracy: 50.5051, Avg. duration: 0.0274 s\n",
      "Epoch: 490, Train Loss: 0.3038, Test Loss: 0.3450, Train Accuracy: 52.5189, Test Accuracy: 50.5051, Avg. duration: 0.0277 s\n",
      "Epoch: 491, Train Loss: 0.3038, Test Loss: 0.3450, Train Accuracy: 52.5189, Test Accuracy: 50.5051, Avg. duration: 0.0276 s\n",
      "Epoch: 492, Train Loss: 0.3038, Test Loss: 0.3450, Train Accuracy: 52.5189, Test Accuracy: 50.5051, Avg. duration: 0.0279 s\n",
      "Epoch: 493, Train Loss: 0.3038, Test Loss: 0.3450, Train Accuracy: 52.5189, Test Accuracy: 50.5051, Avg. duration: 0.0278 s\n",
      "Epoch: 494, Train Loss: 0.3038, Test Loss: 0.3450, Train Accuracy: 52.5189, Test Accuracy: 50.5051, Avg. duration: 0.0274 s\n",
      "Epoch: 495, Train Loss: 0.3038, Test Loss: 0.3450, Train Accuracy: 52.5189, Test Accuracy: 50.5051, Avg. duration: 0.0280 s\n",
      "Epoch: 496, Train Loss: 0.3038, Test Loss: 0.3450, Train Accuracy: 52.5189, Test Accuracy: 50.5051, Avg. duration: 0.0277 s\n",
      "Epoch: 497, Train Loss: 0.3038, Test Loss: 0.3450, Train Accuracy: 52.5189, Test Accuracy: 50.5051, Avg. duration: 0.0275 s\n",
      "Epoch: 498, Train Loss: 0.3038, Test Loss: 0.3450, Train Accuracy: 52.5189, Test Accuracy: 50.5051, Avg. duration: 0.0274 s\n",
      "Epoch: 499, Train Loss: 0.3038, Test Loss: 0.3450, Train Accuracy: 52.5189, Test Accuracy: 50.5051, Avg. duration: 0.0283 s\n",
      "Epoch: 500, Train Loss: 0.3038, Test Loss: 0.3450, Train Accuracy: 52.5189, Test Accuracy: 50.5051, Avg. duration: 0.0275 s\n",
      "Epoch: 501, Train Loss: 0.2950, Test Loss: 0.3421, Train Accuracy: 53.6524, Test Accuracy: 53.5354, Avg. duration: 2.7251 s\n",
      "Epoch: 502, Train Loss: 0.2950, Test Loss: 0.3421, Train Accuracy: 53.6524, Test Accuracy: 53.5354, Avg. duration: 0.0283 s\n",
      "Epoch: 503, Train Loss: 0.2950, Test Loss: 0.3421, Train Accuracy: 53.6524, Test Accuracy: 53.5354, Avg. duration: 0.0274 s\n",
      "Epoch: 504, Train Loss: 0.2950, Test Loss: 0.3421, Train Accuracy: 53.6524, Test Accuracy: 53.5354, Avg. duration: 0.0273 s\n",
      "Epoch: 505, Train Loss: 0.2950, Test Loss: 0.3421, Train Accuracy: 53.6524, Test Accuracy: 53.5354, Avg. duration: 0.0276 s\n",
      "Epoch: 506, Train Loss: 0.2950, Test Loss: 0.3421, Train Accuracy: 53.6524, Test Accuracy: 53.5354, Avg. duration: 0.0267 s\n",
      "Epoch: 507, Train Loss: 0.2950, Test Loss: 0.3421, Train Accuracy: 53.6524, Test Accuracy: 53.5354, Avg. duration: 0.0268 s\n",
      "Epoch: 508, Train Loss: 0.2950, Test Loss: 0.3421, Train Accuracy: 53.6524, Test Accuracy: 53.5354, Avg. duration: 0.0269 s\n",
      "Epoch: 509, Train Loss: 0.2950, Test Loss: 0.3421, Train Accuracy: 53.6524, Test Accuracy: 53.5354, Avg. duration: 0.0276 s\n",
      "Epoch: 510, Train Loss: 0.2950, Test Loss: 0.3421, Train Accuracy: 53.6524, Test Accuracy: 53.5354, Avg. duration: 0.0275 s\n",
      "Epoch: 511, Train Loss: 0.2950, Test Loss: 0.3421, Train Accuracy: 53.6524, Test Accuracy: 53.5354, Avg. duration: 0.0277 s\n",
      "Epoch: 512, Train Loss: 0.2950, Test Loss: 0.3421, Train Accuracy: 53.6524, Test Accuracy: 53.5354, Avg. duration: 0.0269 s\n",
      "Epoch: 513, Train Loss: 0.2950, Test Loss: 0.3421, Train Accuracy: 53.6524, Test Accuracy: 53.5354, Avg. duration: 0.0268 s\n",
      "Epoch: 514, Train Loss: 0.2950, Test Loss: 0.3421, Train Accuracy: 53.6524, Test Accuracy: 53.5354, Avg. duration: 0.0269 s\n",
      "Epoch: 515, Train Loss: 0.2950, Test Loss: 0.3421, Train Accuracy: 53.6524, Test Accuracy: 53.5354, Avg. duration: 0.0272 s\n",
      "Epoch: 516, Train Loss: 0.2950, Test Loss: 0.3421, Train Accuracy: 53.6524, Test Accuracy: 53.5354, Avg. duration: 0.0277 s\n",
      "Epoch: 517, Train Loss: 0.2950, Test Loss: 0.3421, Train Accuracy: 53.6524, Test Accuracy: 53.5354, Avg. duration: 0.0277 s\n",
      "Epoch: 518, Train Loss: 0.2950, Test Loss: 0.3421, Train Accuracy: 53.6524, Test Accuracy: 53.5354, Avg. duration: 0.0273 s\n",
      "Epoch: 519, Train Loss: 0.2950, Test Loss: 0.3421, Train Accuracy: 53.6524, Test Accuracy: 53.5354, Avg. duration: 0.0267 s\n",
      "Epoch: 520, Train Loss: 0.2950, Test Loss: 0.3421, Train Accuracy: 53.6524, Test Accuracy: 53.5354, Avg. duration: 0.0272 s\n",
      "Epoch: 521, Train Loss: 0.2950, Test Loss: 0.3421, Train Accuracy: 53.6524, Test Accuracy: 53.5354, Avg. duration: 0.0268 s\n",
      "Epoch: 522, Train Loss: 0.2950, Test Loss: 0.3421, Train Accuracy: 53.6524, Test Accuracy: 53.5354, Avg. duration: 0.0274 s\n",
      "Epoch: 523, Train Loss: 0.2950, Test Loss: 0.3421, Train Accuracy: 53.6524, Test Accuracy: 53.5354, Avg. duration: 0.0275 s\n",
      "Epoch: 524, Train Loss: 0.2950, Test Loss: 0.3421, Train Accuracy: 53.6524, Test Accuracy: 53.5354, Avg. duration: 0.0272 s\n",
      "Epoch: 525, Train Loss: 0.2950, Test Loss: 0.3421, Train Accuracy: 53.6524, Test Accuracy: 53.5354, Avg. duration: 0.0277 s\n",
      "Epoch: 526, Train Loss: 0.2950, Test Loss: 0.3421, Train Accuracy: 53.6524, Test Accuracy: 53.5354, Avg. duration: 0.0269 s\n",
      "Epoch: 527, Train Loss: 0.2950, Test Loss: 0.3421, Train Accuracy: 53.6524, Test Accuracy: 53.5354, Avg. duration: 0.0272 s\n",
      "Epoch: 528, Train Loss: 0.2950, Test Loss: 0.3421, Train Accuracy: 53.6524, Test Accuracy: 53.5354, Avg. duration: 0.0270 s\n",
      "Epoch: 529, Train Loss: 0.2950, Test Loss: 0.3421, Train Accuracy: 53.6524, Test Accuracy: 53.5354, Avg. duration: 0.0275 s\n",
      "Epoch: 530, Train Loss: 0.2950, Test Loss: 0.3421, Train Accuracy: 53.6524, Test Accuracy: 53.5354, Avg. duration: 0.0271 s\n",
      "Epoch: 531, Train Loss: 0.2950, Test Loss: 0.3421, Train Accuracy: 53.6524, Test Accuracy: 53.5354, Avg. duration: 0.0268 s\n",
      "Epoch: 532, Train Loss: 0.2950, Test Loss: 0.3421, Train Accuracy: 53.6524, Test Accuracy: 53.5354, Avg. duration: 0.0271 s\n",
      "Epoch: 533, Train Loss: 0.2950, Test Loss: 0.3421, Train Accuracy: 53.6524, Test Accuracy: 53.5354, Avg. duration: 0.0272 s\n",
      "Epoch: 534, Train Loss: 0.2950, Test Loss: 0.3421, Train Accuracy: 53.6524, Test Accuracy: 53.5354, Avg. duration: 0.0275 s\n",
      "Epoch: 535, Train Loss: 0.2950, Test Loss: 0.3421, Train Accuracy: 53.6524, Test Accuracy: 53.5354, Avg. duration: 0.0276 s\n",
      "Epoch: 536, Train Loss: 0.2950, Test Loss: 0.3421, Train Accuracy: 53.6524, Test Accuracy: 53.5354, Avg. duration: 0.0271 s\n",
      "Epoch: 537, Train Loss: 0.2950, Test Loss: 0.3421, Train Accuracy: 53.6524, Test Accuracy: 53.5354, Avg. duration: 0.0267 s\n",
      "Epoch: 538, Train Loss: 0.2950, Test Loss: 0.3421, Train Accuracy: 53.6524, Test Accuracy: 53.5354, Avg. duration: 0.0269 s\n",
      "Epoch: 539, Train Loss: 0.2950, Test Loss: 0.3421, Train Accuracy: 53.6524, Test Accuracy: 53.5354, Avg. duration: 0.3162 s\n",
      "Epoch: 540, Train Loss: 0.2950, Test Loss: 0.3421, Train Accuracy: 53.6524, Test Accuracy: 53.5354, Avg. duration: 0.0284 s\n",
      "Epoch: 541, Train Loss: 0.2950, Test Loss: 0.3421, Train Accuracy: 53.6524, Test Accuracy: 53.5354, Avg. duration: 0.0275 s\n",
      "Epoch: 542, Train Loss: 0.2950, Test Loss: 0.3421, Train Accuracy: 53.6524, Test Accuracy: 53.5354, Avg. duration: 0.0271 s\n",
      "Epoch: 543, Train Loss: 0.2950, Test Loss: 0.3421, Train Accuracy: 53.6524, Test Accuracy: 53.5354, Avg. duration: 0.0273 s\n",
      "Epoch: 544, Train Loss: 0.2950, Test Loss: 0.3421, Train Accuracy: 53.6524, Test Accuracy: 53.5354, Avg. duration: 0.0271 s\n",
      "Epoch: 545, Train Loss: 0.2950, Test Loss: 0.3421, Train Accuracy: 53.6524, Test Accuracy: 53.5354, Avg. duration: 0.0270 s\n",
      "Epoch: 546, Train Loss: 0.2950, Test Loss: 0.3421, Train Accuracy: 53.6524, Test Accuracy: 53.5354, Avg. duration: 0.0274 s\n",
      "Epoch: 547, Train Loss: 0.2950, Test Loss: 0.3421, Train Accuracy: 53.6524, Test Accuracy: 53.5354, Avg. duration: 0.0276 s\n",
      "Epoch: 548, Train Loss: 0.2950, Test Loss: 0.3421, Train Accuracy: 53.6524, Test Accuracy: 53.5354, Avg. duration: 0.0269 s\n",
      "Epoch: 549, Train Loss: 0.2950, Test Loss: 0.3421, Train Accuracy: 53.6524, Test Accuracy: 53.5354, Avg. duration: 0.0275 s\n",
      "Epoch: 550, Train Loss: 0.2950, Test Loss: 0.3421, Train Accuracy: 53.6524, Test Accuracy: 53.5354, Avg. duration: 0.0270 s\n",
      "Epoch: 551, Train Loss: 0.2950, Test Loss: 0.3421, Train Accuracy: 53.6524, Test Accuracy: 53.5354, Avg. duration: 0.0275 s\n",
      "Epoch: 552, Train Loss: 0.2950, Test Loss: 0.3421, Train Accuracy: 53.6524, Test Accuracy: 53.5354, Avg. duration: 0.0275 s\n",
      "Epoch: 553, Train Loss: 0.2950, Test Loss: 0.3421, Train Accuracy: 53.6524, Test Accuracy: 53.5354, Avg. duration: 0.0270 s\n",
      "Epoch: 554, Train Loss: 0.2950, Test Loss: 0.3421, Train Accuracy: 53.6524, Test Accuracy: 53.5354, Avg. duration: 0.0268 s\n",
      "Epoch: 555, Train Loss: 0.2950, Test Loss: 0.3421, Train Accuracy: 53.6524, Test Accuracy: 53.5354, Avg. duration: 0.0278 s\n",
      "Epoch: 556, Train Loss: 0.2950, Test Loss: 0.3421, Train Accuracy: 53.6524, Test Accuracy: 53.5354, Avg. duration: 0.0275 s\n",
      "Epoch: 557, Train Loss: 0.2950, Test Loss: 0.3421, Train Accuracy: 53.6524, Test Accuracy: 53.5354, Avg. duration: 0.0277 s\n",
      "Epoch: 558, Train Loss: 0.2950, Test Loss: 0.3421, Train Accuracy: 53.6524, Test Accuracy: 53.5354, Avg. duration: 0.0278 s\n",
      "Epoch: 559, Train Loss: 0.2950, Test Loss: 0.3421, Train Accuracy: 53.6524, Test Accuracy: 53.5354, Avg. duration: 0.0276 s\n",
      "Epoch: 560, Train Loss: 0.2950, Test Loss: 0.3421, Train Accuracy: 53.6524, Test Accuracy: 53.5354, Avg. duration: 0.0273 s\n",
      "Epoch: 561, Train Loss: 0.2950, Test Loss: 0.3421, Train Accuracy: 53.6524, Test Accuracy: 53.5354, Avg. duration: 0.0272 s\n",
      "Epoch: 562, Train Loss: 0.2950, Test Loss: 0.3421, Train Accuracy: 53.6524, Test Accuracy: 53.5354, Avg. duration: 0.0277 s\n",
      "Epoch: 563, Train Loss: 0.2950, Test Loss: 0.3421, Train Accuracy: 53.6524, Test Accuracy: 53.5354, Avg. duration: 0.0277 s\n",
      "Epoch: 564, Train Loss: 0.2950, Test Loss: 0.3421, Train Accuracy: 53.6524, Test Accuracy: 53.5354, Avg. duration: 0.0278 s\n",
      "Epoch: 565, Train Loss: 0.2950, Test Loss: 0.3421, Train Accuracy: 53.6524, Test Accuracy: 53.5354, Avg. duration: 0.0277 s\n",
      "Epoch: 566, Train Loss: 0.2950, Test Loss: 0.3421, Train Accuracy: 53.6524, Test Accuracy: 53.5354, Avg. duration: 0.0277 s\n",
      "Epoch: 567, Train Loss: 0.2950, Test Loss: 0.3421, Train Accuracy: 53.6524, Test Accuracy: 53.5354, Avg. duration: 0.0272 s\n",
      "Epoch: 568, Train Loss: 0.2950, Test Loss: 0.3421, Train Accuracy: 53.6524, Test Accuracy: 53.5354, Avg. duration: 0.0275 s\n",
      "Epoch: 569, Train Loss: 0.2950, Test Loss: 0.3421, Train Accuracy: 53.6524, Test Accuracy: 53.5354, Avg. duration: 0.0277 s\n",
      "Epoch: 570, Train Loss: 0.2950, Test Loss: 0.3421, Train Accuracy: 53.6524, Test Accuracy: 53.5354, Avg. duration: 0.0274 s\n",
      "Epoch: 571, Train Loss: 0.2950, Test Loss: 0.3421, Train Accuracy: 53.6524, Test Accuracy: 53.5354, Avg. duration: 0.0282 s\n",
      "Epoch: 572, Train Loss: 0.2950, Test Loss: 0.3421, Train Accuracy: 53.6524, Test Accuracy: 53.5354, Avg. duration: 0.0276 s\n",
      "Epoch: 573, Train Loss: 0.2950, Test Loss: 0.3421, Train Accuracy: 53.6524, Test Accuracy: 53.5354, Avg. duration: 0.0276 s\n",
      "Epoch: 574, Train Loss: 0.2950, Test Loss: 0.3421, Train Accuracy: 53.6524, Test Accuracy: 53.5354, Avg. duration: 0.0276 s\n",
      "Epoch: 575, Train Loss: 0.2950, Test Loss: 0.3421, Train Accuracy: 53.6524, Test Accuracy: 53.5354, Avg. duration: 0.0278 s\n",
      "Epoch: 576, Train Loss: 0.2950, Test Loss: 0.3421, Train Accuracy: 53.6524, Test Accuracy: 53.5354, Avg. duration: 0.0276 s\n",
      "Epoch: 577, Train Loss: 0.2950, Test Loss: 0.3421, Train Accuracy: 53.6524, Test Accuracy: 53.5354, Avg. duration: 0.0278 s\n",
      "Epoch: 578, Train Loss: 0.2950, Test Loss: 0.3421, Train Accuracy: 53.6524, Test Accuracy: 53.5354, Avg. duration: 0.0273 s\n",
      "Epoch: 579, Train Loss: 0.2950, Test Loss: 0.3421, Train Accuracy: 53.6524, Test Accuracy: 53.5354, Avg. duration: 0.0280 s\n",
      "Epoch: 580, Train Loss: 0.2950, Test Loss: 0.3421, Train Accuracy: 53.6524, Test Accuracy: 53.5354, Avg. duration: 0.0277 s\n",
      "Epoch: 581, Train Loss: 0.2950, Test Loss: 0.3421, Train Accuracy: 53.6524, Test Accuracy: 53.5354, Avg. duration: 0.0279 s\n",
      "Epoch: 582, Train Loss: 0.2950, Test Loss: 0.3421, Train Accuracy: 53.6524, Test Accuracy: 53.5354, Avg. duration: 0.0277 s\n",
      "Epoch: 583, Train Loss: 0.2950, Test Loss: 0.3421, Train Accuracy: 53.6524, Test Accuracy: 53.5354, Avg. duration: 0.0280 s\n",
      "Epoch: 584, Train Loss: 0.2950, Test Loss: 0.3421, Train Accuracy: 53.6524, Test Accuracy: 53.5354, Avg. duration: 0.0271 s\n",
      "Epoch: 585, Train Loss: 0.2950, Test Loss: 0.3421, Train Accuracy: 53.6524, Test Accuracy: 53.5354, Avg. duration: 0.0274 s\n",
      "Epoch: 586, Train Loss: 0.2950, Test Loss: 0.3421, Train Accuracy: 53.6524, Test Accuracy: 53.5354, Avg. duration: 0.0274 s\n",
      "Epoch: 587, Train Loss: 0.2950, Test Loss: 0.3421, Train Accuracy: 53.6524, Test Accuracy: 53.5354, Avg. duration: 0.0281 s\n",
      "Epoch: 588, Train Loss: 0.2950, Test Loss: 0.3421, Train Accuracy: 53.6524, Test Accuracy: 53.5354, Avg. duration: 0.0278 s\n",
      "Epoch: 589, Train Loss: 0.2950, Test Loss: 0.3421, Train Accuracy: 53.6524, Test Accuracy: 53.5354, Avg. duration: 0.0276 s\n",
      "Epoch: 590, Train Loss: 0.2950, Test Loss: 0.3421, Train Accuracy: 53.6524, Test Accuracy: 53.5354, Avg. duration: 0.0275 s\n",
      "Epoch: 591, Train Loss: 0.2950, Test Loss: 0.3421, Train Accuracy: 53.6524, Test Accuracy: 53.5354, Avg. duration: 0.0274 s\n",
      "Epoch: 592, Train Loss: 0.2950, Test Loss: 0.3421, Train Accuracy: 53.6524, Test Accuracy: 53.5354, Avg. duration: 0.0272 s\n",
      "Epoch: 593, Train Loss: 0.2950, Test Loss: 0.3421, Train Accuracy: 53.6524, Test Accuracy: 53.5354, Avg. duration: 0.0277 s\n",
      "Epoch: 594, Train Loss: 0.2950, Test Loss: 0.3421, Train Accuracy: 53.6524, Test Accuracy: 53.5354, Avg. duration: 0.0277 s\n",
      "Epoch: 595, Train Loss: 0.2950, Test Loss: 0.3421, Train Accuracy: 53.6524, Test Accuracy: 53.5354, Avg. duration: 0.0279 s\n",
      "Epoch: 596, Train Loss: 0.2950, Test Loss: 0.3421, Train Accuracy: 53.6524, Test Accuracy: 53.5354, Avg. duration: 0.0274 s\n",
      "Epoch: 597, Train Loss: 0.2950, Test Loss: 0.3421, Train Accuracy: 53.6524, Test Accuracy: 53.5354, Avg. duration: 0.0271 s\n",
      "Epoch: 598, Train Loss: 0.2950, Test Loss: 0.3421, Train Accuracy: 53.6524, Test Accuracy: 53.5354, Avg. duration: 0.0276 s\n",
      "Epoch: 599, Train Loss: 0.2950, Test Loss: 0.3421, Train Accuracy: 53.6524, Test Accuracy: 53.5354, Avg. duration: 0.0277 s\n",
      "Epoch: 600, Train Loss: 0.2950, Test Loss: 0.3421, Train Accuracy: 53.6524, Test Accuracy: 53.5354, Avg. duration: 0.0278 s\n",
      "Epoch: 601, Train Loss: 0.2853, Test Loss: 0.3330, Train Accuracy: 55.2897, Test Accuracy: 54.5455, Avg. duration: 2.7243 s\n",
      "Epoch: 602, Train Loss: 0.2853, Test Loss: 0.3330, Train Accuracy: 55.2897, Test Accuracy: 54.5455, Avg. duration: 0.0282 s\n",
      "Epoch: 603, Train Loss: 0.2853, Test Loss: 0.3330, Train Accuracy: 55.2897, Test Accuracy: 54.5455, Avg. duration: 0.0274 s\n",
      "Epoch: 604, Train Loss: 0.2853, Test Loss: 0.3330, Train Accuracy: 55.2897, Test Accuracy: 54.5455, Avg. duration: 0.0273 s\n",
      "Epoch: 605, Train Loss: 0.2853, Test Loss: 0.3330, Train Accuracy: 55.2897, Test Accuracy: 54.5455, Avg. duration: 0.0269 s\n",
      "Epoch: 606, Train Loss: 0.2853, Test Loss: 0.3330, Train Accuracy: 55.2897, Test Accuracy: 54.5455, Avg. duration: 0.3139 s\n",
      "Epoch: 607, Train Loss: 0.2853, Test Loss: 0.3330, Train Accuracy: 55.2897, Test Accuracy: 54.5455, Avg. duration: 0.0277 s\n",
      "Epoch: 608, Train Loss: 0.2853, Test Loss: 0.3330, Train Accuracy: 55.2897, Test Accuracy: 54.5455, Avg. duration: 0.0275 s\n",
      "Epoch: 609, Train Loss: 0.2853, Test Loss: 0.3330, Train Accuracy: 55.2897, Test Accuracy: 54.5455, Avg. duration: 0.0271 s\n",
      "Epoch: 610, Train Loss: 0.2853, Test Loss: 0.3330, Train Accuracy: 55.2897, Test Accuracy: 54.5455, Avg. duration: 0.0271 s\n",
      "Epoch: 611, Train Loss: 0.2853, Test Loss: 0.3330, Train Accuracy: 55.2897, Test Accuracy: 54.5455, Avg. duration: 0.0272 s\n",
      "Epoch: 612, Train Loss: 0.2853, Test Loss: 0.3330, Train Accuracy: 55.2897, Test Accuracy: 54.5455, Avg. duration: 0.0275 s\n",
      "Epoch: 613, Train Loss: 0.2853, Test Loss: 0.3330, Train Accuracy: 55.2897, Test Accuracy: 54.5455, Avg. duration: 0.0267 s\n",
      "Epoch: 614, Train Loss: 0.2853, Test Loss: 0.3330, Train Accuracy: 55.2897, Test Accuracy: 54.5455, Avg. duration: 0.0275 s\n",
      "Epoch: 615, Train Loss: 0.2853, Test Loss: 0.3330, Train Accuracy: 55.2897, Test Accuracy: 54.5455, Avg. duration: 0.0271 s\n",
      "Epoch: 616, Train Loss: 0.2853, Test Loss: 0.3330, Train Accuracy: 55.2897, Test Accuracy: 54.5455, Avg. duration: 0.0268 s\n",
      "Epoch: 617, Train Loss: 0.2853, Test Loss: 0.3330, Train Accuracy: 55.2897, Test Accuracy: 54.5455, Avg. duration: 0.0271 s\n",
      "Epoch: 618, Train Loss: 0.2853, Test Loss: 0.3330, Train Accuracy: 55.2897, Test Accuracy: 54.5455, Avg. duration: 0.0274 s\n",
      "Epoch: 619, Train Loss: 0.2853, Test Loss: 0.3330, Train Accuracy: 55.2897, Test Accuracy: 54.5455, Avg. duration: 0.0268 s\n",
      "Epoch: 620, Train Loss: 0.2853, Test Loss: 0.3330, Train Accuracy: 55.2897, Test Accuracy: 54.5455, Avg. duration: 0.0267 s\n",
      "Epoch: 621, Train Loss: 0.2853, Test Loss: 0.3330, Train Accuracy: 55.2897, Test Accuracy: 54.5455, Avg. duration: 0.0267 s\n",
      "Epoch: 622, Train Loss: 0.2853, Test Loss: 0.3330, Train Accuracy: 55.2897, Test Accuracy: 54.5455, Avg. duration: 0.0276 s\n",
      "Epoch: 623, Train Loss: 0.2853, Test Loss: 0.3330, Train Accuracy: 55.2897, Test Accuracy: 54.5455, Avg. duration: 0.0275 s\n",
      "Epoch: 624, Train Loss: 0.2853, Test Loss: 0.3330, Train Accuracy: 55.2897, Test Accuracy: 54.5455, Avg. duration: 0.0270 s\n",
      "Epoch: 625, Train Loss: 0.2853, Test Loss: 0.3330, Train Accuracy: 55.2897, Test Accuracy: 54.5455, Avg. duration: 0.0268 s\n",
      "Epoch: 626, Train Loss: 0.2853, Test Loss: 0.3330, Train Accuracy: 55.2897, Test Accuracy: 54.5455, Avg. duration: 0.0268 s\n",
      "Epoch: 627, Train Loss: 0.2853, Test Loss: 0.3330, Train Accuracy: 55.2897, Test Accuracy: 54.5455, Avg. duration: 0.0269 s\n",
      "Epoch: 628, Train Loss: 0.2853, Test Loss: 0.3330, Train Accuracy: 55.2897, Test Accuracy: 54.5455, Avg. duration: 0.0270 s\n",
      "Epoch: 629, Train Loss: 0.2853, Test Loss: 0.3330, Train Accuracy: 55.2897, Test Accuracy: 54.5455, Avg. duration: 0.0274 s\n",
      "Epoch: 630, Train Loss: 0.2853, Test Loss: 0.3330, Train Accuracy: 55.2897, Test Accuracy: 54.5455, Avg. duration: 0.0276 s\n",
      "Epoch: 631, Train Loss: 0.2853, Test Loss: 0.3330, Train Accuracy: 55.2897, Test Accuracy: 54.5455, Avg. duration: 0.0267 s\n",
      "Epoch: 632, Train Loss: 0.2853, Test Loss: 0.3330, Train Accuracy: 55.2897, Test Accuracy: 54.5455, Avg. duration: 0.0268 s\n",
      "Epoch: 633, Train Loss: 0.2853, Test Loss: 0.3330, Train Accuracy: 55.2897, Test Accuracy: 54.5455, Avg. duration: 0.0269 s\n",
      "Epoch: 634, Train Loss: 0.2853, Test Loss: 0.3330, Train Accuracy: 55.2897, Test Accuracy: 54.5455, Avg. duration: 0.0272 s\n",
      "Epoch: 635, Train Loss: 0.2853, Test Loss: 0.3330, Train Accuracy: 55.2897, Test Accuracy: 54.5455, Avg. duration: 0.0270 s\n",
      "Epoch: 636, Train Loss: 0.2853, Test Loss: 0.3330, Train Accuracy: 55.2897, Test Accuracy: 54.5455, Avg. duration: 0.0271 s\n",
      "Epoch: 637, Train Loss: 0.2853, Test Loss: 0.3330, Train Accuracy: 55.2897, Test Accuracy: 54.5455, Avg. duration: 0.0270 s\n",
      "Epoch: 638, Train Loss: 0.2853, Test Loss: 0.3330, Train Accuracy: 55.2897, Test Accuracy: 54.5455, Avg. duration: 0.0272 s\n",
      "Epoch: 639, Train Loss: 0.2853, Test Loss: 0.3330, Train Accuracy: 55.2897, Test Accuracy: 54.5455, Avg. duration: 0.0272 s\n",
      "Epoch: 640, Train Loss: 0.2853, Test Loss: 0.3330, Train Accuracy: 55.2897, Test Accuracy: 54.5455, Avg. duration: 0.0271 s\n",
      "Epoch: 641, Train Loss: 0.2853, Test Loss: 0.3330, Train Accuracy: 55.2897, Test Accuracy: 54.5455, Avg. duration: 0.0270 s\n",
      "Epoch: 642, Train Loss: 0.2853, Test Loss: 0.3330, Train Accuracy: 55.2897, Test Accuracy: 54.5455, Avg. duration: 0.0275 s\n",
      "Epoch: 643, Train Loss: 0.2853, Test Loss: 0.3330, Train Accuracy: 55.2897, Test Accuracy: 54.5455, Avg. duration: 0.0266 s\n",
      "Epoch: 644, Train Loss: 0.2853, Test Loss: 0.3330, Train Accuracy: 55.2897, Test Accuracy: 54.5455, Avg. duration: 0.0267 s\n",
      "Epoch: 645, Train Loss: 0.2853, Test Loss: 0.3330, Train Accuracy: 55.2897, Test Accuracy: 54.5455, Avg. duration: 0.0268 s\n",
      "Epoch: 646, Train Loss: 0.2853, Test Loss: 0.3330, Train Accuracy: 55.2897, Test Accuracy: 54.5455, Avg. duration: 0.0275 s\n",
      "Epoch: 647, Train Loss: 0.2853, Test Loss: 0.3330, Train Accuracy: 55.2897, Test Accuracy: 54.5455, Avg. duration: 0.0271 s\n",
      "Epoch: 648, Train Loss: 0.2853, Test Loss: 0.3330, Train Accuracy: 55.2897, Test Accuracy: 54.5455, Avg. duration: 0.0272 s\n",
      "Epoch: 649, Train Loss: 0.2853, Test Loss: 0.3330, Train Accuracy: 55.2897, Test Accuracy: 54.5455, Avg. duration: 0.0270 s\n",
      "Epoch: 650, Train Loss: 0.2853, Test Loss: 0.3330, Train Accuracy: 55.2897, Test Accuracy: 54.5455, Avg. duration: 0.0269 s\n",
      "Epoch: 651, Train Loss: 0.2853, Test Loss: 0.3330, Train Accuracy: 55.2897, Test Accuracy: 54.5455, Avg. duration: 0.0272 s\n",
      "Epoch: 652, Train Loss: 0.2853, Test Loss: 0.3330, Train Accuracy: 55.2897, Test Accuracy: 54.5455, Avg. duration: 0.0272 s\n",
      "Epoch: 653, Train Loss: 0.2853, Test Loss: 0.3330, Train Accuracy: 55.2897, Test Accuracy: 54.5455, Avg. duration: 0.0276 s\n",
      "Epoch: 654, Train Loss: 0.2853, Test Loss: 0.3330, Train Accuracy: 55.2897, Test Accuracy: 54.5455, Avg. duration: 0.0280 s\n",
      "Epoch: 655, Train Loss: 0.2853, Test Loss: 0.3330, Train Accuracy: 55.2897, Test Accuracy: 54.5455, Avg. duration: 0.0273 s\n",
      "Epoch: 656, Train Loss: 0.2853, Test Loss: 0.3330, Train Accuracy: 55.2897, Test Accuracy: 54.5455, Avg. duration: 0.0272 s\n",
      "Epoch: 657, Train Loss: 0.2853, Test Loss: 0.3330, Train Accuracy: 55.2897, Test Accuracy: 54.5455, Avg. duration: 0.0274 s\n",
      "Epoch: 658, Train Loss: 0.2853, Test Loss: 0.3330, Train Accuracy: 55.2897, Test Accuracy: 54.5455, Avg. duration: 0.0271 s\n",
      "Epoch: 659, Train Loss: 0.2853, Test Loss: 0.3330, Train Accuracy: 55.2897, Test Accuracy: 54.5455, Avg. duration: 0.0276 s\n",
      "Epoch: 660, Train Loss: 0.2853, Test Loss: 0.3330, Train Accuracy: 55.2897, Test Accuracy: 54.5455, Avg. duration: 0.0278 s\n",
      "Epoch: 661, Train Loss: 0.2853, Test Loss: 0.3330, Train Accuracy: 55.2897, Test Accuracy: 54.5455, Avg. duration: 0.0268 s\n",
      "Epoch: 662, Train Loss: 0.2853, Test Loss: 0.3330, Train Accuracy: 55.2897, Test Accuracy: 54.5455, Avg. duration: 0.0277 s\n",
      "Epoch: 663, Train Loss: 0.2853, Test Loss: 0.3330, Train Accuracy: 55.2897, Test Accuracy: 54.5455, Avg. duration: 0.0275 s\n",
      "Epoch: 664, Train Loss: 0.2853, Test Loss: 0.3330, Train Accuracy: 55.2897, Test Accuracy: 54.5455, Avg. duration: 0.0273 s\n",
      "Epoch: 665, Train Loss: 0.2853, Test Loss: 0.3330, Train Accuracy: 55.2897, Test Accuracy: 54.5455, Avg. duration: 0.0272 s\n",
      "Epoch: 666, Train Loss: 0.2853, Test Loss: 0.3330, Train Accuracy: 55.2897, Test Accuracy: 54.5455, Avg. duration: 0.0278 s\n",
      "Epoch: 667, Train Loss: 0.2853, Test Loss: 0.3330, Train Accuracy: 55.2897, Test Accuracy: 54.5455, Avg. duration: 0.0276 s\n",
      "Epoch: 668, Train Loss: 0.2853, Test Loss: 0.3330, Train Accuracy: 55.2897, Test Accuracy: 54.5455, Avg. duration: 0.0269 s\n",
      "Epoch: 669, Train Loss: 0.2853, Test Loss: 0.3330, Train Accuracy: 55.2897, Test Accuracy: 54.5455, Avg. duration: 0.0274 s\n",
      "Epoch: 670, Train Loss: 0.2853, Test Loss: 0.3330, Train Accuracy: 55.2897, Test Accuracy: 54.5455, Avg. duration: 0.0276 s\n",
      "Epoch: 671, Train Loss: 0.2853, Test Loss: 0.3330, Train Accuracy: 55.2897, Test Accuracy: 54.5455, Avg. duration: 0.0279 s\n",
      "Epoch: 672, Train Loss: 0.2853, Test Loss: 0.3330, Train Accuracy: 55.2897, Test Accuracy: 54.5455, Avg. duration: 0.0278 s\n",
      "Epoch: 673, Train Loss: 0.2853, Test Loss: 0.3330, Train Accuracy: 55.2897, Test Accuracy: 54.5455, Avg. duration: 0.0270 s\n",
      "Epoch: 674, Train Loss: 0.2853, Test Loss: 0.3330, Train Accuracy: 55.2897, Test Accuracy: 54.5455, Avg. duration: 0.0273 s\n",
      "Epoch: 675, Train Loss: 0.2853, Test Loss: 0.3330, Train Accuracy: 55.2897, Test Accuracy: 54.5455, Avg. duration: 0.0272 s\n",
      "Epoch: 676, Train Loss: 0.2853, Test Loss: 0.3330, Train Accuracy: 55.2897, Test Accuracy: 54.5455, Avg. duration: 0.0272 s\n",
      "Epoch: 677, Train Loss: 0.2853, Test Loss: 0.3330, Train Accuracy: 55.2897, Test Accuracy: 54.5455, Avg. duration: 0.0273 s\n",
      "Epoch: 678, Train Loss: 0.2853, Test Loss: 0.3330, Train Accuracy: 55.2897, Test Accuracy: 54.5455, Avg. duration: 0.0283 s\n",
      "Epoch: 679, Train Loss: 0.2853, Test Loss: 0.3330, Train Accuracy: 55.2897, Test Accuracy: 54.5455, Avg. duration: 0.0270 s\n",
      "Epoch: 680, Train Loss: 0.2853, Test Loss: 0.3330, Train Accuracy: 55.2897, Test Accuracy: 54.5455, Avg. duration: 0.0274 s\n",
      "Epoch: 681, Train Loss: 0.2853, Test Loss: 0.3330, Train Accuracy: 55.2897, Test Accuracy: 54.5455, Avg. duration: 0.0271 s\n",
      "Epoch: 682, Train Loss: 0.2853, Test Loss: 0.3330, Train Accuracy: 55.2897, Test Accuracy: 54.5455, Avg. duration: 0.3144 s\n",
      "Epoch: 683, Train Loss: 0.2853, Test Loss: 0.3330, Train Accuracy: 55.2897, Test Accuracy: 54.5455, Avg. duration: 0.0284 s\n",
      "Epoch: 684, Train Loss: 0.2853, Test Loss: 0.3330, Train Accuracy: 55.2897, Test Accuracy: 54.5455, Avg. duration: 0.0282 s\n",
      "Epoch: 685, Train Loss: 0.2853, Test Loss: 0.3330, Train Accuracy: 55.2897, Test Accuracy: 54.5455, Avg. duration: 0.0277 s\n",
      "Epoch: 686, Train Loss: 0.2853, Test Loss: 0.3330, Train Accuracy: 55.2897, Test Accuracy: 54.5455, Avg. duration: 0.0275 s\n",
      "Epoch: 687, Train Loss: 0.2853, Test Loss: 0.3330, Train Accuracy: 55.2897, Test Accuracy: 54.5455, Avg. duration: 0.0277 s\n",
      "Epoch: 688, Train Loss: 0.2853, Test Loss: 0.3330, Train Accuracy: 55.2897, Test Accuracy: 54.5455, Avg. duration: 0.0275 s\n",
      "Epoch: 689, Train Loss: 0.2853, Test Loss: 0.3330, Train Accuracy: 55.2897, Test Accuracy: 54.5455, Avg. duration: 0.0276 s\n",
      "Epoch: 690, Train Loss: 0.2853, Test Loss: 0.3330, Train Accuracy: 55.2897, Test Accuracy: 54.5455, Avg. duration: 0.0282 s\n",
      "Epoch: 691, Train Loss: 0.2853, Test Loss: 0.3330, Train Accuracy: 55.2897, Test Accuracy: 54.5455, Avg. duration: 0.0273 s\n",
      "Epoch: 692, Train Loss: 0.2853, Test Loss: 0.3330, Train Accuracy: 55.2897, Test Accuracy: 54.5455, Avg. duration: 0.0274 s\n",
      "Epoch: 693, Train Loss: 0.2853, Test Loss: 0.3330, Train Accuracy: 55.2897, Test Accuracy: 54.5455, Avg. duration: 0.0276 s\n",
      "Epoch: 694, Train Loss: 0.2853, Test Loss: 0.3330, Train Accuracy: 55.2897, Test Accuracy: 54.5455, Avg. duration: 0.0277 s\n",
      "Epoch: 695, Train Loss: 0.2853, Test Loss: 0.3330, Train Accuracy: 55.2897, Test Accuracy: 54.5455, Avg. duration: 0.0278 s\n",
      "Epoch: 696, Train Loss: 0.2853, Test Loss: 0.3330, Train Accuracy: 55.2897, Test Accuracy: 54.5455, Avg. duration: 0.0276 s\n",
      "Epoch: 697, Train Loss: 0.2853, Test Loss: 0.3330, Train Accuracy: 55.2897, Test Accuracy: 54.5455, Avg. duration: 0.0274 s\n",
      "Epoch: 698, Train Loss: 0.2853, Test Loss: 0.3330, Train Accuracy: 55.2897, Test Accuracy: 54.5455, Avg. duration: 0.0281 s\n",
      "Epoch: 699, Train Loss: 0.2853, Test Loss: 0.3330, Train Accuracy: 55.2897, Test Accuracy: 54.5455, Avg. duration: 0.0276 s\n",
      "Epoch: 700, Train Loss: 0.2853, Test Loss: 0.3330, Train Accuracy: 55.2897, Test Accuracy: 54.5455, Avg. duration: 0.0279 s\n",
      "Epoch: 701, Train Loss: 0.2729, Test Loss: 0.3191, Train Accuracy: 56.1713, Test Accuracy: 55.5556, Avg. duration: 2.7280 s\n",
      "Epoch: 702, Train Loss: 0.2729, Test Loss: 0.3191, Train Accuracy: 56.1713, Test Accuracy: 55.5556, Avg. duration: 0.0293 s\n",
      "Epoch: 703, Train Loss: 0.2729, Test Loss: 0.3191, Train Accuracy: 56.1713, Test Accuracy: 55.5556, Avg. duration: 0.0275 s\n",
      "Epoch: 704, Train Loss: 0.2729, Test Loss: 0.3191, Train Accuracy: 56.1713, Test Accuracy: 55.5556, Avg. duration: 0.0270 s\n",
      "Epoch: 705, Train Loss: 0.2729, Test Loss: 0.3191, Train Accuracy: 56.1713, Test Accuracy: 55.5556, Avg. duration: 0.0274 s\n",
      "Epoch: 706, Train Loss: 0.2729, Test Loss: 0.3191, Train Accuracy: 56.1713, Test Accuracy: 55.5556, Avg. duration: 0.0271 s\n",
      "Epoch: 707, Train Loss: 0.2729, Test Loss: 0.3191, Train Accuracy: 56.1713, Test Accuracy: 55.5556, Avg. duration: 0.0275 s\n",
      "Epoch: 708, Train Loss: 0.2729, Test Loss: 0.3191, Train Accuracy: 56.1713, Test Accuracy: 55.5556, Avg. duration: 0.0271 s\n",
      "Epoch: 709, Train Loss: 0.2729, Test Loss: 0.3191, Train Accuracy: 56.1713, Test Accuracy: 55.5556, Avg. duration: 0.0276 s\n",
      "Epoch: 710, Train Loss: 0.2729, Test Loss: 0.3191, Train Accuracy: 56.1713, Test Accuracy: 55.5556, Avg. duration: 0.0271 s\n",
      "Epoch: 711, Train Loss: 0.2729, Test Loss: 0.3191, Train Accuracy: 56.1713, Test Accuracy: 55.5556, Avg. duration: 0.0272 s\n",
      "Epoch: 712, Train Loss: 0.2729, Test Loss: 0.3191, Train Accuracy: 56.1713, Test Accuracy: 55.5556, Avg. duration: 0.0270 s\n",
      "Epoch: 713, Train Loss: 0.2729, Test Loss: 0.3191, Train Accuracy: 56.1713, Test Accuracy: 55.5556, Avg. duration: 0.0274 s\n",
      "Epoch: 714, Train Loss: 0.2729, Test Loss: 0.3191, Train Accuracy: 56.1713, Test Accuracy: 55.5556, Avg. duration: 0.0273 s\n",
      "Epoch: 715, Train Loss: 0.2729, Test Loss: 0.3191, Train Accuracy: 56.1713, Test Accuracy: 55.5556, Avg. duration: 0.0271 s\n",
      "Epoch: 716, Train Loss: 0.2729, Test Loss: 0.3191, Train Accuracy: 56.1713, Test Accuracy: 55.5556, Avg. duration: 0.0270 s\n",
      "Epoch: 717, Train Loss: 0.2729, Test Loss: 0.3191, Train Accuracy: 56.1713, Test Accuracy: 55.5556, Avg. duration: 0.0277 s\n",
      "Epoch: 718, Train Loss: 0.2729, Test Loss: 0.3191, Train Accuracy: 56.1713, Test Accuracy: 55.5556, Avg. duration: 0.0273 s\n",
      "Epoch: 719, Train Loss: 0.2729, Test Loss: 0.3191, Train Accuracy: 56.1713, Test Accuracy: 55.5556, Avg. duration: 0.0272 s\n",
      "Epoch: 720, Train Loss: 0.2729, Test Loss: 0.3191, Train Accuracy: 56.1713, Test Accuracy: 55.5556, Avg. duration: 0.0275 s\n",
      "Epoch: 721, Train Loss: 0.2729, Test Loss: 0.3191, Train Accuracy: 56.1713, Test Accuracy: 55.5556, Avg. duration: 0.0269 s\n",
      "Epoch: 722, Train Loss: 0.2729, Test Loss: 0.3191, Train Accuracy: 56.1713, Test Accuracy: 55.5556, Avg. duration: 0.0268 s\n",
      "Epoch: 723, Train Loss: 0.2729, Test Loss: 0.3191, Train Accuracy: 56.1713, Test Accuracy: 55.5556, Avg. duration: 0.0269 s\n",
      "Epoch: 724, Train Loss: 0.2729, Test Loss: 0.3191, Train Accuracy: 56.1713, Test Accuracy: 55.5556, Avg. duration: 0.0273 s\n",
      "Epoch: 725, Train Loss: 0.2729, Test Loss: 0.3191, Train Accuracy: 56.1713, Test Accuracy: 55.5556, Avg. duration: 0.0278 s\n",
      "Epoch: 726, Train Loss: 0.2729, Test Loss: 0.3191, Train Accuracy: 56.1713, Test Accuracy: 55.5556, Avg. duration: 0.0274 s\n",
      "Epoch: 727, Train Loss: 0.2729, Test Loss: 0.3191, Train Accuracy: 56.1713, Test Accuracy: 55.5556, Avg. duration: 0.0269 s\n",
      "Epoch: 728, Train Loss: 0.2729, Test Loss: 0.3191, Train Accuracy: 56.1713, Test Accuracy: 55.5556, Avg. duration: 0.0270 s\n",
      "Epoch: 729, Train Loss: 0.2729, Test Loss: 0.3191, Train Accuracy: 56.1713, Test Accuracy: 55.5556, Avg. duration: 0.0269 s\n",
      "Epoch: 730, Train Loss: 0.2729, Test Loss: 0.3191, Train Accuracy: 56.1713, Test Accuracy: 55.5556, Avg. duration: 0.0268 s\n",
      "Epoch: 731, Train Loss: 0.2729, Test Loss: 0.3191, Train Accuracy: 56.1713, Test Accuracy: 55.5556, Avg. duration: 0.0273 s\n",
      "Epoch: 732, Train Loss: 0.2729, Test Loss: 0.3191, Train Accuracy: 56.1713, Test Accuracy: 55.5556, Avg. duration: 0.0273 s\n",
      "Epoch: 733, Train Loss: 0.2729, Test Loss: 0.3191, Train Accuracy: 56.1713, Test Accuracy: 55.5556, Avg. duration: 0.0275 s\n",
      "Epoch: 734, Train Loss: 0.2729, Test Loss: 0.3191, Train Accuracy: 56.1713, Test Accuracy: 55.5556, Avg. duration: 0.0272 s\n",
      "Epoch: 735, Train Loss: 0.2729, Test Loss: 0.3191, Train Accuracy: 56.1713, Test Accuracy: 55.5556, Avg. duration: 0.0274 s\n",
      "Epoch: 736, Train Loss: 0.2729, Test Loss: 0.3191, Train Accuracy: 56.1713, Test Accuracy: 55.5556, Avg. duration: 0.0271 s\n",
      "Epoch: 737, Train Loss: 0.2729, Test Loss: 0.3191, Train Accuracy: 56.1713, Test Accuracy: 55.5556, Avg. duration: 0.0275 s\n",
      "Epoch: 738, Train Loss: 0.2729, Test Loss: 0.3191, Train Accuracy: 56.1713, Test Accuracy: 55.5556, Avg. duration: 0.0275 s\n",
      "Epoch: 739, Train Loss: 0.2729, Test Loss: 0.3191, Train Accuracy: 56.1713, Test Accuracy: 55.5556, Avg. duration: 0.0277 s\n",
      "Epoch: 740, Train Loss: 0.2729, Test Loss: 0.3191, Train Accuracy: 56.1713, Test Accuracy: 55.5556, Avg. duration: 0.0269 s\n",
      "Epoch: 741, Train Loss: 0.2729, Test Loss: 0.3191, Train Accuracy: 56.1713, Test Accuracy: 55.5556, Avg. duration: 0.0277 s\n",
      "Epoch: 742, Train Loss: 0.2729, Test Loss: 0.3191, Train Accuracy: 56.1713, Test Accuracy: 55.5556, Avg. duration: 0.0275 s\n",
      "Epoch: 743, Train Loss: 0.2729, Test Loss: 0.3191, Train Accuracy: 56.1713, Test Accuracy: 55.5556, Avg. duration: 0.0273 s\n",
      "Epoch: 744, Train Loss: 0.2729, Test Loss: 0.3191, Train Accuracy: 56.1713, Test Accuracy: 55.5556, Avg. duration: 0.0273 s\n",
      "Epoch: 745, Train Loss: 0.2729, Test Loss: 0.3191, Train Accuracy: 56.1713, Test Accuracy: 55.5556, Avg. duration: 0.0271 s\n",
      "Epoch: 746, Train Loss: 0.2729, Test Loss: 0.3191, Train Accuracy: 56.1713, Test Accuracy: 55.5556, Avg. duration: 0.0274 s\n",
      "Epoch: 747, Train Loss: 0.2729, Test Loss: 0.3191, Train Accuracy: 56.1713, Test Accuracy: 55.5556, Avg. duration: 0.0271 s\n",
      "Epoch: 748, Train Loss: 0.2729, Test Loss: 0.3191, Train Accuracy: 56.1713, Test Accuracy: 55.5556, Avg. duration: 0.0272 s\n",
      "Epoch: 749, Train Loss: 0.2729, Test Loss: 0.3191, Train Accuracy: 56.1713, Test Accuracy: 55.5556, Avg. duration: 0.3167 s\n",
      "Epoch: 750, Train Loss: 0.2729, Test Loss: 0.3191, Train Accuracy: 56.1713, Test Accuracy: 55.5556, Avg. duration: 0.0284 s\n",
      "Epoch: 751, Train Loss: 0.2729, Test Loss: 0.3191, Train Accuracy: 56.1713, Test Accuracy: 55.5556, Avg. duration: 0.0276 s\n",
      "Epoch: 752, Train Loss: 0.2729, Test Loss: 0.3191, Train Accuracy: 56.1713, Test Accuracy: 55.5556, Avg. duration: 0.0276 s\n",
      "Epoch: 753, Train Loss: 0.2729, Test Loss: 0.3191, Train Accuracy: 56.1713, Test Accuracy: 55.5556, Avg. duration: 0.0277 s\n",
      "Epoch: 754, Train Loss: 0.2729, Test Loss: 0.3191, Train Accuracy: 56.1713, Test Accuracy: 55.5556, Avg. duration: 0.0278 s\n",
      "Epoch: 755, Train Loss: 0.2729, Test Loss: 0.3191, Train Accuracy: 56.1713, Test Accuracy: 55.5556, Avg. duration: 0.0278 s\n",
      "Epoch: 756, Train Loss: 0.2729, Test Loss: 0.3191, Train Accuracy: 56.1713, Test Accuracy: 55.5556, Avg. duration: 0.0271 s\n",
      "Epoch: 757, Train Loss: 0.2729, Test Loss: 0.3191, Train Accuracy: 56.1713, Test Accuracy: 55.5556, Avg. duration: 0.0280 s\n",
      "Epoch: 758, Train Loss: 0.2729, Test Loss: 0.3191, Train Accuracy: 56.1713, Test Accuracy: 55.5556, Avg. duration: 0.0273 s\n",
      "Epoch: 759, Train Loss: 0.2729, Test Loss: 0.3191, Train Accuracy: 56.1713, Test Accuracy: 55.5556, Avg. duration: 0.0275 s\n",
      "Epoch: 760, Train Loss: 0.2729, Test Loss: 0.3191, Train Accuracy: 56.1713, Test Accuracy: 55.5556, Avg. duration: 0.0274 s\n",
      "Epoch: 761, Train Loss: 0.2729, Test Loss: 0.3191, Train Accuracy: 56.1713, Test Accuracy: 55.5556, Avg. duration: 0.0279 s\n",
      "Epoch: 762, Train Loss: 0.2729, Test Loss: 0.3191, Train Accuracy: 56.1713, Test Accuracy: 55.5556, Avg. duration: 0.0272 s\n",
      "Epoch: 763, Train Loss: 0.2729, Test Loss: 0.3191, Train Accuracy: 56.1713, Test Accuracy: 55.5556, Avg. duration: 0.0274 s\n",
      "Epoch: 764, Train Loss: 0.2729, Test Loss: 0.3191, Train Accuracy: 56.1713, Test Accuracy: 55.5556, Avg. duration: 0.0274 s\n",
      "Epoch: 765, Train Loss: 0.2729, Test Loss: 0.3191, Train Accuracy: 56.1713, Test Accuracy: 55.5556, Avg. duration: 0.0281 s\n",
      "Epoch: 766, Train Loss: 0.2729, Test Loss: 0.3191, Train Accuracy: 56.1713, Test Accuracy: 55.5556, Avg. duration: 0.0278 s\n",
      "Epoch: 767, Train Loss: 0.2729, Test Loss: 0.3191, Train Accuracy: 56.1713, Test Accuracy: 55.5556, Avg. duration: 0.0278 s\n",
      "Epoch: 768, Train Loss: 0.2729, Test Loss: 0.3191, Train Accuracy: 56.1713, Test Accuracy: 55.5556, Avg. duration: 0.0271 s\n",
      "Epoch: 769, Train Loss: 0.2729, Test Loss: 0.3191, Train Accuracy: 56.1713, Test Accuracy: 55.5556, Avg. duration: 0.0273 s\n",
      "Epoch: 770, Train Loss: 0.2729, Test Loss: 0.3191, Train Accuracy: 56.1713, Test Accuracy: 55.5556, Avg. duration: 0.0276 s\n",
      "Epoch: 771, Train Loss: 0.2729, Test Loss: 0.3191, Train Accuracy: 56.1713, Test Accuracy: 55.5556, Avg. duration: 0.0278 s\n",
      "Epoch: 772, Train Loss: 0.2729, Test Loss: 0.3191, Train Accuracy: 56.1713, Test Accuracy: 55.5556, Avg. duration: 0.0274 s\n",
      "Epoch: 773, Train Loss: 0.2729, Test Loss: 0.3191, Train Accuracy: 56.1713, Test Accuracy: 55.5556, Avg. duration: 0.0283 s\n",
      "Epoch: 774, Train Loss: 0.2729, Test Loss: 0.3191, Train Accuracy: 56.1713, Test Accuracy: 55.5556, Avg. duration: 0.0274 s\n",
      "Epoch: 775, Train Loss: 0.2729, Test Loss: 0.3191, Train Accuracy: 56.1713, Test Accuracy: 55.5556, Avg. duration: 0.0276 s\n",
      "Epoch: 776, Train Loss: 0.2729, Test Loss: 0.3191, Train Accuracy: 56.1713, Test Accuracy: 55.5556, Avg. duration: 0.0273 s\n",
      "Epoch: 777, Train Loss: 0.2729, Test Loss: 0.3191, Train Accuracy: 56.1713, Test Accuracy: 55.5556, Avg. duration: 0.0275 s\n",
      "Epoch: 778, Train Loss: 0.2729, Test Loss: 0.3191, Train Accuracy: 56.1713, Test Accuracy: 55.5556, Avg. duration: 0.0276 s\n",
      "Epoch: 779, Train Loss: 0.2729, Test Loss: 0.3191, Train Accuracy: 56.1713, Test Accuracy: 55.5556, Avg. duration: 0.0278 s\n",
      "Epoch: 780, Train Loss: 0.2729, Test Loss: 0.3191, Train Accuracy: 56.1713, Test Accuracy: 55.5556, Avg. duration: 0.0275 s\n",
      "Epoch: 781, Train Loss: 0.2729, Test Loss: 0.3191, Train Accuracy: 56.1713, Test Accuracy: 55.5556, Avg. duration: 0.0279 s\n",
      "Epoch: 782, Train Loss: 0.2729, Test Loss: 0.3191, Train Accuracy: 56.1713, Test Accuracy: 55.5556, Avg. duration: 0.0277 s\n",
      "Epoch: 783, Train Loss: 0.2729, Test Loss: 0.3191, Train Accuracy: 56.1713, Test Accuracy: 55.5556, Avg. duration: 0.0276 s\n",
      "Epoch: 784, Train Loss: 0.2729, Test Loss: 0.3191, Train Accuracy: 56.1713, Test Accuracy: 55.5556, Avg. duration: 0.0278 s\n",
      "Epoch: 785, Train Loss: 0.2729, Test Loss: 0.3191, Train Accuracy: 56.1713, Test Accuracy: 55.5556, Avg. duration: 0.0278 s\n",
      "Epoch: 786, Train Loss: 0.2729, Test Loss: 0.3191, Train Accuracy: 56.1713, Test Accuracy: 55.5556, Avg. duration: 0.0272 s\n",
      "Epoch: 787, Train Loss: 0.2729, Test Loss: 0.3191, Train Accuracy: 56.1713, Test Accuracy: 55.5556, Avg. duration: 0.0272 s\n",
      "Epoch: 788, Train Loss: 0.2729, Test Loss: 0.3191, Train Accuracy: 56.1713, Test Accuracy: 55.5556, Avg. duration: 0.0273 s\n",
      "Epoch: 789, Train Loss: 0.2729, Test Loss: 0.3191, Train Accuracy: 56.1713, Test Accuracy: 55.5556, Avg. duration: 0.0282 s\n",
      "Epoch: 790, Train Loss: 0.2729, Test Loss: 0.3191, Train Accuracy: 56.1713, Test Accuracy: 55.5556, Avg. duration: 0.0279 s\n",
      "Epoch: 791, Train Loss: 0.2729, Test Loss: 0.3191, Train Accuracy: 56.1713, Test Accuracy: 55.5556, Avg. duration: 0.0278 s\n",
      "Epoch: 792, Train Loss: 0.2729, Test Loss: 0.3191, Train Accuracy: 56.1713, Test Accuracy: 55.5556, Avg. duration: 0.0270 s\n",
      "Epoch: 793, Train Loss: 0.2729, Test Loss: 0.3191, Train Accuracy: 56.1713, Test Accuracy: 55.5556, Avg. duration: 0.0274 s\n",
      "Epoch: 794, Train Loss: 0.2729, Test Loss: 0.3191, Train Accuracy: 56.1713, Test Accuracy: 55.5556, Avg. duration: 0.0276 s\n",
      "Epoch: 795, Train Loss: 0.2729, Test Loss: 0.3191, Train Accuracy: 56.1713, Test Accuracy: 55.5556, Avg. duration: 0.0278 s\n",
      "Epoch: 796, Train Loss: 0.2729, Test Loss: 0.3191, Train Accuracy: 56.1713, Test Accuracy: 55.5556, Avg. duration: 0.0277 s\n",
      "Epoch: 797, Train Loss: 0.2729, Test Loss: 0.3191, Train Accuracy: 56.1713, Test Accuracy: 55.5556, Avg. duration: 0.0281 s\n",
      "Epoch: 798, Train Loss: 0.2729, Test Loss: 0.3191, Train Accuracy: 56.1713, Test Accuracy: 55.5556, Avg. duration: 0.0275 s\n",
      "Epoch: 799, Train Loss: 0.2729, Test Loss: 0.3191, Train Accuracy: 56.1713, Test Accuracy: 55.5556, Avg. duration: 0.0276 s\n",
      "Epoch: 800, Train Loss: 0.2729, Test Loss: 0.3191, Train Accuracy: 56.1713, Test Accuracy: 55.5556, Avg. duration: 0.0277 s\n",
      "Epoch: 801, Train Loss: 0.2635, Test Loss: 0.3128, Train Accuracy: 58.4383, Test Accuracy: 57.5758, Avg. duration: 2.7328 s\n",
      "Epoch: 802, Train Loss: 0.2635, Test Loss: 0.3128, Train Accuracy: 58.4383, Test Accuracy: 57.5758, Avg. duration: 0.0298 s\n",
      "Epoch: 803, Train Loss: 0.2635, Test Loss: 0.3128, Train Accuracy: 58.4383, Test Accuracy: 57.5758, Avg. duration: 0.0278 s\n",
      "Epoch: 804, Train Loss: 0.2635, Test Loss: 0.3128, Train Accuracy: 58.4383, Test Accuracy: 57.5758, Avg. duration: 0.0271 s\n",
      "Epoch: 805, Train Loss: 0.2635, Test Loss: 0.3128, Train Accuracy: 58.4383, Test Accuracy: 57.5758, Avg. duration: 0.0271 s\n",
      "Epoch: 806, Train Loss: 0.2635, Test Loss: 0.3128, Train Accuracy: 58.4383, Test Accuracy: 57.5758, Avg. duration: 0.0269 s\n",
      "Epoch: 807, Train Loss: 0.2635, Test Loss: 0.3128, Train Accuracy: 58.4383, Test Accuracy: 57.5758, Avg. duration: 0.0271 s\n",
      "Epoch: 808, Train Loss: 0.2635, Test Loss: 0.3128, Train Accuracy: 58.4383, Test Accuracy: 57.5758, Avg. duration: 0.0272 s\n",
      "Epoch: 809, Train Loss: 0.2635, Test Loss: 0.3128, Train Accuracy: 58.4383, Test Accuracy: 57.5758, Avg. duration: 0.0278 s\n",
      "Epoch: 810, Train Loss: 0.2635, Test Loss: 0.3128, Train Accuracy: 58.4383, Test Accuracy: 57.5758, Avg. duration: 0.0272 s\n",
      "Epoch: 811, Train Loss: 0.2635, Test Loss: 0.3128, Train Accuracy: 58.4383, Test Accuracy: 57.5758, Avg. duration: 0.0277 s\n",
      "Epoch: 812, Train Loss: 0.2635, Test Loss: 0.3128, Train Accuracy: 58.4383, Test Accuracy: 57.5758, Avg. duration: 0.0271 s\n",
      "Epoch: 813, Train Loss: 0.2635, Test Loss: 0.3128, Train Accuracy: 58.4383, Test Accuracy: 57.5758, Avg. duration: 0.0270 s\n",
      "Epoch: 814, Train Loss: 0.2635, Test Loss: 0.3128, Train Accuracy: 58.4383, Test Accuracy: 57.5758, Avg. duration: 0.0274 s\n",
      "Epoch: 815, Train Loss: 0.2635, Test Loss: 0.3128, Train Accuracy: 58.4383, Test Accuracy: 57.5758, Avg. duration: 0.0272 s\n",
      "Epoch: 816, Train Loss: 0.2635, Test Loss: 0.3128, Train Accuracy: 58.4383, Test Accuracy: 57.5758, Avg. duration: 0.0270 s\n",
      "Epoch: 817, Train Loss: 0.2635, Test Loss: 0.3128, Train Accuracy: 58.4383, Test Accuracy: 57.5758, Avg. duration: 0.0273 s\n",
      "Epoch: 818, Train Loss: 0.2635, Test Loss: 0.3128, Train Accuracy: 58.4383, Test Accuracy: 57.5758, Avg. duration: 0.0271 s\n",
      "Epoch: 819, Train Loss: 0.2635, Test Loss: 0.3128, Train Accuracy: 58.4383, Test Accuracy: 57.5758, Avg. duration: 0.0271 s\n",
      "Epoch: 820, Train Loss: 0.2635, Test Loss: 0.3128, Train Accuracy: 58.4383, Test Accuracy: 57.5758, Avg. duration: 0.0274 s\n",
      "Epoch: 821, Train Loss: 0.2635, Test Loss: 0.3128, Train Accuracy: 58.4383, Test Accuracy: 57.5758, Avg. duration: 0.0271 s\n",
      "Epoch: 822, Train Loss: 0.2635, Test Loss: 0.3128, Train Accuracy: 58.4383, Test Accuracy: 57.5758, Avg. duration: 0.0267 s\n",
      "Epoch: 823, Train Loss: 0.2635, Test Loss: 0.3128, Train Accuracy: 58.4383, Test Accuracy: 57.5758, Avg. duration: 0.0267 s\n",
      "Epoch: 824, Train Loss: 0.2635, Test Loss: 0.3128, Train Accuracy: 58.4383, Test Accuracy: 57.5758, Avg. duration: 0.0269 s\n",
      "Epoch: 825, Train Loss: 0.2635, Test Loss: 0.3128, Train Accuracy: 58.4383, Test Accuracy: 57.5758, Avg. duration: 0.3062 s\n",
      "Epoch: 826, Train Loss: 0.2635, Test Loss: 0.3128, Train Accuracy: 58.4383, Test Accuracy: 57.5758, Avg. duration: 0.0281 s\n",
      "Epoch: 827, Train Loss: 0.2635, Test Loss: 0.3128, Train Accuracy: 58.4383, Test Accuracy: 57.5758, Avg. duration: 0.0278 s\n",
      "Epoch: 828, Train Loss: 0.2635, Test Loss: 0.3128, Train Accuracy: 58.4383, Test Accuracy: 57.5758, Avg. duration: 0.0269 s\n",
      "Epoch: 829, Train Loss: 0.2635, Test Loss: 0.3128, Train Accuracy: 58.4383, Test Accuracy: 57.5758, Avg. duration: 0.0269 s\n",
      "Epoch: 830, Train Loss: 0.2635, Test Loss: 0.3128, Train Accuracy: 58.4383, Test Accuracy: 57.5758, Avg. duration: 0.0276 s\n",
      "Epoch: 831, Train Loss: 0.2635, Test Loss: 0.3128, Train Accuracy: 58.4383, Test Accuracy: 57.5758, Avg. duration: 0.0273 s\n",
      "Epoch: 832, Train Loss: 0.2635, Test Loss: 0.3128, Train Accuracy: 58.4383, Test Accuracy: 57.5758, Avg. duration: 0.0272 s\n",
      "Epoch: 833, Train Loss: 0.2635, Test Loss: 0.3128, Train Accuracy: 58.4383, Test Accuracy: 57.5758, Avg. duration: 0.0278 s\n",
      "Epoch: 834, Train Loss: 0.2635, Test Loss: 0.3128, Train Accuracy: 58.4383, Test Accuracy: 57.5758, Avg. duration: 0.0271 s\n",
      "Epoch: 835, Train Loss: 0.2635, Test Loss: 0.3128, Train Accuracy: 58.4383, Test Accuracy: 57.5758, Avg. duration: 0.0270 s\n",
      "Epoch: 836, Train Loss: 0.2635, Test Loss: 0.3128, Train Accuracy: 58.4383, Test Accuracy: 57.5758, Avg. duration: 0.0270 s\n",
      "Epoch: 837, Train Loss: 0.2635, Test Loss: 0.3128, Train Accuracy: 58.4383, Test Accuracy: 57.5758, Avg. duration: 0.0273 s\n",
      "Epoch: 838, Train Loss: 0.2635, Test Loss: 0.3128, Train Accuracy: 58.4383, Test Accuracy: 57.5758, Avg. duration: 0.0275 s\n",
      "Epoch: 839, Train Loss: 0.2635, Test Loss: 0.3128, Train Accuracy: 58.4383, Test Accuracy: 57.5758, Avg. duration: 0.0272 s\n",
      "Epoch: 840, Train Loss: 0.2635, Test Loss: 0.3128, Train Accuracy: 58.4383, Test Accuracy: 57.5758, Avg. duration: 0.0268 s\n",
      "Epoch: 841, Train Loss: 0.2635, Test Loss: 0.3128, Train Accuracy: 58.4383, Test Accuracy: 57.5758, Avg. duration: 0.0277 s\n",
      "Epoch: 842, Train Loss: 0.2635, Test Loss: 0.3128, Train Accuracy: 58.4383, Test Accuracy: 57.5758, Avg. duration: 0.0271 s\n",
      "Epoch: 843, Train Loss: 0.2635, Test Loss: 0.3128, Train Accuracy: 58.4383, Test Accuracy: 57.5758, Avg. duration: 0.0272 s\n",
      "Epoch: 844, Train Loss: 0.2635, Test Loss: 0.3128, Train Accuracy: 58.4383, Test Accuracy: 57.5758, Avg. duration: 0.0276 s\n",
      "Epoch: 845, Train Loss: 0.2635, Test Loss: 0.3128, Train Accuracy: 58.4383, Test Accuracy: 57.5758, Avg. duration: 0.0277 s\n",
      "Epoch: 846, Train Loss: 0.2635, Test Loss: 0.3128, Train Accuracy: 58.4383, Test Accuracy: 57.5758, Avg. duration: 0.0269 s\n",
      "Epoch: 847, Train Loss: 0.2635, Test Loss: 0.3128, Train Accuracy: 58.4383, Test Accuracy: 57.5758, Avg. duration: 0.0269 s\n",
      "Epoch: 848, Train Loss: 0.2635, Test Loss: 0.3128, Train Accuracy: 58.4383, Test Accuracy: 57.5758, Avg. duration: 0.0274 s\n",
      "Epoch: 849, Train Loss: 0.2635, Test Loss: 0.3128, Train Accuracy: 58.4383, Test Accuracy: 57.5758, Avg. duration: 0.0278 s\n",
      "Epoch: 850, Train Loss: 0.2635, Test Loss: 0.3128, Train Accuracy: 58.4383, Test Accuracy: 57.5758, Avg. duration: 0.0275 s\n",
      "Epoch: 851, Train Loss: 0.2635, Test Loss: 0.3128, Train Accuracy: 58.4383, Test Accuracy: 57.5758, Avg. duration: 0.0272 s\n",
      "Epoch: 852, Train Loss: 0.2635, Test Loss: 0.3128, Train Accuracy: 58.4383, Test Accuracy: 57.5758, Avg. duration: 0.0276 s\n",
      "Epoch: 853, Train Loss: 0.2635, Test Loss: 0.3128, Train Accuracy: 58.4383, Test Accuracy: 57.5758, Avg. duration: 0.0278 s\n",
      "Epoch: 854, Train Loss: 0.2635, Test Loss: 0.3128, Train Accuracy: 58.4383, Test Accuracy: 57.5758, Avg. duration: 0.0278 s\n",
      "Epoch: 855, Train Loss: 0.2635, Test Loss: 0.3128, Train Accuracy: 58.4383, Test Accuracy: 57.5758, Avg. duration: 0.0272 s\n",
      "Epoch: 856, Train Loss: 0.2635, Test Loss: 0.3128, Train Accuracy: 58.4383, Test Accuracy: 57.5758, Avg. duration: 0.0276 s\n",
      "Epoch: 857, Train Loss: 0.2635, Test Loss: 0.3128, Train Accuracy: 58.4383, Test Accuracy: 57.5758, Avg. duration: 0.0281 s\n",
      "Epoch: 858, Train Loss: 0.2635, Test Loss: 0.3128, Train Accuracy: 58.4383, Test Accuracy: 57.5758, Avg. duration: 0.0271 s\n",
      "Epoch: 859, Train Loss: 0.2635, Test Loss: 0.3128, Train Accuracy: 58.4383, Test Accuracy: 57.5758, Avg. duration: 0.0276 s\n",
      "Epoch: 860, Train Loss: 0.2635, Test Loss: 0.3128, Train Accuracy: 58.4383, Test Accuracy: 57.5758, Avg. duration: 0.0275 s\n",
      "Epoch: 861, Train Loss: 0.2635, Test Loss: 0.3128, Train Accuracy: 58.4383, Test Accuracy: 57.5758, Avg. duration: 0.0276 s\n",
      "Epoch: 862, Train Loss: 0.2635, Test Loss: 0.3128, Train Accuracy: 58.4383, Test Accuracy: 57.5758, Avg. duration: 0.0279 s\n",
      "Epoch: 863, Train Loss: 0.2635, Test Loss: 0.3128, Train Accuracy: 58.4383, Test Accuracy: 57.5758, Avg. duration: 0.0278 s\n",
      "Epoch: 864, Train Loss: 0.2635, Test Loss: 0.3128, Train Accuracy: 58.4383, Test Accuracy: 57.5758, Avg. duration: 0.0271 s\n",
      "Epoch: 865, Train Loss: 0.2635, Test Loss: 0.3128, Train Accuracy: 58.4383, Test Accuracy: 57.5758, Avg. duration: 0.0277 s\n",
      "Epoch: 866, Train Loss: 0.2635, Test Loss: 0.3128, Train Accuracy: 58.4383, Test Accuracy: 57.5758, Avg. duration: 0.0276 s\n",
      "Epoch: 867, Train Loss: 0.2635, Test Loss: 0.3128, Train Accuracy: 58.4383, Test Accuracy: 57.5758, Avg. duration: 0.0277 s\n",
      "Epoch: 868, Train Loss: 0.2635, Test Loss: 0.3128, Train Accuracy: 58.4383, Test Accuracy: 57.5758, Avg. duration: 0.0274 s\n",
      "Epoch: 869, Train Loss: 0.2635, Test Loss: 0.3128, Train Accuracy: 58.4383, Test Accuracy: 57.5758, Avg. duration: 0.0273 s\n",
      "Epoch: 870, Train Loss: 0.2635, Test Loss: 0.3128, Train Accuracy: 58.4383, Test Accuracy: 57.5758, Avg. duration: 0.0275 s\n",
      "Epoch: 871, Train Loss: 0.2635, Test Loss: 0.3128, Train Accuracy: 58.4383, Test Accuracy: 57.5758, Avg. duration: 0.0278 s\n",
      "Epoch: 872, Train Loss: 0.2635, Test Loss: 0.3128, Train Accuracy: 58.4383, Test Accuracy: 57.5758, Avg. duration: 0.0276 s\n",
      "Epoch: 873, Train Loss: 0.2635, Test Loss: 0.3128, Train Accuracy: 58.4383, Test Accuracy: 57.5758, Avg. duration: 0.0281 s\n",
      "Epoch: 874, Train Loss: 0.2635, Test Loss: 0.3128, Train Accuracy: 58.4383, Test Accuracy: 57.5758, Avg. duration: 0.0275 s\n",
      "Epoch: 875, Train Loss: 0.2635, Test Loss: 0.3128, Train Accuracy: 58.4383, Test Accuracy: 57.5758, Avg. duration: 0.0277 s\n",
      "Epoch: 876, Train Loss: 0.2635, Test Loss: 0.3128, Train Accuracy: 58.4383, Test Accuracy: 57.5758, Avg. duration: 0.0274 s\n",
      "Epoch: 877, Train Loss: 0.2635, Test Loss: 0.3128, Train Accuracy: 58.4383, Test Accuracy: 57.5758, Avg. duration: 0.0276 s\n",
      "Epoch: 878, Train Loss: 0.2635, Test Loss: 0.3128, Train Accuracy: 58.4383, Test Accuracy: 57.5758, Avg. duration: 0.0273 s\n",
      "Epoch: 879, Train Loss: 0.2635, Test Loss: 0.3128, Train Accuracy: 58.4383, Test Accuracy: 57.5758, Avg. duration: 0.0276 s\n",
      "Epoch: 880, Train Loss: 0.2635, Test Loss: 0.3128, Train Accuracy: 58.4383, Test Accuracy: 57.5758, Avg. duration: 0.0278 s\n",
      "Epoch: 881, Train Loss: 0.2635, Test Loss: 0.3128, Train Accuracy: 58.4383, Test Accuracy: 57.5758, Avg. duration: 0.0282 s\n",
      "Epoch: 882, Train Loss: 0.2635, Test Loss: 0.3128, Train Accuracy: 58.4383, Test Accuracy: 57.5758, Avg. duration: 0.0272 s\n",
      "Epoch: 883, Train Loss: 0.2635, Test Loss: 0.3128, Train Accuracy: 58.4383, Test Accuracy: 57.5758, Avg. duration: 0.0277 s\n",
      "Epoch: 884, Train Loss: 0.2635, Test Loss: 0.3128, Train Accuracy: 58.4383, Test Accuracy: 57.5758, Avg. duration: 0.0276 s\n",
      "Epoch: 885, Train Loss: 0.2635, Test Loss: 0.3128, Train Accuracy: 58.4383, Test Accuracy: 57.5758, Avg. duration: 0.0277 s\n",
      "Epoch: 886, Train Loss: 0.2635, Test Loss: 0.3128, Train Accuracy: 58.4383, Test Accuracy: 57.5758, Avg. duration: 0.0279 s\n",
      "Epoch: 887, Train Loss: 0.2635, Test Loss: 0.3128, Train Accuracy: 58.4383, Test Accuracy: 57.5758, Avg. duration: 0.0277 s\n",
      "Epoch: 888, Train Loss: 0.2635, Test Loss: 0.3128, Train Accuracy: 58.4383, Test Accuracy: 57.5758, Avg. duration: 0.0274 s\n",
      "Epoch: 889, Train Loss: 0.2635, Test Loss: 0.3128, Train Accuracy: 58.4383, Test Accuracy: 57.5758, Avg. duration: 0.0280 s\n",
      "Epoch: 890, Train Loss: 0.2635, Test Loss: 0.3128, Train Accuracy: 58.4383, Test Accuracy: 57.5758, Avg. duration: 0.0278 s\n",
      "Epoch: 891, Train Loss: 0.2635, Test Loss: 0.3128, Train Accuracy: 58.4383, Test Accuracy: 57.5758, Avg. duration: 0.0278 s\n",
      "Epoch: 892, Train Loss: 0.2635, Test Loss: 0.3128, Train Accuracy: 58.4383, Test Accuracy: 57.5758, Avg. duration: 0.3084 s\n",
      "Epoch: 893, Train Loss: 0.2635, Test Loss: 0.3128, Train Accuracy: 58.4383, Test Accuracy: 57.5758, Avg. duration: 0.0286 s\n",
      "Epoch: 894, Train Loss: 0.2635, Test Loss: 0.3128, Train Accuracy: 58.4383, Test Accuracy: 57.5758, Avg. duration: 0.0279 s\n",
      "Epoch: 895, Train Loss: 0.2635, Test Loss: 0.3128, Train Accuracy: 58.4383, Test Accuracy: 57.5758, Avg. duration: 0.0278 s\n",
      "Epoch: 896, Train Loss: 0.2635, Test Loss: 0.3128, Train Accuracy: 58.4383, Test Accuracy: 57.5758, Avg. duration: 0.0279 s\n",
      "Epoch: 897, Train Loss: 0.2635, Test Loss: 0.3128, Train Accuracy: 58.4383, Test Accuracy: 57.5758, Avg. duration: 0.0280 s\n",
      "Epoch: 898, Train Loss: 0.2635, Test Loss: 0.3128, Train Accuracy: 58.4383, Test Accuracy: 57.5758, Avg. duration: 0.0277 s\n",
      "Epoch: 899, Train Loss: 0.2635, Test Loss: 0.3128, Train Accuracy: 58.4383, Test Accuracy: 57.5758, Avg. duration: 0.0277 s\n",
      "Epoch: 900, Train Loss: 0.2635, Test Loss: 0.3128, Train Accuracy: 58.4383, Test Accuracy: 57.5758, Avg. duration: 0.0281 s\n",
      "Epoch: 901, Train Loss: 0.2550, Test Loss: 0.3074, Train Accuracy: 58.9421, Test Accuracy: 59.5960, Avg. duration: 2.7317 s\n",
      "Epoch: 902, Train Loss: 0.2550, Test Loss: 0.3074, Train Accuracy: 58.9421, Test Accuracy: 59.5960, Avg. duration: 0.0291 s\n",
      "Epoch: 903, Train Loss: 0.2550, Test Loss: 0.3074, Train Accuracy: 58.9421, Test Accuracy: 59.5960, Avg. duration: 0.0277 s\n",
      "Epoch: 904, Train Loss: 0.2550, Test Loss: 0.3074, Train Accuracy: 58.9421, Test Accuracy: 59.5960, Avg. duration: 0.0276 s\n",
      "Epoch: 905, Train Loss: 0.2550, Test Loss: 0.3074, Train Accuracy: 58.9421, Test Accuracy: 59.5960, Avg. duration: 0.0270 s\n",
      "Epoch: 906, Train Loss: 0.2550, Test Loss: 0.3074, Train Accuracy: 58.9421, Test Accuracy: 59.5960, Avg. duration: 0.0270 s\n",
      "Epoch: 907, Train Loss: 0.2550, Test Loss: 0.3074, Train Accuracy: 58.9421, Test Accuracy: 59.5960, Avg. duration: 0.0274 s\n",
      "Epoch: 908, Train Loss: 0.2550, Test Loss: 0.3074, Train Accuracy: 58.9421, Test Accuracy: 59.5960, Avg. duration: 0.0273 s\n",
      "Epoch: 909, Train Loss: 0.2550, Test Loss: 0.3074, Train Accuracy: 58.9421, Test Accuracy: 59.5960, Avg. duration: 0.0276 s\n",
      "Epoch: 910, Train Loss: 0.2550, Test Loss: 0.3074, Train Accuracy: 58.9421, Test Accuracy: 59.5960, Avg. duration: 0.0275 s\n",
      "Epoch: 911, Train Loss: 0.2550, Test Loss: 0.3074, Train Accuracy: 58.9421, Test Accuracy: 59.5960, Avg. duration: 0.0272 s\n",
      "Epoch: 912, Train Loss: 0.2550, Test Loss: 0.3074, Train Accuracy: 58.9421, Test Accuracy: 59.5960, Avg. duration: 0.0269 s\n",
      "Epoch: 913, Train Loss: 0.2550, Test Loss: 0.3074, Train Accuracy: 58.9421, Test Accuracy: 59.5960, Avg. duration: 0.0276 s\n",
      "Epoch: 914, Train Loss: 0.2550, Test Loss: 0.3074, Train Accuracy: 58.9421, Test Accuracy: 59.5960, Avg. duration: 0.0270 s\n",
      "Epoch: 915, Train Loss: 0.2550, Test Loss: 0.3074, Train Accuracy: 58.9421, Test Accuracy: 59.5960, Avg. duration: 0.0274 s\n",
      "Epoch: 916, Train Loss: 0.2550, Test Loss: 0.3074, Train Accuracy: 58.9421, Test Accuracy: 59.5960, Avg. duration: 0.0275 s\n",
      "Epoch: 917, Train Loss: 0.2550, Test Loss: 0.3074, Train Accuracy: 58.9421, Test Accuracy: 59.5960, Avg. duration: 0.0273 s\n",
      "Epoch: 918, Train Loss: 0.2550, Test Loss: 0.3074, Train Accuracy: 58.9421, Test Accuracy: 59.5960, Avg. duration: 0.0270 s\n",
      "Epoch: 919, Train Loss: 0.2550, Test Loss: 0.3074, Train Accuracy: 58.9421, Test Accuracy: 59.5960, Avg. duration: 0.0271 s\n",
      "Epoch: 920, Train Loss: 0.2550, Test Loss: 0.3074, Train Accuracy: 58.9421, Test Accuracy: 59.5960, Avg. duration: 0.0268 s\n",
      "Epoch: 921, Train Loss: 0.2550, Test Loss: 0.3074, Train Accuracy: 58.9421, Test Accuracy: 59.5960, Avg. duration: 0.0275 s\n",
      "Epoch: 922, Train Loss: 0.2550, Test Loss: 0.3074, Train Accuracy: 58.9421, Test Accuracy: 59.5960, Avg. duration: 0.0271 s\n",
      "Epoch: 923, Train Loss: 0.2550, Test Loss: 0.3074, Train Accuracy: 58.9421, Test Accuracy: 59.5960, Avg. duration: 0.0268 s\n",
      "Epoch: 924, Train Loss: 0.2550, Test Loss: 0.3074, Train Accuracy: 58.9421, Test Accuracy: 59.5960, Avg. duration: 0.0266 s\n",
      "Epoch: 925, Train Loss: 0.2550, Test Loss: 0.3074, Train Accuracy: 58.9421, Test Accuracy: 59.5960, Avg. duration: 0.0269 s\n",
      "Epoch: 926, Train Loss: 0.2550, Test Loss: 0.3074, Train Accuracy: 58.9421, Test Accuracy: 59.5960, Avg. duration: 0.0275 s\n",
      "Epoch: 927, Train Loss: 0.2550, Test Loss: 0.3074, Train Accuracy: 58.9421, Test Accuracy: 59.5960, Avg. duration: 0.0271 s\n",
      "Epoch: 928, Train Loss: 0.2550, Test Loss: 0.3074, Train Accuracy: 58.9421, Test Accuracy: 59.5960, Avg. duration: 0.0273 s\n",
      "Epoch: 929, Train Loss: 0.2550, Test Loss: 0.3074, Train Accuracy: 58.9421, Test Accuracy: 59.5960, Avg. duration: 0.0267 s\n",
      "Epoch: 930, Train Loss: 0.2550, Test Loss: 0.3074, Train Accuracy: 58.9421, Test Accuracy: 59.5960, Avg. duration: 0.0270 s\n",
      "Epoch: 931, Train Loss: 0.2550, Test Loss: 0.3074, Train Accuracy: 58.9421, Test Accuracy: 59.5960, Avg. duration: 0.0270 s\n",
      "Epoch: 932, Train Loss: 0.2550, Test Loss: 0.3074, Train Accuracy: 58.9421, Test Accuracy: 59.5960, Avg. duration: 0.0274 s\n",
      "Epoch: 933, Train Loss: 0.2550, Test Loss: 0.3074, Train Accuracy: 58.9421, Test Accuracy: 59.5960, Avg. duration: 0.0278 s\n",
      "Epoch: 934, Train Loss: 0.2550, Test Loss: 0.3074, Train Accuracy: 58.9421, Test Accuracy: 59.5960, Avg. duration: 0.0278 s\n",
      "Epoch: 935, Train Loss: 0.2550, Test Loss: 0.3074, Train Accuracy: 58.9421, Test Accuracy: 59.5960, Avg. duration: 0.0270 s\n",
      "Epoch: 936, Train Loss: 0.2550, Test Loss: 0.3074, Train Accuracy: 58.9421, Test Accuracy: 59.5960, Avg. duration: 0.0269 s\n",
      "Epoch: 937, Train Loss: 0.2550, Test Loss: 0.3074, Train Accuracy: 58.9421, Test Accuracy: 59.5960, Avg. duration: 0.0273 s\n",
      "Epoch: 938, Train Loss: 0.2550, Test Loss: 0.3074, Train Accuracy: 58.9421, Test Accuracy: 59.5960, Avg. duration: 0.0272 s\n",
      "Epoch: 939, Train Loss: 0.2550, Test Loss: 0.3074, Train Accuracy: 58.9421, Test Accuracy: 59.5960, Avg. duration: 0.0273 s\n",
      "Epoch: 940, Train Loss: 0.2550, Test Loss: 0.3074, Train Accuracy: 58.9421, Test Accuracy: 59.5960, Avg. duration: 0.0274 s\n",
      "Epoch: 941, Train Loss: 0.2550, Test Loss: 0.3074, Train Accuracy: 58.9421, Test Accuracy: 59.5960, Avg. duration: 0.0273 s\n",
      "Epoch: 942, Train Loss: 0.2550, Test Loss: 0.3074, Train Accuracy: 58.9421, Test Accuracy: 59.5960, Avg. duration: 0.0272 s\n",
      "Epoch: 943, Train Loss: 0.2550, Test Loss: 0.3074, Train Accuracy: 58.9421, Test Accuracy: 59.5960, Avg. duration: 0.0272 s\n",
      "Epoch: 944, Train Loss: 0.2550, Test Loss: 0.3074, Train Accuracy: 58.9421, Test Accuracy: 59.5960, Avg. duration: 0.0273 s\n",
      "Epoch: 945, Train Loss: 0.2550, Test Loss: 0.3074, Train Accuracy: 58.9421, Test Accuracy: 59.5960, Avg. duration: 0.0271 s\n",
      "Epoch: 946, Train Loss: 0.2550, Test Loss: 0.3074, Train Accuracy: 58.9421, Test Accuracy: 59.5960, Avg. duration: 0.0274 s\n",
      "Epoch: 947, Train Loss: 0.2550, Test Loss: 0.3074, Train Accuracy: 58.9421, Test Accuracy: 59.5960, Avg. duration: 0.0271 s\n",
      "Epoch: 948, Train Loss: 0.2550, Test Loss: 0.3074, Train Accuracy: 58.9421, Test Accuracy: 59.5960, Avg. duration: 0.0269 s\n",
      "Epoch: 949, Train Loss: 0.2550, Test Loss: 0.3074, Train Accuracy: 58.9421, Test Accuracy: 59.5960, Avg. duration: 0.0277 s\n",
      "Epoch: 950, Train Loss: 0.2550, Test Loss: 0.3074, Train Accuracy: 58.9421, Test Accuracy: 59.5960, Avg. duration: 0.0274 s\n",
      "Epoch: 951, Train Loss: 0.2550, Test Loss: 0.3074, Train Accuracy: 58.9421, Test Accuracy: 59.5960, Avg. duration: 0.0272 s\n",
      "Epoch: 952, Train Loss: 0.2550, Test Loss: 0.3074, Train Accuracy: 58.9421, Test Accuracy: 59.5960, Avg. duration: 0.0277 s\n",
      "Epoch: 953, Train Loss: 0.2550, Test Loss: 0.3074, Train Accuracy: 58.9421, Test Accuracy: 59.5960, Avg. duration: 0.0270 s\n",
      "Epoch: 954, Train Loss: 0.2550, Test Loss: 0.3074, Train Accuracy: 58.9421, Test Accuracy: 59.5960, Avg. duration: 0.0273 s\n",
      "Epoch: 955, Train Loss: 0.2550, Test Loss: 0.3074, Train Accuracy: 58.9421, Test Accuracy: 59.5960, Avg. duration: 0.0270 s\n",
      "Epoch: 956, Train Loss: 0.2550, Test Loss: 0.3074, Train Accuracy: 58.9421, Test Accuracy: 59.5960, Avg. duration: 0.0275 s\n",
      "Epoch: 957, Train Loss: 0.2550, Test Loss: 0.3074, Train Accuracy: 58.9421, Test Accuracy: 59.5960, Avg. duration: 0.0279 s\n",
      "Epoch: 958, Train Loss: 0.2550, Test Loss: 0.3074, Train Accuracy: 58.9421, Test Accuracy: 59.5960, Avg. duration: 0.0278 s\n",
      "Epoch: 959, Train Loss: 0.2550, Test Loss: 0.3074, Train Accuracy: 58.9421, Test Accuracy: 59.5960, Avg. duration: 0.0270 s\n",
      "Epoch: 960, Train Loss: 0.2550, Test Loss: 0.3074, Train Accuracy: 58.9421, Test Accuracy: 59.5960, Avg. duration: 0.0270 s\n",
      "Epoch: 961, Train Loss: 0.2550, Test Loss: 0.3074, Train Accuracy: 58.9421, Test Accuracy: 59.5960, Avg. duration: 0.0273 s\n",
      "Epoch: 962, Train Loss: 0.2550, Test Loss: 0.3074, Train Accuracy: 58.9421, Test Accuracy: 59.5960, Avg. duration: 0.0275 s\n",
      "Epoch: 963, Train Loss: 0.2550, Test Loss: 0.3074, Train Accuracy: 58.9421, Test Accuracy: 59.5960, Avg. duration: 0.0277 s\n",
      "Epoch: 964, Train Loss: 0.2550, Test Loss: 0.3074, Train Accuracy: 58.9421, Test Accuracy: 59.5960, Avg. duration: 0.0275 s\n",
      "Epoch: 965, Train Loss: 0.2550, Test Loss: 0.3074, Train Accuracy: 58.9421, Test Accuracy: 59.5960, Avg. duration: 0.0279 s\n",
      "Epoch: 966, Train Loss: 0.2550, Test Loss: 0.3074, Train Accuracy: 58.9421, Test Accuracy: 59.5960, Avg. duration: 0.0272 s\n",
      "Epoch: 967, Train Loss: 0.2550, Test Loss: 0.3074, Train Accuracy: 58.9421, Test Accuracy: 59.5960, Avg. duration: 0.0274 s\n",
      "Epoch: 968, Train Loss: 0.2550, Test Loss: 0.3074, Train Accuracy: 58.9421, Test Accuracy: 59.5960, Avg. duration: 0.3248 s\n",
      "Epoch: 969, Train Loss: 0.2550, Test Loss: 0.3074, Train Accuracy: 58.9421, Test Accuracy: 59.5960, Avg. duration: 0.0282 s\n",
      "Epoch: 970, Train Loss: 0.2550, Test Loss: 0.3074, Train Accuracy: 58.9421, Test Accuracy: 59.5960, Avg. duration: 0.0278 s\n",
      "Epoch: 971, Train Loss: 0.2550, Test Loss: 0.3074, Train Accuracy: 58.9421, Test Accuracy: 59.5960, Avg. duration: 0.0275 s\n",
      "Epoch: 972, Train Loss: 0.2550, Test Loss: 0.3074, Train Accuracy: 58.9421, Test Accuracy: 59.5960, Avg. duration: 0.0276 s\n",
      "Epoch: 973, Train Loss: 0.2550, Test Loss: 0.3074, Train Accuracy: 58.9421, Test Accuracy: 59.5960, Avg. duration: 0.0274 s\n",
      "Epoch: 974, Train Loss: 0.2550, Test Loss: 0.3074, Train Accuracy: 58.9421, Test Accuracy: 59.5960, Avg. duration: 0.0272 s\n",
      "Epoch: 975, Train Loss: 0.2550, Test Loss: 0.3074, Train Accuracy: 58.9421, Test Accuracy: 59.5960, Avg. duration: 0.0275 s\n",
      "Epoch: 976, Train Loss: 0.2550, Test Loss: 0.3074, Train Accuracy: 58.9421, Test Accuracy: 59.5960, Avg. duration: 0.0280 s\n",
      "Epoch: 977, Train Loss: 0.2550, Test Loss: 0.3074, Train Accuracy: 58.9421, Test Accuracy: 59.5960, Avg. duration: 0.0276 s\n",
      "Epoch: 978, Train Loss: 0.2550, Test Loss: 0.3074, Train Accuracy: 58.9421, Test Accuracy: 59.5960, Avg. duration: 0.0275 s\n",
      "Epoch: 979, Train Loss: 0.2550, Test Loss: 0.3074, Train Accuracy: 58.9421, Test Accuracy: 59.5960, Avg. duration: 0.0272 s\n",
      "Epoch: 980, Train Loss: 0.2550, Test Loss: 0.3074, Train Accuracy: 58.9421, Test Accuracy: 59.5960, Avg. duration: 0.0276 s\n",
      "Epoch: 981, Train Loss: 0.2550, Test Loss: 0.3074, Train Accuracy: 58.9421, Test Accuracy: 59.5960, Avg. duration: 0.0278 s\n",
      "Epoch: 982, Train Loss: 0.2550, Test Loss: 0.3074, Train Accuracy: 58.9421, Test Accuracy: 59.5960, Avg. duration: 0.0275 s\n",
      "Epoch: 983, Train Loss: 0.2550, Test Loss: 0.3074, Train Accuracy: 58.9421, Test Accuracy: 59.5960, Avg. duration: 0.0271 s\n",
      "Epoch: 984, Train Loss: 0.2550, Test Loss: 0.3074, Train Accuracy: 58.9421, Test Accuracy: 59.5960, Avg. duration: 0.0278 s\n",
      "Epoch: 985, Train Loss: 0.2550, Test Loss: 0.3074, Train Accuracy: 58.9421, Test Accuracy: 59.5960, Avg. duration: 0.0275 s\n",
      "Epoch: 986, Train Loss: 0.2550, Test Loss: 0.3074, Train Accuracy: 58.9421, Test Accuracy: 59.5960, Avg. duration: 0.0276 s\n",
      "Epoch: 987, Train Loss: 0.2550, Test Loss: 0.3074, Train Accuracy: 58.9421, Test Accuracy: 59.5960, Avg. duration: 0.0279 s\n",
      "Epoch: 988, Train Loss: 0.2550, Test Loss: 0.3074, Train Accuracy: 58.9421, Test Accuracy: 59.5960, Avg. duration: 0.0276 s\n",
      "Epoch: 989, Train Loss: 0.2550, Test Loss: 0.3074, Train Accuracy: 58.9421, Test Accuracy: 59.5960, Avg. duration: 0.0273 s\n",
      "Epoch: 990, Train Loss: 0.2550, Test Loss: 0.3074, Train Accuracy: 58.9421, Test Accuracy: 59.5960, Avg. duration: 0.0275 s\n",
      "Epoch: 991, Train Loss: 0.2550, Test Loss: 0.3074, Train Accuracy: 58.9421, Test Accuracy: 59.5960, Avg. duration: 0.0277 s\n",
      "Epoch: 992, Train Loss: 0.2550, Test Loss: 0.3074, Train Accuracy: 58.9421, Test Accuracy: 59.5960, Avg. duration: 0.0277 s\n",
      "Epoch: 993, Train Loss: 0.2550, Test Loss: 0.3074, Train Accuracy: 58.9421, Test Accuracy: 59.5960, Avg. duration: 0.0277 s\n",
      "Epoch: 994, Train Loss: 0.2550, Test Loss: 0.3074, Train Accuracy: 58.9421, Test Accuracy: 59.5960, Avg. duration: 0.0278 s\n",
      "Epoch: 995, Train Loss: 0.2550, Test Loss: 0.3074, Train Accuracy: 58.9421, Test Accuracy: 59.5960, Avg. duration: 0.0276 s\n",
      "Epoch: 996, Train Loss: 0.2550, Test Loss: 0.3074, Train Accuracy: 58.9421, Test Accuracy: 59.5960, Avg. duration: 0.0273 s\n",
      "Epoch: 997, Train Loss: 0.2550, Test Loss: 0.3074, Train Accuracy: 58.9421, Test Accuracy: 59.5960, Avg. duration: 0.0274 s\n",
      "Epoch: 998, Train Loss: 0.2550, Test Loss: 0.3074, Train Accuracy: 58.9421, Test Accuracy: 59.5960, Avg. duration: 0.0275 s\n",
      "Epoch: 999, Train Loss: 0.2550, Test Loss: 0.3074, Train Accuracy: 58.9421, Test Accuracy: 59.5960, Avg. duration: 0.0280 s\n",
      "Epoch: 1000, Train Loss: 0.2550, Test Loss: 0.3074, Train Accuracy: 58.9421, Test Accuracy: 59.5960, Avg. duration: 0.0280 s\n",
      "Epoch: 1001, Train Loss: 0.2503, Test Loss: 0.3054, Train Accuracy: 60.3275, Test Accuracy: 59.0909, Avg. duration: 2.7246 s\n",
      "Epoch: 1002, Train Loss: 0.2503, Test Loss: 0.3054, Train Accuracy: 60.3275, Test Accuracy: 59.0909, Avg. duration: 0.0286 s\n",
      "Epoch: 1003, Train Loss: 0.2503, Test Loss: 0.3054, Train Accuracy: 60.3275, Test Accuracy: 59.0909, Avg. duration: 0.0275 s\n",
      "Epoch: 1004, Train Loss: 0.2503, Test Loss: 0.3054, Train Accuracy: 60.3275, Test Accuracy: 59.0909, Avg. duration: 0.0272 s\n",
      "Epoch: 1005, Train Loss: 0.2503, Test Loss: 0.3054, Train Accuracy: 60.3275, Test Accuracy: 59.0909, Avg. duration: 0.0273 s\n",
      "Epoch: 1006, Train Loss: 0.2503, Test Loss: 0.3054, Train Accuracy: 60.3275, Test Accuracy: 59.0909, Avg. duration: 0.0272 s\n",
      "Epoch: 1007, Train Loss: 0.2503, Test Loss: 0.3054, Train Accuracy: 60.3275, Test Accuracy: 59.0909, Avg. duration: 0.0273 s\n",
      "Epoch: 1008, Train Loss: 0.2503, Test Loss: 0.3054, Train Accuracy: 60.3275, Test Accuracy: 59.0909, Avg. duration: 0.0270 s\n",
      "Epoch: 1009, Train Loss: 0.2503, Test Loss: 0.3054, Train Accuracy: 60.3275, Test Accuracy: 59.0909, Avg. duration: 0.0275 s\n",
      "Epoch: 1010, Train Loss: 0.2503, Test Loss: 0.3054, Train Accuracy: 60.3275, Test Accuracy: 59.0909, Avg. duration: 0.0273 s\n",
      "Epoch: 1011, Train Loss: 0.2503, Test Loss: 0.3054, Train Accuracy: 60.3275, Test Accuracy: 59.0909, Avg. duration: 0.0278 s\n",
      "Epoch: 1012, Train Loss: 0.2503, Test Loss: 0.3054, Train Accuracy: 60.3275, Test Accuracy: 59.0909, Avg. duration: 0.0274 s\n",
      "Epoch: 1013, Train Loss: 0.2503, Test Loss: 0.3054, Train Accuracy: 60.3275, Test Accuracy: 59.0909, Avg. duration: 0.0267 s\n",
      "Epoch: 1014, Train Loss: 0.2503, Test Loss: 0.3054, Train Accuracy: 60.3275, Test Accuracy: 59.0909, Avg. duration: 0.0271 s\n",
      "Epoch: 1015, Train Loss: 0.2503, Test Loss: 0.3054, Train Accuracy: 60.3275, Test Accuracy: 59.0909, Avg. duration: 0.0270 s\n",
      "Epoch: 1016, Train Loss: 0.2503, Test Loss: 0.3054, Train Accuracy: 60.3275, Test Accuracy: 59.0909, Avg. duration: 0.0275 s\n",
      "Epoch: 1017, Train Loss: 0.2503, Test Loss: 0.3054, Train Accuracy: 60.3275, Test Accuracy: 59.0909, Avg. duration: 0.0277 s\n",
      "Epoch: 1018, Train Loss: 0.2503, Test Loss: 0.3054, Train Accuracy: 60.3275, Test Accuracy: 59.0909, Avg. duration: 0.0278 s\n",
      "Epoch: 1019, Train Loss: 0.2503, Test Loss: 0.3054, Train Accuracy: 60.3275, Test Accuracy: 59.0909, Avg. duration: 0.0269 s\n",
      "Epoch: 1020, Train Loss: 0.2503, Test Loss: 0.3054, Train Accuracy: 60.3275, Test Accuracy: 59.0909, Avg. duration: 0.0269 s\n",
      "Epoch: 1021, Train Loss: 0.2503, Test Loss: 0.3054, Train Accuracy: 60.3275, Test Accuracy: 59.0909, Avg. duration: 0.0273 s\n",
      "Epoch: 1022, Train Loss: 0.2503, Test Loss: 0.3054, Train Accuracy: 60.3275, Test Accuracy: 59.0909, Avg. duration: 0.0272 s\n",
      "Epoch: 1023, Train Loss: 0.2503, Test Loss: 0.3054, Train Accuracy: 60.3275, Test Accuracy: 59.0909, Avg. duration: 0.0273 s\n",
      "Epoch: 1024, Train Loss: 0.2503, Test Loss: 0.3054, Train Accuracy: 60.3275, Test Accuracy: 59.0909, Avg. duration: 0.0273 s\n",
      "Epoch: 1025, Train Loss: 0.2503, Test Loss: 0.3054, Train Accuracy: 60.3275, Test Accuracy: 59.0909, Avg. duration: 0.0274 s\n",
      "Epoch: 1026, Train Loss: 0.2503, Test Loss: 0.3054, Train Accuracy: 60.3275, Test Accuracy: 59.0909, Avg. duration: 0.0274 s\n",
      "Epoch: 1027, Train Loss: 0.2503, Test Loss: 0.3054, Train Accuracy: 60.3275, Test Accuracy: 59.0909, Avg. duration: 0.0271 s\n",
      "Epoch: 1028, Train Loss: 0.2503, Test Loss: 0.3054, Train Accuracy: 60.3275, Test Accuracy: 59.0909, Avg. duration: 0.0273 s\n",
      "Epoch: 1029, Train Loss: 0.2503, Test Loss: 0.3054, Train Accuracy: 60.3275, Test Accuracy: 59.0909, Avg. duration: 0.0273 s\n",
      "Epoch: 1030, Train Loss: 0.2503, Test Loss: 0.3054, Train Accuracy: 60.3275, Test Accuracy: 59.0909, Avg. duration: 0.0276 s\n",
      "Epoch: 1031, Train Loss: 0.2503, Test Loss: 0.3054, Train Accuracy: 60.3275, Test Accuracy: 59.0909, Avg. duration: 0.0268 s\n",
      "Epoch: 1032, Train Loss: 0.2503, Test Loss: 0.3054, Train Accuracy: 60.3275, Test Accuracy: 59.0909, Avg. duration: 0.0272 s\n",
      "Epoch: 1033, Train Loss: 0.2503, Test Loss: 0.3054, Train Accuracy: 60.3275, Test Accuracy: 59.0909, Avg. duration: 0.0274 s\n",
      "Epoch: 1034, Train Loss: 0.2503, Test Loss: 0.3054, Train Accuracy: 60.3275, Test Accuracy: 59.0909, Avg. duration: 0.0272 s\n",
      "Epoch: 1035, Train Loss: 0.2503, Test Loss: 0.3054, Train Accuracy: 60.3275, Test Accuracy: 59.0909, Avg. duration: 0.3170 s\n",
      "Epoch: 1036, Train Loss: 0.2503, Test Loss: 0.3054, Train Accuracy: 60.3275, Test Accuracy: 59.0909, Avg. duration: 0.0282 s\n",
      "Epoch: 1037, Train Loss: 0.2503, Test Loss: 0.3054, Train Accuracy: 60.3275, Test Accuracy: 59.0909, Avg. duration: 0.0275 s\n",
      "Epoch: 1038, Train Loss: 0.2503, Test Loss: 0.3054, Train Accuracy: 60.3275, Test Accuracy: 59.0909, Avg. duration: 0.0272 s\n",
      "Epoch: 1039, Train Loss: 0.2503, Test Loss: 0.3054, Train Accuracy: 60.3275, Test Accuracy: 59.0909, Avg. duration: 0.0271 s\n",
      "Epoch: 1040, Train Loss: 0.2503, Test Loss: 0.3054, Train Accuracy: 60.3275, Test Accuracy: 59.0909, Avg. duration: 0.0272 s\n",
      "Epoch: 1041, Train Loss: 0.2503, Test Loss: 0.3054, Train Accuracy: 60.3275, Test Accuracy: 59.0909, Avg. duration: 0.0273 s\n",
      "Epoch: 1042, Train Loss: 0.2503, Test Loss: 0.3054, Train Accuracy: 60.3275, Test Accuracy: 59.0909, Avg. duration: 0.0272 s\n",
      "Epoch: 1043, Train Loss: 0.2503, Test Loss: 0.3054, Train Accuracy: 60.3275, Test Accuracy: 59.0909, Avg. duration: 0.0277 s\n",
      "Epoch: 1044, Train Loss: 0.2503, Test Loss: 0.3054, Train Accuracy: 60.3275, Test Accuracy: 59.0909, Avg. duration: 0.0274 s\n",
      "Epoch: 1045, Train Loss: 0.2503, Test Loss: 0.3054, Train Accuracy: 60.3275, Test Accuracy: 59.0909, Avg. duration: 0.0270 s\n",
      "Epoch: 1046, Train Loss: 0.2503, Test Loss: 0.3054, Train Accuracy: 60.3275, Test Accuracy: 59.0909, Avg. duration: 0.0274 s\n",
      "Epoch: 1047, Train Loss: 0.2503, Test Loss: 0.3054, Train Accuracy: 60.3275, Test Accuracy: 59.0909, Avg. duration: 0.0273 s\n",
      "Epoch: 1048, Train Loss: 0.2503, Test Loss: 0.3054, Train Accuracy: 60.3275, Test Accuracy: 59.0909, Avg. duration: 0.0270 s\n",
      "Epoch: 1049, Train Loss: 0.2503, Test Loss: 0.3054, Train Accuracy: 60.3275, Test Accuracy: 59.0909, Avg. duration: 0.0270 s\n",
      "Epoch: 1050, Train Loss: 0.2503, Test Loss: 0.3054, Train Accuracy: 60.3275, Test Accuracy: 59.0909, Avg. duration: 0.0268 s\n",
      "Epoch: 1051, Train Loss: 0.2503, Test Loss: 0.3054, Train Accuracy: 60.3275, Test Accuracy: 59.0909, Avg. duration: 0.0276 s\n",
      "Epoch: 1052, Train Loss: 0.2503, Test Loss: 0.3054, Train Accuracy: 60.3275, Test Accuracy: 59.0909, Avg. duration: 0.0275 s\n",
      "Epoch: 1053, Train Loss: 0.2503, Test Loss: 0.3054, Train Accuracy: 60.3275, Test Accuracy: 59.0909, Avg. duration: 0.0277 s\n",
      "Epoch: 1054, Train Loss: 0.2503, Test Loss: 0.3054, Train Accuracy: 60.3275, Test Accuracy: 59.0909, Avg. duration: 0.0270 s\n",
      "Epoch: 1055, Train Loss: 0.2503, Test Loss: 0.3054, Train Accuracy: 60.3275, Test Accuracy: 59.0909, Avg. duration: 0.0275 s\n",
      "Epoch: 1056, Train Loss: 0.2503, Test Loss: 0.3054, Train Accuracy: 60.3275, Test Accuracy: 59.0909, Avg. duration: 0.0278 s\n",
      "Epoch: 1057, Train Loss: 0.2503, Test Loss: 0.3054, Train Accuracy: 60.3275, Test Accuracy: 59.0909, Avg. duration: 0.0275 s\n",
      "Epoch: 1058, Train Loss: 0.2503, Test Loss: 0.3054, Train Accuracy: 60.3275, Test Accuracy: 59.0909, Avg. duration: 0.0276 s\n",
      "Epoch: 1059, Train Loss: 0.2503, Test Loss: 0.3054, Train Accuracy: 60.3275, Test Accuracy: 59.0909, Avg. duration: 0.0281 s\n",
      "Epoch: 1060, Train Loss: 0.2503, Test Loss: 0.3054, Train Accuracy: 60.3275, Test Accuracy: 59.0909, Avg. duration: 0.0277 s\n",
      "Epoch: 1061, Train Loss: 0.2503, Test Loss: 0.3054, Train Accuracy: 60.3275, Test Accuracy: 59.0909, Avg. duration: 0.0273 s\n",
      "Epoch: 1062, Train Loss: 0.2503, Test Loss: 0.3054, Train Accuracy: 60.3275, Test Accuracy: 59.0909, Avg. duration: 0.0273 s\n",
      "Epoch: 1063, Train Loss: 0.2503, Test Loss: 0.3054, Train Accuracy: 60.3275, Test Accuracy: 59.0909, Avg. duration: 0.0273 s\n",
      "Epoch: 1064, Train Loss: 0.2503, Test Loss: 0.3054, Train Accuracy: 60.3275, Test Accuracy: 59.0909, Avg. duration: 0.0280 s\n",
      "Epoch: 1065, Train Loss: 0.2503, Test Loss: 0.3054, Train Accuracy: 60.3275, Test Accuracy: 59.0909, Avg. duration: 0.0277 s\n",
      "Epoch: 1066, Train Loss: 0.2503, Test Loss: 0.3054, Train Accuracy: 60.3275, Test Accuracy: 59.0909, Avg. duration: 0.0269 s\n",
      "Epoch: 1067, Train Loss: 0.2503, Test Loss: 0.3054, Train Accuracy: 60.3275, Test Accuracy: 59.0909, Avg. duration: 0.0277 s\n",
      "Epoch: 1068, Train Loss: 0.2503, Test Loss: 0.3054, Train Accuracy: 60.3275, Test Accuracy: 59.0909, Avg. duration: 0.0273 s\n",
      "Epoch: 1069, Train Loss: 0.2503, Test Loss: 0.3054, Train Accuracy: 60.3275, Test Accuracy: 59.0909, Avg. duration: 0.0272 s\n",
      "Epoch: 1070, Train Loss: 0.2503, Test Loss: 0.3054, Train Accuracy: 60.3275, Test Accuracy: 59.0909, Avg. duration: 0.0277 s\n",
      "Epoch: 1071, Train Loss: 0.2503, Test Loss: 0.3054, Train Accuracy: 60.3275, Test Accuracy: 59.0909, Avg. duration: 0.0275 s\n",
      "Epoch: 1072, Train Loss: 0.2503, Test Loss: 0.3054, Train Accuracy: 60.3275, Test Accuracy: 59.0909, Avg. duration: 0.0274 s\n",
      "Epoch: 1073, Train Loss: 0.2503, Test Loss: 0.3054, Train Accuracy: 60.3275, Test Accuracy: 59.0909, Avg. duration: 0.0271 s\n",
      "Epoch: 1074, Train Loss: 0.2503, Test Loss: 0.3054, Train Accuracy: 60.3275, Test Accuracy: 59.0909, Avg. duration: 0.0275 s\n",
      "Epoch: 1075, Train Loss: 0.2503, Test Loss: 0.3054, Train Accuracy: 60.3275, Test Accuracy: 59.0909, Avg. duration: 0.0280 s\n",
      "Epoch: 1076, Train Loss: 0.2503, Test Loss: 0.3054, Train Accuracy: 60.3275, Test Accuracy: 59.0909, Avg. duration: 0.0276 s\n",
      "Epoch: 1077, Train Loss: 0.2503, Test Loss: 0.3054, Train Accuracy: 60.3275, Test Accuracy: 59.0909, Avg. duration: 0.0278 s\n",
      "Epoch: 1078, Train Loss: 0.2503, Test Loss: 0.3054, Train Accuracy: 60.3275, Test Accuracy: 59.0909, Avg. duration: 0.0269 s\n",
      "Epoch: 1079, Train Loss: 0.2503, Test Loss: 0.3054, Train Accuracy: 60.3275, Test Accuracy: 59.0909, Avg. duration: 0.0275 s\n",
      "Epoch: 1080, Train Loss: 0.2503, Test Loss: 0.3054, Train Accuracy: 60.3275, Test Accuracy: 59.0909, Avg. duration: 0.0272 s\n",
      "Epoch: 1081, Train Loss: 0.2503, Test Loss: 0.3054, Train Accuracy: 60.3275, Test Accuracy: 59.0909, Avg. duration: 0.0277 s\n",
      "Epoch: 1082, Train Loss: 0.2503, Test Loss: 0.3054, Train Accuracy: 60.3275, Test Accuracy: 59.0909, Avg. duration: 0.0278 s\n",
      "Epoch: 1083, Train Loss: 0.2503, Test Loss: 0.3054, Train Accuracy: 60.3275, Test Accuracy: 59.0909, Avg. duration: 0.0282 s\n",
      "Epoch: 1084, Train Loss: 0.2503, Test Loss: 0.3054, Train Accuracy: 60.3275, Test Accuracy: 59.0909, Avg. duration: 0.0271 s\n",
      "Epoch: 1085, Train Loss: 0.2503, Test Loss: 0.3054, Train Accuracy: 60.3275, Test Accuracy: 59.0909, Avg. duration: 0.0274 s\n",
      "Epoch: 1086, Train Loss: 0.2503, Test Loss: 0.3054, Train Accuracy: 60.3275, Test Accuracy: 59.0909, Avg. duration: 0.0279 s\n",
      "Epoch: 1087, Train Loss: 0.2503, Test Loss: 0.3054, Train Accuracy: 60.3275, Test Accuracy: 59.0909, Avg. duration: 0.0276 s\n",
      "Epoch: 1088, Train Loss: 0.2503, Test Loss: 0.3054, Train Accuracy: 60.3275, Test Accuracy: 59.0909, Avg. duration: 0.0277 s\n",
      "Epoch: 1089, Train Loss: 0.2503, Test Loss: 0.3054, Train Accuracy: 60.3275, Test Accuracy: 59.0909, Avg. duration: 0.0278 s\n",
      "Epoch: 1090, Train Loss: 0.2503, Test Loss: 0.3054, Train Accuracy: 60.3275, Test Accuracy: 59.0909, Avg. duration: 0.0272 s\n",
      "Epoch: 1091, Train Loss: 0.2503, Test Loss: 0.3054, Train Accuracy: 60.3275, Test Accuracy: 59.0909, Avg. duration: 0.0278 s\n",
      "Epoch: 1092, Train Loss: 0.2503, Test Loss: 0.3054, Train Accuracy: 60.3275, Test Accuracy: 59.0909, Avg. duration: 0.0276 s\n",
      "Epoch: 1093, Train Loss: 0.2503, Test Loss: 0.3054, Train Accuracy: 60.3275, Test Accuracy: 59.0909, Avg. duration: 0.0276 s\n",
      "Epoch: 1094, Train Loss: 0.2503, Test Loss: 0.3054, Train Accuracy: 60.3275, Test Accuracy: 59.0909, Avg. duration: 0.0277 s\n",
      "Epoch: 1095, Train Loss: 0.2503, Test Loss: 0.3054, Train Accuracy: 60.3275, Test Accuracy: 59.0909, Avg. duration: 0.0278 s\n",
      "Epoch: 1096, Train Loss: 0.2503, Test Loss: 0.3054, Train Accuracy: 60.3275, Test Accuracy: 59.0909, Avg. duration: 0.0274 s\n",
      "Epoch: 1097, Train Loss: 0.2503, Test Loss: 0.3054, Train Accuracy: 60.3275, Test Accuracy: 59.0909, Avg. duration: 0.0273 s\n",
      "Epoch: 1098, Train Loss: 0.2503, Test Loss: 0.3054, Train Accuracy: 60.3275, Test Accuracy: 59.0909, Avg. duration: 0.0272 s\n",
      "Epoch: 1099, Train Loss: 0.2503, Test Loss: 0.3054, Train Accuracy: 60.3275, Test Accuracy: 59.0909, Avg. duration: 0.0280 s\n",
      "Epoch: 1100, Train Loss: 0.2503, Test Loss: 0.3054, Train Accuracy: 60.3275, Test Accuracy: 59.0909, Avg. duration: 0.0277 s\n",
      "Epoch: 1101, Train Loss: 0.2455, Test Loss: 0.3051, Train Accuracy: 59.8237, Test Accuracy: 60.1010, Avg. duration: 2.7254 s\n",
      "Epoch: 1102, Train Loss: 0.2455, Test Loss: 0.3051, Train Accuracy: 59.8237, Test Accuracy: 60.1010, Avg. duration: 0.0282 s\n",
      "Epoch: 1103, Train Loss: 0.2455, Test Loss: 0.3051, Train Accuracy: 59.8237, Test Accuracy: 60.1010, Avg. duration: 0.0274 s\n",
      "Epoch: 1104, Train Loss: 0.2455, Test Loss: 0.3051, Train Accuracy: 59.8237, Test Accuracy: 60.1010, Avg. duration: 0.0271 s\n",
      "Epoch: 1105, Train Loss: 0.2455, Test Loss: 0.3051, Train Accuracy: 59.8237, Test Accuracy: 60.1010, Avg. duration: 0.0271 s\n",
      "Epoch: 1106, Train Loss: 0.2455, Test Loss: 0.3051, Train Accuracy: 59.8237, Test Accuracy: 60.1010, Avg. duration: 0.0268 s\n",
      "Epoch: 1107, Train Loss: 0.2455, Test Loss: 0.3051, Train Accuracy: 59.8237, Test Accuracy: 60.1010, Avg. duration: 0.0277 s\n",
      "Epoch: 1108, Train Loss: 0.2455, Test Loss: 0.3051, Train Accuracy: 59.8237, Test Accuracy: 60.1010, Avg. duration: 0.0268 s\n",
      "Epoch: 1109, Train Loss: 0.2455, Test Loss: 0.3051, Train Accuracy: 59.8237, Test Accuracy: 60.1010, Avg. duration: 0.0278 s\n",
      "Epoch: 1110, Train Loss: 0.2455, Test Loss: 0.3051, Train Accuracy: 59.8237, Test Accuracy: 60.1010, Avg. duration: 0.0272 s\n",
      "Epoch: 1111, Train Loss: 0.2455, Test Loss: 0.3051, Train Accuracy: 59.8237, Test Accuracy: 60.1010, Avg. duration: 0.3191 s\n",
      "Epoch: 1112, Train Loss: 0.2455, Test Loss: 0.3051, Train Accuracy: 59.8237, Test Accuracy: 60.1010, Avg. duration: 0.0281 s\n",
      "Epoch: 1113, Train Loss: 0.2455, Test Loss: 0.3051, Train Accuracy: 59.8237, Test Accuracy: 60.1010, Avg. duration: 0.0276 s\n",
      "Epoch: 1114, Train Loss: 0.2455, Test Loss: 0.3051, Train Accuracy: 59.8237, Test Accuracy: 60.1010, Avg. duration: 0.0272 s\n",
      "Epoch: 1115, Train Loss: 0.2455, Test Loss: 0.3051, Train Accuracy: 59.8237, Test Accuracy: 60.1010, Avg. duration: 0.0271 s\n",
      "Epoch: 1116, Train Loss: 0.2455, Test Loss: 0.3051, Train Accuracy: 59.8237, Test Accuracy: 60.1010, Avg. duration: 0.0272 s\n",
      "Epoch: 1117, Train Loss: 0.2455, Test Loss: 0.3051, Train Accuracy: 59.8237, Test Accuracy: 60.1010, Avg. duration: 0.0274 s\n",
      "Epoch: 1118, Train Loss: 0.2455, Test Loss: 0.3051, Train Accuracy: 59.8237, Test Accuracy: 60.1010, Avg. duration: 0.0275 s\n",
      "Epoch: 1119, Train Loss: 0.2455, Test Loss: 0.3051, Train Accuracy: 59.8237, Test Accuracy: 60.1010, Avg. duration: 0.0278 s\n",
      "Epoch: 1120, Train Loss: 0.2455, Test Loss: 0.3051, Train Accuracy: 59.8237, Test Accuracy: 60.1010, Avg. duration: 0.0269 s\n",
      "Epoch: 1121, Train Loss: 0.2455, Test Loss: 0.3051, Train Accuracy: 59.8237, Test Accuracy: 60.1010, Avg. duration: 0.0272 s\n",
      "Epoch: 1122, Train Loss: 0.2455, Test Loss: 0.3051, Train Accuracy: 59.8237, Test Accuracy: 60.1010, Avg. duration: 0.0272 s\n",
      "Epoch: 1123, Train Loss: 0.2455, Test Loss: 0.3051, Train Accuracy: 59.8237, Test Accuracy: 60.1010, Avg. duration: 0.0276 s\n",
      "Epoch: 1124, Train Loss: 0.2455, Test Loss: 0.3051, Train Accuracy: 59.8237, Test Accuracy: 60.1010, Avg. duration: 0.0272 s\n",
      "Epoch: 1125, Train Loss: 0.2455, Test Loss: 0.3051, Train Accuracy: 59.8237, Test Accuracy: 60.1010, Avg. duration: 0.0273 s\n",
      "Epoch: 1126, Train Loss: 0.2455, Test Loss: 0.3051, Train Accuracy: 59.8237, Test Accuracy: 60.1010, Avg. duration: 0.0268 s\n",
      "Epoch: 1127, Train Loss: 0.2455, Test Loss: 0.3051, Train Accuracy: 59.8237, Test Accuracy: 60.1010, Avg. duration: 0.0277 s\n",
      "Epoch: 1128, Train Loss: 0.2455, Test Loss: 0.3051, Train Accuracy: 59.8237, Test Accuracy: 60.1010, Avg. duration: 0.0271 s\n",
      "Epoch: 1129, Train Loss: 0.2455, Test Loss: 0.3051, Train Accuracy: 59.8237, Test Accuracy: 60.1010, Avg. duration: 0.0274 s\n",
      "Epoch: 1130, Train Loss: 0.2455, Test Loss: 0.3051, Train Accuracy: 59.8237, Test Accuracy: 60.1010, Avg. duration: 0.0276 s\n",
      "Epoch: 1131, Train Loss: 0.2455, Test Loss: 0.3051, Train Accuracy: 59.8237, Test Accuracy: 60.1010, Avg. duration: 0.0274 s\n",
      "Epoch: 1132, Train Loss: 0.2455, Test Loss: 0.3051, Train Accuracy: 59.8237, Test Accuracy: 60.1010, Avg. duration: 0.0270 s\n",
      "Epoch: 1133, Train Loss: 0.2455, Test Loss: 0.3051, Train Accuracy: 59.8237, Test Accuracy: 60.1010, Avg. duration: 0.0269 s\n",
      "Epoch: 1134, Train Loss: 0.2455, Test Loss: 0.3051, Train Accuracy: 59.8237, Test Accuracy: 60.1010, Avg. duration: 0.0269 s\n",
      "Epoch: 1135, Train Loss: 0.2455, Test Loss: 0.3051, Train Accuracy: 59.8237, Test Accuracy: 60.1010, Avg. duration: 0.0275 s\n",
      "Epoch: 1136, Train Loss: 0.2455, Test Loss: 0.3051, Train Accuracy: 59.8237, Test Accuracy: 60.1010, Avg. duration: 0.0277 s\n",
      "Epoch: 1137, Train Loss: 0.2455, Test Loss: 0.3051, Train Accuracy: 59.8237, Test Accuracy: 60.1010, Avg. duration: 0.0271 s\n",
      "Epoch: 1138, Train Loss: 0.2455, Test Loss: 0.3051, Train Accuracy: 59.8237, Test Accuracy: 60.1010, Avg. duration: 0.0272 s\n",
      "Epoch: 1139, Train Loss: 0.2455, Test Loss: 0.3051, Train Accuracy: 59.8237, Test Accuracy: 60.1010, Avg. duration: 0.0270 s\n",
      "Epoch: 1140, Train Loss: 0.2455, Test Loss: 0.3051, Train Accuracy: 59.8237, Test Accuracy: 60.1010, Avg. duration: 0.0269 s\n",
      "Epoch: 1141, Train Loss: 0.2455, Test Loss: 0.3051, Train Accuracy: 59.8237, Test Accuracy: 60.1010, Avg. duration: 0.0276 s\n",
      "Epoch: 1142, Train Loss: 0.2455, Test Loss: 0.3051, Train Accuracy: 59.8237, Test Accuracy: 60.1010, Avg. duration: 0.0277 s\n",
      "Epoch: 1143, Train Loss: 0.2455, Test Loss: 0.3051, Train Accuracy: 59.8237, Test Accuracy: 60.1010, Avg. duration: 0.0280 s\n",
      "Epoch: 1144, Train Loss: 0.2455, Test Loss: 0.3051, Train Accuracy: 59.8237, Test Accuracy: 60.1010, Avg. duration: 0.0275 s\n",
      "Epoch: 1145, Train Loss: 0.2455, Test Loss: 0.3051, Train Accuracy: 59.8237, Test Accuracy: 60.1010, Avg. duration: 0.0268 s\n",
      "Epoch: 1146, Train Loss: 0.2455, Test Loss: 0.3051, Train Accuracy: 59.8237, Test Accuracy: 60.1010, Avg. duration: 0.0270 s\n",
      "Epoch: 1147, Train Loss: 0.2455, Test Loss: 0.3051, Train Accuracy: 59.8237, Test Accuracy: 60.1010, Avg. duration: 0.0273 s\n",
      "Epoch: 1148, Train Loss: 0.2455, Test Loss: 0.3051, Train Accuracy: 59.8237, Test Accuracy: 60.1010, Avg. duration: 0.0272 s\n",
      "Epoch: 1149, Train Loss: 0.2455, Test Loss: 0.3051, Train Accuracy: 59.8237, Test Accuracy: 60.1010, Avg. duration: 0.0272 s\n",
      "Epoch: 1150, Train Loss: 0.2455, Test Loss: 0.3051, Train Accuracy: 59.8237, Test Accuracy: 60.1010, Avg. duration: 0.0268 s\n",
      "Epoch: 1151, Train Loss: 0.2455, Test Loss: 0.3051, Train Accuracy: 59.8237, Test Accuracy: 60.1010, Avg. duration: 0.0272 s\n",
      "Epoch: 1152, Train Loss: 0.2455, Test Loss: 0.3051, Train Accuracy: 59.8237, Test Accuracy: 60.1010, Avg. duration: 0.0271 s\n",
      "Epoch: 1153, Train Loss: 0.2455, Test Loss: 0.3051, Train Accuracy: 59.8237, Test Accuracy: 60.1010, Avg. duration: 0.0272 s\n",
      "Epoch: 1154, Train Loss: 0.2455, Test Loss: 0.3051, Train Accuracy: 59.8237, Test Accuracy: 60.1010, Avg. duration: 0.0277 s\n",
      "Epoch: 1155, Train Loss: 0.2455, Test Loss: 0.3051, Train Accuracy: 59.8237, Test Accuracy: 60.1010, Avg. duration: 0.0277 s\n",
      "Epoch: 1156, Train Loss: 0.2455, Test Loss: 0.3051, Train Accuracy: 59.8237, Test Accuracy: 60.1010, Avg. duration: 0.0268 s\n",
      "Epoch: 1157, Train Loss: 0.2455, Test Loss: 0.3051, Train Accuracy: 59.8237, Test Accuracy: 60.1010, Avg. duration: 0.0275 s\n",
      "Epoch: 1158, Train Loss: 0.2455, Test Loss: 0.3051, Train Accuracy: 59.8237, Test Accuracy: 60.1010, Avg. duration: 0.0275 s\n",
      "Epoch: 1159, Train Loss: 0.2455, Test Loss: 0.3051, Train Accuracy: 59.8237, Test Accuracy: 60.1010, Avg. duration: 0.0282 s\n",
      "Epoch: 1160, Train Loss: 0.2455, Test Loss: 0.3051, Train Accuracy: 59.8237, Test Accuracy: 60.1010, Avg. duration: 0.0277 s\n",
      "Epoch: 1161, Train Loss: 0.2455, Test Loss: 0.3051, Train Accuracy: 59.8237, Test Accuracy: 60.1010, Avg. duration: 0.0275 s\n",
      "Epoch: 1162, Train Loss: 0.2455, Test Loss: 0.3051, Train Accuracy: 59.8237, Test Accuracy: 60.1010, Avg. duration: 0.0270 s\n",
      "Epoch: 1163, Train Loss: 0.2455, Test Loss: 0.3051, Train Accuracy: 59.8237, Test Accuracy: 60.1010, Avg. duration: 0.0274 s\n",
      "Epoch: 1164, Train Loss: 0.2455, Test Loss: 0.3051, Train Accuracy: 59.8237, Test Accuracy: 60.1010, Avg. duration: 0.0271 s\n",
      "Epoch: 1165, Train Loss: 0.2455, Test Loss: 0.3051, Train Accuracy: 59.8237, Test Accuracy: 60.1010, Avg. duration: 0.0275 s\n",
      "Epoch: 1166, Train Loss: 0.2455, Test Loss: 0.3051, Train Accuracy: 59.8237, Test Accuracy: 60.1010, Avg. duration: 0.0277 s\n",
      "Epoch: 1167, Train Loss: 0.2455, Test Loss: 0.3051, Train Accuracy: 59.8237, Test Accuracy: 60.1010, Avg. duration: 0.0279 s\n",
      "Epoch: 1168, Train Loss: 0.2455, Test Loss: 0.3051, Train Accuracy: 59.8237, Test Accuracy: 60.1010, Avg. duration: 0.0277 s\n",
      "Epoch: 1169, Train Loss: 0.2455, Test Loss: 0.3051, Train Accuracy: 59.8237, Test Accuracy: 60.1010, Avg. duration: 0.0271 s\n",
      "Epoch: 1170, Train Loss: 0.2455, Test Loss: 0.3051, Train Accuracy: 59.8237, Test Accuracy: 60.1010, Avg. duration: 0.0274 s\n",
      "Epoch: 1171, Train Loss: 0.2455, Test Loss: 0.3051, Train Accuracy: 59.8237, Test Accuracy: 60.1010, Avg. duration: 0.0274 s\n",
      "Epoch: 1172, Train Loss: 0.2455, Test Loss: 0.3051, Train Accuracy: 59.8237, Test Accuracy: 60.1010, Avg. duration: 0.0279 s\n",
      "Epoch: 1173, Train Loss: 0.2455, Test Loss: 0.3051, Train Accuracy: 59.8237, Test Accuracy: 60.1010, Avg. duration: 0.0280 s\n",
      "Epoch: 1174, Train Loss: 0.2455, Test Loss: 0.3051, Train Accuracy: 59.8237, Test Accuracy: 60.1010, Avg. duration: 0.0271 s\n",
      "Epoch: 1175, Train Loss: 0.2455, Test Loss: 0.3051, Train Accuracy: 59.8237, Test Accuracy: 60.1010, Avg. duration: 0.0276 s\n",
      "Epoch: 1176, Train Loss: 0.2455, Test Loss: 0.3051, Train Accuracy: 59.8237, Test Accuracy: 60.1010, Avg. duration: 0.0276 s\n",
      "Epoch: 1177, Train Loss: 0.2455, Test Loss: 0.3051, Train Accuracy: 59.8237, Test Accuracy: 60.1010, Avg. duration: 0.0278 s\n",
      "Epoch: 1178, Train Loss: 0.2455, Test Loss: 0.3051, Train Accuracy: 59.8237, Test Accuracy: 60.1010, Avg. duration: 0.3185 s\n",
      "Epoch: 1179, Train Loss: 0.2455, Test Loss: 0.3051, Train Accuracy: 59.8237, Test Accuracy: 60.1010, Avg. duration: 0.0284 s\n",
      "Epoch: 1180, Train Loss: 0.2455, Test Loss: 0.3051, Train Accuracy: 59.8237, Test Accuracy: 60.1010, Avg. duration: 0.0275 s\n",
      "Epoch: 1181, Train Loss: 0.2455, Test Loss: 0.3051, Train Accuracy: 59.8237, Test Accuracy: 60.1010, Avg. duration: 0.0277 s\n",
      "Epoch: 1182, Train Loss: 0.2455, Test Loss: 0.3051, Train Accuracy: 59.8237, Test Accuracy: 60.1010, Avg. duration: 0.0275 s\n",
      "Epoch: 1183, Train Loss: 0.2455, Test Loss: 0.3051, Train Accuracy: 59.8237, Test Accuracy: 60.1010, Avg. duration: 0.0278 s\n",
      "Epoch: 1184, Train Loss: 0.2455, Test Loss: 0.3051, Train Accuracy: 59.8237, Test Accuracy: 60.1010, Avg. duration: 0.0281 s\n",
      "Epoch: 1185, Train Loss: 0.2455, Test Loss: 0.3051, Train Accuracy: 59.8237, Test Accuracy: 60.1010, Avg. duration: 0.0272 s\n",
      "Epoch: 1186, Train Loss: 0.2455, Test Loss: 0.3051, Train Accuracy: 59.8237, Test Accuracy: 60.1010, Avg. duration: 0.0281 s\n",
      "Epoch: 1187, Train Loss: 0.2455, Test Loss: 0.3051, Train Accuracy: 59.8237, Test Accuracy: 60.1010, Avg. duration: 0.0278 s\n",
      "Epoch: 1188, Train Loss: 0.2455, Test Loss: 0.3051, Train Accuracy: 59.8237, Test Accuracy: 60.1010, Avg. duration: 0.0279 s\n",
      "Epoch: 1189, Train Loss: 0.2455, Test Loss: 0.3051, Train Accuracy: 59.8237, Test Accuracy: 60.1010, Avg. duration: 0.0276 s\n",
      "Epoch: 1190, Train Loss: 0.2455, Test Loss: 0.3051, Train Accuracy: 59.8237, Test Accuracy: 60.1010, Avg. duration: 0.0277 s\n",
      "Epoch: 1191, Train Loss: 0.2455, Test Loss: 0.3051, Train Accuracy: 59.8237, Test Accuracy: 60.1010, Avg. duration: 0.0274 s\n",
      "Epoch: 1192, Train Loss: 0.2455, Test Loss: 0.3051, Train Accuracy: 59.8237, Test Accuracy: 60.1010, Avg. duration: 0.0271 s\n",
      "Epoch: 1193, Train Loss: 0.2455, Test Loss: 0.3051, Train Accuracy: 59.8237, Test Accuracy: 60.1010, Avg. duration: 0.0278 s\n",
      "Epoch: 1194, Train Loss: 0.2455, Test Loss: 0.3051, Train Accuracy: 59.8237, Test Accuracy: 60.1010, Avg. duration: 0.0282 s\n",
      "Epoch: 1195, Train Loss: 0.2455, Test Loss: 0.3051, Train Accuracy: 59.8237, Test Accuracy: 60.1010, Avg. duration: 0.0279 s\n",
      "Epoch: 1196, Train Loss: 0.2455, Test Loss: 0.3051, Train Accuracy: 59.8237, Test Accuracy: 60.1010, Avg. duration: 0.0276 s\n",
      "Epoch: 1197, Train Loss: 0.2455, Test Loss: 0.3051, Train Accuracy: 59.8237, Test Accuracy: 60.1010, Avg. duration: 0.0280 s\n",
      "Epoch: 1198, Train Loss: 0.2455, Test Loss: 0.3051, Train Accuracy: 59.8237, Test Accuracy: 60.1010, Avg. duration: 0.0279 s\n",
      "Epoch: 1199, Train Loss: 0.2455, Test Loss: 0.3051, Train Accuracy: 59.8237, Test Accuracy: 60.1010, Avg. duration: 0.0279 s\n",
      "Epoch: 1200, Train Loss: 0.2455, Test Loss: 0.3051, Train Accuracy: 59.8237, Test Accuracy: 60.1010, Avg. duration: 0.0277 s\n",
      "Epoch: 1201, Train Loss: 0.2410, Test Loss: 0.3041, Train Accuracy: 61.3350, Test Accuracy: 60.6061, Avg. duration: 2.7256 s\n",
      "Epoch: 1202, Train Loss: 0.2410, Test Loss: 0.3041, Train Accuracy: 61.3350, Test Accuracy: 60.6061, Avg. duration: 0.0294 s\n",
      "Epoch: 1203, Train Loss: 0.2410, Test Loss: 0.3041, Train Accuracy: 61.3350, Test Accuracy: 60.6061, Avg. duration: 0.0279 s\n",
      "Epoch: 1204, Train Loss: 0.2410, Test Loss: 0.3041, Train Accuracy: 61.3350, Test Accuracy: 60.6061, Avg. duration: 0.0273 s\n",
      "Epoch: 1205, Train Loss: 0.2410, Test Loss: 0.3041, Train Accuracy: 61.3350, Test Accuracy: 60.6061, Avg. duration: 0.0268 s\n",
      "Epoch: 1206, Train Loss: 0.2410, Test Loss: 0.3041, Train Accuracy: 61.3350, Test Accuracy: 60.6061, Avg. duration: 0.0271 s\n",
      "Epoch: 1207, Train Loss: 0.2410, Test Loss: 0.3041, Train Accuracy: 61.3350, Test Accuracy: 60.6061, Avg. duration: 0.0277 s\n",
      "Epoch: 1208, Train Loss: 0.2410, Test Loss: 0.3041, Train Accuracy: 61.3350, Test Accuracy: 60.6061, Avg. duration: 0.0276 s\n",
      "Epoch: 1209, Train Loss: 0.2410, Test Loss: 0.3041, Train Accuracy: 61.3350, Test Accuracy: 60.6061, Avg. duration: 0.0279 s\n",
      "Epoch: 1210, Train Loss: 0.2410, Test Loss: 0.3041, Train Accuracy: 61.3350, Test Accuracy: 60.6061, Avg. duration: 0.0270 s\n",
      "Epoch: 1211, Train Loss: 0.2410, Test Loss: 0.3041, Train Accuracy: 61.3350, Test Accuracy: 60.6061, Avg. duration: 0.0268 s\n",
      "Epoch: 1212, Train Loss: 0.2410, Test Loss: 0.3041, Train Accuracy: 61.3350, Test Accuracy: 60.6061, Avg. duration: 0.0274 s\n",
      "Epoch: 1213, Train Loss: 0.2410, Test Loss: 0.3041, Train Accuracy: 61.3350, Test Accuracy: 60.6061, Avg. duration: 0.0272 s\n",
      "Epoch: 1214, Train Loss: 0.2410, Test Loss: 0.3041, Train Accuracy: 61.3350, Test Accuracy: 60.6061, Avg. duration: 0.0275 s\n",
      "Epoch: 1215, Train Loss: 0.2410, Test Loss: 0.3041, Train Accuracy: 61.3350, Test Accuracy: 60.6061, Avg. duration: 0.0267 s\n",
      "Epoch: 1216, Train Loss: 0.2410, Test Loss: 0.3041, Train Accuracy: 61.3350, Test Accuracy: 60.6061, Avg. duration: 0.0268 s\n",
      "Epoch: 1217, Train Loss: 0.2410, Test Loss: 0.3041, Train Accuracy: 61.3350, Test Accuracy: 60.6061, Avg. duration: 0.0276 s\n",
      "Epoch: 1218, Train Loss: 0.2410, Test Loss: 0.3041, Train Accuracy: 61.3350, Test Accuracy: 60.6061, Avg. duration: 0.0276 s\n",
      "Epoch: 1219, Train Loss: 0.2410, Test Loss: 0.3041, Train Accuracy: 61.3350, Test Accuracy: 60.6061, Avg. duration: 0.0273 s\n",
      "Epoch: 1220, Train Loss: 0.2410, Test Loss: 0.3041, Train Accuracy: 61.3350, Test Accuracy: 60.6061, Avg. duration: 0.0273 s\n",
      "Epoch: 1221, Train Loss: 0.2410, Test Loss: 0.3041, Train Accuracy: 61.3350, Test Accuracy: 60.6061, Avg. duration: 0.0268 s\n",
      "Epoch: 1222, Train Loss: 0.2410, Test Loss: 0.3041, Train Accuracy: 61.3350, Test Accuracy: 60.6061, Avg. duration: 0.0268 s\n",
      "Epoch: 1223, Train Loss: 0.2410, Test Loss: 0.3041, Train Accuracy: 61.3350, Test Accuracy: 60.6061, Avg. duration: 0.0271 s\n",
      "Epoch: 1224, Train Loss: 0.2410, Test Loss: 0.3041, Train Accuracy: 61.3350, Test Accuracy: 60.6061, Avg. duration: 0.0272 s\n",
      "Epoch: 1225, Train Loss: 0.2410, Test Loss: 0.3041, Train Accuracy: 61.3350, Test Accuracy: 60.6061, Avg. duration: 0.0278 s\n",
      "Epoch: 1226, Train Loss: 0.2410, Test Loss: 0.3041, Train Accuracy: 61.3350, Test Accuracy: 60.6061, Avg. duration: 0.0273 s\n",
      "Epoch: 1227, Train Loss: 0.2410, Test Loss: 0.3041, Train Accuracy: 61.3350, Test Accuracy: 60.6061, Avg. duration: 0.0268 s\n",
      "Epoch: 1228, Train Loss: 0.2410, Test Loss: 0.3041, Train Accuracy: 61.3350, Test Accuracy: 60.6061, Avg. duration: 0.0270 s\n",
      "Epoch: 1229, Train Loss: 0.2410, Test Loss: 0.3041, Train Accuracy: 61.3350, Test Accuracy: 60.6061, Avg. duration: 0.0271 s\n",
      "Epoch: 1230, Train Loss: 0.2410, Test Loss: 0.3041, Train Accuracy: 61.3350, Test Accuracy: 60.6061, Avg. duration: 0.0273 s\n",
      "Epoch: 1231, Train Loss: 0.2410, Test Loss: 0.3041, Train Accuracy: 61.3350, Test Accuracy: 60.6061, Avg. duration: 0.0273 s\n",
      "Epoch: 1232, Train Loss: 0.2410, Test Loss: 0.3041, Train Accuracy: 61.3350, Test Accuracy: 60.6061, Avg. duration: 0.0276 s\n",
      "Epoch: 1233, Train Loss: 0.2410, Test Loss: 0.3041, Train Accuracy: 61.3350, Test Accuracy: 60.6061, Avg. duration: 0.0276 s\n",
      "Epoch: 1234, Train Loss: 0.2410, Test Loss: 0.3041, Train Accuracy: 61.3350, Test Accuracy: 60.6061, Avg. duration: 0.0276 s\n",
      "Epoch: 1235, Train Loss: 0.2410, Test Loss: 0.3041, Train Accuracy: 61.3350, Test Accuracy: 60.6061, Avg. duration: 0.0269 s\n",
      "Epoch: 1236, Train Loss: 0.2410, Test Loss: 0.3041, Train Accuracy: 61.3350, Test Accuracy: 60.6061, Avg. duration: 0.0276 s\n",
      "Epoch: 1237, Train Loss: 0.2410, Test Loss: 0.3041, Train Accuracy: 61.3350, Test Accuracy: 60.6061, Avg. duration: 0.0275 s\n",
      "Epoch: 1238, Train Loss: 0.2410, Test Loss: 0.3041, Train Accuracy: 61.3350, Test Accuracy: 60.6061, Avg. duration: 0.0273 s\n",
      "Epoch: 1239, Train Loss: 0.2410, Test Loss: 0.3041, Train Accuracy: 61.3350, Test Accuracy: 60.6061, Avg. duration: 0.0273 s\n",
      "Epoch: 1240, Train Loss: 0.2410, Test Loss: 0.3041, Train Accuracy: 61.3350, Test Accuracy: 60.6061, Avg. duration: 0.0272 s\n",
      "Epoch: 1241, Train Loss: 0.2410, Test Loss: 0.3041, Train Accuracy: 61.3350, Test Accuracy: 60.6061, Avg. duration: 0.0277 s\n",
      "Epoch: 1242, Train Loss: 0.2410, Test Loss: 0.3041, Train Accuracy: 61.3350, Test Accuracy: 60.6061, Avg. duration: 0.0275 s\n",
      "Epoch: 1243, Train Loss: 0.2410, Test Loss: 0.3041, Train Accuracy: 61.3350, Test Accuracy: 60.6061, Avg. duration: 0.0277 s\n",
      "Epoch: 1244, Train Loss: 0.2410, Test Loss: 0.3041, Train Accuracy: 61.3350, Test Accuracy: 60.6061, Avg. duration: 0.0275 s\n",
      "Epoch: 1245, Train Loss: 0.2410, Test Loss: 0.3041, Train Accuracy: 61.3350, Test Accuracy: 60.6061, Avg. duration: 0.0270 s\n",
      "Epoch: 1246, Train Loss: 0.2410, Test Loss: 0.3041, Train Accuracy: 61.3350, Test Accuracy: 60.6061, Avg. duration: 0.0292 s\n",
      "Epoch: 1247, Train Loss: 0.2410, Test Loss: 0.3041, Train Accuracy: 61.3350, Test Accuracy: 60.6061, Avg. duration: 0.0272 s\n",
      "Epoch: 1248, Train Loss: 0.2410, Test Loss: 0.3041, Train Accuracy: 61.3350, Test Accuracy: 60.6061, Avg. duration: 0.0275 s\n",
      "Epoch: 1249, Train Loss: 0.2410, Test Loss: 0.3041, Train Accuracy: 61.3350, Test Accuracy: 60.6061, Avg. duration: 0.0280 s\n",
      "Epoch: 1250, Train Loss: 0.2410, Test Loss: 0.3041, Train Accuracy: 61.3350, Test Accuracy: 60.6061, Avg. duration: 0.0274 s\n",
      "Epoch: 1251, Train Loss: 0.2410, Test Loss: 0.3041, Train Accuracy: 61.3350, Test Accuracy: 60.6061, Avg. duration: 0.0270 s\n",
      "Epoch: 1252, Train Loss: 0.2410, Test Loss: 0.3041, Train Accuracy: 61.3350, Test Accuracy: 60.6061, Avg. duration: 0.0271 s\n",
      "Epoch: 1253, Train Loss: 0.2410, Test Loss: 0.3041, Train Accuracy: 61.3350, Test Accuracy: 60.6061, Avg. duration: 0.0272 s\n",
      "Epoch: 1254, Train Loss: 0.2410, Test Loss: 0.3041, Train Accuracy: 61.3350, Test Accuracy: 60.6061, Avg. duration: 0.3084 s\n",
      "Epoch: 1255, Train Loss: 0.2410, Test Loss: 0.3041, Train Accuracy: 61.3350, Test Accuracy: 60.6061, Avg. duration: 0.0284 s\n",
      "Epoch: 1256, Train Loss: 0.2410, Test Loss: 0.3041, Train Accuracy: 61.3350, Test Accuracy: 60.6061, Avg. duration: 0.0278 s\n",
      "Epoch: 1257, Train Loss: 0.2410, Test Loss: 0.3041, Train Accuracy: 61.3350, Test Accuracy: 60.6061, Avg. duration: 0.0275 s\n",
      "Epoch: 1258, Train Loss: 0.2410, Test Loss: 0.3041, Train Accuracy: 61.3350, Test Accuracy: 60.6061, Avg. duration: 0.0276 s\n",
      "Epoch: 1259, Train Loss: 0.2410, Test Loss: 0.3041, Train Accuracy: 61.3350, Test Accuracy: 60.6061, Avg. duration: 0.0272 s\n",
      "Epoch: 1260, Train Loss: 0.2410, Test Loss: 0.3041, Train Accuracy: 61.3350, Test Accuracy: 60.6061, Avg. duration: 0.0275 s\n",
      "Epoch: 1261, Train Loss: 0.2410, Test Loss: 0.3041, Train Accuracy: 61.3350, Test Accuracy: 60.6061, Avg. duration: 0.0279 s\n",
      "Epoch: 1262, Train Loss: 0.2410, Test Loss: 0.3041, Train Accuracy: 61.3350, Test Accuracy: 60.6061, Avg. duration: 0.0279 s\n",
      "Epoch: 1263, Train Loss: 0.2410, Test Loss: 0.3041, Train Accuracy: 61.3350, Test Accuracy: 60.6061, Avg. duration: 0.0274 s\n",
      "Epoch: 1264, Train Loss: 0.2410, Test Loss: 0.3041, Train Accuracy: 61.3350, Test Accuracy: 60.6061, Avg. duration: 0.0276 s\n",
      "Epoch: 1265, Train Loss: 0.2410, Test Loss: 0.3041, Train Accuracy: 61.3350, Test Accuracy: 60.6061, Avg. duration: 0.0276 s\n",
      "Epoch: 1266, Train Loss: 0.2410, Test Loss: 0.3041, Train Accuracy: 61.3350, Test Accuracy: 60.6061, Avg. duration: 0.0278 s\n",
      "Epoch: 1267, Train Loss: 0.2410, Test Loss: 0.3041, Train Accuracy: 61.3350, Test Accuracy: 60.6061, Avg. duration: 0.0278 s\n",
      "Epoch: 1268, Train Loss: 0.2410, Test Loss: 0.3041, Train Accuracy: 61.3350, Test Accuracy: 60.6061, Avg. duration: 0.0278 s\n",
      "Epoch: 1269, Train Loss: 0.2410, Test Loss: 0.3041, Train Accuracy: 61.3350, Test Accuracy: 60.6061, Avg. duration: 0.0271 s\n",
      "Epoch: 1270, Train Loss: 0.2410, Test Loss: 0.3041, Train Accuracy: 61.3350, Test Accuracy: 60.6061, Avg. duration: 0.0277 s\n",
      "Epoch: 1271, Train Loss: 0.2410, Test Loss: 0.3041, Train Accuracy: 61.3350, Test Accuracy: 60.6061, Avg. duration: 0.0275 s\n",
      "Epoch: 1272, Train Loss: 0.2410, Test Loss: 0.3041, Train Accuracy: 61.3350, Test Accuracy: 60.6061, Avg. duration: 0.0276 s\n",
      "Epoch: 1273, Train Loss: 0.2410, Test Loss: 0.3041, Train Accuracy: 61.3350, Test Accuracy: 60.6061, Avg. duration: 0.0278 s\n",
      "Epoch: 1274, Train Loss: 0.2410, Test Loss: 0.3041, Train Accuracy: 61.3350, Test Accuracy: 60.6061, Avg. duration: 0.0277 s\n",
      "Epoch: 1275, Train Loss: 0.2410, Test Loss: 0.3041, Train Accuracy: 61.3350, Test Accuracy: 60.6061, Avg. duration: 0.0274 s\n",
      "Epoch: 1276, Train Loss: 0.2410, Test Loss: 0.3041, Train Accuracy: 61.3350, Test Accuracy: 60.6061, Avg. duration: 0.0273 s\n",
      "Epoch: 1277, Train Loss: 0.2410, Test Loss: 0.3041, Train Accuracy: 61.3350, Test Accuracy: 60.6061, Avg. duration: 0.0276 s\n",
      "Epoch: 1278, Train Loss: 0.2410, Test Loss: 0.3041, Train Accuracy: 61.3350, Test Accuracy: 60.6061, Avg. duration: 0.0280 s\n",
      "Epoch: 1279, Train Loss: 0.2410, Test Loss: 0.3041, Train Accuracy: 61.3350, Test Accuracy: 60.6061, Avg. duration: 0.0279 s\n",
      "Epoch: 1280, Train Loss: 0.2410, Test Loss: 0.3041, Train Accuracy: 61.3350, Test Accuracy: 60.6061, Avg. duration: 0.0276 s\n",
      "Epoch: 1281, Train Loss: 0.2410, Test Loss: 0.3041, Train Accuracy: 61.3350, Test Accuracy: 60.6061, Avg. duration: 0.0274 s\n",
      "Epoch: 1282, Train Loss: 0.2410, Test Loss: 0.3041, Train Accuracy: 61.3350, Test Accuracy: 60.6061, Avg. duration: 0.0273 s\n",
      "Epoch: 1283, Train Loss: 0.2410, Test Loss: 0.3041, Train Accuracy: 61.3350, Test Accuracy: 60.6061, Avg. duration: 0.0273 s\n",
      "Epoch: 1284, Train Loss: 0.2410, Test Loss: 0.3041, Train Accuracy: 61.3350, Test Accuracy: 60.6061, Avg. duration: 0.0276 s\n",
      "Epoch: 1285, Train Loss: 0.2410, Test Loss: 0.3041, Train Accuracy: 61.3350, Test Accuracy: 60.6061, Avg. duration: 0.0277 s\n",
      "Epoch: 1286, Train Loss: 0.2410, Test Loss: 0.3041, Train Accuracy: 61.3350, Test Accuracy: 60.6061, Avg. duration: 0.0280 s\n",
      "Epoch: 1287, Train Loss: 0.2410, Test Loss: 0.3041, Train Accuracy: 61.3350, Test Accuracy: 60.6061, Avg. duration: 0.0274 s\n",
      "Epoch: 1288, Train Loss: 0.2410, Test Loss: 0.3041, Train Accuracy: 61.3350, Test Accuracy: 60.6061, Avg. duration: 0.0275 s\n",
      "Epoch: 1289, Train Loss: 0.2410, Test Loss: 0.3041, Train Accuracy: 61.3350, Test Accuracy: 60.6061, Avg. duration: 0.0277 s\n",
      "Epoch: 1290, Train Loss: 0.2410, Test Loss: 0.3041, Train Accuracy: 61.3350, Test Accuracy: 60.6061, Avg. duration: 0.0277 s\n",
      "Epoch: 1291, Train Loss: 0.2410, Test Loss: 0.3041, Train Accuracy: 61.3350, Test Accuracy: 60.6061, Avg. duration: 0.0278 s\n",
      "Epoch: 1292, Train Loss: 0.2410, Test Loss: 0.3041, Train Accuracy: 61.3350, Test Accuracy: 60.6061, Avg. duration: 0.0277 s\n",
      "Epoch: 1293, Train Loss: 0.2410, Test Loss: 0.3041, Train Accuracy: 61.3350, Test Accuracy: 60.6061, Avg. duration: 0.0275 s\n",
      "Epoch: 1294, Train Loss: 0.2410, Test Loss: 0.3041, Train Accuracy: 61.3350, Test Accuracy: 60.6061, Avg. duration: 0.0280 s\n",
      "Epoch: 1295, Train Loss: 0.2410, Test Loss: 0.3041, Train Accuracy: 61.3350, Test Accuracy: 60.6061, Avg. duration: 0.0276 s\n",
      "Epoch: 1296, Train Loss: 0.2410, Test Loss: 0.3041, Train Accuracy: 61.3350, Test Accuracy: 60.6061, Avg. duration: 0.0277 s\n",
      "Epoch: 1297, Train Loss: 0.2410, Test Loss: 0.3041, Train Accuracy: 61.3350, Test Accuracy: 60.6061, Avg. duration: 0.0278 s\n",
      "Epoch: 1298, Train Loss: 0.2410, Test Loss: 0.3041, Train Accuracy: 61.3350, Test Accuracy: 60.6061, Avg. duration: 0.0276 s\n",
      "Epoch: 1299, Train Loss: 0.2410, Test Loss: 0.3041, Train Accuracy: 61.3350, Test Accuracy: 60.6061, Avg. duration: 0.0278 s\n",
      "Epoch: 1300, Train Loss: 0.2410, Test Loss: 0.3041, Train Accuracy: 61.3350, Test Accuracy: 60.6061, Avg. duration: 0.0277 s\n",
      "Epoch: 1301, Train Loss: 0.2363, Test Loss: 0.3036, Train Accuracy: 62.2166, Test Accuracy: 61.6162, Avg. duration: 2.7264 s\n",
      "Epoch: 1302, Train Loss: 0.2363, Test Loss: 0.3036, Train Accuracy: 62.2166, Test Accuracy: 61.6162, Avg. duration: 0.0289 s\n",
      "Epoch: 1303, Train Loss: 0.2363, Test Loss: 0.3036, Train Accuracy: 62.2166, Test Accuracy: 61.6162, Avg. duration: 0.0278 s\n",
      "Epoch: 1304, Train Loss: 0.2363, Test Loss: 0.3036, Train Accuracy: 62.2166, Test Accuracy: 61.6162, Avg. duration: 0.0278 s\n",
      "Epoch: 1305, Train Loss: 0.2363, Test Loss: 0.3036, Train Accuracy: 62.2166, Test Accuracy: 61.6162, Avg. duration: 0.0269 s\n",
      "Epoch: 1306, Train Loss: 0.2363, Test Loss: 0.3036, Train Accuracy: 62.2166, Test Accuracy: 61.6162, Avg. duration: 0.0271 s\n",
      "Epoch: 1307, Train Loss: 0.2363, Test Loss: 0.3036, Train Accuracy: 62.2166, Test Accuracy: 61.6162, Avg. duration: 0.0272 s\n",
      "Epoch: 1308, Train Loss: 0.2363, Test Loss: 0.3036, Train Accuracy: 62.2166, Test Accuracy: 61.6162, Avg. duration: 0.0277 s\n",
      "Epoch: 1309, Train Loss: 0.2363, Test Loss: 0.3036, Train Accuracy: 62.2166, Test Accuracy: 61.6162, Avg. duration: 0.0282 s\n",
      "Epoch: 1310, Train Loss: 0.2363, Test Loss: 0.3036, Train Accuracy: 62.2166, Test Accuracy: 61.6162, Avg. duration: 0.0272 s\n",
      "Epoch: 1311, Train Loss: 0.2363, Test Loss: 0.3036, Train Accuracy: 62.2166, Test Accuracy: 61.6162, Avg. duration: 0.0268 s\n",
      "Epoch: 1312, Train Loss: 0.2363, Test Loss: 0.3036, Train Accuracy: 62.2166, Test Accuracy: 61.6162, Avg. duration: 0.0271 s\n",
      "Epoch: 1313, Train Loss: 0.2363, Test Loss: 0.3036, Train Accuracy: 62.2166, Test Accuracy: 61.6162, Avg. duration: 0.0272 s\n",
      "Epoch: 1314, Train Loss: 0.2363, Test Loss: 0.3036, Train Accuracy: 62.2166, Test Accuracy: 61.6162, Avg. duration: 0.0270 s\n",
      "Epoch: 1315, Train Loss: 0.2363, Test Loss: 0.3036, Train Accuracy: 62.2166, Test Accuracy: 61.6162, Avg. duration: 0.0275 s\n",
      "Epoch: 1316, Train Loss: 0.2363, Test Loss: 0.3036, Train Accuracy: 62.2166, Test Accuracy: 61.6162, Avg. duration: 0.0277 s\n",
      "Epoch: 1317, Train Loss: 0.2363, Test Loss: 0.3036, Train Accuracy: 62.2166, Test Accuracy: 61.6162, Avg. duration: 0.0276 s\n",
      "Epoch: 1318, Train Loss: 0.2363, Test Loss: 0.3036, Train Accuracy: 62.2166, Test Accuracy: 61.6162, Avg. duration: 0.0270 s\n",
      "Epoch: 1319, Train Loss: 0.2363, Test Loss: 0.3036, Train Accuracy: 62.2166, Test Accuracy: 61.6162, Avg. duration: 0.0274 s\n",
      "Epoch: 1320, Train Loss: 0.2363, Test Loss: 0.3036, Train Accuracy: 62.2166, Test Accuracy: 61.6162, Avg. duration: 0.0275 s\n",
      "Epoch: 1321, Train Loss: 0.2363, Test Loss: 0.3036, Train Accuracy: 62.2166, Test Accuracy: 61.6162, Avg. duration: 0.3157 s\n",
      "Epoch: 1322, Train Loss: 0.2363, Test Loss: 0.3036, Train Accuracy: 62.2166, Test Accuracy: 61.6162, Avg. duration: 0.0280 s\n",
      "Epoch: 1323, Train Loss: 0.2363, Test Loss: 0.3036, Train Accuracy: 62.2166, Test Accuracy: 61.6162, Avg. duration: 0.0278 s\n",
      "Epoch: 1324, Train Loss: 0.2363, Test Loss: 0.3036, Train Accuracy: 62.2166, Test Accuracy: 61.6162, Avg. duration: 0.0269 s\n",
      "Epoch: 1325, Train Loss: 0.2363, Test Loss: 0.3036, Train Accuracy: 62.2166, Test Accuracy: 61.6162, Avg. duration: 0.0272 s\n",
      "Epoch: 1326, Train Loss: 0.2363, Test Loss: 0.3036, Train Accuracy: 62.2166, Test Accuracy: 61.6162, Avg. duration: 0.0272 s\n",
      "Epoch: 1327, Train Loss: 0.2363, Test Loss: 0.3036, Train Accuracy: 62.2166, Test Accuracy: 61.6162, Avg. duration: 0.0277 s\n",
      "Epoch: 1328, Train Loss: 0.2363, Test Loss: 0.3036, Train Accuracy: 62.2166, Test Accuracy: 61.6162, Avg. duration: 0.0269 s\n",
      "Epoch: 1329, Train Loss: 0.2363, Test Loss: 0.3036, Train Accuracy: 62.2166, Test Accuracy: 61.6162, Avg. duration: 0.0277 s\n",
      "Epoch: 1330, Train Loss: 0.2363, Test Loss: 0.3036, Train Accuracy: 62.2166, Test Accuracy: 61.6162, Avg. duration: 0.0269 s\n",
      "Epoch: 1331, Train Loss: 0.2363, Test Loss: 0.3036, Train Accuracy: 62.2166, Test Accuracy: 61.6162, Avg. duration: 0.0270 s\n",
      "Epoch: 1332, Train Loss: 0.2363, Test Loss: 0.3036, Train Accuracy: 62.2166, Test Accuracy: 61.6162, Avg. duration: 0.0275 s\n",
      "Epoch: 1333, Train Loss: 0.2363, Test Loss: 0.3036, Train Accuracy: 62.2166, Test Accuracy: 61.6162, Avg. duration: 0.0276 s\n",
      "Epoch: 1334, Train Loss: 0.2363, Test Loss: 0.3036, Train Accuracy: 62.2166, Test Accuracy: 61.6162, Avg. duration: 0.0272 s\n",
      "Epoch: 1335, Train Loss: 0.2363, Test Loss: 0.3036, Train Accuracy: 62.2166, Test Accuracy: 61.6162, Avg. duration: 0.0269 s\n",
      "Epoch: 1336, Train Loss: 0.2363, Test Loss: 0.3036, Train Accuracy: 62.2166, Test Accuracy: 61.6162, Avg. duration: 0.0275 s\n",
      "Epoch: 1337, Train Loss: 0.2363, Test Loss: 0.3036, Train Accuracy: 62.2166, Test Accuracy: 61.6162, Avg. duration: 0.0279 s\n",
      "Epoch: 1338, Train Loss: 0.2363, Test Loss: 0.3036, Train Accuracy: 62.2166, Test Accuracy: 61.6162, Avg. duration: 0.0277 s\n",
      "Epoch: 1339, Train Loss: 0.2363, Test Loss: 0.3036, Train Accuracy: 62.2166, Test Accuracy: 61.6162, Avg. duration: 0.0275 s\n",
      "Epoch: 1340, Train Loss: 0.2363, Test Loss: 0.3036, Train Accuracy: 62.2166, Test Accuracy: 61.6162, Avg. duration: 0.0270 s\n",
      "Epoch: 1341, Train Loss: 0.2363, Test Loss: 0.3036, Train Accuracy: 62.2166, Test Accuracy: 61.6162, Avg. duration: 0.0267 s\n",
      "Epoch: 1342, Train Loss: 0.2363, Test Loss: 0.3036, Train Accuracy: 62.2166, Test Accuracy: 61.6162, Avg. duration: 0.0273 s\n",
      "Epoch: 1343, Train Loss: 0.2363, Test Loss: 0.3036, Train Accuracy: 62.2166, Test Accuracy: 61.6162, Avg. duration: 0.0272 s\n",
      "Epoch: 1344, Train Loss: 0.2363, Test Loss: 0.3036, Train Accuracy: 62.2166, Test Accuracy: 61.6162, Avg. duration: 0.0276 s\n",
      "Epoch: 1345, Train Loss: 0.2363, Test Loss: 0.3036, Train Accuracy: 62.2166, Test Accuracy: 61.6162, Avg. duration: 0.0279 s\n",
      "Epoch: 1346, Train Loss: 0.2363, Test Loss: 0.3036, Train Accuracy: 62.2166, Test Accuracy: 61.6162, Avg. duration: 0.0274 s\n",
      "Epoch: 1347, Train Loss: 0.2363, Test Loss: 0.3036, Train Accuracy: 62.2166, Test Accuracy: 61.6162, Avg. duration: 0.0273 s\n",
      "Epoch: 1348, Train Loss: 0.2363, Test Loss: 0.3036, Train Accuracy: 62.2166, Test Accuracy: 61.6162, Avg. duration: 0.0273 s\n",
      "Epoch: 1349, Train Loss: 0.2363, Test Loss: 0.3036, Train Accuracy: 62.2166, Test Accuracy: 61.6162, Avg. duration: 0.0275 s\n",
      "Epoch: 1350, Train Loss: 0.2363, Test Loss: 0.3036, Train Accuracy: 62.2166, Test Accuracy: 61.6162, Avg. duration: 0.0276 s\n",
      "Epoch: 1351, Train Loss: 0.2363, Test Loss: 0.3036, Train Accuracy: 62.2166, Test Accuracy: 61.6162, Avg. duration: 0.0275 s\n",
      "Epoch: 1352, Train Loss: 0.2363, Test Loss: 0.3036, Train Accuracy: 62.2166, Test Accuracy: 61.6162, Avg. duration: 0.0273 s\n",
      "Epoch: 1353, Train Loss: 0.2363, Test Loss: 0.3036, Train Accuracy: 62.2166, Test Accuracy: 61.6162, Avg. duration: 0.0278 s\n",
      "Epoch: 1354, Train Loss: 0.2363, Test Loss: 0.3036, Train Accuracy: 62.2166, Test Accuracy: 61.6162, Avg. duration: 0.0274 s\n",
      "Epoch: 1355, Train Loss: 0.2363, Test Loss: 0.3036, Train Accuracy: 62.2166, Test Accuracy: 61.6162, Avg. duration: 0.0276 s\n",
      "Epoch: 1356, Train Loss: 0.2363, Test Loss: 0.3036, Train Accuracy: 62.2166, Test Accuracy: 61.6162, Avg. duration: 0.0279 s\n",
      "Epoch: 1357, Train Loss: 0.2363, Test Loss: 0.3036, Train Accuracy: 62.2166, Test Accuracy: 61.6162, Avg. duration: 0.0278 s\n",
      "Epoch: 1358, Train Loss: 0.2363, Test Loss: 0.3036, Train Accuracy: 62.2166, Test Accuracy: 61.6162, Avg. duration: 0.0276 s\n",
      "Epoch: 1359, Train Loss: 0.2363, Test Loss: 0.3036, Train Accuracy: 62.2166, Test Accuracy: 61.6162, Avg. duration: 0.0278 s\n",
      "Epoch: 1360, Train Loss: 0.2363, Test Loss: 0.3036, Train Accuracy: 62.2166, Test Accuracy: 61.6162, Avg. duration: 0.0276 s\n",
      "Epoch: 1361, Train Loss: 0.2363, Test Loss: 0.3036, Train Accuracy: 62.2166, Test Accuracy: 61.6162, Avg. duration: 0.0282 s\n",
      "Epoch: 1362, Train Loss: 0.2363, Test Loss: 0.3036, Train Accuracy: 62.2166, Test Accuracy: 61.6162, Avg. duration: 0.0277 s\n",
      "Epoch: 1363, Train Loss: 0.2363, Test Loss: 0.3036, Train Accuracy: 62.2166, Test Accuracy: 61.6162, Avg. duration: 0.0275 s\n",
      "Epoch: 1364, Train Loss: 0.2363, Test Loss: 0.3036, Train Accuracy: 62.2166, Test Accuracy: 61.6162, Avg. duration: 0.0272 s\n",
      "Epoch: 1365, Train Loss: 0.2363, Test Loss: 0.3036, Train Accuracy: 62.2166, Test Accuracy: 61.6162, Avg. duration: 0.0272 s\n",
      "Epoch: 1366, Train Loss: 0.2363, Test Loss: 0.3036, Train Accuracy: 62.2166, Test Accuracy: 61.6162, Avg. duration: 0.0277 s\n",
      "Epoch: 1367, Train Loss: 0.2363, Test Loss: 0.3036, Train Accuracy: 62.2166, Test Accuracy: 61.6162, Avg. duration: 0.0276 s\n",
      "Epoch: 1368, Train Loss: 0.2363, Test Loss: 0.3036, Train Accuracy: 62.2166, Test Accuracy: 61.6162, Avg. duration: 0.0279 s\n",
      "Epoch: 1369, Train Loss: 0.2363, Test Loss: 0.3036, Train Accuracy: 62.2166, Test Accuracy: 61.6162, Avg. duration: 0.0287 s\n",
      "Epoch: 1370, Train Loss: 0.2363, Test Loss: 0.3036, Train Accuracy: 62.2166, Test Accuracy: 61.6162, Avg. duration: 0.0277 s\n",
      "Epoch: 1371, Train Loss: 0.2363, Test Loss: 0.3036, Train Accuracy: 62.2166, Test Accuracy: 61.6162, Avg. duration: 0.0273 s\n",
      "Epoch: 1372, Train Loss: 0.2363, Test Loss: 0.3036, Train Accuracy: 62.2166, Test Accuracy: 61.6162, Avg. duration: 0.0276 s\n",
      "Epoch: 1373, Train Loss: 0.2363, Test Loss: 0.3036, Train Accuracy: 62.2166, Test Accuracy: 61.6162, Avg. duration: 0.0277 s\n",
      "Epoch: 1374, Train Loss: 0.2363, Test Loss: 0.3036, Train Accuracy: 62.2166, Test Accuracy: 61.6162, Avg. duration: 0.0281 s\n",
      "Epoch: 1375, Train Loss: 0.2363, Test Loss: 0.3036, Train Accuracy: 62.2166, Test Accuracy: 61.6162, Avg. duration: 0.0275 s\n",
      "Epoch: 1376, Train Loss: 0.2363, Test Loss: 0.3036, Train Accuracy: 62.2166, Test Accuracy: 61.6162, Avg. duration: 0.0275 s\n",
      "Epoch: 1377, Train Loss: 0.2363, Test Loss: 0.3036, Train Accuracy: 62.2166, Test Accuracy: 61.6162, Avg. duration: 0.0280 s\n",
      "Epoch: 1378, Train Loss: 0.2363, Test Loss: 0.3036, Train Accuracy: 62.2166, Test Accuracy: 61.6162, Avg. duration: 0.0276 s\n",
      "Epoch: 1379, Train Loss: 0.2363, Test Loss: 0.3036, Train Accuracy: 62.2166, Test Accuracy: 61.6162, Avg. duration: 0.0278 s\n",
      "Epoch: 1380, Train Loss: 0.2363, Test Loss: 0.3036, Train Accuracy: 62.2166, Test Accuracy: 61.6162, Avg. duration: 0.0278 s\n",
      "Epoch: 1381, Train Loss: 0.2363, Test Loss: 0.3036, Train Accuracy: 62.2166, Test Accuracy: 61.6162, Avg. duration: 0.0299 s\n",
      "Epoch: 1382, Train Loss: 0.2363, Test Loss: 0.3036, Train Accuracy: 62.2166, Test Accuracy: 61.6162, Avg. duration: 0.0276 s\n",
      "Epoch: 1383, Train Loss: 0.2363, Test Loss: 0.3036, Train Accuracy: 62.2166, Test Accuracy: 61.6162, Avg. duration: 0.0278 s\n",
      "Epoch: 1384, Train Loss: 0.2363, Test Loss: 0.3036, Train Accuracy: 62.2166, Test Accuracy: 61.6162, Avg. duration: 0.0278 s\n",
      "Epoch: 1385, Train Loss: 0.2363, Test Loss: 0.3036, Train Accuracy: 62.2166, Test Accuracy: 61.6162, Avg. duration: 0.0287 s\n",
      "Epoch: 1386, Train Loss: 0.2363, Test Loss: 0.3036, Train Accuracy: 62.2166, Test Accuracy: 61.6162, Avg. duration: 0.0277 s\n",
      "Epoch: 1387, Train Loss: 0.2363, Test Loss: 0.3036, Train Accuracy: 62.2166, Test Accuracy: 61.6162, Avg. duration: 0.0277 s\n",
      "Epoch: 1388, Train Loss: 0.2363, Test Loss: 0.3036, Train Accuracy: 62.2166, Test Accuracy: 61.6162, Avg. duration: 0.0277 s\n",
      "Epoch: 1389, Train Loss: 0.2363, Test Loss: 0.3036, Train Accuracy: 62.2166, Test Accuracy: 61.6162, Avg. duration: 0.0277 s\n",
      "Epoch: 1390, Train Loss: 0.2363, Test Loss: 0.3036, Train Accuracy: 62.2166, Test Accuracy: 61.6162, Avg. duration: 0.0277 s\n",
      "Epoch: 1391, Train Loss: 0.2363, Test Loss: 0.3036, Train Accuracy: 62.2166, Test Accuracy: 61.6162, Avg. duration: 0.0279 s\n",
      "Epoch: 1392, Train Loss: 0.2363, Test Loss: 0.3036, Train Accuracy: 62.2166, Test Accuracy: 61.6162, Avg. duration: 0.0277 s\n",
      "Epoch: 1393, Train Loss: 0.2363, Test Loss: 0.3036, Train Accuracy: 62.2166, Test Accuracy: 61.6162, Avg. duration: 0.0283 s\n",
      "Epoch: 1394, Train Loss: 0.2363, Test Loss: 0.3036, Train Accuracy: 62.2166, Test Accuracy: 61.6162, Avg. duration: 0.0275 s\n",
      "Epoch: 1395, Train Loss: 0.2363, Test Loss: 0.3036, Train Accuracy: 62.2166, Test Accuracy: 61.6162, Avg. duration: 0.0273 s\n",
      "Epoch: 1396, Train Loss: 0.2363, Test Loss: 0.3036, Train Accuracy: 62.2166, Test Accuracy: 61.6162, Avg. duration: 0.0277 s\n",
      "Epoch: 1397, Train Loss: 0.2363, Test Loss: 0.3036, Train Accuracy: 62.2166, Test Accuracy: 61.6162, Avg. duration: 0.3168 s\n",
      "Epoch: 1398, Train Loss: 0.2363, Test Loss: 0.3036, Train Accuracy: 62.2166, Test Accuracy: 61.6162, Avg. duration: 0.0291 s\n",
      "Epoch: 1399, Train Loss: 0.2363, Test Loss: 0.3036, Train Accuracy: 62.2166, Test Accuracy: 61.6162, Avg. duration: 0.0286 s\n",
      "Epoch: 1400, Train Loss: 0.2363, Test Loss: 0.3036, Train Accuracy: 62.2166, Test Accuracy: 61.6162, Avg. duration: 0.0277 s\n",
      "Epoch: 1401, Train Loss: 0.2329, Test Loss: 0.3041, Train Accuracy: 61.7128, Test Accuracy: 60.6061, Avg. duration: 2.7374 s\n",
      "Epoch: 1402, Train Loss: 0.2329, Test Loss: 0.3041, Train Accuracy: 61.7128, Test Accuracy: 60.6061, Avg. duration: 0.0293 s\n",
      "Epoch: 1403, Train Loss: 0.2329, Test Loss: 0.3041, Train Accuracy: 61.7128, Test Accuracy: 60.6061, Avg. duration: 0.0281 s\n",
      "Epoch: 1404, Train Loss: 0.2329, Test Loss: 0.3041, Train Accuracy: 61.7128, Test Accuracy: 60.6061, Avg. duration: 0.0276 s\n",
      "Epoch: 1405, Train Loss: 0.2329, Test Loss: 0.3041, Train Accuracy: 61.7128, Test Accuracy: 60.6061, Avg. duration: 0.0278 s\n",
      "Epoch: 1406, Train Loss: 0.2329, Test Loss: 0.3041, Train Accuracy: 61.7128, Test Accuracy: 60.6061, Avg. duration: 0.0269 s\n",
      "Epoch: 1407, Train Loss: 0.2329, Test Loss: 0.3041, Train Accuracy: 61.7128, Test Accuracy: 60.6061, Avg. duration: 0.0275 s\n",
      "Epoch: 1408, Train Loss: 0.2329, Test Loss: 0.3041, Train Accuracy: 61.7128, Test Accuracy: 60.6061, Avg. duration: 0.0270 s\n",
      "Epoch: 1409, Train Loss: 0.2329, Test Loss: 0.3041, Train Accuracy: 61.7128, Test Accuracy: 60.6061, Avg. duration: 0.0278 s\n",
      "Epoch: 1410, Train Loss: 0.2329, Test Loss: 0.3041, Train Accuracy: 61.7128, Test Accuracy: 60.6061, Avg. duration: 0.0276 s\n",
      "Epoch: 1411, Train Loss: 0.2329, Test Loss: 0.3041, Train Accuracy: 61.7128, Test Accuracy: 60.6061, Avg. duration: 0.0275 s\n",
      "Epoch: 1412, Train Loss: 0.2329, Test Loss: 0.3041, Train Accuracy: 61.7128, Test Accuracy: 60.6061, Avg. duration: 0.0268 s\n",
      "Epoch: 1413, Train Loss: 0.2329, Test Loss: 0.3041, Train Accuracy: 61.7128, Test Accuracy: 60.6061, Avg. duration: 0.0270 s\n",
      "Epoch: 1414, Train Loss: 0.2329, Test Loss: 0.3041, Train Accuracy: 61.7128, Test Accuracy: 60.6061, Avg. duration: 0.0269 s\n",
      "Epoch: 1415, Train Loss: 0.2329, Test Loss: 0.3041, Train Accuracy: 61.7128, Test Accuracy: 60.6061, Avg. duration: 0.0274 s\n",
      "Epoch: 1416, Train Loss: 0.2329, Test Loss: 0.3041, Train Accuracy: 61.7128, Test Accuracy: 60.6061, Avg. duration: 0.0275 s\n",
      "Epoch: 1417, Train Loss: 0.2329, Test Loss: 0.3041, Train Accuracy: 61.7128, Test Accuracy: 60.6061, Avg. duration: 0.0282 s\n",
      "Epoch: 1418, Train Loss: 0.2329, Test Loss: 0.3041, Train Accuracy: 61.7128, Test Accuracy: 60.6061, Avg. duration: 0.0270 s\n",
      "Epoch: 1419, Train Loss: 0.2329, Test Loss: 0.3041, Train Accuracy: 61.7128, Test Accuracy: 60.6061, Avg. duration: 0.0272 s\n",
      "Epoch: 1420, Train Loss: 0.2329, Test Loss: 0.3041, Train Accuracy: 61.7128, Test Accuracy: 60.6061, Avg. duration: 0.0270 s\n",
      "Epoch: 1421, Train Loss: 0.2329, Test Loss: 0.3041, Train Accuracy: 61.7128, Test Accuracy: 60.6061, Avg. duration: 0.0272 s\n",
      "Epoch: 1422, Train Loss: 0.2329, Test Loss: 0.3041, Train Accuracy: 61.7128, Test Accuracy: 60.6061, Avg. duration: 0.0276 s\n",
      "Epoch: 1423, Train Loss: 0.2329, Test Loss: 0.3041, Train Accuracy: 61.7128, Test Accuracy: 60.6061, Avg. duration: 0.0271 s\n",
      "Epoch: 1424, Train Loss: 0.2329, Test Loss: 0.3041, Train Accuracy: 61.7128, Test Accuracy: 60.6061, Avg. duration: 0.0268 s\n",
      "Epoch: 1425, Train Loss: 0.2329, Test Loss: 0.3041, Train Accuracy: 61.7128, Test Accuracy: 60.6061, Avg. duration: 0.0277 s\n",
      "Epoch: 1426, Train Loss: 0.2329, Test Loss: 0.3041, Train Accuracy: 61.7128, Test Accuracy: 60.6061, Avg. duration: 0.0272 s\n",
      "Epoch: 1427, Train Loss: 0.2329, Test Loss: 0.3041, Train Accuracy: 61.7128, Test Accuracy: 60.6061, Avg. duration: 0.0271 s\n",
      "Epoch: 1428, Train Loss: 0.2329, Test Loss: 0.3041, Train Accuracy: 61.7128, Test Accuracy: 60.6061, Avg. duration: 0.0275 s\n",
      "Epoch: 1429, Train Loss: 0.2329, Test Loss: 0.3041, Train Accuracy: 61.7128, Test Accuracy: 60.6061, Avg. duration: 0.0271 s\n",
      "Epoch: 1430, Train Loss: 0.2329, Test Loss: 0.3041, Train Accuracy: 61.7128, Test Accuracy: 60.6061, Avg. duration: 0.0272 s\n",
      "Epoch: 1431, Train Loss: 0.2329, Test Loss: 0.3041, Train Accuracy: 61.7128, Test Accuracy: 60.6061, Avg. duration: 0.0272 s\n",
      "Epoch: 1432, Train Loss: 0.2329, Test Loss: 0.3041, Train Accuracy: 61.7128, Test Accuracy: 60.6061, Avg. duration: 0.0269 s\n",
      "Epoch: 1433, Train Loss: 0.2329, Test Loss: 0.3041, Train Accuracy: 61.7128, Test Accuracy: 60.6061, Avg. duration: 0.0281 s\n",
      "Epoch: 1434, Train Loss: 0.2329, Test Loss: 0.3041, Train Accuracy: 61.7128, Test Accuracy: 60.6061, Avg. duration: 0.0277 s\n",
      "Epoch: 1435, Train Loss: 0.2329, Test Loss: 0.3041, Train Accuracy: 61.7128, Test Accuracy: 60.6061, Avg. duration: 0.0274 s\n",
      "Epoch: 1436, Train Loss: 0.2329, Test Loss: 0.3041, Train Accuracy: 61.7128, Test Accuracy: 60.6061, Avg. duration: 0.0270 s\n",
      "Epoch: 1437, Train Loss: 0.2329, Test Loss: 0.3041, Train Accuracy: 61.7128, Test Accuracy: 60.6061, Avg. duration: 0.0270 s\n",
      "Epoch: 1438, Train Loss: 0.2329, Test Loss: 0.3041, Train Accuracy: 61.7128, Test Accuracy: 60.6061, Avg. duration: 0.0274 s\n",
      "Epoch: 1439, Train Loss: 0.2329, Test Loss: 0.3041, Train Accuracy: 61.7128, Test Accuracy: 60.6061, Avg. duration: 0.0271 s\n",
      "Epoch: 1440, Train Loss: 0.2329, Test Loss: 0.3041, Train Accuracy: 61.7128, Test Accuracy: 60.6061, Avg. duration: 0.0275 s\n",
      "Epoch: 1441, Train Loss: 0.2329, Test Loss: 0.3041, Train Accuracy: 61.7128, Test Accuracy: 60.6061, Avg. duration: 0.0279 s\n",
      "Epoch: 1442, Train Loss: 0.2329, Test Loss: 0.3041, Train Accuracy: 61.7128, Test Accuracy: 60.6061, Avg. duration: 0.0276 s\n",
      "Epoch: 1443, Train Loss: 0.2329, Test Loss: 0.3041, Train Accuracy: 61.7128, Test Accuracy: 60.6061, Avg. duration: 0.0270 s\n",
      "Epoch: 1444, Train Loss: 0.2329, Test Loss: 0.3041, Train Accuracy: 61.7128, Test Accuracy: 60.6061, Avg. duration: 0.0276 s\n",
      "Epoch: 1445, Train Loss: 0.2329, Test Loss: 0.3041, Train Accuracy: 61.7128, Test Accuracy: 60.6061, Avg. duration: 0.0275 s\n",
      "Epoch: 1446, Train Loss: 0.2329, Test Loss: 0.3041, Train Accuracy: 61.7128, Test Accuracy: 60.6061, Avg. duration: 0.0275 s\n",
      "Epoch: 1447, Train Loss: 0.2329, Test Loss: 0.3041, Train Accuracy: 61.7128, Test Accuracy: 60.6061, Avg. duration: 0.0277 s\n",
      "Epoch: 1448, Train Loss: 0.2329, Test Loss: 0.3041, Train Accuracy: 61.7128, Test Accuracy: 60.6061, Avg. duration: 0.0272 s\n",
      "Epoch: 1449, Train Loss: 0.2329, Test Loss: 0.3041, Train Accuracy: 61.7128, Test Accuracy: 60.6061, Avg. duration: 0.0278 s\n",
      "Epoch: 1450, Train Loss: 0.2329, Test Loss: 0.3041, Train Accuracy: 61.7128, Test Accuracy: 60.6061, Avg. duration: 0.0270 s\n",
      "Epoch: 1451, Train Loss: 0.2329, Test Loss: 0.3041, Train Accuracy: 61.7128, Test Accuracy: 60.6061, Avg. duration: 0.0273 s\n",
      "Epoch: 1452, Train Loss: 0.2329, Test Loss: 0.3041, Train Accuracy: 61.7128, Test Accuracy: 60.6061, Avg. duration: 0.0277 s\n",
      "Epoch: 1453, Train Loss: 0.2329, Test Loss: 0.3041, Train Accuracy: 61.7128, Test Accuracy: 60.6061, Avg. duration: 0.0277 s\n",
      "Epoch: 1454, Train Loss: 0.2329, Test Loss: 0.3041, Train Accuracy: 61.7128, Test Accuracy: 60.6061, Avg. duration: 0.0274 s\n",
      "Epoch: 1455, Train Loss: 0.2329, Test Loss: 0.3041, Train Accuracy: 61.7128, Test Accuracy: 60.6061, Avg. duration: 0.0274 s\n",
      "Epoch: 1456, Train Loss: 0.2329, Test Loss: 0.3041, Train Accuracy: 61.7128, Test Accuracy: 60.6061, Avg. duration: 0.0275 s\n",
      "Epoch: 1457, Train Loss: 0.2329, Test Loss: 0.3041, Train Accuracy: 61.7128, Test Accuracy: 60.6061, Avg. duration: 0.0279 s\n",
      "Epoch: 1458, Train Loss: 0.2329, Test Loss: 0.3041, Train Accuracy: 61.7128, Test Accuracy: 60.6061, Avg. duration: 0.0276 s\n",
      "Epoch: 1459, Train Loss: 0.2329, Test Loss: 0.3041, Train Accuracy: 61.7128, Test Accuracy: 60.6061, Avg. duration: 0.0275 s\n",
      "Epoch: 1460, Train Loss: 0.2329, Test Loss: 0.3041, Train Accuracy: 61.7128, Test Accuracy: 60.6061, Avg. duration: 0.0273 s\n",
      "Epoch: 1461, Train Loss: 0.2329, Test Loss: 0.3041, Train Accuracy: 61.7128, Test Accuracy: 60.6061, Avg. duration: 0.0271 s\n",
      "Epoch: 1462, Train Loss: 0.2329, Test Loss: 0.3041, Train Accuracy: 61.7128, Test Accuracy: 60.6061, Avg. duration: 0.0278 s\n",
      "Epoch: 1463, Train Loss: 0.2329, Test Loss: 0.3041, Train Accuracy: 61.7128, Test Accuracy: 60.6061, Avg. duration: 0.0278 s\n",
      "Epoch: 1464, Train Loss: 0.2329, Test Loss: 0.3041, Train Accuracy: 61.7128, Test Accuracy: 60.6061, Avg. duration: 0.3185 s\n",
      "Epoch: 1465, Train Loss: 0.2329, Test Loss: 0.3041, Train Accuracy: 61.7128, Test Accuracy: 60.6061, Avg. duration: 0.0285 s\n",
      "Epoch: 1466, Train Loss: 0.2329, Test Loss: 0.3041, Train Accuracy: 61.7128, Test Accuracy: 60.6061, Avg. duration: 0.0281 s\n",
      "Epoch: 1467, Train Loss: 0.2329, Test Loss: 0.3041, Train Accuracy: 61.7128, Test Accuracy: 60.6061, Avg. duration: 0.0281 s\n",
      "Epoch: 1468, Train Loss: 0.2329, Test Loss: 0.3041, Train Accuracy: 61.7128, Test Accuracy: 60.6061, Avg. duration: 0.0275 s\n",
      "Epoch: 1469, Train Loss: 0.2329, Test Loss: 0.3041, Train Accuracy: 61.7128, Test Accuracy: 60.6061, Avg. duration: 0.0280 s\n",
      "Epoch: 1470, Train Loss: 0.2329, Test Loss: 0.3041, Train Accuracy: 61.7128, Test Accuracy: 60.6061, Avg. duration: 0.0278 s\n",
      "Epoch: 1471, Train Loss: 0.2329, Test Loss: 0.3041, Train Accuracy: 61.7128, Test Accuracy: 60.6061, Avg. duration: 0.0273 s\n",
      "Epoch: 1472, Train Loss: 0.2329, Test Loss: 0.3041, Train Accuracy: 61.7128, Test Accuracy: 60.6061, Avg. duration: 0.0280 s\n",
      "Epoch: 1473, Train Loss: 0.2329, Test Loss: 0.3041, Train Accuracy: 61.7128, Test Accuracy: 60.6061, Avg. duration: 0.0275 s\n",
      "Epoch: 1474, Train Loss: 0.2329, Test Loss: 0.3041, Train Accuracy: 61.7128, Test Accuracy: 60.6061, Avg. duration: 0.0280 s\n",
      "Epoch: 1475, Train Loss: 0.2329, Test Loss: 0.3041, Train Accuracy: 61.7128, Test Accuracy: 60.6061, Avg. duration: 0.0279 s\n",
      "Epoch: 1476, Train Loss: 0.2329, Test Loss: 0.3041, Train Accuracy: 61.7128, Test Accuracy: 60.6061, Avg. duration: 0.0277 s\n",
      "Epoch: 1477, Train Loss: 0.2329, Test Loss: 0.3041, Train Accuracy: 61.7128, Test Accuracy: 60.6061, Avg. duration: 0.0274 s\n",
      "Epoch: 1478, Train Loss: 0.2329, Test Loss: 0.3041, Train Accuracy: 61.7128, Test Accuracy: 60.6061, Avg. duration: 0.0276 s\n",
      "Epoch: 1479, Train Loss: 0.2329, Test Loss: 0.3041, Train Accuracy: 61.7128, Test Accuracy: 60.6061, Avg. duration: 0.0278 s\n",
      "Epoch: 1480, Train Loss: 0.2329, Test Loss: 0.3041, Train Accuracy: 61.7128, Test Accuracy: 60.6061, Avg. duration: 0.0282 s\n",
      "Epoch: 1481, Train Loss: 0.2329, Test Loss: 0.3041, Train Accuracy: 61.7128, Test Accuracy: 60.6061, Avg. duration: 0.0278 s\n",
      "Epoch: 1482, Train Loss: 0.2329, Test Loss: 0.3041, Train Accuracy: 61.7128, Test Accuracy: 60.6061, Avg. duration: 0.0281 s\n",
      "Epoch: 1483, Train Loss: 0.2329, Test Loss: 0.3041, Train Accuracy: 61.7128, Test Accuracy: 60.6061, Avg. duration: 0.0273 s\n",
      "Epoch: 1484, Train Loss: 0.2329, Test Loss: 0.3041, Train Accuracy: 61.7128, Test Accuracy: 60.6061, Avg. duration: 0.0272 s\n",
      "Epoch: 1485, Train Loss: 0.2329, Test Loss: 0.3041, Train Accuracy: 61.7128, Test Accuracy: 60.6061, Avg. duration: 0.0277 s\n",
      "Epoch: 1486, Train Loss: 0.2329, Test Loss: 0.3041, Train Accuracy: 61.7128, Test Accuracy: 60.6061, Avg. duration: 0.0278 s\n",
      "Epoch: 1487, Train Loss: 0.2329, Test Loss: 0.3041, Train Accuracy: 61.7128, Test Accuracy: 60.6061, Avg. duration: 0.0280 s\n",
      "Epoch: 1488, Train Loss: 0.2329, Test Loss: 0.3041, Train Accuracy: 61.7128, Test Accuracy: 60.6061, Avg. duration: 0.0287 s\n",
      "Epoch: 1489, Train Loss: 0.2329, Test Loss: 0.3041, Train Accuracy: 61.7128, Test Accuracy: 60.6061, Avg. duration: 0.0278 s\n",
      "Epoch: 1490, Train Loss: 0.2329, Test Loss: 0.3041, Train Accuracy: 61.7128, Test Accuracy: 60.6061, Avg. duration: 0.0276 s\n",
      "Epoch: 1491, Train Loss: 0.2329, Test Loss: 0.3041, Train Accuracy: 61.7128, Test Accuracy: 60.6061, Avg. duration: 0.0279 s\n",
      "Epoch: 1492, Train Loss: 0.2329, Test Loss: 0.3041, Train Accuracy: 61.7128, Test Accuracy: 60.6061, Avg. duration: 0.0278 s\n",
      "Epoch: 1493, Train Loss: 0.2329, Test Loss: 0.3041, Train Accuracy: 61.7128, Test Accuracy: 60.6061, Avg. duration: 0.0278 s\n",
      "Epoch: 1494, Train Loss: 0.2329, Test Loss: 0.3041, Train Accuracy: 61.7128, Test Accuracy: 60.6061, Avg. duration: 0.0280 s\n",
      "Epoch: 1495, Train Loss: 0.2329, Test Loss: 0.3041, Train Accuracy: 61.7128, Test Accuracy: 60.6061, Avg. duration: 0.0277 s\n",
      "Epoch: 1496, Train Loss: 0.2329, Test Loss: 0.3041, Train Accuracy: 61.7128, Test Accuracy: 60.6061, Avg. duration: 0.0279 s\n",
      "Epoch: 1497, Train Loss: 0.2329, Test Loss: 0.3041, Train Accuracy: 61.7128, Test Accuracy: 60.6061, Avg. duration: 0.0274 s\n",
      "Epoch: 1498, Train Loss: 0.2329, Test Loss: 0.3041, Train Accuracy: 61.7128, Test Accuracy: 60.6061, Avg. duration: 0.0277 s\n",
      "Epoch: 1499, Train Loss: 0.2329, Test Loss: 0.3041, Train Accuracy: 61.7128, Test Accuracy: 60.6061, Avg. duration: 0.0280 s\n",
      "Epoch: 1500, Train Loss: 0.2329, Test Loss: 0.3041, Train Accuracy: 61.7128, Test Accuracy: 60.6061, Avg. duration: 0.0282 s\n",
      "Epoch: 1501, Train Loss: 0.2293, Test Loss: 0.3037, Train Accuracy: 63.0982, Test Accuracy: 61.6162, Avg. duration: 2.7236 s\n",
      "Epoch: 1502, Train Loss: 0.2293, Test Loss: 0.3037, Train Accuracy: 63.0982, Test Accuracy: 61.6162, Avg. duration: 0.0287 s\n",
      "Epoch: 1503, Train Loss: 0.2293, Test Loss: 0.3037, Train Accuracy: 63.0982, Test Accuracy: 61.6162, Avg. duration: 0.0272 s\n",
      "Epoch: 1504, Train Loss: 0.2293, Test Loss: 0.3037, Train Accuracy: 63.0982, Test Accuracy: 61.6162, Avg. duration: 0.0272 s\n",
      "Epoch: 1505, Train Loss: 0.2293, Test Loss: 0.3037, Train Accuracy: 63.0982, Test Accuracy: 61.6162, Avg. duration: 0.0272 s\n",
      "Epoch: 1506, Train Loss: 0.2293, Test Loss: 0.3037, Train Accuracy: 63.0982, Test Accuracy: 61.6162, Avg. duration: 0.0273 s\n",
      "Epoch: 1507, Train Loss: 0.2293, Test Loss: 0.3037, Train Accuracy: 63.0982, Test Accuracy: 61.6162, Avg. duration: 0.0270 s\n",
      "Epoch: 1508, Train Loss: 0.2293, Test Loss: 0.3037, Train Accuracy: 63.0982, Test Accuracy: 61.6162, Avg. duration: 0.0270 s\n",
      "Epoch: 1509, Train Loss: 0.2293, Test Loss: 0.3037, Train Accuracy: 63.0982, Test Accuracy: 61.6162, Avg. duration: 0.0276 s\n",
      "Epoch: 1510, Train Loss: 0.2293, Test Loss: 0.3037, Train Accuracy: 63.0982, Test Accuracy: 61.6162, Avg. duration: 0.0274 s\n",
      "Epoch: 1511, Train Loss: 0.2293, Test Loss: 0.3037, Train Accuracy: 63.0982, Test Accuracy: 61.6162, Avg. duration: 0.0271 s\n",
      "Epoch: 1512, Train Loss: 0.2293, Test Loss: 0.3037, Train Accuracy: 63.0982, Test Accuracy: 61.6162, Avg. duration: 0.0273 s\n",
      "Epoch: 1513, Train Loss: 0.2293, Test Loss: 0.3037, Train Accuracy: 63.0982, Test Accuracy: 61.6162, Avg. duration: 0.0269 s\n",
      "Epoch: 1514, Train Loss: 0.2293, Test Loss: 0.3037, Train Accuracy: 63.0982, Test Accuracy: 61.6162, Avg. duration: 0.0269 s\n",
      "Epoch: 1515, Train Loss: 0.2293, Test Loss: 0.3037, Train Accuracy: 63.0982, Test Accuracy: 61.6162, Avg. duration: 0.0272 s\n",
      "Epoch: 1516, Train Loss: 0.2293, Test Loss: 0.3037, Train Accuracy: 63.0982, Test Accuracy: 61.6162, Avg. duration: 0.0274 s\n",
      "Epoch: 1517, Train Loss: 0.2293, Test Loss: 0.3037, Train Accuracy: 63.0982, Test Accuracy: 61.6162, Avg. duration: 0.0275 s\n",
      "Epoch: 1518, Train Loss: 0.2293, Test Loss: 0.3037, Train Accuracy: 63.0982, Test Accuracy: 61.6162, Avg. duration: 0.0277 s\n",
      "Epoch: 1519, Train Loss: 0.2293, Test Loss: 0.3037, Train Accuracy: 63.0982, Test Accuracy: 61.6162, Avg. duration: 0.0270 s\n",
      "Epoch: 1520, Train Loss: 0.2293, Test Loss: 0.3037, Train Accuracy: 63.0982, Test Accuracy: 61.6162, Avg. duration: 0.0267 s\n",
      "Epoch: 1521, Train Loss: 0.2293, Test Loss: 0.3037, Train Accuracy: 63.0982, Test Accuracy: 61.6162, Avg. duration: 0.0269 s\n",
      "Epoch: 1522, Train Loss: 0.2293, Test Loss: 0.3037, Train Accuracy: 63.0982, Test Accuracy: 61.6162, Avg. duration: 0.0276 s\n",
      "Epoch: 1523, Train Loss: 0.2293, Test Loss: 0.3037, Train Accuracy: 63.0982, Test Accuracy: 61.6162, Avg. duration: 0.0274 s\n",
      "Epoch: 1524, Train Loss: 0.2293, Test Loss: 0.3037, Train Accuracy: 63.0982, Test Accuracy: 61.6162, Avg. duration: 0.0273 s\n",
      "Epoch: 1525, Train Loss: 0.2293, Test Loss: 0.3037, Train Accuracy: 63.0982, Test Accuracy: 61.6162, Avg. duration: 0.0276 s\n",
      "Epoch: 1526, Train Loss: 0.2293, Test Loss: 0.3037, Train Accuracy: 63.0982, Test Accuracy: 61.6162, Avg. duration: 0.0268 s\n",
      "Epoch: 1527, Train Loss: 0.2293, Test Loss: 0.3037, Train Accuracy: 63.0982, Test Accuracy: 61.6162, Avg. duration: 0.0272 s\n",
      "Epoch: 1528, Train Loss: 0.2293, Test Loss: 0.3037, Train Accuracy: 63.0982, Test Accuracy: 61.6162, Avg. duration: 0.0273 s\n",
      "Epoch: 1529, Train Loss: 0.2293, Test Loss: 0.3037, Train Accuracy: 63.0982, Test Accuracy: 61.6162, Avg. duration: 0.0274 s\n",
      "Epoch: 1530, Train Loss: 0.2293, Test Loss: 0.3037, Train Accuracy: 63.0982, Test Accuracy: 61.6162, Avg. duration: 0.0271 s\n",
      "Epoch: 1531, Train Loss: 0.2293, Test Loss: 0.3037, Train Accuracy: 63.0982, Test Accuracy: 61.6162, Avg. duration: 0.0272 s\n",
      "Epoch: 1532, Train Loss: 0.2293, Test Loss: 0.3037, Train Accuracy: 63.0982, Test Accuracy: 61.6162, Avg. duration: 0.0272 s\n",
      "Epoch: 1533, Train Loss: 0.2293, Test Loss: 0.3037, Train Accuracy: 63.0982, Test Accuracy: 61.6162, Avg. duration: 0.0276 s\n",
      "Epoch: 1534, Train Loss: 0.2293, Test Loss: 0.3037, Train Accuracy: 63.0982, Test Accuracy: 61.6162, Avg. duration: 0.0276 s\n",
      "Epoch: 1535, Train Loss: 0.2293, Test Loss: 0.3037, Train Accuracy: 63.0982, Test Accuracy: 61.6162, Avg. duration: 0.0272 s\n",
      "Epoch: 1536, Train Loss: 0.2293, Test Loss: 0.3037, Train Accuracy: 63.0982, Test Accuracy: 61.6162, Avg. duration: 0.0276 s\n",
      "Epoch: 1537, Train Loss: 0.2293, Test Loss: 0.3037, Train Accuracy: 63.0982, Test Accuracy: 61.6162, Avg. duration: 0.0268 s\n",
      "Epoch: 1538, Train Loss: 0.2293, Test Loss: 0.3037, Train Accuracy: 63.0982, Test Accuracy: 61.6162, Avg. duration: 0.0274 s\n",
      "Epoch: 1539, Train Loss: 0.2293, Test Loss: 0.3037, Train Accuracy: 63.0982, Test Accuracy: 61.6162, Avg. duration: 0.0271 s\n",
      "Epoch: 1540, Train Loss: 0.2293, Test Loss: 0.3037, Train Accuracy: 63.0982, Test Accuracy: 61.6162, Avg. duration: 0.3134 s\n",
      "Epoch: 1541, Train Loss: 0.2293, Test Loss: 0.3037, Train Accuracy: 63.0982, Test Accuracy: 61.6162, Avg. duration: 0.0283 s\n",
      "Epoch: 1542, Train Loss: 0.2293, Test Loss: 0.3037, Train Accuracy: 63.0982, Test Accuracy: 61.6162, Avg. duration: 0.0276 s\n",
      "Epoch: 1543, Train Loss: 0.2293, Test Loss: 0.3037, Train Accuracy: 63.0982, Test Accuracy: 61.6162, Avg. duration: 0.0273 s\n",
      "Epoch: 1544, Train Loss: 0.2293, Test Loss: 0.3037, Train Accuracy: 63.0982, Test Accuracy: 61.6162, Avg. duration: 0.0271 s\n",
      "Epoch: 1545, Train Loss: 0.2293, Test Loss: 0.3037, Train Accuracy: 63.0982, Test Accuracy: 61.6162, Avg. duration: 0.0273 s\n",
      "Epoch: 1546, Train Loss: 0.2293, Test Loss: 0.3037, Train Accuracy: 63.0982, Test Accuracy: 61.6162, Avg. duration: 0.0273 s\n",
      "Epoch: 1547, Train Loss: 0.2293, Test Loss: 0.3037, Train Accuracy: 63.0982, Test Accuracy: 61.6162, Avg. duration: 0.0276 s\n",
      "Epoch: 1548, Train Loss: 0.2293, Test Loss: 0.3037, Train Accuracy: 63.0982, Test Accuracy: 61.6162, Avg. duration: 0.0279 s\n",
      "Epoch: 1549, Train Loss: 0.2293, Test Loss: 0.3037, Train Accuracy: 63.0982, Test Accuracy: 61.6162, Avg. duration: 0.0274 s\n",
      "Epoch: 1550, Train Loss: 0.2293, Test Loss: 0.3037, Train Accuracy: 63.0982, Test Accuracy: 61.6162, Avg. duration: 0.0273 s\n",
      "Epoch: 1551, Train Loss: 0.2293, Test Loss: 0.3037, Train Accuracy: 63.0982, Test Accuracy: 61.6162, Avg. duration: 0.0276 s\n",
      "Epoch: 1552, Train Loss: 0.2293, Test Loss: 0.3037, Train Accuracy: 63.0982, Test Accuracy: 61.6162, Avg. duration: 0.0277 s\n",
      "Epoch: 1553, Train Loss: 0.2293, Test Loss: 0.3037, Train Accuracy: 63.0982, Test Accuracy: 61.6162, Avg. duration: 0.0279 s\n",
      "Epoch: 1554, Train Loss: 0.2293, Test Loss: 0.3037, Train Accuracy: 63.0982, Test Accuracy: 61.6162, Avg. duration: 0.0280 s\n",
      "Epoch: 1555, Train Loss: 0.2293, Test Loss: 0.3037, Train Accuracy: 63.0982, Test Accuracy: 61.6162, Avg. duration: 0.0275 s\n",
      "Epoch: 1556, Train Loss: 0.2293, Test Loss: 0.3037, Train Accuracy: 63.0982, Test Accuracy: 61.6162, Avg. duration: 0.0282 s\n",
      "Epoch: 1557, Train Loss: 0.2293, Test Loss: 0.3037, Train Accuracy: 63.0982, Test Accuracy: 61.6162, Avg. duration: 0.0277 s\n",
      "Epoch: 1558, Train Loss: 0.2293, Test Loss: 0.3037, Train Accuracy: 63.0982, Test Accuracy: 61.6162, Avg. duration: 0.0276 s\n",
      "Epoch: 1559, Train Loss: 0.2293, Test Loss: 0.3037, Train Accuracy: 63.0982, Test Accuracy: 61.6162, Avg. duration: 0.0275 s\n",
      "Epoch: 1560, Train Loss: 0.2293, Test Loss: 0.3037, Train Accuracy: 63.0982, Test Accuracy: 61.6162, Avg. duration: 0.0276 s\n",
      "Epoch: 1561, Train Loss: 0.2293, Test Loss: 0.3037, Train Accuracy: 63.0982, Test Accuracy: 61.6162, Avg. duration: 0.0272 s\n",
      "Epoch: 1562, Train Loss: 0.2293, Test Loss: 0.3037, Train Accuracy: 63.0982, Test Accuracy: 61.6162, Avg. duration: 0.0277 s\n",
      "Epoch: 1563, Train Loss: 0.2293, Test Loss: 0.3037, Train Accuracy: 63.0982, Test Accuracy: 61.6162, Avg. duration: 0.0276 s\n",
      "Epoch: 1564, Train Loss: 0.2293, Test Loss: 0.3037, Train Accuracy: 63.0982, Test Accuracy: 61.6162, Avg. duration: 0.0281 s\n",
      "Epoch: 1565, Train Loss: 0.2293, Test Loss: 0.3037, Train Accuracy: 63.0982, Test Accuracy: 61.6162, Avg. duration: 0.0276 s\n",
      "Epoch: 1566, Train Loss: 0.2293, Test Loss: 0.3037, Train Accuracy: 63.0982, Test Accuracy: 61.6162, Avg. duration: 0.0277 s\n",
      "Epoch: 1567, Train Loss: 0.2293, Test Loss: 0.3037, Train Accuracy: 63.0982, Test Accuracy: 61.6162, Avg. duration: 0.0275 s\n",
      "Epoch: 1568, Train Loss: 0.2293, Test Loss: 0.3037, Train Accuracy: 63.0982, Test Accuracy: 61.6162, Avg. duration: 0.0272 s\n",
      "Epoch: 1569, Train Loss: 0.2293, Test Loss: 0.3037, Train Accuracy: 63.0982, Test Accuracy: 61.6162, Avg. duration: 0.0275 s\n",
      "Epoch: 1570, Train Loss: 0.2293, Test Loss: 0.3037, Train Accuracy: 63.0982, Test Accuracy: 61.6162, Avg. duration: 0.0277 s\n",
      "Epoch: 1571, Train Loss: 0.2293, Test Loss: 0.3037, Train Accuracy: 63.0982, Test Accuracy: 61.6162, Avg. duration: 0.0278 s\n",
      "Epoch: 1572, Train Loss: 0.2293, Test Loss: 0.3037, Train Accuracy: 63.0982, Test Accuracy: 61.6162, Avg. duration: 0.0281 s\n",
      "Epoch: 1573, Train Loss: 0.2293, Test Loss: 0.3037, Train Accuracy: 63.0982, Test Accuracy: 61.6162, Avg. duration: 0.0274 s\n",
      "Epoch: 1574, Train Loss: 0.2293, Test Loss: 0.3037, Train Accuracy: 63.0982, Test Accuracy: 61.6162, Avg. duration: 0.0278 s\n",
      "Epoch: 1575, Train Loss: 0.2293, Test Loss: 0.3037, Train Accuracy: 63.0982, Test Accuracy: 61.6162, Avg. duration: 0.0278 s\n",
      "Epoch: 1576, Train Loss: 0.2293, Test Loss: 0.3037, Train Accuracy: 63.0982, Test Accuracy: 61.6162, Avg. duration: 0.0276 s\n",
      "Epoch: 1577, Train Loss: 0.2293, Test Loss: 0.3037, Train Accuracy: 63.0982, Test Accuracy: 61.6162, Avg. duration: 0.0279 s\n",
      "Epoch: 1578, Train Loss: 0.2293, Test Loss: 0.3037, Train Accuracy: 63.0982, Test Accuracy: 61.6162, Avg. duration: 0.0278 s\n",
      "Epoch: 1579, Train Loss: 0.2293, Test Loss: 0.3037, Train Accuracy: 63.0982, Test Accuracy: 61.6162, Avg. duration: 0.0276 s\n",
      "Epoch: 1580, Train Loss: 0.2293, Test Loss: 0.3037, Train Accuracy: 63.0982, Test Accuracy: 61.6162, Avg. duration: 0.0277 s\n",
      "Epoch: 1581, Train Loss: 0.2293, Test Loss: 0.3037, Train Accuracy: 63.0982, Test Accuracy: 61.6162, Avg. duration: 0.0278 s\n",
      "Epoch: 1582, Train Loss: 0.2293, Test Loss: 0.3037, Train Accuracy: 63.0982, Test Accuracy: 61.6162, Avg. duration: 0.0278 s\n",
      "Epoch: 1583, Train Loss: 0.2293, Test Loss: 0.3037, Train Accuracy: 63.0982, Test Accuracy: 61.6162, Avg. duration: 0.0279 s\n",
      "Epoch: 1584, Train Loss: 0.2293, Test Loss: 0.3037, Train Accuracy: 63.0982, Test Accuracy: 61.6162, Avg. duration: 0.0278 s\n",
      "Epoch: 1585, Train Loss: 0.2293, Test Loss: 0.3037, Train Accuracy: 63.0982, Test Accuracy: 61.6162, Avg. duration: 0.0274 s\n",
      "Epoch: 1586, Train Loss: 0.2293, Test Loss: 0.3037, Train Accuracy: 63.0982, Test Accuracy: 61.6162, Avg. duration: 0.0273 s\n",
      "Epoch: 1587, Train Loss: 0.2293, Test Loss: 0.3037, Train Accuracy: 63.0982, Test Accuracy: 61.6162, Avg. duration: 0.0274 s\n",
      "Epoch: 1588, Train Loss: 0.2293, Test Loss: 0.3037, Train Accuracy: 63.0982, Test Accuracy: 61.6162, Avg. duration: 0.0282 s\n",
      "Epoch: 1589, Train Loss: 0.2293, Test Loss: 0.3037, Train Accuracy: 63.0982, Test Accuracy: 61.6162, Avg. duration: 0.0280 s\n",
      "Epoch: 1590, Train Loss: 0.2293, Test Loss: 0.3037, Train Accuracy: 63.0982, Test Accuracy: 61.6162, Avg. duration: 0.0280 s\n",
      "Epoch: 1591, Train Loss: 0.2293, Test Loss: 0.3037, Train Accuracy: 63.0982, Test Accuracy: 61.6162, Avg. duration: 0.0274 s\n",
      "Epoch: 1592, Train Loss: 0.2293, Test Loss: 0.3037, Train Accuracy: 63.0982, Test Accuracy: 61.6162, Avg. duration: 0.0279 s\n",
      "Epoch: 1593, Train Loss: 0.2293, Test Loss: 0.3037, Train Accuracy: 63.0982, Test Accuracy: 61.6162, Avg. duration: 0.0277 s\n",
      "Epoch: 1594, Train Loss: 0.2293, Test Loss: 0.3037, Train Accuracy: 63.0982, Test Accuracy: 61.6162, Avg. duration: 0.0280 s\n",
      "Epoch: 1595, Train Loss: 0.2293, Test Loss: 0.3037, Train Accuracy: 63.0982, Test Accuracy: 61.6162, Avg. duration: 0.0277 s\n",
      "Epoch: 1596, Train Loss: 0.2293, Test Loss: 0.3037, Train Accuracy: 63.0982, Test Accuracy: 61.6162, Avg. duration: 0.0288 s\n",
      "Epoch: 1597, Train Loss: 0.2293, Test Loss: 0.3037, Train Accuracy: 63.0982, Test Accuracy: 61.6162, Avg. duration: 0.0276 s\n",
      "Epoch: 1598, Train Loss: 0.2293, Test Loss: 0.3037, Train Accuracy: 63.0982, Test Accuracy: 61.6162, Avg. duration: 0.0275 s\n",
      "Epoch: 1599, Train Loss: 0.2293, Test Loss: 0.3037, Train Accuracy: 63.0982, Test Accuracy: 61.6162, Avg. duration: 0.0280 s\n",
      "Epoch: 1600, Train Loss: 0.2293, Test Loss: 0.3037, Train Accuracy: 63.0982, Test Accuracy: 61.6162, Avg. duration: 0.0275 s\n",
      "Epoch: 1601, Train Loss: 0.2259, Test Loss: 0.3075, Train Accuracy: 63.7280, Test Accuracy: 61.1111, Avg. duration: 2.7270 s\n",
      "Epoch: 1602, Train Loss: 0.2259, Test Loss: 0.3075, Train Accuracy: 63.7280, Test Accuracy: 61.1111, Avg. duration: 0.0289 s\n",
      "Epoch: 1603, Train Loss: 0.2259, Test Loss: 0.3075, Train Accuracy: 63.7280, Test Accuracy: 61.1111, Avg. duration: 0.0275 s\n",
      "Epoch: 1604, Train Loss: 0.2259, Test Loss: 0.3075, Train Accuracy: 63.7280, Test Accuracy: 61.1111, Avg. duration: 0.0274 s\n",
      "Epoch: 1605, Train Loss: 0.2259, Test Loss: 0.3075, Train Accuracy: 63.7280, Test Accuracy: 61.1111, Avg. duration: 0.0274 s\n",
      "Epoch: 1606, Train Loss: 0.2259, Test Loss: 0.3075, Train Accuracy: 63.7280, Test Accuracy: 61.1111, Avg. duration: 0.0273 s\n",
      "Epoch: 1607, Train Loss: 0.2259, Test Loss: 0.3075, Train Accuracy: 63.7280, Test Accuracy: 61.1111, Avg. duration: 0.3147 s\n",
      "Epoch: 1608, Train Loss: 0.2259, Test Loss: 0.3075, Train Accuracy: 63.7280, Test Accuracy: 61.1111, Avg. duration: 0.0283 s\n",
      "Epoch: 1609, Train Loss: 0.2259, Test Loss: 0.3075, Train Accuracy: 63.7280, Test Accuracy: 61.1111, Avg. duration: 0.0273 s\n",
      "Epoch: 1610, Train Loss: 0.2259, Test Loss: 0.3075, Train Accuracy: 63.7280, Test Accuracy: 61.1111, Avg. duration: 0.0274 s\n",
      "Epoch: 1611, Train Loss: 0.2259, Test Loss: 0.3075, Train Accuracy: 63.7280, Test Accuracy: 61.1111, Avg. duration: 0.0278 s\n",
      "Epoch: 1612, Train Loss: 0.2259, Test Loss: 0.3075, Train Accuracy: 63.7280, Test Accuracy: 61.1111, Avg. duration: 0.0277 s\n",
      "Epoch: 1613, Train Loss: 0.2259, Test Loss: 0.3075, Train Accuracy: 63.7280, Test Accuracy: 61.1111, Avg. duration: 0.0278 s\n",
      "Epoch: 1614, Train Loss: 0.2259, Test Loss: 0.3075, Train Accuracy: 63.7280, Test Accuracy: 61.1111, Avg. duration: 0.0268 s\n",
      "Epoch: 1615, Train Loss: 0.2259, Test Loss: 0.3075, Train Accuracy: 63.7280, Test Accuracy: 61.1111, Avg. duration: 0.0278 s\n",
      "Epoch: 1616, Train Loss: 0.2259, Test Loss: 0.3075, Train Accuracy: 63.7280, Test Accuracy: 61.1111, Avg. duration: 0.0271 s\n",
      "Epoch: 1617, Train Loss: 0.2259, Test Loss: 0.3075, Train Accuracy: 63.7280, Test Accuracy: 61.1111, Avg. duration: 0.0269 s\n",
      "Epoch: 1618, Train Loss: 0.2259, Test Loss: 0.3075, Train Accuracy: 63.7280, Test Accuracy: 61.1111, Avg. duration: 0.0269 s\n",
      "Epoch: 1619, Train Loss: 0.2259, Test Loss: 0.3075, Train Accuracy: 63.7280, Test Accuracy: 61.1111, Avg. duration: 0.0276 s\n",
      "Epoch: 1620, Train Loss: 0.2259, Test Loss: 0.3075, Train Accuracy: 63.7280, Test Accuracy: 61.1111, Avg. duration: 0.0270 s\n",
      "Epoch: 1621, Train Loss: 0.2259, Test Loss: 0.3075, Train Accuracy: 63.7280, Test Accuracy: 61.1111, Avg. duration: 0.0269 s\n",
      "Epoch: 1622, Train Loss: 0.2259, Test Loss: 0.3075, Train Accuracy: 63.7280, Test Accuracy: 61.1111, Avg. duration: 0.0267 s\n",
      "Epoch: 1623, Train Loss: 0.2259, Test Loss: 0.3075, Train Accuracy: 63.7280, Test Accuracy: 61.1111, Avg. duration: 0.0277 s\n",
      "Epoch: 1624, Train Loss: 0.2259, Test Loss: 0.3075, Train Accuracy: 63.7280, Test Accuracy: 61.1111, Avg. duration: 0.0275 s\n",
      "Epoch: 1625, Train Loss: 0.2259, Test Loss: 0.3075, Train Accuracy: 63.7280, Test Accuracy: 61.1111, Avg. duration: 0.0272 s\n",
      "Epoch: 1626, Train Loss: 0.2259, Test Loss: 0.3075, Train Accuracy: 63.7280, Test Accuracy: 61.1111, Avg. duration: 0.0271 s\n",
      "Epoch: 1627, Train Loss: 0.2259, Test Loss: 0.3075, Train Accuracy: 63.7280, Test Accuracy: 61.1111, Avg. duration: 0.0269 s\n",
      "Epoch: 1628, Train Loss: 0.2259, Test Loss: 0.3075, Train Accuracy: 63.7280, Test Accuracy: 61.1111, Avg. duration: 0.0270 s\n",
      "Epoch: 1629, Train Loss: 0.2259, Test Loss: 0.3075, Train Accuracy: 63.7280, Test Accuracy: 61.1111, Avg. duration: 0.0273 s\n",
      "Epoch: 1630, Train Loss: 0.2259, Test Loss: 0.3075, Train Accuracy: 63.7280, Test Accuracy: 61.1111, Avg. duration: 0.0272 s\n",
      "Epoch: 1631, Train Loss: 0.2259, Test Loss: 0.3075, Train Accuracy: 63.7280, Test Accuracy: 61.1111, Avg. duration: 0.0280 s\n",
      "Epoch: 1632, Train Loss: 0.2259, Test Loss: 0.3075, Train Accuracy: 63.7280, Test Accuracy: 61.1111, Avg. duration: 0.0268 s\n",
      "Epoch: 1633, Train Loss: 0.2259, Test Loss: 0.3075, Train Accuracy: 63.7280, Test Accuracy: 61.1111, Avg. duration: 0.0272 s\n",
      "Epoch: 1634, Train Loss: 0.2259, Test Loss: 0.3075, Train Accuracy: 63.7280, Test Accuracy: 61.1111, Avg. duration: 0.0276 s\n",
      "Epoch: 1635, Train Loss: 0.2259, Test Loss: 0.3075, Train Accuracy: 63.7280, Test Accuracy: 61.1111, Avg. duration: 0.0273 s\n",
      "Epoch: 1636, Train Loss: 0.2259, Test Loss: 0.3075, Train Accuracy: 63.7280, Test Accuracy: 61.1111, Avg. duration: 0.0272 s\n",
      "Epoch: 1637, Train Loss: 0.2259, Test Loss: 0.3075, Train Accuracy: 63.7280, Test Accuracy: 61.1111, Avg. duration: 0.0276 s\n",
      "Epoch: 1638, Train Loss: 0.2259, Test Loss: 0.3075, Train Accuracy: 63.7280, Test Accuracy: 61.1111, Avg. duration: 0.0270 s\n",
      "Epoch: 1639, Train Loss: 0.2259, Test Loss: 0.3075, Train Accuracy: 63.7280, Test Accuracy: 61.1111, Avg. duration: 0.0274 s\n",
      "Epoch: 1640, Train Loss: 0.2259, Test Loss: 0.3075, Train Accuracy: 63.7280, Test Accuracy: 61.1111, Avg. duration: 0.0270 s\n",
      "Epoch: 1641, Train Loss: 0.2259, Test Loss: 0.3075, Train Accuracy: 63.7280, Test Accuracy: 61.1111, Avg. duration: 0.0272 s\n",
      "Epoch: 1642, Train Loss: 0.2259, Test Loss: 0.3075, Train Accuracy: 63.7280, Test Accuracy: 61.1111, Avg. duration: 0.0270 s\n",
      "Epoch: 1643, Train Loss: 0.2259, Test Loss: 0.3075, Train Accuracy: 63.7280, Test Accuracy: 61.1111, Avg. duration: 0.0273 s\n",
      "Epoch: 1644, Train Loss: 0.2259, Test Loss: 0.3075, Train Accuracy: 63.7280, Test Accuracy: 61.1111, Avg. duration: 0.0270 s\n",
      "Epoch: 1645, Train Loss: 0.2259, Test Loss: 0.3075, Train Accuracy: 63.7280, Test Accuracy: 61.1111, Avg. duration: 0.0269 s\n",
      "Epoch: 1646, Train Loss: 0.2259, Test Loss: 0.3075, Train Accuracy: 63.7280, Test Accuracy: 61.1111, Avg. duration: 0.0268 s\n",
      "Epoch: 1647, Train Loss: 0.2259, Test Loss: 0.3075, Train Accuracy: 63.7280, Test Accuracy: 61.1111, Avg. duration: 0.0273 s\n",
      "Epoch: 1648, Train Loss: 0.2259, Test Loss: 0.3075, Train Accuracy: 63.7280, Test Accuracy: 61.1111, Avg. duration: 0.0277 s\n",
      "Epoch: 1649, Train Loss: 0.2259, Test Loss: 0.3075, Train Accuracy: 63.7280, Test Accuracy: 61.1111, Avg. duration: 0.0277 s\n",
      "Epoch: 1650, Train Loss: 0.2259, Test Loss: 0.3075, Train Accuracy: 63.7280, Test Accuracy: 61.1111, Avg. duration: 0.0270 s\n",
      "Epoch: 1651, Train Loss: 0.2259, Test Loss: 0.3075, Train Accuracy: 63.7280, Test Accuracy: 61.1111, Avg. duration: 0.0269 s\n",
      "Epoch: 1652, Train Loss: 0.2259, Test Loss: 0.3075, Train Accuracy: 63.7280, Test Accuracy: 61.1111, Avg. duration: 0.0269 s\n",
      "Epoch: 1653, Train Loss: 0.2259, Test Loss: 0.3075, Train Accuracy: 63.7280, Test Accuracy: 61.1111, Avg. duration: 0.0275 s\n",
      "Epoch: 1654, Train Loss: 0.2259, Test Loss: 0.3075, Train Accuracy: 63.7280, Test Accuracy: 61.1111, Avg. duration: 0.0274 s\n",
      "Epoch: 1655, Train Loss: 0.2259, Test Loss: 0.3075, Train Accuracy: 63.7280, Test Accuracy: 61.1111, Avg. duration: 0.0282 s\n",
      "Epoch: 1656, Train Loss: 0.2259, Test Loss: 0.3075, Train Accuracy: 63.7280, Test Accuracy: 61.1111, Avg. duration: 0.0275 s\n",
      "Epoch: 1657, Train Loss: 0.2259, Test Loss: 0.3075, Train Accuracy: 63.7280, Test Accuracy: 61.1111, Avg. duration: 0.0271 s\n",
      "Epoch: 1658, Train Loss: 0.2259, Test Loss: 0.3075, Train Accuracy: 63.7280, Test Accuracy: 61.1111, Avg. duration: 0.0275 s\n",
      "Epoch: 1659, Train Loss: 0.2259, Test Loss: 0.3075, Train Accuracy: 63.7280, Test Accuracy: 61.1111, Avg. duration: 0.0275 s\n",
      "Epoch: 1660, Train Loss: 0.2259, Test Loss: 0.3075, Train Accuracy: 63.7280, Test Accuracy: 61.1111, Avg. duration: 0.0276 s\n",
      "Epoch: 1661, Train Loss: 0.2259, Test Loss: 0.3075, Train Accuracy: 63.7280, Test Accuracy: 61.1111, Avg. duration: 0.0278 s\n",
      "Epoch: 1662, Train Loss: 0.2259, Test Loss: 0.3075, Train Accuracy: 63.7280, Test Accuracy: 61.1111, Avg. duration: 0.0272 s\n",
      "Epoch: 1663, Train Loss: 0.2259, Test Loss: 0.3075, Train Accuracy: 63.7280, Test Accuracy: 61.1111, Avg. duration: 0.0276 s\n",
      "Epoch: 1664, Train Loss: 0.2259, Test Loss: 0.3075, Train Accuracy: 63.7280, Test Accuracy: 61.1111, Avg. duration: 0.0274 s\n",
      "Epoch: 1665, Train Loss: 0.2259, Test Loss: 0.3075, Train Accuracy: 63.7280, Test Accuracy: 61.1111, Avg. duration: 0.0279 s\n",
      "Epoch: 1666, Train Loss: 0.2259, Test Loss: 0.3075, Train Accuracy: 63.7280, Test Accuracy: 61.1111, Avg. duration: 0.0277 s\n",
      "Epoch: 1667, Train Loss: 0.2259, Test Loss: 0.3075, Train Accuracy: 63.7280, Test Accuracy: 61.1111, Avg. duration: 0.0275 s\n",
      "Epoch: 1668, Train Loss: 0.2259, Test Loss: 0.3075, Train Accuracy: 63.7280, Test Accuracy: 61.1111, Avg. duration: 0.0272 s\n",
      "Epoch: 1669, Train Loss: 0.2259, Test Loss: 0.3075, Train Accuracy: 63.7280, Test Accuracy: 61.1111, Avg. duration: 0.0274 s\n",
      "Epoch: 1670, Train Loss: 0.2259, Test Loss: 0.3075, Train Accuracy: 63.7280, Test Accuracy: 61.1111, Avg. duration: 0.0274 s\n",
      "Epoch: 1671, Train Loss: 0.2259, Test Loss: 0.3075, Train Accuracy: 63.7280, Test Accuracy: 61.1111, Avg. duration: 0.0282 s\n",
      "Epoch: 1672, Train Loss: 0.2259, Test Loss: 0.3075, Train Accuracy: 63.7280, Test Accuracy: 61.1111, Avg. duration: 0.0275 s\n",
      "Epoch: 1673, Train Loss: 0.2259, Test Loss: 0.3075, Train Accuracy: 63.7280, Test Accuracy: 61.1111, Avg. duration: 0.0276 s\n",
      "Epoch: 1674, Train Loss: 0.2259, Test Loss: 0.3075, Train Accuracy: 63.7280, Test Accuracy: 61.1111, Avg. duration: 0.0272 s\n",
      "Epoch: 1675, Train Loss: 0.2259, Test Loss: 0.3075, Train Accuracy: 63.7280, Test Accuracy: 61.1111, Avg. duration: 0.0275 s\n",
      "Epoch: 1676, Train Loss: 0.2259, Test Loss: 0.3075, Train Accuracy: 63.7280, Test Accuracy: 61.1111, Avg. duration: 0.0279 s\n",
      "Epoch: 1677, Train Loss: 0.2259, Test Loss: 0.3075, Train Accuracy: 63.7280, Test Accuracy: 61.1111, Avg. duration: 0.0278 s\n",
      "Epoch: 1678, Train Loss: 0.2259, Test Loss: 0.3075, Train Accuracy: 63.7280, Test Accuracy: 61.1111, Avg. duration: 0.0277 s\n",
      "Epoch: 1679, Train Loss: 0.2259, Test Loss: 0.3075, Train Accuracy: 63.7280, Test Accuracy: 61.1111, Avg. duration: 0.0280 s\n",
      "Epoch: 1680, Train Loss: 0.2259, Test Loss: 0.3075, Train Accuracy: 63.7280, Test Accuracy: 61.1111, Avg. duration: 0.0275 s\n",
      "Epoch: 1681, Train Loss: 0.2259, Test Loss: 0.3075, Train Accuracy: 63.7280, Test Accuracy: 61.1111, Avg. duration: 0.0274 s\n",
      "Epoch: 1682, Train Loss: 0.2259, Test Loss: 0.3075, Train Accuracy: 63.7280, Test Accuracy: 61.1111, Avg. duration: 0.0273 s\n",
      "Epoch: 1683, Train Loss: 0.2259, Test Loss: 0.3075, Train Accuracy: 63.7280, Test Accuracy: 61.1111, Avg. duration: 0.3146 s\n",
      "Epoch: 1684, Train Loss: 0.2259, Test Loss: 0.3075, Train Accuracy: 63.7280, Test Accuracy: 61.1111, Avg. duration: 0.0288 s\n",
      "Epoch: 1685, Train Loss: 0.2259, Test Loss: 0.3075, Train Accuracy: 63.7280, Test Accuracy: 61.1111, Avg. duration: 0.0280 s\n",
      "Epoch: 1686, Train Loss: 0.2259, Test Loss: 0.3075, Train Accuracy: 63.7280, Test Accuracy: 61.1111, Avg. duration: 0.0276 s\n",
      "Epoch: 1687, Train Loss: 0.2259, Test Loss: 0.3075, Train Accuracy: 63.7280, Test Accuracy: 61.1111, Avg. duration: 0.0277 s\n",
      "Epoch: 1688, Train Loss: 0.2259, Test Loss: 0.3075, Train Accuracy: 63.7280, Test Accuracy: 61.1111, Avg. duration: 0.0277 s\n",
      "Epoch: 1689, Train Loss: 0.2259, Test Loss: 0.3075, Train Accuracy: 63.7280, Test Accuracy: 61.1111, Avg. duration: 0.0278 s\n",
      "Epoch: 1690, Train Loss: 0.2259, Test Loss: 0.3075, Train Accuracy: 63.7280, Test Accuracy: 61.1111, Avg. duration: 0.0279 s\n",
      "Epoch: 1691, Train Loss: 0.2259, Test Loss: 0.3075, Train Accuracy: 63.7280, Test Accuracy: 61.1111, Avg. duration: 0.0286 s\n",
      "Epoch: 1692, Train Loss: 0.2259, Test Loss: 0.3075, Train Accuracy: 63.7280, Test Accuracy: 61.1111, Avg. duration: 0.0278 s\n",
      "Epoch: 1693, Train Loss: 0.2259, Test Loss: 0.3075, Train Accuracy: 63.7280, Test Accuracy: 61.1111, Avg. duration: 0.0278 s\n",
      "Epoch: 1694, Train Loss: 0.2259, Test Loss: 0.3075, Train Accuracy: 63.7280, Test Accuracy: 61.1111, Avg. duration: 0.0273 s\n",
      "Epoch: 1695, Train Loss: 0.2259, Test Loss: 0.3075, Train Accuracy: 63.7280, Test Accuracy: 61.1111, Avg. duration: 0.0280 s\n",
      "Epoch: 1696, Train Loss: 0.2259, Test Loss: 0.3075, Train Accuracy: 63.7280, Test Accuracy: 61.1111, Avg. duration: 0.0281 s\n",
      "Epoch: 1697, Train Loss: 0.2259, Test Loss: 0.3075, Train Accuracy: 63.7280, Test Accuracy: 61.1111, Avg. duration: 0.0283 s\n",
      "Epoch: 1698, Train Loss: 0.2259, Test Loss: 0.3075, Train Accuracy: 63.7280, Test Accuracy: 61.1111, Avg. duration: 0.0276 s\n",
      "Epoch: 1699, Train Loss: 0.2259, Test Loss: 0.3075, Train Accuracy: 63.7280, Test Accuracy: 61.1111, Avg. duration: 0.0283 s\n",
      "Epoch: 1700, Train Loss: 0.2259, Test Loss: 0.3075, Train Accuracy: 63.7280, Test Accuracy: 61.1111, Avg. duration: 0.0276 s\n",
      "Epoch: 1701, Train Loss: 0.2231, Test Loss: 0.3091, Train Accuracy: 64.3577, Test Accuracy: 60.6061, Avg. duration: 2.7304 s\n",
      "Epoch: 1702, Train Loss: 0.2231, Test Loss: 0.3091, Train Accuracy: 64.3577, Test Accuracy: 60.6061, Avg. duration: 0.0295 s\n",
      "Epoch: 1703, Train Loss: 0.2231, Test Loss: 0.3091, Train Accuracy: 64.3577, Test Accuracy: 60.6061, Avg. duration: 0.0275 s\n",
      "Epoch: 1704, Train Loss: 0.2231, Test Loss: 0.3091, Train Accuracy: 64.3577, Test Accuracy: 60.6061, Avg. duration: 0.0270 s\n",
      "Epoch: 1705, Train Loss: 0.2231, Test Loss: 0.3091, Train Accuracy: 64.3577, Test Accuracy: 60.6061, Avg. duration: 0.0273 s\n",
      "Epoch: 1706, Train Loss: 0.2231, Test Loss: 0.3091, Train Accuracy: 64.3577, Test Accuracy: 60.6061, Avg. duration: 0.0270 s\n",
      "Epoch: 1707, Train Loss: 0.2231, Test Loss: 0.3091, Train Accuracy: 64.3577, Test Accuracy: 60.6061, Avg. duration: 0.0270 s\n",
      "Epoch: 1708, Train Loss: 0.2231, Test Loss: 0.3091, Train Accuracy: 64.3577, Test Accuracy: 60.6061, Avg. duration: 0.0273 s\n",
      "Epoch: 1709, Train Loss: 0.2231, Test Loss: 0.3091, Train Accuracy: 64.3577, Test Accuracy: 60.6061, Avg. duration: 0.0280 s\n",
      "Epoch: 1710, Train Loss: 0.2231, Test Loss: 0.3091, Train Accuracy: 64.3577, Test Accuracy: 60.6061, Avg. duration: 0.0273 s\n",
      "Epoch: 1711, Train Loss: 0.2231, Test Loss: 0.3091, Train Accuracy: 64.3577, Test Accuracy: 60.6061, Avg. duration: 0.0268 s\n",
      "Epoch: 1712, Train Loss: 0.2231, Test Loss: 0.3091, Train Accuracy: 64.3577, Test Accuracy: 60.6061, Avg. duration: 0.0271 s\n",
      "Epoch: 1713, Train Loss: 0.2231, Test Loss: 0.3091, Train Accuracy: 64.3577, Test Accuracy: 60.6061, Avg. duration: 0.0275 s\n",
      "Epoch: 1714, Train Loss: 0.2231, Test Loss: 0.3091, Train Accuracy: 64.3577, Test Accuracy: 60.6061, Avg. duration: 0.0274 s\n",
      "Epoch: 1715, Train Loss: 0.2231, Test Loss: 0.3091, Train Accuracy: 64.3577, Test Accuracy: 60.6061, Avg. duration: 0.0272 s\n",
      "Epoch: 1716, Train Loss: 0.2231, Test Loss: 0.3091, Train Accuracy: 64.3577, Test Accuracy: 60.6061, Avg. duration: 0.0269 s\n",
      "Epoch: 1717, Train Loss: 0.2231, Test Loss: 0.3091, Train Accuracy: 64.3577, Test Accuracy: 60.6061, Avg. duration: 0.0275 s\n",
      "Epoch: 1718, Train Loss: 0.2231, Test Loss: 0.3091, Train Accuracy: 64.3577, Test Accuracy: 60.6061, Avg. duration: 0.0273 s\n",
      "Epoch: 1719, Train Loss: 0.2231, Test Loss: 0.3091, Train Accuracy: 64.3577, Test Accuracy: 60.6061, Avg. duration: 0.0271 s\n",
      "Epoch: 1720, Train Loss: 0.2231, Test Loss: 0.3091, Train Accuracy: 64.3577, Test Accuracy: 60.6061, Avg. duration: 0.0274 s\n",
      "Epoch: 1721, Train Loss: 0.2231, Test Loss: 0.3091, Train Accuracy: 64.3577, Test Accuracy: 60.6061, Avg. duration: 0.0270 s\n",
      "Epoch: 1722, Train Loss: 0.2231, Test Loss: 0.3091, Train Accuracy: 64.3577, Test Accuracy: 60.6061, Avg. duration: 0.0269 s\n",
      "Epoch: 1723, Train Loss: 0.2231, Test Loss: 0.3091, Train Accuracy: 64.3577, Test Accuracy: 60.6061, Avg. duration: 0.0269 s\n",
      "Epoch: 1724, Train Loss: 0.2231, Test Loss: 0.3091, Train Accuracy: 64.3577, Test Accuracy: 60.6061, Avg. duration: 0.0269 s\n",
      "Epoch: 1725, Train Loss: 0.2231, Test Loss: 0.3091, Train Accuracy: 64.3577, Test Accuracy: 60.6061, Avg. duration: 0.0275 s\n",
      "Epoch: 1726, Train Loss: 0.2231, Test Loss: 0.3091, Train Accuracy: 64.3577, Test Accuracy: 60.6061, Avg. duration: 0.0273 s\n",
      "Epoch: 1727, Train Loss: 0.2231, Test Loss: 0.3091, Train Accuracy: 64.3577, Test Accuracy: 60.6061, Avg. duration: 0.0274 s\n",
      "Epoch: 1728, Train Loss: 0.2231, Test Loss: 0.3091, Train Accuracy: 64.3577, Test Accuracy: 60.6061, Avg. duration: 0.0270 s\n",
      "Epoch: 1729, Train Loss: 0.2231, Test Loss: 0.3091, Train Accuracy: 64.3577, Test Accuracy: 60.6061, Avg. duration: 0.0269 s\n",
      "Epoch: 1730, Train Loss: 0.2231, Test Loss: 0.3091, Train Accuracy: 64.3577, Test Accuracy: 60.6061, Avg. duration: 0.0272 s\n",
      "Epoch: 1731, Train Loss: 0.2231, Test Loss: 0.3091, Train Accuracy: 64.3577, Test Accuracy: 60.6061, Avg. duration: 0.0270 s\n",
      "Epoch: 1732, Train Loss: 0.2231, Test Loss: 0.3091, Train Accuracy: 64.3577, Test Accuracy: 60.6061, Avg. duration: 0.0273 s\n",
      "Epoch: 1733, Train Loss: 0.2231, Test Loss: 0.3091, Train Accuracy: 64.3577, Test Accuracy: 60.6061, Avg. duration: 0.0279 s\n",
      "Epoch: 1734, Train Loss: 0.2231, Test Loss: 0.3091, Train Accuracy: 64.3577, Test Accuracy: 60.6061, Avg. duration: 0.0269 s\n",
      "Epoch: 1735, Train Loss: 0.2231, Test Loss: 0.3091, Train Accuracy: 64.3577, Test Accuracy: 60.6061, Avg. duration: 0.0274 s\n",
      "Epoch: 1736, Train Loss: 0.2231, Test Loss: 0.3091, Train Accuracy: 64.3577, Test Accuracy: 60.6061, Avg. duration: 0.0270 s\n",
      "Epoch: 1737, Train Loss: 0.2231, Test Loss: 0.3091, Train Accuracy: 64.3577, Test Accuracy: 60.6061, Avg. duration: 0.0270 s\n",
      "Epoch: 1738, Train Loss: 0.2231, Test Loss: 0.3091, Train Accuracy: 64.3577, Test Accuracy: 60.6061, Avg. duration: 0.0274 s\n",
      "Epoch: 1739, Train Loss: 0.2231, Test Loss: 0.3091, Train Accuracy: 64.3577, Test Accuracy: 60.6061, Avg. duration: 0.0271 s\n",
      "Epoch: 1740, Train Loss: 0.2231, Test Loss: 0.3091, Train Accuracy: 64.3577, Test Accuracy: 60.6061, Avg. duration: 0.0268 s\n",
      "Epoch: 1741, Train Loss: 0.2231, Test Loss: 0.3091, Train Accuracy: 64.3577, Test Accuracy: 60.6061, Avg. duration: 0.0273 s\n",
      "Epoch: 1742, Train Loss: 0.2231, Test Loss: 0.3091, Train Accuracy: 64.3577, Test Accuracy: 60.6061, Avg. duration: 0.0271 s\n",
      "Epoch: 1743, Train Loss: 0.2231, Test Loss: 0.3091, Train Accuracy: 64.3577, Test Accuracy: 60.6061, Avg. duration: 0.0268 s\n",
      "Epoch: 1744, Train Loss: 0.2231, Test Loss: 0.3091, Train Accuracy: 64.3577, Test Accuracy: 60.6061, Avg. duration: 0.0274 s\n",
      "Epoch: 1745, Train Loss: 0.2231, Test Loss: 0.3091, Train Accuracy: 64.3577, Test Accuracy: 60.6061, Avg. duration: 0.0270 s\n",
      "Epoch: 1746, Train Loss: 0.2231, Test Loss: 0.3091, Train Accuracy: 64.3577, Test Accuracy: 60.6061, Avg. duration: 0.0268 s\n",
      "Epoch: 1747, Train Loss: 0.2231, Test Loss: 0.3091, Train Accuracy: 64.3577, Test Accuracy: 60.6061, Avg. duration: 0.0268 s\n",
      "Epoch: 1748, Train Loss: 0.2231, Test Loss: 0.3091, Train Accuracy: 64.3577, Test Accuracy: 60.6061, Avg. duration: 0.0269 s\n",
      "Epoch: 1749, Train Loss: 0.2231, Test Loss: 0.3091, Train Accuracy: 64.3577, Test Accuracy: 60.6061, Avg. duration: 0.0276 s\n",
      "Epoch: 1750, Train Loss: 0.2231, Test Loss: 0.3091, Train Accuracy: 64.3577, Test Accuracy: 60.6061, Avg. duration: 0.3162 s\n",
      "Epoch: 1751, Train Loss: 0.2231, Test Loss: 0.3091, Train Accuracy: 64.3577, Test Accuracy: 60.6061, Avg. duration: 0.0283 s\n",
      "Epoch: 1752, Train Loss: 0.2231, Test Loss: 0.3091, Train Accuracy: 64.3577, Test Accuracy: 60.6061, Avg. duration: 0.0277 s\n",
      "Epoch: 1753, Train Loss: 0.2231, Test Loss: 0.3091, Train Accuracy: 64.3577, Test Accuracy: 60.6061, Avg. duration: 0.0277 s\n",
      "Epoch: 1754, Train Loss: 0.2231, Test Loss: 0.3091, Train Accuracy: 64.3577, Test Accuracy: 60.6061, Avg. duration: 0.0279 s\n",
      "Epoch: 1755, Train Loss: 0.2231, Test Loss: 0.3091, Train Accuracy: 64.3577, Test Accuracy: 60.6061, Avg. duration: 0.0278 s\n",
      "Epoch: 1756, Train Loss: 0.2231, Test Loss: 0.3091, Train Accuracy: 64.3577, Test Accuracy: 60.6061, Avg. duration: 0.0277 s\n",
      "Epoch: 1757, Train Loss: 0.2231, Test Loss: 0.3091, Train Accuracy: 64.3577, Test Accuracy: 60.6061, Avg. duration: 0.0273 s\n",
      "Epoch: 1758, Train Loss: 0.2231, Test Loss: 0.3091, Train Accuracy: 64.3577, Test Accuracy: 60.6061, Avg. duration: 0.0277 s\n",
      "Epoch: 1759, Train Loss: 0.2231, Test Loss: 0.3091, Train Accuracy: 64.3577, Test Accuracy: 60.6061, Avg. duration: 0.0272 s\n",
      "Epoch: 1760, Train Loss: 0.2231, Test Loss: 0.3091, Train Accuracy: 64.3577, Test Accuracy: 60.6061, Avg. duration: 0.0277 s\n",
      "Epoch: 1761, Train Loss: 0.2231, Test Loss: 0.3091, Train Accuracy: 64.3577, Test Accuracy: 60.6061, Avg. duration: 0.0332 s\n",
      "Epoch: 1762, Train Loss: 0.2231, Test Loss: 0.3091, Train Accuracy: 64.3577, Test Accuracy: 60.6061, Avg. duration: 0.0279 s\n",
      "Epoch: 1763, Train Loss: 0.2231, Test Loss: 0.3091, Train Accuracy: 64.3577, Test Accuracy: 60.6061, Avg. duration: 0.0273 s\n",
      "Epoch: 1764, Train Loss: 0.2231, Test Loss: 0.3091, Train Accuracy: 64.3577, Test Accuracy: 60.6061, Avg. duration: 0.0270 s\n",
      "Epoch: 1765, Train Loss: 0.2231, Test Loss: 0.3091, Train Accuracy: 64.3577, Test Accuracy: 60.6061, Avg. duration: 0.0274 s\n",
      "Epoch: 1766, Train Loss: 0.2231, Test Loss: 0.3091, Train Accuracy: 64.3577, Test Accuracy: 60.6061, Avg. duration: 0.0279 s\n",
      "Epoch: 1767, Train Loss: 0.2231, Test Loss: 0.3091, Train Accuracy: 64.3577, Test Accuracy: 60.6061, Avg. duration: 0.0277 s\n",
      "Epoch: 1768, Train Loss: 0.2231, Test Loss: 0.3091, Train Accuracy: 64.3577, Test Accuracy: 60.6061, Avg. duration: 0.0279 s\n",
      "Epoch: 1769, Train Loss: 0.2231, Test Loss: 0.3091, Train Accuracy: 64.3577, Test Accuracy: 60.6061, Avg. duration: 0.0272 s\n",
      "Epoch: 1770, Train Loss: 0.2231, Test Loss: 0.3091, Train Accuracy: 64.3577, Test Accuracy: 60.6061, Avg. duration: 0.0275 s\n",
      "Epoch: 1771, Train Loss: 0.2231, Test Loss: 0.3091, Train Accuracy: 64.3577, Test Accuracy: 60.6061, Avg. duration: 0.0273 s\n",
      "Epoch: 1772, Train Loss: 0.2231, Test Loss: 0.3091, Train Accuracy: 64.3577, Test Accuracy: 60.6061, Avg. duration: 0.0274 s\n",
      "Epoch: 1773, Train Loss: 0.2231, Test Loss: 0.3091, Train Accuracy: 64.3577, Test Accuracy: 60.6061, Avg. duration: 0.0280 s\n",
      "Epoch: 1774, Train Loss: 0.2231, Test Loss: 0.3091, Train Accuracy: 64.3577, Test Accuracy: 60.6061, Avg. duration: 0.0284 s\n",
      "Epoch: 1775, Train Loss: 0.2231, Test Loss: 0.3091, Train Accuracy: 64.3577, Test Accuracy: 60.6061, Avg. duration: 0.0276 s\n",
      "Epoch: 1776, Train Loss: 0.2231, Test Loss: 0.3091, Train Accuracy: 64.3577, Test Accuracy: 60.6061, Avg. duration: 0.0274 s\n",
      "Epoch: 1777, Train Loss: 0.2231, Test Loss: 0.3091, Train Accuracy: 64.3577, Test Accuracy: 60.6061, Avg. duration: 0.0277 s\n",
      "Epoch: 1778, Train Loss: 0.2231, Test Loss: 0.3091, Train Accuracy: 64.3577, Test Accuracy: 60.6061, Avg. duration: 0.0279 s\n",
      "Epoch: 1779, Train Loss: 0.2231, Test Loss: 0.3091, Train Accuracy: 64.3577, Test Accuracy: 60.6061, Avg. duration: 0.0277 s\n",
      "Epoch: 1780, Train Loss: 0.2231, Test Loss: 0.3091, Train Accuracy: 64.3577, Test Accuracy: 60.6061, Avg. duration: 0.0279 s\n",
      "Epoch: 1781, Train Loss: 0.2231, Test Loss: 0.3091, Train Accuracy: 64.3577, Test Accuracy: 60.6061, Avg. duration: 0.0276 s\n",
      "Epoch: 1782, Train Loss: 0.2231, Test Loss: 0.3091, Train Accuracy: 64.3577, Test Accuracy: 60.6061, Avg. duration: 0.0281 s\n",
      "Epoch: 1783, Train Loss: 0.2231, Test Loss: 0.3091, Train Accuracy: 64.3577, Test Accuracy: 60.6061, Avg. duration: 0.0274 s\n",
      "Epoch: 1784, Train Loss: 0.2231, Test Loss: 0.3091, Train Accuracy: 64.3577, Test Accuracy: 60.6061, Avg. duration: 0.0274 s\n",
      "Epoch: 1785, Train Loss: 0.2231, Test Loss: 0.3091, Train Accuracy: 64.3577, Test Accuracy: 60.6061, Avg. duration: 0.0280 s\n",
      "Epoch: 1786, Train Loss: 0.2231, Test Loss: 0.3091, Train Accuracy: 64.3577, Test Accuracy: 60.6061, Avg. duration: 0.0277 s\n",
      "Epoch: 1787, Train Loss: 0.2231, Test Loss: 0.3091, Train Accuracy: 64.3577, Test Accuracy: 60.6061, Avg. duration: 0.0276 s\n",
      "Epoch: 1788, Train Loss: 0.2231, Test Loss: 0.3091, Train Accuracy: 64.3577, Test Accuracy: 60.6061, Avg. duration: 0.0276 s\n",
      "Epoch: 1789, Train Loss: 0.2231, Test Loss: 0.3091, Train Accuracy: 64.3577, Test Accuracy: 60.6061, Avg. duration: 0.0273 s\n",
      "Epoch: 1790, Train Loss: 0.2231, Test Loss: 0.3091, Train Accuracy: 64.3577, Test Accuracy: 60.6061, Avg. duration: 0.0282 s\n",
      "Epoch: 1791, Train Loss: 0.2231, Test Loss: 0.3091, Train Accuracy: 64.3577, Test Accuracy: 60.6061, Avg. duration: 0.0281 s\n",
      "Epoch: 1792, Train Loss: 0.2231, Test Loss: 0.3091, Train Accuracy: 64.3577, Test Accuracy: 60.6061, Avg. duration: 0.0277 s\n",
      "Epoch: 1793, Train Loss: 0.2231, Test Loss: 0.3091, Train Accuracy: 64.3577, Test Accuracy: 60.6061, Avg. duration: 0.0275 s\n",
      "Epoch: 1794, Train Loss: 0.2231, Test Loss: 0.3091, Train Accuracy: 64.3577, Test Accuracy: 60.6061, Avg. duration: 0.0279 s\n",
      "Epoch: 1795, Train Loss: 0.2231, Test Loss: 0.3091, Train Accuracy: 64.3577, Test Accuracy: 60.6061, Avg. duration: 0.0274 s\n",
      "Epoch: 1796, Train Loss: 0.2231, Test Loss: 0.3091, Train Accuracy: 64.3577, Test Accuracy: 60.6061, Avg. duration: 0.0280 s\n",
      "Epoch: 1797, Train Loss: 0.2231, Test Loss: 0.3091, Train Accuracy: 64.3577, Test Accuracy: 60.6061, Avg. duration: 0.0278 s\n",
      "Epoch: 1798, Train Loss: 0.2231, Test Loss: 0.3091, Train Accuracy: 64.3577, Test Accuracy: 60.6061, Avg. duration: 0.0288 s\n",
      "Epoch: 1799, Train Loss: 0.2231, Test Loss: 0.3091, Train Accuracy: 64.3577, Test Accuracy: 60.6061, Avg. duration: 0.0274 s\n",
      "Epoch: 1800, Train Loss: 0.2231, Test Loss: 0.3091, Train Accuracy: 64.3577, Test Accuracy: 60.6061, Avg. duration: 0.0276 s\n",
      "Epoch: 1801, Train Loss: 0.2196, Test Loss: 0.3087, Train Accuracy: 64.3577, Test Accuracy: 60.6061, Avg. duration: 2.7266 s\n",
      "Epoch: 1802, Train Loss: 0.2196, Test Loss: 0.3087, Train Accuracy: 64.3577, Test Accuracy: 60.6061, Avg. duration: 0.0290 s\n",
      "Epoch: 1803, Train Loss: 0.2196, Test Loss: 0.3087, Train Accuracy: 64.3577, Test Accuracy: 60.6061, Avg. duration: 0.0274 s\n",
      "Epoch: 1804, Train Loss: 0.2196, Test Loss: 0.3087, Train Accuracy: 64.3577, Test Accuracy: 60.6061, Avg. duration: 0.0276 s\n",
      "Epoch: 1805, Train Loss: 0.2196, Test Loss: 0.3087, Train Accuracy: 64.3577, Test Accuracy: 60.6061, Avg. duration: 0.0271 s\n",
      "Epoch: 1806, Train Loss: 0.2196, Test Loss: 0.3087, Train Accuracy: 64.3577, Test Accuracy: 60.6061, Avg. duration: 0.0273 s\n",
      "Epoch: 1807, Train Loss: 0.2196, Test Loss: 0.3087, Train Accuracy: 64.3577, Test Accuracy: 60.6061, Avg. duration: 0.0272 s\n",
      "Epoch: 1808, Train Loss: 0.2196, Test Loss: 0.3087, Train Accuracy: 64.3577, Test Accuracy: 60.6061, Avg. duration: 0.0274 s\n",
      "Epoch: 1809, Train Loss: 0.2196, Test Loss: 0.3087, Train Accuracy: 64.3577, Test Accuracy: 60.6061, Avg. duration: 0.0281 s\n",
      "Epoch: 1810, Train Loss: 0.2196, Test Loss: 0.3087, Train Accuracy: 64.3577, Test Accuracy: 60.6061, Avg. duration: 0.0273 s\n",
      "Epoch: 1811, Train Loss: 0.2196, Test Loss: 0.3087, Train Accuracy: 64.3577, Test Accuracy: 60.6061, Avg. duration: 0.0270 s\n",
      "Epoch: 1812, Train Loss: 0.2196, Test Loss: 0.3087, Train Accuracy: 64.3577, Test Accuracy: 60.6061, Avg. duration: 0.0269 s\n",
      "Epoch: 1813, Train Loss: 0.2196, Test Loss: 0.3087, Train Accuracy: 64.3577, Test Accuracy: 60.6061, Avg. duration: 0.0274 s\n",
      "Epoch: 1814, Train Loss: 0.2196, Test Loss: 0.3087, Train Accuracy: 64.3577, Test Accuracy: 60.6061, Avg. duration: 0.0275 s\n",
      "Epoch: 1815, Train Loss: 0.2196, Test Loss: 0.3087, Train Accuracy: 64.3577, Test Accuracy: 60.6061, Avg. duration: 0.0275 s\n",
      "Epoch: 1816, Train Loss: 0.2196, Test Loss: 0.3087, Train Accuracy: 64.3577, Test Accuracy: 60.6061, Avg. duration: 0.0273 s\n",
      "Epoch: 1817, Train Loss: 0.2196, Test Loss: 0.3087, Train Accuracy: 64.3577, Test Accuracy: 60.6061, Avg. duration: 0.0277 s\n",
      "Epoch: 1818, Train Loss: 0.2196, Test Loss: 0.3087, Train Accuracy: 64.3577, Test Accuracy: 60.6061, Avg. duration: 0.0276 s\n",
      "Epoch: 1819, Train Loss: 0.2196, Test Loss: 0.3087, Train Accuracy: 64.3577, Test Accuracy: 60.6061, Avg. duration: 0.0273 s\n",
      "Epoch: 1820, Train Loss: 0.2196, Test Loss: 0.3087, Train Accuracy: 64.3577, Test Accuracy: 60.6061, Avg. duration: 0.0271 s\n",
      "Epoch: 1821, Train Loss: 0.2196, Test Loss: 0.3087, Train Accuracy: 64.3577, Test Accuracy: 60.6061, Avg. duration: 0.3154 s\n",
      "Epoch: 1822, Train Loss: 0.2196, Test Loss: 0.3087, Train Accuracy: 64.3577, Test Accuracy: 60.6061, Avg. duration: 0.0282 s\n",
      "Epoch: 1823, Train Loss: 0.2196, Test Loss: 0.3087, Train Accuracy: 64.3577, Test Accuracy: 60.6061, Avg. duration: 0.0273 s\n",
      "Epoch: 1824, Train Loss: 0.2196, Test Loss: 0.3087, Train Accuracy: 64.3577, Test Accuracy: 60.6061, Avg. duration: 0.0273 s\n",
      "Epoch: 1825, Train Loss: 0.2196, Test Loss: 0.3087, Train Accuracy: 64.3577, Test Accuracy: 60.6061, Avg. duration: 0.0274 s\n",
      "Epoch: 1826, Train Loss: 0.2196, Test Loss: 0.3087, Train Accuracy: 64.3577, Test Accuracy: 60.6061, Avg. duration: 0.0274 s\n",
      "Epoch: 1827, Train Loss: 0.2196, Test Loss: 0.3087, Train Accuracy: 64.3577, Test Accuracy: 60.6061, Avg. duration: 0.0276 s\n",
      "Epoch: 1828, Train Loss: 0.2196, Test Loss: 0.3087, Train Accuracy: 64.3577, Test Accuracy: 60.6061, Avg. duration: 0.0272 s\n",
      "Epoch: 1829, Train Loss: 0.2196, Test Loss: 0.3087, Train Accuracy: 64.3577, Test Accuracy: 60.6061, Avg. duration: 0.0278 s\n",
      "Epoch: 1830, Train Loss: 0.2196, Test Loss: 0.3087, Train Accuracy: 64.3577, Test Accuracy: 60.6061, Avg. duration: 0.0276 s\n",
      "Epoch: 1831, Train Loss: 0.2196, Test Loss: 0.3087, Train Accuracy: 64.3577, Test Accuracy: 60.6061, Avg. duration: 0.0273 s\n",
      "Epoch: 1832, Train Loss: 0.2196, Test Loss: 0.3087, Train Accuracy: 64.3577, Test Accuracy: 60.6061, Avg. duration: 0.0273 s\n",
      "Epoch: 1833, Train Loss: 0.2196, Test Loss: 0.3087, Train Accuracy: 64.3577, Test Accuracy: 60.6061, Avg. duration: 0.0275 s\n",
      "Epoch: 1834, Train Loss: 0.2196, Test Loss: 0.3087, Train Accuracy: 64.3577, Test Accuracy: 60.6061, Avg. duration: 0.0270 s\n",
      "Epoch: 1835, Train Loss: 0.2196, Test Loss: 0.3087, Train Accuracy: 64.3577, Test Accuracy: 60.6061, Avg. duration: 0.0269 s\n",
      "Epoch: 1836, Train Loss: 0.2196, Test Loss: 0.3087, Train Accuracy: 64.3577, Test Accuracy: 60.6061, Avg. duration: 0.0274 s\n",
      "Epoch: 1837, Train Loss: 0.2196, Test Loss: 0.3087, Train Accuracy: 64.3577, Test Accuracy: 60.6061, Avg. duration: 0.0279 s\n",
      "Epoch: 1838, Train Loss: 0.2196, Test Loss: 0.3087, Train Accuracy: 64.3577, Test Accuracy: 60.6061, Avg. duration: 0.0277 s\n",
      "Epoch: 1839, Train Loss: 0.2196, Test Loss: 0.3087, Train Accuracy: 64.3577, Test Accuracy: 60.6061, Avg. duration: 0.0275 s\n",
      "Epoch: 1840, Train Loss: 0.2196, Test Loss: 0.3087, Train Accuracy: 64.3577, Test Accuracy: 60.6061, Avg. duration: 0.0267 s\n",
      "Epoch: 1841, Train Loss: 0.2196, Test Loss: 0.3087, Train Accuracy: 64.3577, Test Accuracy: 60.6061, Avg. duration: 0.0271 s\n",
      "Epoch: 1842, Train Loss: 0.2196, Test Loss: 0.3087, Train Accuracy: 64.3577, Test Accuracy: 60.6061, Avg. duration: 0.0275 s\n",
      "Epoch: 1843, Train Loss: 0.2196, Test Loss: 0.3087, Train Accuracy: 64.3577, Test Accuracy: 60.6061, Avg. duration: 0.0271 s\n",
      "Epoch: 1844, Train Loss: 0.2196, Test Loss: 0.3087, Train Accuracy: 64.3577, Test Accuracy: 60.6061, Avg. duration: 0.0274 s\n",
      "Epoch: 1845, Train Loss: 0.2196, Test Loss: 0.3087, Train Accuracy: 64.3577, Test Accuracy: 60.6061, Avg. duration: 0.0280 s\n",
      "Epoch: 1846, Train Loss: 0.2196, Test Loss: 0.3087, Train Accuracy: 64.3577, Test Accuracy: 60.6061, Avg. duration: 0.0274 s\n",
      "Epoch: 1847, Train Loss: 0.2196, Test Loss: 0.3087, Train Accuracy: 64.3577, Test Accuracy: 60.6061, Avg. duration: 0.0270 s\n",
      "Epoch: 1848, Train Loss: 0.2196, Test Loss: 0.3087, Train Accuracy: 64.3577, Test Accuracy: 60.6061, Avg. duration: 0.0275 s\n",
      "Epoch: 1849, Train Loss: 0.2196, Test Loss: 0.3087, Train Accuracy: 64.3577, Test Accuracy: 60.6061, Avg. duration: 0.0270 s\n",
      "Epoch: 1850, Train Loss: 0.2196, Test Loss: 0.3087, Train Accuracy: 64.3577, Test Accuracy: 60.6061, Avg. duration: 0.0276 s\n",
      "Epoch: 1851, Train Loss: 0.2196, Test Loss: 0.3087, Train Accuracy: 64.3577, Test Accuracy: 60.6061, Avg. duration: 0.0277 s\n",
      "Epoch: 1852, Train Loss: 0.2196, Test Loss: 0.3087, Train Accuracy: 64.3577, Test Accuracy: 60.6061, Avg. duration: 0.0269 s\n",
      "Epoch: 1853, Train Loss: 0.2196, Test Loss: 0.3087, Train Accuracy: 64.3577, Test Accuracy: 60.6061, Avg. duration: 0.0273 s\n",
      "Epoch: 1854, Train Loss: 0.2196, Test Loss: 0.3087, Train Accuracy: 64.3577, Test Accuracy: 60.6061, Avg. duration: 0.0278 s\n",
      "Epoch: 1855, Train Loss: 0.2196, Test Loss: 0.3087, Train Accuracy: 64.3577, Test Accuracy: 60.6061, Avg. duration: 0.0278 s\n",
      "Epoch: 1856, Train Loss: 0.2196, Test Loss: 0.3087, Train Accuracy: 64.3577, Test Accuracy: 60.6061, Avg. duration: 0.0278 s\n",
      "Epoch: 1857, Train Loss: 0.2196, Test Loss: 0.3087, Train Accuracy: 64.3577, Test Accuracy: 60.6061, Avg. duration: 0.0276 s\n",
      "Epoch: 1858, Train Loss: 0.2196, Test Loss: 0.3087, Train Accuracy: 64.3577, Test Accuracy: 60.6061, Avg. duration: 0.0273 s\n",
      "Epoch: 1859, Train Loss: 0.2196, Test Loss: 0.3087, Train Accuracy: 64.3577, Test Accuracy: 60.6061, Avg. duration: 0.0274 s\n",
      "Epoch: 1860, Train Loss: 0.2196, Test Loss: 0.3087, Train Accuracy: 64.3577, Test Accuracy: 60.6061, Avg. duration: 0.0274 s\n",
      "Epoch: 1861, Train Loss: 0.2196, Test Loss: 0.3087, Train Accuracy: 64.3577, Test Accuracy: 60.6061, Avg. duration: 0.0279 s\n",
      "Epoch: 1862, Train Loss: 0.2196, Test Loss: 0.3087, Train Accuracy: 64.3577, Test Accuracy: 60.6061, Avg. duration: 0.0278 s\n",
      "Epoch: 1863, Train Loss: 0.2196, Test Loss: 0.3087, Train Accuracy: 64.3577, Test Accuracy: 60.6061, Avg. duration: 0.0278 s\n",
      "Epoch: 1864, Train Loss: 0.2196, Test Loss: 0.3087, Train Accuracy: 64.3577, Test Accuracy: 60.6061, Avg. duration: 0.0277 s\n",
      "Epoch: 1865, Train Loss: 0.2196, Test Loss: 0.3087, Train Accuracy: 64.3577, Test Accuracy: 60.6061, Avg. duration: 0.0277 s\n",
      "Epoch: 1866, Train Loss: 0.2196, Test Loss: 0.3087, Train Accuracy: 64.3577, Test Accuracy: 60.6061, Avg. duration: 0.0278 s\n",
      "Epoch: 1867, Train Loss: 0.2196, Test Loss: 0.3087, Train Accuracy: 64.3577, Test Accuracy: 60.6061, Avg. duration: 0.0278 s\n",
      "Epoch: 1868, Train Loss: 0.2196, Test Loss: 0.3087, Train Accuracy: 64.3577, Test Accuracy: 60.6061, Avg. duration: 0.0278 s\n",
      "Epoch: 1869, Train Loss: 0.2196, Test Loss: 0.3087, Train Accuracy: 64.3577, Test Accuracy: 60.6061, Avg. duration: 0.0286 s\n",
      "Epoch: 1870, Train Loss: 0.2196, Test Loss: 0.3087, Train Accuracy: 64.3577, Test Accuracy: 60.6061, Avg. duration: 0.0278 s\n",
      "Epoch: 1871, Train Loss: 0.2196, Test Loss: 0.3087, Train Accuracy: 64.3577, Test Accuracy: 60.6061, Avg. duration: 0.0277 s\n",
      "Epoch: 1872, Train Loss: 0.2196, Test Loss: 0.3087, Train Accuracy: 64.3577, Test Accuracy: 60.6061, Avg. duration: 0.0272 s\n",
      "Epoch: 1873, Train Loss: 0.2196, Test Loss: 0.3087, Train Accuracy: 64.3577, Test Accuracy: 60.6061, Avg. duration: 0.0276 s\n",
      "Epoch: 1874, Train Loss: 0.2196, Test Loss: 0.3087, Train Accuracy: 64.3577, Test Accuracy: 60.6061, Avg. duration: 0.0275 s\n",
      "Epoch: 1875, Train Loss: 0.2196, Test Loss: 0.3087, Train Accuracy: 64.3577, Test Accuracy: 60.6061, Avg. duration: 0.0278 s\n",
      "Epoch: 1876, Train Loss: 0.2196, Test Loss: 0.3087, Train Accuracy: 64.3577, Test Accuracy: 60.6061, Avg. duration: 0.0276 s\n",
      "Epoch: 1877, Train Loss: 0.2196, Test Loss: 0.3087, Train Accuracy: 64.3577, Test Accuracy: 60.6061, Avg. duration: 0.0278 s\n",
      "Epoch: 1878, Train Loss: 0.2196, Test Loss: 0.3087, Train Accuracy: 64.3577, Test Accuracy: 60.6061, Avg. duration: 0.0273 s\n",
      "Epoch: 1879, Train Loss: 0.2196, Test Loss: 0.3087, Train Accuracy: 64.3577, Test Accuracy: 60.6061, Avg. duration: 0.0279 s\n",
      "Epoch: 1880, Train Loss: 0.2196, Test Loss: 0.3087, Train Accuracy: 64.3577, Test Accuracy: 60.6061, Avg. duration: 0.0277 s\n",
      "Epoch: 1881, Train Loss: 0.2196, Test Loss: 0.3087, Train Accuracy: 64.3577, Test Accuracy: 60.6061, Avg. duration: 0.0278 s\n",
      "Epoch: 1882, Train Loss: 0.2196, Test Loss: 0.3087, Train Accuracy: 64.3577, Test Accuracy: 60.6061, Avg. duration: 0.0276 s\n",
      "Epoch: 1883, Train Loss: 0.2196, Test Loss: 0.3087, Train Accuracy: 64.3577, Test Accuracy: 60.6061, Avg. duration: 0.0275 s\n",
      "Epoch: 1884, Train Loss: 0.2196, Test Loss: 0.3087, Train Accuracy: 64.3577, Test Accuracy: 60.6061, Avg. duration: 0.0274 s\n",
      "Epoch: 1885, Train Loss: 0.2196, Test Loss: 0.3087, Train Accuracy: 64.3577, Test Accuracy: 60.6061, Avg. duration: 0.0284 s\n",
      "Epoch: 1886, Train Loss: 0.2196, Test Loss: 0.3087, Train Accuracy: 64.3577, Test Accuracy: 60.6061, Avg. duration: 0.0279 s\n",
      "Epoch: 1887, Train Loss: 0.2196, Test Loss: 0.3087, Train Accuracy: 64.3577, Test Accuracy: 60.6061, Avg. duration: 0.0276 s\n",
      "Epoch: 1888, Train Loss: 0.2196, Test Loss: 0.3087, Train Accuracy: 64.3577, Test Accuracy: 60.6061, Avg. duration: 0.0273 s\n",
      "Epoch: 1889, Train Loss: 0.2196, Test Loss: 0.3087, Train Accuracy: 64.3577, Test Accuracy: 60.6061, Avg. duration: 0.0277 s\n",
      "Epoch: 1890, Train Loss: 0.2196, Test Loss: 0.3087, Train Accuracy: 64.3577, Test Accuracy: 60.6061, Avg. duration: 0.0272 s\n",
      "Epoch: 1891, Train Loss: 0.2196, Test Loss: 0.3087, Train Accuracy: 64.3577, Test Accuracy: 60.6061, Avg. duration: 0.0277 s\n",
      "Epoch: 1892, Train Loss: 0.2196, Test Loss: 0.3087, Train Accuracy: 64.3577, Test Accuracy: 60.6061, Avg. duration: 0.0278 s\n",
      "Epoch: 1893, Train Loss: 0.2196, Test Loss: 0.3087, Train Accuracy: 64.3577, Test Accuracy: 60.6061, Avg. duration: 0.0286 s\n",
      "Epoch: 1894, Train Loss: 0.2196, Test Loss: 0.3087, Train Accuracy: 64.3577, Test Accuracy: 60.6061, Avg. duration: 0.0277 s\n",
      "Epoch: 1895, Train Loss: 0.2196, Test Loss: 0.3087, Train Accuracy: 64.3577, Test Accuracy: 60.6061, Avg. duration: 0.0272 s\n",
      "Epoch: 1896, Train Loss: 0.2196, Test Loss: 0.3087, Train Accuracy: 64.3577, Test Accuracy: 60.6061, Avg. duration: 0.0275 s\n",
      "Epoch: 1897, Train Loss: 0.2196, Test Loss: 0.3087, Train Accuracy: 64.3577, Test Accuracy: 60.6061, Avg. duration: 0.3179 s\n",
      "Epoch: 1898, Train Loss: 0.2196, Test Loss: 0.3087, Train Accuracy: 64.3577, Test Accuracy: 60.6061, Avg. duration: 0.0289 s\n",
      "Epoch: 1899, Train Loss: 0.2196, Test Loss: 0.3087, Train Accuracy: 64.3577, Test Accuracy: 60.6061, Avg. duration: 0.0285 s\n",
      "Epoch: 1900, Train Loss: 0.2196, Test Loss: 0.3087, Train Accuracy: 64.3577, Test Accuracy: 60.6061, Avg. duration: 0.0280 s\n",
      "Epoch: 1901, Train Loss: 0.2169, Test Loss: 0.3086, Train Accuracy: 64.1058, Test Accuracy: 61.6162, Avg. duration: 2.7368 s\n",
      "Epoch: 1902, Train Loss: 0.2169, Test Loss: 0.3086, Train Accuracy: 64.1058, Test Accuracy: 61.6162, Avg. duration: 0.0298 s\n",
      "Epoch: 1903, Train Loss: 0.2169, Test Loss: 0.3086, Train Accuracy: 64.1058, Test Accuracy: 61.6162, Avg. duration: 0.0279 s\n",
      "Epoch: 1904, Train Loss: 0.2169, Test Loss: 0.3086, Train Accuracy: 64.1058, Test Accuracy: 61.6162, Avg. duration: 0.0281 s\n",
      "Epoch: 1905, Train Loss: 0.2169, Test Loss: 0.3086, Train Accuracy: 64.1058, Test Accuracy: 61.6162, Avg. duration: 0.0275 s\n",
      "Epoch: 1906, Train Loss: 0.2169, Test Loss: 0.3086, Train Accuracy: 64.1058, Test Accuracy: 61.6162, Avg. duration: 0.0269 s\n",
      "Epoch: 1907, Train Loss: 0.2169, Test Loss: 0.3086, Train Accuracy: 64.1058, Test Accuracy: 61.6162, Avg. duration: 0.0272 s\n",
      "Epoch: 1908, Train Loss: 0.2169, Test Loss: 0.3086, Train Accuracy: 64.1058, Test Accuracy: 61.6162, Avg. duration: 0.0273 s\n",
      "Epoch: 1909, Train Loss: 0.2169, Test Loss: 0.3086, Train Accuracy: 64.1058, Test Accuracy: 61.6162, Avg. duration: 0.0277 s\n",
      "Epoch: 1910, Train Loss: 0.2169, Test Loss: 0.3086, Train Accuracy: 64.1058, Test Accuracy: 61.6162, Avg. duration: 0.0276 s\n",
      "Epoch: 1911, Train Loss: 0.2169, Test Loss: 0.3086, Train Accuracy: 64.1058, Test Accuracy: 61.6162, Avg. duration: 0.0275 s\n",
      "Epoch: 1912, Train Loss: 0.2169, Test Loss: 0.3086, Train Accuracy: 64.1058, Test Accuracy: 61.6162, Avg. duration: 0.0271 s\n",
      "Epoch: 1913, Train Loss: 0.2169, Test Loss: 0.3086, Train Accuracy: 64.1058, Test Accuracy: 61.6162, Avg. duration: 0.0269 s\n",
      "Epoch: 1914, Train Loss: 0.2169, Test Loss: 0.3086, Train Accuracy: 64.1058, Test Accuracy: 61.6162, Avg. duration: 0.0274 s\n",
      "Epoch: 1915, Train Loss: 0.2169, Test Loss: 0.3086, Train Accuracy: 64.1058, Test Accuracy: 61.6162, Avg. duration: 0.0272 s\n",
      "Epoch: 1916, Train Loss: 0.2169, Test Loss: 0.3086, Train Accuracy: 64.1058, Test Accuracy: 61.6162, Avg. duration: 0.0276 s\n",
      "Epoch: 1917, Train Loss: 0.2169, Test Loss: 0.3086, Train Accuracy: 64.1058, Test Accuracy: 61.6162, Avg. duration: 0.0277 s\n",
      "Epoch: 1918, Train Loss: 0.2169, Test Loss: 0.3086, Train Accuracy: 64.1058, Test Accuracy: 61.6162, Avg. duration: 0.0270 s\n",
      "Epoch: 1919, Train Loss: 0.2169, Test Loss: 0.3086, Train Accuracy: 64.1058, Test Accuracy: 61.6162, Avg. duration: 0.0274 s\n",
      "Epoch: 1920, Train Loss: 0.2169, Test Loss: 0.3086, Train Accuracy: 64.1058, Test Accuracy: 61.6162, Avg. duration: 0.0273 s\n",
      "Epoch: 1921, Train Loss: 0.2169, Test Loss: 0.3086, Train Accuracy: 64.1058, Test Accuracy: 61.6162, Avg. duration: 0.0271 s\n",
      "Epoch: 1922, Train Loss: 0.2169, Test Loss: 0.3086, Train Accuracy: 64.1058, Test Accuracy: 61.6162, Avg. duration: 0.0276 s\n",
      "Epoch: 1923, Train Loss: 0.2169, Test Loss: 0.3086, Train Accuracy: 64.1058, Test Accuracy: 61.6162, Avg. duration: 0.0273 s\n",
      "Epoch: 1924, Train Loss: 0.2169, Test Loss: 0.3086, Train Accuracy: 64.1058, Test Accuracy: 61.6162, Avg. duration: 0.0273 s\n",
      "Epoch: 1925, Train Loss: 0.2169, Test Loss: 0.3086, Train Accuracy: 64.1058, Test Accuracy: 61.6162, Avg. duration: 0.0276 s\n",
      "Epoch: 1926, Train Loss: 0.2169, Test Loss: 0.3086, Train Accuracy: 64.1058, Test Accuracy: 61.6162, Avg. duration: 0.0270 s\n",
      "Epoch: 1927, Train Loss: 0.2169, Test Loss: 0.3086, Train Accuracy: 64.1058, Test Accuracy: 61.6162, Avg. duration: 0.0271 s\n",
      "Epoch: 1928, Train Loss: 0.2169, Test Loss: 0.3086, Train Accuracy: 64.1058, Test Accuracy: 61.6162, Avg. duration: 0.0274 s\n",
      "Epoch: 1929, Train Loss: 0.2169, Test Loss: 0.3086, Train Accuracy: 64.1058, Test Accuracy: 61.6162, Avg. duration: 0.0276 s\n",
      "Epoch: 1930, Train Loss: 0.2169, Test Loss: 0.3086, Train Accuracy: 64.1058, Test Accuracy: 61.6162, Avg. duration: 0.0268 s\n",
      "Epoch: 1931, Train Loss: 0.2169, Test Loss: 0.3086, Train Accuracy: 64.1058, Test Accuracy: 61.6162, Avg. duration: 0.0269 s\n",
      "Epoch: 1932, Train Loss: 0.2169, Test Loss: 0.3086, Train Accuracy: 64.1058, Test Accuracy: 61.6162, Avg. duration: 0.0273 s\n",
      "Epoch: 1933, Train Loss: 0.2169, Test Loss: 0.3086, Train Accuracy: 64.1058, Test Accuracy: 61.6162, Avg. duration: 0.0280 s\n",
      "Epoch: 1934, Train Loss: 0.2169, Test Loss: 0.3086, Train Accuracy: 64.1058, Test Accuracy: 61.6162, Avg. duration: 0.0278 s\n",
      "Epoch: 1935, Train Loss: 0.2169, Test Loss: 0.3086, Train Accuracy: 64.1058, Test Accuracy: 61.6162, Avg. duration: 0.0275 s\n",
      "Epoch: 1936, Train Loss: 0.2169, Test Loss: 0.3086, Train Accuracy: 64.1058, Test Accuracy: 61.6162, Avg. duration: 0.0269 s\n",
      "Epoch: 1937, Train Loss: 0.2169, Test Loss: 0.3086, Train Accuracy: 64.1058, Test Accuracy: 61.6162, Avg. duration: 0.0274 s\n",
      "Epoch: 1938, Train Loss: 0.2169, Test Loss: 0.3086, Train Accuracy: 64.1058, Test Accuracy: 61.6162, Avg. duration: 0.0271 s\n",
      "Epoch: 1939, Train Loss: 0.2169, Test Loss: 0.3086, Train Accuracy: 64.1058, Test Accuracy: 61.6162, Avg. duration: 0.0275 s\n",
      "Epoch: 1940, Train Loss: 0.2169, Test Loss: 0.3086, Train Accuracy: 64.1058, Test Accuracy: 61.6162, Avg. duration: 0.0272 s\n",
      "Epoch: 1941, Train Loss: 0.2169, Test Loss: 0.3086, Train Accuracy: 64.1058, Test Accuracy: 61.6162, Avg. duration: 0.0277 s\n",
      "Epoch: 1942, Train Loss: 0.2169, Test Loss: 0.3086, Train Accuracy: 64.1058, Test Accuracy: 61.6162, Avg. duration: 0.0273 s\n",
      "Epoch: 1943, Train Loss: 0.2169, Test Loss: 0.3086, Train Accuracy: 64.1058, Test Accuracy: 61.6162, Avg. duration: 0.0277 s\n",
      "Epoch: 1944, Train Loss: 0.2169, Test Loss: 0.3086, Train Accuracy: 64.1058, Test Accuracy: 61.6162, Avg. duration: 0.0274 s\n",
      "Epoch: 1945, Train Loss: 0.2169, Test Loss: 0.3086, Train Accuracy: 64.1058, Test Accuracy: 61.6162, Avg. duration: 0.0273 s\n",
      "Epoch: 1946, Train Loss: 0.2169, Test Loss: 0.3086, Train Accuracy: 64.1058, Test Accuracy: 61.6162, Avg. duration: 0.0276 s\n",
      "Epoch: 1947, Train Loss: 0.2169, Test Loss: 0.3086, Train Accuracy: 64.1058, Test Accuracy: 61.6162, Avg. duration: 0.0275 s\n",
      "Epoch: 1948, Train Loss: 0.2169, Test Loss: 0.3086, Train Accuracy: 64.1058, Test Accuracy: 61.6162, Avg. duration: 0.0272 s\n",
      "Epoch: 1949, Train Loss: 0.2169, Test Loss: 0.3086, Train Accuracy: 64.1058, Test Accuracy: 61.6162, Avg. duration: 0.0275 s\n",
      "Epoch: 1950, Train Loss: 0.2169, Test Loss: 0.3086, Train Accuracy: 64.1058, Test Accuracy: 61.6162, Avg. duration: 0.0273 s\n",
      "Epoch: 1951, Train Loss: 0.2169, Test Loss: 0.3086, Train Accuracy: 64.1058, Test Accuracy: 61.6162, Avg. duration: 0.0277 s\n",
      "Epoch: 1952, Train Loss: 0.2169, Test Loss: 0.3086, Train Accuracy: 64.1058, Test Accuracy: 61.6162, Avg. duration: 0.0278 s\n",
      "Epoch: 1953, Train Loss: 0.2169, Test Loss: 0.3086, Train Accuracy: 64.1058, Test Accuracy: 61.6162, Avg. duration: 0.0276 s\n",
      "Epoch: 1954, Train Loss: 0.2169, Test Loss: 0.3086, Train Accuracy: 64.1058, Test Accuracy: 61.6162, Avg. duration: 0.0271 s\n",
      "Epoch: 1955, Train Loss: 0.2169, Test Loss: 0.3086, Train Accuracy: 64.1058, Test Accuracy: 61.6162, Avg. duration: 0.0276 s\n",
      "Epoch: 1956, Train Loss: 0.2169, Test Loss: 0.3086, Train Accuracy: 64.1058, Test Accuracy: 61.6162, Avg. duration: 0.0273 s\n",
      "Epoch: 1957, Train Loss: 0.2169, Test Loss: 0.3086, Train Accuracy: 64.1058, Test Accuracy: 61.6162, Avg. duration: 0.0281 s\n",
      "Epoch: 1958, Train Loss: 0.2169, Test Loss: 0.3086, Train Accuracy: 64.1058, Test Accuracy: 61.6162, Avg. duration: 0.0276 s\n",
      "Epoch: 1959, Train Loss: 0.2169, Test Loss: 0.3086, Train Accuracy: 64.1058, Test Accuracy: 61.6162, Avg. duration: 0.0272 s\n",
      "Epoch: 1960, Train Loss: 0.2169, Test Loss: 0.3086, Train Accuracy: 64.1058, Test Accuracy: 61.6162, Avg. duration: 0.0273 s\n",
      "Epoch: 1961, Train Loss: 0.2169, Test Loss: 0.3086, Train Accuracy: 64.1058, Test Accuracy: 61.6162, Avg. duration: 0.0273 s\n",
      "Epoch: 1962, Train Loss: 0.2169, Test Loss: 0.3086, Train Accuracy: 64.1058, Test Accuracy: 61.6162, Avg. duration: 0.0274 s\n",
      "Epoch: 1963, Train Loss: 0.2169, Test Loss: 0.3086, Train Accuracy: 64.1058, Test Accuracy: 61.6162, Avg. duration: 0.0273 s\n",
      "Epoch: 1964, Train Loss: 0.2169, Test Loss: 0.3086, Train Accuracy: 64.1058, Test Accuracy: 61.6162, Avg. duration: 0.3209 s\n",
      "Epoch: 1965, Train Loss: 0.2169, Test Loss: 0.3086, Train Accuracy: 64.1058, Test Accuracy: 61.6162, Avg. duration: 0.0288 s\n",
      "Epoch: 1966, Train Loss: 0.2169, Test Loss: 0.3086, Train Accuracy: 64.1058, Test Accuracy: 61.6162, Avg. duration: 0.0279 s\n",
      "Epoch: 1967, Train Loss: 0.2169, Test Loss: 0.3086, Train Accuracy: 64.1058, Test Accuracy: 61.6162, Avg. duration: 0.0277 s\n",
      "Epoch: 1968, Train Loss: 0.2169, Test Loss: 0.3086, Train Accuracy: 64.1058, Test Accuracy: 61.6162, Avg. duration: 0.0278 s\n",
      "Epoch: 1969, Train Loss: 0.2169, Test Loss: 0.3086, Train Accuracy: 64.1058, Test Accuracy: 61.6162, Avg. duration: 0.0274 s\n",
      "Epoch: 1970, Train Loss: 0.2169, Test Loss: 0.3086, Train Accuracy: 64.1058, Test Accuracy: 61.6162, Avg. duration: 0.0276 s\n",
      "Epoch: 1971, Train Loss: 0.2169, Test Loss: 0.3086, Train Accuracy: 64.1058, Test Accuracy: 61.6162, Avg. duration: 0.0272 s\n",
      "Epoch: 1972, Train Loss: 0.2169, Test Loss: 0.3086, Train Accuracy: 64.1058, Test Accuracy: 61.6162, Avg. duration: 0.0277 s\n",
      "Epoch: 1973, Train Loss: 0.2169, Test Loss: 0.3086, Train Accuracy: 64.1058, Test Accuracy: 61.6162, Avg. duration: 0.0275 s\n",
      "Epoch: 1974, Train Loss: 0.2169, Test Loss: 0.3086, Train Accuracy: 64.1058, Test Accuracy: 61.6162, Avg. duration: 0.0276 s\n",
      "Epoch: 1975, Train Loss: 0.2169, Test Loss: 0.3086, Train Accuracy: 64.1058, Test Accuracy: 61.6162, Avg. duration: 0.0279 s\n",
      "Epoch: 1976, Train Loss: 0.2169, Test Loss: 0.3086, Train Accuracy: 64.1058, Test Accuracy: 61.6162, Avg. duration: 0.0278 s\n",
      "Epoch: 1977, Train Loss: 0.2169, Test Loss: 0.3086, Train Accuracy: 64.1058, Test Accuracy: 61.6162, Avg. duration: 0.0275 s\n",
      "Epoch: 1978, Train Loss: 0.2169, Test Loss: 0.3086, Train Accuracy: 64.1058, Test Accuracy: 61.6162, Avg. duration: 0.0270 s\n",
      "Epoch: 1979, Train Loss: 0.2169, Test Loss: 0.3086, Train Accuracy: 64.1058, Test Accuracy: 61.6162, Avg. duration: 0.0274 s\n",
      "Epoch: 1980, Train Loss: 0.2169, Test Loss: 0.3086, Train Accuracy: 64.1058, Test Accuracy: 61.6162, Avg. duration: 0.0281 s\n",
      "Epoch: 1981, Train Loss: 0.2169, Test Loss: 0.3086, Train Accuracy: 64.1058, Test Accuracy: 61.6162, Avg. duration: 0.0278 s\n",
      "Epoch: 1982, Train Loss: 0.2169, Test Loss: 0.3086, Train Accuracy: 64.1058, Test Accuracy: 61.6162, Avg. duration: 0.0278 s\n",
      "Epoch: 1983, Train Loss: 0.2169, Test Loss: 0.3086, Train Accuracy: 64.1058, Test Accuracy: 61.6162, Avg. duration: 0.0275 s\n",
      "Epoch: 1984, Train Loss: 0.2169, Test Loss: 0.3086, Train Accuracy: 64.1058, Test Accuracy: 61.6162, Avg. duration: 0.0276 s\n",
      "Epoch: 1985, Train Loss: 0.2169, Test Loss: 0.3086, Train Accuracy: 64.1058, Test Accuracy: 61.6162, Avg. duration: 0.0279 s\n",
      "Epoch: 1986, Train Loss: 0.2169, Test Loss: 0.3086, Train Accuracy: 64.1058, Test Accuracy: 61.6162, Avg. duration: 0.0275 s\n",
      "Epoch: 1987, Train Loss: 0.2169, Test Loss: 0.3086, Train Accuracy: 64.1058, Test Accuracy: 61.6162, Avg. duration: 0.0281 s\n",
      "Epoch: 1988, Train Loss: 0.2169, Test Loss: 0.3086, Train Accuracy: 64.1058, Test Accuracy: 61.6162, Avg. duration: 0.0286 s\n",
      "Epoch: 1989, Train Loss: 0.2169, Test Loss: 0.3086, Train Accuracy: 64.1058, Test Accuracy: 61.6162, Avg. duration: 0.0274 s\n",
      "Epoch: 1990, Train Loss: 0.2169, Test Loss: 0.3086, Train Accuracy: 64.1058, Test Accuracy: 61.6162, Avg. duration: 0.0278 s\n",
      "Epoch: 1991, Train Loss: 0.2169, Test Loss: 0.3086, Train Accuracy: 64.1058, Test Accuracy: 61.6162, Avg. duration: 0.0276 s\n",
      "Epoch: 1992, Train Loss: 0.2169, Test Loss: 0.3086, Train Accuracy: 64.1058, Test Accuracy: 61.6162, Avg. duration: 0.0277 s\n",
      "Epoch: 1993, Train Loss: 0.2169, Test Loss: 0.3086, Train Accuracy: 64.1058, Test Accuracy: 61.6162, Avg. duration: 0.0279 s\n",
      "Epoch: 1994, Train Loss: 0.2169, Test Loss: 0.3086, Train Accuracy: 64.1058, Test Accuracy: 61.6162, Avg. duration: 0.0276 s\n",
      "Epoch: 1995, Train Loss: 0.2169, Test Loss: 0.3086, Train Accuracy: 64.1058, Test Accuracy: 61.6162, Avg. duration: 0.0273 s\n",
      "Epoch: 1996, Train Loss: 0.2169, Test Loss: 0.3086, Train Accuracy: 64.1058, Test Accuracy: 61.6162, Avg. duration: 0.0277 s\n",
      "Epoch: 1997, Train Loss: 0.2169, Test Loss: 0.3086, Train Accuracy: 64.1058, Test Accuracy: 61.6162, Avg. duration: 0.0277 s\n",
      "Epoch: 1998, Train Loss: 0.2169, Test Loss: 0.3086, Train Accuracy: 64.1058, Test Accuracy: 61.6162, Avg. duration: 0.0278 s\n",
      "Epoch: 1999, Train Loss: 0.2169, Test Loss: 0.3086, Train Accuracy: 64.1058, Test Accuracy: 61.6162, Avg. duration: 0.0277 s\n",
      "Epoch: 2000, Train Loss: 0.2169, Test Loss: 0.3086, Train Accuracy: 64.1058, Test Accuracy: 61.6162, Avg. duration: 0.0279 s\n",
      "Epoch: 2001, Train Loss: 0.2146, Test Loss: 0.3109, Train Accuracy: 64.6096, Test Accuracy: 61.6162, Avg. duration: 2.7311 s\n",
      "Epoch: 2002, Train Loss: 0.2146, Test Loss: 0.3109, Train Accuracy: 64.6096, Test Accuracy: 61.6162, Avg. duration: 0.0287 s\n",
      "Epoch: 2003, Train Loss: 0.2146, Test Loss: 0.3109, Train Accuracy: 64.6096, Test Accuracy: 61.6162, Avg. duration: 0.0273 s\n",
      "Epoch: 2004, Train Loss: 0.2146, Test Loss: 0.3109, Train Accuracy: 64.6096, Test Accuracy: 61.6162, Avg. duration: 0.0273 s\n",
      "Epoch: 2005, Train Loss: 0.2146, Test Loss: 0.3109, Train Accuracy: 64.6096, Test Accuracy: 61.6162, Avg. duration: 0.0275 s\n",
      "Epoch: 2006, Train Loss: 0.2146, Test Loss: 0.3109, Train Accuracy: 64.6096, Test Accuracy: 61.6162, Avg. duration: 0.0273 s\n",
      "Epoch: 2007, Train Loss: 0.2146, Test Loss: 0.3109, Train Accuracy: 64.6096, Test Accuracy: 61.6162, Avg. duration: 0.0270 s\n",
      "Epoch: 2008, Train Loss: 0.2146, Test Loss: 0.3109, Train Accuracy: 64.6096, Test Accuracy: 61.6162, Avg. duration: 0.0268 s\n",
      "Epoch: 2009, Train Loss: 0.2146, Test Loss: 0.3109, Train Accuracy: 64.6096, Test Accuracy: 61.6162, Avg. duration: 0.0277 s\n",
      "Epoch: 2010, Train Loss: 0.2146, Test Loss: 0.3109, Train Accuracy: 64.6096, Test Accuracy: 61.6162, Avg. duration: 0.0271 s\n",
      "Epoch: 2011, Train Loss: 0.2146, Test Loss: 0.3109, Train Accuracy: 64.6096, Test Accuracy: 61.6162, Avg. duration: 0.0272 s\n",
      "Epoch: 2012, Train Loss: 0.2146, Test Loss: 0.3109, Train Accuracy: 64.6096, Test Accuracy: 61.6162, Avg. duration: 0.0272 s\n",
      "Epoch: 2013, Train Loss: 0.2146, Test Loss: 0.3109, Train Accuracy: 64.6096, Test Accuracy: 61.6162, Avg. duration: 0.0269 s\n",
      "Epoch: 2014, Train Loss: 0.2146, Test Loss: 0.3109, Train Accuracy: 64.6096, Test Accuracy: 61.6162, Avg. duration: 0.0269 s\n",
      "Epoch: 2015, Train Loss: 0.2146, Test Loss: 0.3109, Train Accuracy: 64.6096, Test Accuracy: 61.6162, Avg. duration: 0.0273 s\n",
      "Epoch: 2016, Train Loss: 0.2146, Test Loss: 0.3109, Train Accuracy: 64.6096, Test Accuracy: 61.6162, Avg. duration: 0.0271 s\n",
      "Epoch: 2017, Train Loss: 0.2146, Test Loss: 0.3109, Train Accuracy: 64.6096, Test Accuracy: 61.6162, Avg. duration: 0.0277 s\n",
      "Epoch: 2018, Train Loss: 0.2146, Test Loss: 0.3109, Train Accuracy: 64.6096, Test Accuracy: 61.6162, Avg. duration: 0.0277 s\n",
      "Epoch: 2019, Train Loss: 0.2146, Test Loss: 0.3109, Train Accuracy: 64.6096, Test Accuracy: 61.6162, Avg. duration: 0.0267 s\n",
      "Epoch: 2020, Train Loss: 0.2146, Test Loss: 0.3109, Train Accuracy: 64.6096, Test Accuracy: 61.6162, Avg. duration: 0.0269 s\n",
      "Epoch: 2021, Train Loss: 0.2146, Test Loss: 0.3109, Train Accuracy: 64.6096, Test Accuracy: 61.6162, Avg. duration: 0.0268 s\n",
      "Epoch: 2022, Train Loss: 0.2146, Test Loss: 0.3109, Train Accuracy: 64.6096, Test Accuracy: 61.6162, Avg. duration: 0.0270 s\n",
      "Epoch: 2023, Train Loss: 0.2146, Test Loss: 0.3109, Train Accuracy: 64.6096, Test Accuracy: 61.6162, Avg. duration: 0.0273 s\n",
      "Epoch: 2024, Train Loss: 0.2146, Test Loss: 0.3109, Train Accuracy: 64.6096, Test Accuracy: 61.6162, Avg. duration: 0.0276 s\n",
      "Epoch: 2025, Train Loss: 0.2146, Test Loss: 0.3109, Train Accuracy: 64.6096, Test Accuracy: 61.6162, Avg. duration: 0.0272 s\n",
      "Epoch: 2026, Train Loss: 0.2146, Test Loss: 0.3109, Train Accuracy: 64.6096, Test Accuracy: 61.6162, Avg. duration: 0.0273 s\n",
      "Epoch: 2027, Train Loss: 0.2146, Test Loss: 0.3109, Train Accuracy: 64.6096, Test Accuracy: 61.6162, Avg. duration: 0.0270 s\n",
      "Epoch: 2028, Train Loss: 0.2146, Test Loss: 0.3109, Train Accuracy: 64.6096, Test Accuracy: 61.6162, Avg. duration: 0.0271 s\n",
      "Epoch: 2029, Train Loss: 0.2146, Test Loss: 0.3109, Train Accuracy: 64.6096, Test Accuracy: 61.6162, Avg. duration: 0.0270 s\n",
      "Epoch: 2030, Train Loss: 0.2146, Test Loss: 0.3109, Train Accuracy: 64.6096, Test Accuracy: 61.6162, Avg. duration: 0.0273 s\n",
      "Epoch: 2031, Train Loss: 0.2146, Test Loss: 0.3109, Train Accuracy: 64.6096, Test Accuracy: 61.6162, Avg. duration: 0.0271 s\n",
      "Epoch: 2032, Train Loss: 0.2146, Test Loss: 0.3109, Train Accuracy: 64.6096, Test Accuracy: 61.6162, Avg. duration: 0.0270 s\n",
      "Epoch: 2033, Train Loss: 0.2146, Test Loss: 0.3109, Train Accuracy: 64.6096, Test Accuracy: 61.6162, Avg. duration: 0.0274 s\n",
      "Epoch: 2034, Train Loss: 0.2146, Test Loss: 0.3109, Train Accuracy: 64.6096, Test Accuracy: 61.6162, Avg. duration: 0.0271 s\n",
      "Epoch: 2035, Train Loss: 0.2146, Test Loss: 0.3109, Train Accuracy: 64.6096, Test Accuracy: 61.6162, Avg. duration: 0.0275 s\n",
      "Epoch: 2036, Train Loss: 0.2146, Test Loss: 0.3109, Train Accuracy: 64.6096, Test Accuracy: 61.6162, Avg. duration: 0.0273 s\n",
      "Epoch: 2037, Train Loss: 0.2146, Test Loss: 0.3109, Train Accuracy: 64.6096, Test Accuracy: 61.6162, Avg. duration: 0.0272 s\n",
      "Epoch: 2038, Train Loss: 0.2146, Test Loss: 0.3109, Train Accuracy: 64.6096, Test Accuracy: 61.6162, Avg. duration: 0.0269 s\n",
      "Epoch: 2039, Train Loss: 0.2146, Test Loss: 0.3109, Train Accuracy: 64.6096, Test Accuracy: 61.6162, Avg. duration: 0.0270 s\n",
      "Epoch: 2040, Train Loss: 0.2146, Test Loss: 0.3109, Train Accuracy: 64.6096, Test Accuracy: 61.6162, Avg. duration: 0.3163 s\n",
      "Epoch: 2041, Train Loss: 0.2146, Test Loss: 0.3109, Train Accuracy: 64.6096, Test Accuracy: 61.6162, Avg. duration: 0.0283 s\n",
      "Epoch: 2042, Train Loss: 0.2146, Test Loss: 0.3109, Train Accuracy: 64.6096, Test Accuracy: 61.6162, Avg. duration: 0.0277 s\n",
      "Epoch: 2043, Train Loss: 0.2146, Test Loss: 0.3109, Train Accuracy: 64.6096, Test Accuracy: 61.6162, Avg. duration: 0.0269 s\n",
      "Epoch: 2044, Train Loss: 0.2146, Test Loss: 0.3109, Train Accuracy: 64.6096, Test Accuracy: 61.6162, Avg. duration: 0.0271 s\n",
      "Epoch: 2045, Train Loss: 0.2146, Test Loss: 0.3109, Train Accuracy: 64.6096, Test Accuracy: 61.6162, Avg. duration: 0.0272 s\n",
      "Epoch: 2046, Train Loss: 0.2146, Test Loss: 0.3109, Train Accuracy: 64.6096, Test Accuracy: 61.6162, Avg. duration: 0.0272 s\n",
      "Epoch: 2047, Train Loss: 0.2146, Test Loss: 0.3109, Train Accuracy: 64.6096, Test Accuracy: 61.6162, Avg. duration: 0.0273 s\n",
      "Epoch: 2048, Train Loss: 0.2146, Test Loss: 0.3109, Train Accuracy: 64.6096, Test Accuracy: 61.6162, Avg. duration: 0.0276 s\n",
      "Epoch: 2049, Train Loss: 0.2146, Test Loss: 0.3109, Train Accuracy: 64.6096, Test Accuracy: 61.6162, Avg. duration: 0.0271 s\n",
      "Epoch: 2050, Train Loss: 0.2146, Test Loss: 0.3109, Train Accuracy: 64.6096, Test Accuracy: 61.6162, Avg. duration: 0.0270 s\n",
      "Epoch: 2051, Train Loss: 0.2146, Test Loss: 0.3109, Train Accuracy: 64.6096, Test Accuracy: 61.6162, Avg. duration: 0.0272 s\n",
      "Epoch: 2052, Train Loss: 0.2146, Test Loss: 0.3109, Train Accuracy: 64.6096, Test Accuracy: 61.6162, Avg. duration: 0.0270 s\n",
      "Epoch: 2053, Train Loss: 0.2146, Test Loss: 0.3109, Train Accuracy: 64.6096, Test Accuracy: 61.6162, Avg. duration: 0.0274 s\n",
      "Epoch: 2054, Train Loss: 0.2146, Test Loss: 0.3109, Train Accuracy: 64.6096, Test Accuracy: 61.6162, Avg. duration: 0.0277 s\n",
      "Epoch: 2055, Train Loss: 0.2146, Test Loss: 0.3109, Train Accuracy: 64.6096, Test Accuracy: 61.6162, Avg. duration: 0.0272 s\n",
      "Epoch: 2056, Train Loss: 0.2146, Test Loss: 0.3109, Train Accuracy: 64.6096, Test Accuracy: 61.6162, Avg. duration: 0.0272 s\n",
      "Epoch: 2057, Train Loss: 0.2146, Test Loss: 0.3109, Train Accuracy: 64.6096, Test Accuracy: 61.6162, Avg. duration: 0.0276 s\n",
      "Epoch: 2058, Train Loss: 0.2146, Test Loss: 0.3109, Train Accuracy: 64.6096, Test Accuracy: 61.6162, Avg. duration: 0.0274 s\n",
      "Epoch: 2059, Train Loss: 0.2146, Test Loss: 0.3109, Train Accuracy: 64.6096, Test Accuracy: 61.6162, Avg. duration: 0.0277 s\n",
      "Epoch: 2060, Train Loss: 0.2146, Test Loss: 0.3109, Train Accuracy: 64.6096, Test Accuracy: 61.6162, Avg. duration: 0.0273 s\n",
      "Epoch: 2061, Train Loss: 0.2146, Test Loss: 0.3109, Train Accuracy: 64.6096, Test Accuracy: 61.6162, Avg. duration: 0.0272 s\n",
      "Epoch: 2062, Train Loss: 0.2146, Test Loss: 0.3109, Train Accuracy: 64.6096, Test Accuracy: 61.6162, Avg. duration: 0.0271 s\n",
      "Epoch: 2063, Train Loss: 0.2146, Test Loss: 0.3109, Train Accuracy: 64.6096, Test Accuracy: 61.6162, Avg. duration: 0.0276 s\n",
      "Epoch: 2064, Train Loss: 0.2146, Test Loss: 0.3109, Train Accuracy: 64.6096, Test Accuracy: 61.6162, Avg. duration: 0.0280 s\n",
      "Epoch: 2065, Train Loss: 0.2146, Test Loss: 0.3109, Train Accuracy: 64.6096, Test Accuracy: 61.6162, Avg. duration: 0.0276 s\n",
      "Epoch: 2066, Train Loss: 0.2146, Test Loss: 0.3109, Train Accuracy: 64.6096, Test Accuracy: 61.6162, Avg. duration: 0.0277 s\n",
      "Epoch: 2067, Train Loss: 0.2146, Test Loss: 0.3109, Train Accuracy: 64.6096, Test Accuracy: 61.6162, Avg. duration: 0.0276 s\n",
      "Epoch: 2068, Train Loss: 0.2146, Test Loss: 0.3109, Train Accuracy: 64.6096, Test Accuracy: 61.6162, Avg. duration: 0.0273 s\n",
      "Epoch: 2069, Train Loss: 0.2146, Test Loss: 0.3109, Train Accuracy: 64.6096, Test Accuracy: 61.6162, Avg. duration: 0.0275 s\n",
      "Epoch: 2070, Train Loss: 0.2146, Test Loss: 0.3109, Train Accuracy: 64.6096, Test Accuracy: 61.6162, Avg. duration: 0.0274 s\n",
      "Epoch: 2071, Train Loss: 0.2146, Test Loss: 0.3109, Train Accuracy: 64.6096, Test Accuracy: 61.6162, Avg. duration: 0.0279 s\n",
      "Epoch: 2072, Train Loss: 0.2146, Test Loss: 0.3109, Train Accuracy: 64.6096, Test Accuracy: 61.6162, Avg. duration: 0.0281 s\n",
      "Epoch: 2073, Train Loss: 0.2146, Test Loss: 0.3109, Train Accuracy: 64.6096, Test Accuracy: 61.6162, Avg. duration: 0.0273 s\n",
      "Epoch: 2074, Train Loss: 0.2146, Test Loss: 0.3109, Train Accuracy: 64.6096, Test Accuracy: 61.6162, Avg. duration: 0.0276 s\n",
      "Epoch: 2075, Train Loss: 0.2146, Test Loss: 0.3109, Train Accuracy: 64.6096, Test Accuracy: 61.6162, Avg. duration: 0.0272 s\n",
      "Epoch: 2076, Train Loss: 0.2146, Test Loss: 0.3109, Train Accuracy: 64.6096, Test Accuracy: 61.6162, Avg. duration: 0.0276 s\n",
      "Epoch: 2077, Train Loss: 0.2146, Test Loss: 0.3109, Train Accuracy: 64.6096, Test Accuracy: 61.6162, Avg. duration: 0.0277 s\n",
      "Epoch: 2078, Train Loss: 0.2146, Test Loss: 0.3109, Train Accuracy: 64.6096, Test Accuracy: 61.6162, Avg. duration: 0.0277 s\n",
      "Epoch: 2079, Train Loss: 0.2146, Test Loss: 0.3109, Train Accuracy: 64.6096, Test Accuracy: 61.6162, Avg. duration: 0.0277 s\n",
      "Epoch: 2080, Train Loss: 0.2146, Test Loss: 0.3109, Train Accuracy: 64.6096, Test Accuracy: 61.6162, Avg. duration: 0.0278 s\n",
      "Epoch: 2081, Train Loss: 0.2146, Test Loss: 0.3109, Train Accuracy: 64.6096, Test Accuracy: 61.6162, Avg. duration: 0.0275 s\n",
      "Epoch: 2082, Train Loss: 0.2146, Test Loss: 0.3109, Train Accuracy: 64.6096, Test Accuracy: 61.6162, Avg. duration: 0.0278 s\n",
      "Epoch: 2083, Train Loss: 0.2146, Test Loss: 0.3109, Train Accuracy: 64.6096, Test Accuracy: 61.6162, Avg. duration: 0.0278 s\n",
      "Epoch: 2084, Train Loss: 0.2146, Test Loss: 0.3109, Train Accuracy: 64.6096, Test Accuracy: 61.6162, Avg. duration: 0.0277 s\n",
      "Epoch: 2085, Train Loss: 0.2146, Test Loss: 0.3109, Train Accuracy: 64.6096, Test Accuracy: 61.6162, Avg. duration: 0.0272 s\n",
      "Epoch: 2086, Train Loss: 0.2146, Test Loss: 0.3109, Train Accuracy: 64.6096, Test Accuracy: 61.6162, Avg. duration: 0.0272 s\n",
      "Epoch: 2087, Train Loss: 0.2146, Test Loss: 0.3109, Train Accuracy: 64.6096, Test Accuracy: 61.6162, Avg. duration: 0.0277 s\n",
      "Epoch: 2088, Train Loss: 0.2146, Test Loss: 0.3109, Train Accuracy: 64.6096, Test Accuracy: 61.6162, Avg. duration: 0.0280 s\n",
      "Epoch: 2089, Train Loss: 0.2146, Test Loss: 0.3109, Train Accuracy: 64.6096, Test Accuracy: 61.6162, Avg. duration: 0.0277 s\n",
      "Epoch: 2090, Train Loss: 0.2146, Test Loss: 0.3109, Train Accuracy: 64.6096, Test Accuracy: 61.6162, Avg. duration: 0.0275 s\n",
      "Epoch: 2091, Train Loss: 0.2146, Test Loss: 0.3109, Train Accuracy: 64.6096, Test Accuracy: 61.6162, Avg. duration: 0.0276 s\n",
      "Epoch: 2092, Train Loss: 0.2146, Test Loss: 0.3109, Train Accuracy: 64.6096, Test Accuracy: 61.6162, Avg. duration: 0.0277 s\n",
      "Epoch: 2093, Train Loss: 0.2146, Test Loss: 0.3109, Train Accuracy: 64.6096, Test Accuracy: 61.6162, Avg. duration: 0.0278 s\n",
      "Epoch: 2094, Train Loss: 0.2146, Test Loss: 0.3109, Train Accuracy: 64.6096, Test Accuracy: 61.6162, Avg. duration: 0.0278 s\n",
      "Epoch: 2095, Train Loss: 0.2146, Test Loss: 0.3109, Train Accuracy: 64.6096, Test Accuracy: 61.6162, Avg. duration: 0.0277 s\n",
      "Epoch: 2096, Train Loss: 0.2146, Test Loss: 0.3109, Train Accuracy: 64.6096, Test Accuracy: 61.6162, Avg. duration: 0.0281 s\n",
      "Epoch: 2097, Train Loss: 0.2146, Test Loss: 0.3109, Train Accuracy: 64.6096, Test Accuracy: 61.6162, Avg. duration: 0.0272 s\n",
      "Epoch: 2098, Train Loss: 0.2146, Test Loss: 0.3109, Train Accuracy: 64.6096, Test Accuracy: 61.6162, Avg. duration: 0.0277 s\n",
      "Epoch: 2099, Train Loss: 0.2146, Test Loss: 0.3109, Train Accuracy: 64.6096, Test Accuracy: 61.6162, Avg. duration: 0.0274 s\n",
      "Epoch: 2100, Train Loss: 0.2146, Test Loss: 0.3109, Train Accuracy: 64.6096, Test Accuracy: 61.6162, Avg. duration: 0.0274 s\n",
      "Epoch: 2101, Train Loss: 0.2128, Test Loss: 0.3105, Train Accuracy: 64.4836, Test Accuracy: 62.1212, Avg. duration: 2.7300 s\n",
      "Epoch: 2102, Train Loss: 0.2128, Test Loss: 0.3105, Train Accuracy: 64.4836, Test Accuracy: 62.1212, Avg. duration: 0.0291 s\n",
      "Epoch: 2103, Train Loss: 0.2128, Test Loss: 0.3105, Train Accuracy: 64.4836, Test Accuracy: 62.1212, Avg. duration: 0.0276 s\n",
      "Epoch: 2104, Train Loss: 0.2128, Test Loss: 0.3105, Train Accuracy: 64.4836, Test Accuracy: 62.1212, Avg. duration: 0.0270 s\n",
      "Epoch: 2105, Train Loss: 0.2128, Test Loss: 0.3105, Train Accuracy: 64.4836, Test Accuracy: 62.1212, Avg. duration: 0.0274 s\n",
      "Epoch: 2106, Train Loss: 0.2128, Test Loss: 0.3105, Train Accuracy: 64.4836, Test Accuracy: 62.1212, Avg. duration: 0.0273 s\n",
      "Epoch: 2107, Train Loss: 0.2128, Test Loss: 0.3105, Train Accuracy: 64.4836, Test Accuracy: 62.1212, Avg. duration: 0.3121 s\n",
      "Epoch: 2108, Train Loss: 0.2128, Test Loss: 0.3105, Train Accuracy: 64.4836, Test Accuracy: 62.1212, Avg. duration: 0.0284 s\n",
      "Epoch: 2109, Train Loss: 0.2128, Test Loss: 0.3105, Train Accuracy: 64.4836, Test Accuracy: 62.1212, Avg. duration: 0.0276 s\n",
      "Epoch: 2110, Train Loss: 0.2128, Test Loss: 0.3105, Train Accuracy: 64.4836, Test Accuracy: 62.1212, Avg. duration: 0.0277 s\n",
      "Epoch: 2111, Train Loss: 0.2128, Test Loss: 0.3105, Train Accuracy: 64.4836, Test Accuracy: 62.1212, Avg. duration: 0.0272 s\n",
      "Epoch: 2112, Train Loss: 0.2128, Test Loss: 0.3105, Train Accuracy: 64.4836, Test Accuracy: 62.1212, Avg. duration: 0.0272 s\n",
      "Epoch: 2113, Train Loss: 0.2128, Test Loss: 0.3105, Train Accuracy: 64.4836, Test Accuracy: 62.1212, Avg. duration: 0.0276 s\n",
      "Epoch: 2114, Train Loss: 0.2128, Test Loss: 0.3105, Train Accuracy: 64.4836, Test Accuracy: 62.1212, Avg. duration: 0.0270 s\n",
      "Epoch: 2115, Train Loss: 0.2128, Test Loss: 0.3105, Train Accuracy: 64.4836, Test Accuracy: 62.1212, Avg. duration: 0.0276 s\n",
      "Epoch: 2116, Train Loss: 0.2128, Test Loss: 0.3105, Train Accuracy: 64.4836, Test Accuracy: 62.1212, Avg. duration: 0.0277 s\n",
      "Epoch: 2117, Train Loss: 0.2128, Test Loss: 0.3105, Train Accuracy: 64.4836, Test Accuracy: 62.1212, Avg. duration: 0.0270 s\n",
      "Epoch: 2118, Train Loss: 0.2128, Test Loss: 0.3105, Train Accuracy: 64.4836, Test Accuracy: 62.1212, Avg. duration: 0.0276 s\n",
      "Epoch: 2119, Train Loss: 0.2128, Test Loss: 0.3105, Train Accuracy: 64.4836, Test Accuracy: 62.1212, Avg. duration: 0.0277 s\n",
      "Epoch: 2120, Train Loss: 0.2128, Test Loss: 0.3105, Train Accuracy: 64.4836, Test Accuracy: 62.1212, Avg. duration: 0.0269 s\n",
      "Epoch: 2121, Train Loss: 0.2128, Test Loss: 0.3105, Train Accuracy: 64.4836, Test Accuracy: 62.1212, Avg. duration: 0.0268 s\n",
      "Epoch: 2122, Train Loss: 0.2128, Test Loss: 0.3105, Train Accuracy: 64.4836, Test Accuracy: 62.1212, Avg. duration: 0.0272 s\n",
      "Epoch: 2123, Train Loss: 0.2128, Test Loss: 0.3105, Train Accuracy: 64.4836, Test Accuracy: 62.1212, Avg. duration: 0.0281 s\n",
      "Epoch: 2124, Train Loss: 0.2128, Test Loss: 0.3105, Train Accuracy: 64.4836, Test Accuracy: 62.1212, Avg. duration: 0.0278 s\n",
      "Epoch: 2125, Train Loss: 0.2128, Test Loss: 0.3105, Train Accuracy: 64.4836, Test Accuracy: 62.1212, Avg. duration: 0.0273 s\n",
      "Epoch: 2126, Train Loss: 0.2128, Test Loss: 0.3105, Train Accuracy: 64.4836, Test Accuracy: 62.1212, Avg. duration: 0.0270 s\n",
      "Epoch: 2127, Train Loss: 0.2128, Test Loss: 0.3105, Train Accuracy: 64.4836, Test Accuracy: 62.1212, Avg. duration: 0.0270 s\n",
      "Epoch: 2128, Train Loss: 0.2128, Test Loss: 0.3105, Train Accuracy: 64.4836, Test Accuracy: 62.1212, Avg. duration: 0.0275 s\n",
      "Epoch: 2129, Train Loss: 0.2128, Test Loss: 0.3105, Train Accuracy: 64.4836, Test Accuracy: 62.1212, Avg. duration: 0.0275 s\n",
      "Epoch: 2130, Train Loss: 0.2128, Test Loss: 0.3105, Train Accuracy: 64.4836, Test Accuracy: 62.1212, Avg. duration: 0.0273 s\n",
      "Epoch: 2131, Train Loss: 0.2128, Test Loss: 0.3105, Train Accuracy: 64.4836, Test Accuracy: 62.1212, Avg. duration: 0.0286 s\n",
      "Epoch: 2132, Train Loss: 0.2128, Test Loss: 0.3105, Train Accuracy: 64.4836, Test Accuracy: 62.1212, Avg. duration: 0.0276 s\n",
      "Epoch: 2133, Train Loss: 0.2128, Test Loss: 0.3105, Train Accuracy: 64.4836, Test Accuracy: 62.1212, Avg. duration: 0.0270 s\n",
      "Epoch: 2134, Train Loss: 0.2128, Test Loss: 0.3105, Train Accuracy: 64.4836, Test Accuracy: 62.1212, Avg. duration: 0.0274 s\n",
      "Epoch: 2135, Train Loss: 0.2128, Test Loss: 0.3105, Train Accuracy: 64.4836, Test Accuracy: 62.1212, Avg. duration: 0.0271 s\n",
      "Epoch: 2136, Train Loss: 0.2128, Test Loss: 0.3105, Train Accuracy: 64.4836, Test Accuracy: 62.1212, Avg. duration: 0.0275 s\n",
      "Epoch: 2137, Train Loss: 0.2128, Test Loss: 0.3105, Train Accuracy: 64.4836, Test Accuracy: 62.1212, Avg. duration: 0.0278 s\n",
      "Epoch: 2138, Train Loss: 0.2128, Test Loss: 0.3105, Train Accuracy: 64.4836, Test Accuracy: 62.1212, Avg. duration: 0.0271 s\n",
      "Epoch: 2139, Train Loss: 0.2128, Test Loss: 0.3105, Train Accuracy: 64.4836, Test Accuracy: 62.1212, Avg. duration: 0.0276 s\n",
      "Epoch: 2140, Train Loss: 0.2128, Test Loss: 0.3105, Train Accuracy: 64.4836, Test Accuracy: 62.1212, Avg. duration: 0.0274 s\n",
      "Epoch: 2141, Train Loss: 0.2128, Test Loss: 0.3105, Train Accuracy: 64.4836, Test Accuracy: 62.1212, Avg. duration: 0.0274 s\n",
      "Epoch: 2142, Train Loss: 0.2128, Test Loss: 0.3105, Train Accuracy: 64.4836, Test Accuracy: 62.1212, Avg. duration: 0.0274 s\n",
      "Epoch: 2143, Train Loss: 0.2128, Test Loss: 0.3105, Train Accuracy: 64.4836, Test Accuracy: 62.1212, Avg. duration: 0.0278 s\n",
      "Epoch: 2144, Train Loss: 0.2128, Test Loss: 0.3105, Train Accuracy: 64.4836, Test Accuracy: 62.1212, Avg. duration: 0.0276 s\n",
      "Epoch: 2145, Train Loss: 0.2128, Test Loss: 0.3105, Train Accuracy: 64.4836, Test Accuracy: 62.1212, Avg. duration: 0.0271 s\n",
      "Epoch: 2146, Train Loss: 0.2128, Test Loss: 0.3105, Train Accuracy: 64.4836, Test Accuracy: 62.1212, Avg. duration: 0.0274 s\n",
      "Epoch: 2147, Train Loss: 0.2128, Test Loss: 0.3105, Train Accuracy: 64.4836, Test Accuracy: 62.1212, Avg. duration: 0.0278 s\n",
      "Epoch: 2148, Train Loss: 0.2128, Test Loss: 0.3105, Train Accuracy: 64.4836, Test Accuracy: 62.1212, Avg. duration: 0.0274 s\n",
      "Epoch: 2149, Train Loss: 0.2128, Test Loss: 0.3105, Train Accuracy: 64.4836, Test Accuracy: 62.1212, Avg. duration: 0.0277 s\n",
      "Epoch: 2150, Train Loss: 0.2128, Test Loss: 0.3105, Train Accuracy: 64.4836, Test Accuracy: 62.1212, Avg. duration: 0.0270 s\n",
      "Epoch: 2151, Train Loss: 0.2128, Test Loss: 0.3105, Train Accuracy: 64.4836, Test Accuracy: 62.1212, Avg. duration: 0.0273 s\n",
      "Epoch: 2152, Train Loss: 0.2128, Test Loss: 0.3105, Train Accuracy: 64.4836, Test Accuracy: 62.1212, Avg. duration: 0.0271 s\n",
      "Epoch: 2153, Train Loss: 0.2128, Test Loss: 0.3105, Train Accuracy: 64.4836, Test Accuracy: 62.1212, Avg. duration: 0.0278 s\n",
      "Epoch: 2154, Train Loss: 0.2128, Test Loss: 0.3105, Train Accuracy: 64.4836, Test Accuracy: 62.1212, Avg. duration: 0.0278 s\n",
      "Epoch: 2155, Train Loss: 0.2128, Test Loss: 0.3105, Train Accuracy: 64.4836, Test Accuracy: 62.1212, Avg. duration: 0.0285 s\n",
      "Epoch: 2156, Train Loss: 0.2128, Test Loss: 0.3105, Train Accuracy: 64.4836, Test Accuracy: 62.1212, Avg. duration: 0.0273 s\n",
      "Epoch: 2157, Train Loss: 0.2128, Test Loss: 0.3105, Train Accuracy: 64.4836, Test Accuracy: 62.1212, Avg. duration: 0.0273 s\n",
      "Epoch: 2158, Train Loss: 0.2128, Test Loss: 0.3105, Train Accuracy: 64.4836, Test Accuracy: 62.1212, Avg. duration: 0.0275 s\n",
      "Epoch: 2159, Train Loss: 0.2128, Test Loss: 0.3105, Train Accuracy: 64.4836, Test Accuracy: 62.1212, Avg. duration: 0.0278 s\n",
      "Epoch: 2160, Train Loss: 0.2128, Test Loss: 0.3105, Train Accuracy: 64.4836, Test Accuracy: 62.1212, Avg. duration: 0.0279 s\n",
      "Epoch: 2161, Train Loss: 0.2128, Test Loss: 0.3105, Train Accuracy: 64.4836, Test Accuracy: 62.1212, Avg. duration: 0.0277 s\n",
      "Epoch: 2162, Train Loss: 0.2128, Test Loss: 0.3105, Train Accuracy: 64.4836, Test Accuracy: 62.1212, Avg. duration: 0.0277 s\n",
      "Epoch: 2163, Train Loss: 0.2128, Test Loss: 0.3105, Train Accuracy: 64.4836, Test Accuracy: 62.1212, Avg. duration: 0.0278 s\n",
      "Epoch: 2164, Train Loss: 0.2128, Test Loss: 0.3105, Train Accuracy: 64.4836, Test Accuracy: 62.1212, Avg. duration: 0.0277 s\n",
      "Epoch: 2165, Train Loss: 0.2128, Test Loss: 0.3105, Train Accuracy: 64.4836, Test Accuracy: 62.1212, Avg. duration: 0.0279 s\n",
      "Epoch: 2166, Train Loss: 0.2128, Test Loss: 0.3105, Train Accuracy: 64.4836, Test Accuracy: 62.1212, Avg. duration: 0.0275 s\n",
      "Epoch: 2167, Train Loss: 0.2128, Test Loss: 0.3105, Train Accuracy: 64.4836, Test Accuracy: 62.1212, Avg. duration: 0.0280 s\n",
      "Epoch: 2168, Train Loss: 0.2128, Test Loss: 0.3105, Train Accuracy: 64.4836, Test Accuracy: 62.1212, Avg. duration: 0.0271 s\n",
      "Epoch: 2169, Train Loss: 0.2128, Test Loss: 0.3105, Train Accuracy: 64.4836, Test Accuracy: 62.1212, Avg. duration: 0.0275 s\n",
      "Epoch: 2170, Train Loss: 0.2128, Test Loss: 0.3105, Train Accuracy: 64.4836, Test Accuracy: 62.1212, Avg. duration: 0.0276 s\n",
      "Epoch: 2171, Train Loss: 0.2128, Test Loss: 0.3105, Train Accuracy: 64.4836, Test Accuracy: 62.1212, Avg. duration: 0.0281 s\n",
      "Epoch: 2172, Train Loss: 0.2128, Test Loss: 0.3105, Train Accuracy: 64.4836, Test Accuracy: 62.1212, Avg. duration: 0.0277 s\n",
      "Epoch: 2173, Train Loss: 0.2128, Test Loss: 0.3105, Train Accuracy: 64.4836, Test Accuracy: 62.1212, Avg. duration: 0.0276 s\n",
      "Epoch: 2174, Train Loss: 0.2128, Test Loss: 0.3105, Train Accuracy: 64.4836, Test Accuracy: 62.1212, Avg. duration: 0.0277 s\n",
      "Epoch: 2175, Train Loss: 0.2128, Test Loss: 0.3105, Train Accuracy: 64.4836, Test Accuracy: 62.1212, Avg. duration: 0.0275 s\n",
      "Epoch: 2176, Train Loss: 0.2128, Test Loss: 0.3105, Train Accuracy: 64.4836, Test Accuracy: 62.1212, Avg. duration: 0.0276 s\n",
      "Epoch: 2177, Train Loss: 0.2128, Test Loss: 0.3105, Train Accuracy: 64.4836, Test Accuracy: 62.1212, Avg. duration: 0.0277 s\n",
      "Epoch: 2178, Train Loss: 0.2128, Test Loss: 0.3105, Train Accuracy: 64.4836, Test Accuracy: 62.1212, Avg. duration: 0.0279 s\n",
      "Epoch: 2179, Train Loss: 0.2128, Test Loss: 0.3105, Train Accuracy: 64.4836, Test Accuracy: 62.1212, Avg. duration: 0.0281 s\n",
      "Epoch: 2180, Train Loss: 0.2128, Test Loss: 0.3105, Train Accuracy: 64.4836, Test Accuracy: 62.1212, Avg. duration: 0.0276 s\n",
      "Epoch: 2181, Train Loss: 0.2128, Test Loss: 0.3105, Train Accuracy: 64.4836, Test Accuracy: 62.1212, Avg. duration: 0.0275 s\n",
      "Epoch: 2182, Train Loss: 0.2128, Test Loss: 0.3105, Train Accuracy: 64.4836, Test Accuracy: 62.1212, Avg. duration: 0.0271 s\n",
      "Epoch: 2183, Train Loss: 0.2128, Test Loss: 0.3105, Train Accuracy: 64.4836, Test Accuracy: 62.1212, Avg. duration: 0.3253 s\n",
      "Epoch: 2184, Train Loss: 0.2128, Test Loss: 0.3105, Train Accuracy: 64.4836, Test Accuracy: 62.1212, Avg. duration: 0.0287 s\n",
      "Epoch: 2185, Train Loss: 0.2128, Test Loss: 0.3105, Train Accuracy: 64.4836, Test Accuracy: 62.1212, Avg. duration: 0.0284 s\n",
      "Epoch: 2186, Train Loss: 0.2128, Test Loss: 0.3105, Train Accuracy: 64.4836, Test Accuracy: 62.1212, Avg. duration: 0.0278 s\n",
      "Epoch: 2187, Train Loss: 0.2128, Test Loss: 0.3105, Train Accuracy: 64.4836, Test Accuracy: 62.1212, Avg. duration: 0.0276 s\n",
      "Epoch: 2188, Train Loss: 0.2128, Test Loss: 0.3105, Train Accuracy: 64.4836, Test Accuracy: 62.1212, Avg. duration: 0.0278 s\n",
      "Epoch: 2189, Train Loss: 0.2128, Test Loss: 0.3105, Train Accuracy: 64.4836, Test Accuracy: 62.1212, Avg. duration: 0.0278 s\n",
      "Epoch: 2190, Train Loss: 0.2128, Test Loss: 0.3105, Train Accuracy: 64.4836, Test Accuracy: 62.1212, Avg. duration: 0.0282 s\n",
      "Epoch: 2191, Train Loss: 0.2128, Test Loss: 0.3105, Train Accuracy: 64.4836, Test Accuracy: 62.1212, Avg. duration: 0.0286 s\n",
      "Epoch: 2192, Train Loss: 0.2128, Test Loss: 0.3105, Train Accuracy: 64.4836, Test Accuracy: 62.1212, Avg. duration: 0.0281 s\n",
      "Epoch: 2193, Train Loss: 0.2128, Test Loss: 0.3105, Train Accuracy: 64.4836, Test Accuracy: 62.1212, Avg. duration: 0.0277 s\n",
      "Epoch: 2194, Train Loss: 0.2128, Test Loss: 0.3105, Train Accuracy: 64.4836, Test Accuracy: 62.1212, Avg. duration: 0.0279 s\n",
      "Epoch: 2195, Train Loss: 0.2128, Test Loss: 0.3105, Train Accuracy: 64.4836, Test Accuracy: 62.1212, Avg. duration: 0.0277 s\n",
      "Epoch: 2196, Train Loss: 0.2128, Test Loss: 0.3105, Train Accuracy: 64.4836, Test Accuracy: 62.1212, Avg. duration: 0.0279 s\n",
      "Epoch: 2197, Train Loss: 0.2128, Test Loss: 0.3105, Train Accuracy: 64.4836, Test Accuracy: 62.1212, Avg. duration: 0.0280 s\n",
      "Epoch: 2198, Train Loss: 0.2128, Test Loss: 0.3105, Train Accuracy: 64.4836, Test Accuracy: 62.1212, Avg. duration: 0.0276 s\n",
      "Epoch: 2199, Train Loss: 0.2128, Test Loss: 0.3105, Train Accuracy: 64.4836, Test Accuracy: 62.1212, Avg. duration: 0.0282 s\n",
      "Epoch: 2200, Train Loss: 0.2128, Test Loss: 0.3105, Train Accuracy: 64.4836, Test Accuracy: 62.1212, Avg. duration: 0.0278 s\n",
      "Epoch: 2201, Train Loss: 0.2104, Test Loss: 0.3140, Train Accuracy: 64.6096, Test Accuracy: 62.1212, Avg. duration: 2.7294 s\n",
      "Epoch: 2202, Train Loss: 0.2104, Test Loss: 0.3140, Train Accuracy: 64.6096, Test Accuracy: 62.1212, Avg. duration: 0.0282 s\n",
      "Epoch: 2203, Train Loss: 0.2104, Test Loss: 0.3140, Train Accuracy: 64.6096, Test Accuracy: 62.1212, Avg. duration: 0.0275 s\n",
      "Epoch: 2204, Train Loss: 0.2104, Test Loss: 0.3140, Train Accuracy: 64.6096, Test Accuracy: 62.1212, Avg. duration: 0.0271 s\n",
      "Epoch: 2205, Train Loss: 0.2104, Test Loss: 0.3140, Train Accuracy: 64.6096, Test Accuracy: 62.1212, Avg. duration: 0.0268 s\n",
      "Epoch: 2206, Train Loss: 0.2104, Test Loss: 0.3140, Train Accuracy: 64.6096, Test Accuracy: 62.1212, Avg. duration: 0.0272 s\n",
      "Epoch: 2207, Train Loss: 0.2104, Test Loss: 0.3140, Train Accuracy: 64.6096, Test Accuracy: 62.1212, Avg. duration: 0.0274 s\n",
      "Epoch: 2208, Train Loss: 0.2104, Test Loss: 0.3140, Train Accuracy: 64.6096, Test Accuracy: 62.1212, Avg. duration: 0.0273 s\n",
      "Epoch: 2209, Train Loss: 0.2104, Test Loss: 0.3140, Train Accuracy: 64.6096, Test Accuracy: 62.1212, Avg. duration: 0.0283 s\n",
      "Epoch: 2210, Train Loss: 0.2104, Test Loss: 0.3140, Train Accuracy: 64.6096, Test Accuracy: 62.1212, Avg. duration: 0.0272 s\n",
      "Epoch: 2211, Train Loss: 0.2104, Test Loss: 0.3140, Train Accuracy: 64.6096, Test Accuracy: 62.1212, Avg. duration: 0.0272 s\n",
      "Epoch: 2212, Train Loss: 0.2104, Test Loss: 0.3140, Train Accuracy: 64.6096, Test Accuracy: 62.1212, Avg. duration: 0.0270 s\n",
      "Epoch: 2213, Train Loss: 0.2104, Test Loss: 0.3140, Train Accuracy: 64.6096, Test Accuracy: 62.1212, Avg. duration: 0.0274 s\n",
      "Epoch: 2214, Train Loss: 0.2104, Test Loss: 0.3140, Train Accuracy: 64.6096, Test Accuracy: 62.1212, Avg. duration: 0.0276 s\n",
      "Epoch: 2215, Train Loss: 0.2104, Test Loss: 0.3140, Train Accuracy: 64.6096, Test Accuracy: 62.1212, Avg. duration: 0.0279 s\n",
      "Epoch: 2216, Train Loss: 0.2104, Test Loss: 0.3140, Train Accuracy: 64.6096, Test Accuracy: 62.1212, Avg. duration: 0.0268 s\n",
      "Epoch: 2217, Train Loss: 0.2104, Test Loss: 0.3140, Train Accuracy: 64.6096, Test Accuracy: 62.1212, Avg. duration: 0.0277 s\n",
      "Epoch: 2218, Train Loss: 0.2104, Test Loss: 0.3140, Train Accuracy: 64.6096, Test Accuracy: 62.1212, Avg. duration: 0.0269 s\n",
      "Epoch: 2219, Train Loss: 0.2104, Test Loss: 0.3140, Train Accuracy: 64.6096, Test Accuracy: 62.1212, Avg. duration: 0.0276 s\n",
      "Epoch: 2220, Train Loss: 0.2104, Test Loss: 0.3140, Train Accuracy: 64.6096, Test Accuracy: 62.1212, Avg. duration: 0.0271 s\n",
      "Epoch: 2221, Train Loss: 0.2104, Test Loss: 0.3140, Train Accuracy: 64.6096, Test Accuracy: 62.1212, Avg. duration: 0.0273 s\n",
      "Epoch: 2222, Train Loss: 0.2104, Test Loss: 0.3140, Train Accuracy: 64.6096, Test Accuracy: 62.1212, Avg. duration: 0.0267 s\n",
      "Epoch: 2223, Train Loss: 0.2104, Test Loss: 0.3140, Train Accuracy: 64.6096, Test Accuracy: 62.1212, Avg. duration: 0.0269 s\n",
      "Epoch: 2224, Train Loss: 0.2104, Test Loss: 0.3140, Train Accuracy: 64.6096, Test Accuracy: 62.1212, Avg. duration: 0.0272 s\n",
      "Epoch: 2225, Train Loss: 0.2104, Test Loss: 0.3140, Train Accuracy: 64.6096, Test Accuracy: 62.1212, Avg. duration: 0.0280 s\n",
      "Epoch: 2226, Train Loss: 0.2104, Test Loss: 0.3140, Train Accuracy: 64.6096, Test Accuracy: 62.1212, Avg. duration: 0.0276 s\n",
      "Epoch: 2227, Train Loss: 0.2104, Test Loss: 0.3140, Train Accuracy: 64.6096, Test Accuracy: 62.1212, Avg. duration: 0.0275 s\n",
      "Epoch: 2228, Train Loss: 0.2104, Test Loss: 0.3140, Train Accuracy: 64.6096, Test Accuracy: 62.1212, Avg. duration: 0.0272 s\n",
      "Epoch: 2229, Train Loss: 0.2104, Test Loss: 0.3140, Train Accuracy: 64.6096, Test Accuracy: 62.1212, Avg. duration: 0.0274 s\n",
      "Epoch: 2230, Train Loss: 0.2104, Test Loss: 0.3140, Train Accuracy: 64.6096, Test Accuracy: 62.1212, Avg. duration: 0.0271 s\n",
      "Epoch: 2231, Train Loss: 0.2104, Test Loss: 0.3140, Train Accuracy: 64.6096, Test Accuracy: 62.1212, Avg. duration: 0.0274 s\n",
      "Epoch: 2232, Train Loss: 0.2104, Test Loss: 0.3140, Train Accuracy: 64.6096, Test Accuracy: 62.1212, Avg. duration: 0.0276 s\n",
      "Epoch: 2233, Train Loss: 0.2104, Test Loss: 0.3140, Train Accuracy: 64.6096, Test Accuracy: 62.1212, Avg. duration: 0.0280 s\n",
      "Epoch: 2234, Train Loss: 0.2104, Test Loss: 0.3140, Train Accuracy: 64.6096, Test Accuracy: 62.1212, Avg. duration: 0.0268 s\n",
      "Epoch: 2235, Train Loss: 0.2104, Test Loss: 0.3140, Train Accuracy: 64.6096, Test Accuracy: 62.1212, Avg. duration: 0.0268 s\n",
      "Epoch: 2236, Train Loss: 0.2104, Test Loss: 0.3140, Train Accuracy: 64.6096, Test Accuracy: 62.1212, Avg. duration: 0.0272 s\n",
      "Epoch: 2237, Train Loss: 0.2104, Test Loss: 0.3140, Train Accuracy: 64.6096, Test Accuracy: 62.1212, Avg. duration: 0.0276 s\n",
      "Epoch: 2238, Train Loss: 0.2104, Test Loss: 0.3140, Train Accuracy: 64.6096, Test Accuracy: 62.1212, Avg. duration: 0.0272 s\n",
      "Epoch: 2239, Train Loss: 0.2104, Test Loss: 0.3140, Train Accuracy: 64.6096, Test Accuracy: 62.1212, Avg. duration: 0.0275 s\n",
      "Epoch: 2240, Train Loss: 0.2104, Test Loss: 0.3140, Train Accuracy: 64.6096, Test Accuracy: 62.1212, Avg. duration: 0.0271 s\n",
      "Epoch: 2241, Train Loss: 0.2104, Test Loss: 0.3140, Train Accuracy: 64.6096, Test Accuracy: 62.1212, Avg. duration: 0.0276 s\n",
      "Epoch: 2242, Train Loss: 0.2104, Test Loss: 0.3140, Train Accuracy: 64.6096, Test Accuracy: 62.1212, Avg. duration: 0.0275 s\n",
      "Epoch: 2243, Train Loss: 0.2104, Test Loss: 0.3140, Train Accuracy: 64.6096, Test Accuracy: 62.1212, Avg. duration: 0.0271 s\n",
      "Epoch: 2244, Train Loss: 0.2104, Test Loss: 0.3140, Train Accuracy: 64.6096, Test Accuracy: 62.1212, Avg. duration: 0.0276 s\n",
      "Epoch: 2245, Train Loss: 0.2104, Test Loss: 0.3140, Train Accuracy: 64.6096, Test Accuracy: 62.1212, Avg. duration: 0.0276 s\n",
      "Epoch: 2246, Train Loss: 0.2104, Test Loss: 0.3140, Train Accuracy: 64.6096, Test Accuracy: 62.1212, Avg. duration: 0.0271 s\n",
      "Epoch: 2247, Train Loss: 0.2104, Test Loss: 0.3140, Train Accuracy: 64.6096, Test Accuracy: 62.1212, Avg. duration: 0.0273 s\n",
      "Epoch: 2248, Train Loss: 0.2104, Test Loss: 0.3140, Train Accuracy: 64.6096, Test Accuracy: 62.1212, Avg. duration: 0.0272 s\n",
      "Epoch: 2249, Train Loss: 0.2104, Test Loss: 0.3140, Train Accuracy: 64.6096, Test Accuracy: 62.1212, Avg. duration: 0.0277 s\n",
      "Epoch: 2250, Train Loss: 0.2104, Test Loss: 0.3140, Train Accuracy: 64.6096, Test Accuracy: 62.1212, Avg. duration: 0.3181 s\n",
      "Epoch: 2251, Train Loss: 0.2104, Test Loss: 0.3140, Train Accuracy: 64.6096, Test Accuracy: 62.1212, Avg. duration: 0.0285 s\n",
      "Epoch: 2252, Train Loss: 0.2104, Test Loss: 0.3140, Train Accuracy: 64.6096, Test Accuracy: 62.1212, Avg. duration: 0.0278 s\n",
      "Epoch: 2253, Train Loss: 0.2104, Test Loss: 0.3140, Train Accuracy: 64.6096, Test Accuracy: 62.1212, Avg. duration: 0.0276 s\n",
      "Epoch: 2254, Train Loss: 0.2104, Test Loss: 0.3140, Train Accuracy: 64.6096, Test Accuracy: 62.1212, Avg. duration: 0.0279 s\n",
      "Epoch: 2255, Train Loss: 0.2104, Test Loss: 0.3140, Train Accuracy: 64.6096, Test Accuracy: 62.1212, Avg. duration: 0.0278 s\n",
      "Epoch: 2256, Train Loss: 0.2104, Test Loss: 0.3140, Train Accuracy: 64.6096, Test Accuracy: 62.1212, Avg. duration: 0.0278 s\n",
      "Epoch: 2257, Train Loss: 0.2104, Test Loss: 0.3140, Train Accuracy: 64.6096, Test Accuracy: 62.1212, Avg. duration: 0.0276 s\n",
      "Epoch: 2258, Train Loss: 0.2104, Test Loss: 0.3140, Train Accuracy: 64.6096, Test Accuracy: 62.1212, Avg. duration: 0.0278 s\n",
      "Epoch: 2259, Train Loss: 0.2104, Test Loss: 0.3140, Train Accuracy: 64.6096, Test Accuracy: 62.1212, Avg. duration: 0.0274 s\n",
      "Epoch: 2260, Train Loss: 0.2104, Test Loss: 0.3140, Train Accuracy: 64.6096, Test Accuracy: 62.1212, Avg. duration: 0.0279 s\n",
      "Epoch: 2261, Train Loss: 0.2104, Test Loss: 0.3140, Train Accuracy: 64.6096, Test Accuracy: 62.1212, Avg. duration: 0.0279 s\n",
      "Epoch: 2262, Train Loss: 0.2104, Test Loss: 0.3140, Train Accuracy: 64.6096, Test Accuracy: 62.1212, Avg. duration: 0.0279 s\n",
      "Epoch: 2263, Train Loss: 0.2104, Test Loss: 0.3140, Train Accuracy: 64.6096, Test Accuracy: 62.1212, Avg. duration: 0.0275 s\n",
      "Epoch: 2264, Train Loss: 0.2104, Test Loss: 0.3140, Train Accuracy: 64.6096, Test Accuracy: 62.1212, Avg. duration: 0.0272 s\n",
      "Epoch: 2265, Train Loss: 0.2104, Test Loss: 0.3140, Train Accuracy: 64.6096, Test Accuracy: 62.1212, Avg. duration: 0.0275 s\n",
      "Epoch: 2266, Train Loss: 0.2104, Test Loss: 0.3140, Train Accuracy: 64.6096, Test Accuracy: 62.1212, Avg. duration: 0.0282 s\n",
      "Epoch: 2267, Train Loss: 0.2104, Test Loss: 0.3140, Train Accuracy: 64.6096, Test Accuracy: 62.1212, Avg. duration: 0.0280 s\n",
      "Epoch: 2268, Train Loss: 0.2104, Test Loss: 0.3140, Train Accuracy: 64.6096, Test Accuracy: 62.1212, Avg. duration: 0.0278 s\n",
      "Epoch: 2269, Train Loss: 0.2104, Test Loss: 0.3140, Train Accuracy: 64.6096, Test Accuracy: 62.1212, Avg. duration: 0.0275 s\n",
      "Epoch: 2270, Train Loss: 0.2104, Test Loss: 0.3140, Train Accuracy: 64.6096, Test Accuracy: 62.1212, Avg. duration: 0.0271 s\n",
      "Epoch: 2271, Train Loss: 0.2104, Test Loss: 0.3140, Train Accuracy: 64.6096, Test Accuracy: 62.1212, Avg. duration: 0.0271 s\n",
      "Epoch: 2272, Train Loss: 0.2104, Test Loss: 0.3140, Train Accuracy: 64.6096, Test Accuracy: 62.1212, Avg. duration: 0.0278 s\n",
      "Epoch: 2273, Train Loss: 0.2104, Test Loss: 0.3140, Train Accuracy: 64.6096, Test Accuracy: 62.1212, Avg. duration: 0.0276 s\n",
      "Epoch: 2274, Train Loss: 0.2104, Test Loss: 0.3140, Train Accuracy: 64.6096, Test Accuracy: 62.1212, Avg. duration: 0.0281 s\n",
      "Epoch: 2275, Train Loss: 0.2104, Test Loss: 0.3140, Train Accuracy: 64.6096, Test Accuracy: 62.1212, Avg. duration: 0.0279 s\n",
      "Epoch: 2276, Train Loss: 0.2104, Test Loss: 0.3140, Train Accuracy: 64.6096, Test Accuracy: 62.1212, Avg. duration: 0.0275 s\n",
      "Epoch: 2277, Train Loss: 0.2104, Test Loss: 0.3140, Train Accuracy: 64.6096, Test Accuracy: 62.1212, Avg. duration: 0.0280 s\n",
      "Epoch: 2278, Train Loss: 0.2104, Test Loss: 0.3140, Train Accuracy: 64.6096, Test Accuracy: 62.1212, Avg. duration: 0.0279 s\n",
      "Epoch: 2279, Train Loss: 0.2104, Test Loss: 0.3140, Train Accuracy: 64.6096, Test Accuracy: 62.1212, Avg. duration: 0.0279 s\n",
      "Epoch: 2280, Train Loss: 0.2104, Test Loss: 0.3140, Train Accuracy: 64.6096, Test Accuracy: 62.1212, Avg. duration: 0.0278 s\n",
      "Epoch: 2281, Train Loss: 0.2104, Test Loss: 0.3140, Train Accuracy: 64.6096, Test Accuracy: 62.1212, Avg. duration: 0.0274 s\n",
      "Epoch: 2282, Train Loss: 0.2104, Test Loss: 0.3140, Train Accuracy: 64.6096, Test Accuracy: 62.1212, Avg. duration: 0.0278 s\n",
      "Epoch: 2283, Train Loss: 0.2104, Test Loss: 0.3140, Train Accuracy: 64.6096, Test Accuracy: 62.1212, Avg. duration: 0.0278 s\n",
      "Epoch: 2284, Train Loss: 0.2104, Test Loss: 0.3140, Train Accuracy: 64.6096, Test Accuracy: 62.1212, Avg. duration: 0.0275 s\n",
      "Epoch: 2285, Train Loss: 0.2104, Test Loss: 0.3140, Train Accuracy: 64.6096, Test Accuracy: 62.1212, Avg. duration: 0.0279 s\n",
      "Epoch: 2286, Train Loss: 0.2104, Test Loss: 0.3140, Train Accuracy: 64.6096, Test Accuracy: 62.1212, Avg. duration: 0.0280 s\n",
      "Epoch: 2287, Train Loss: 0.2104, Test Loss: 0.3140, Train Accuracy: 64.6096, Test Accuracy: 62.1212, Avg. duration: 0.0278 s\n",
      "Epoch: 2288, Train Loss: 0.2104, Test Loss: 0.3140, Train Accuracy: 64.6096, Test Accuracy: 62.1212, Avg. duration: 0.0277 s\n",
      "Epoch: 2289, Train Loss: 0.2104, Test Loss: 0.3140, Train Accuracy: 64.6096, Test Accuracy: 62.1212, Avg. duration: 0.0276 s\n",
      "Epoch: 2290, Train Loss: 0.2104, Test Loss: 0.3140, Train Accuracy: 64.6096, Test Accuracy: 62.1212, Avg. duration: 0.0280 s\n",
      "Epoch: 2291, Train Loss: 0.2104, Test Loss: 0.3140, Train Accuracy: 64.6096, Test Accuracy: 62.1212, Avg. duration: 0.0279 s\n",
      "Epoch: 2292, Train Loss: 0.2104, Test Loss: 0.3140, Train Accuracy: 64.6096, Test Accuracy: 62.1212, Avg. duration: 0.0279 s\n",
      "Epoch: 2293, Train Loss: 0.2104, Test Loss: 0.3140, Train Accuracy: 64.6096, Test Accuracy: 62.1212, Avg. duration: 0.0275 s\n",
      "Epoch: 2294, Train Loss: 0.2104, Test Loss: 0.3140, Train Accuracy: 64.6096, Test Accuracy: 62.1212, Avg. duration: 0.0275 s\n",
      "Epoch: 2295, Train Loss: 0.2104, Test Loss: 0.3140, Train Accuracy: 64.6096, Test Accuracy: 62.1212, Avg. duration: 0.0276 s\n",
      "Epoch: 2296, Train Loss: 0.2104, Test Loss: 0.3140, Train Accuracy: 64.6096, Test Accuracy: 62.1212, Avg. duration: 0.0279 s\n",
      "Epoch: 2297, Train Loss: 0.2104, Test Loss: 0.3140, Train Accuracy: 64.6096, Test Accuracy: 62.1212, Avg. duration: 0.0277 s\n",
      "Epoch: 2298, Train Loss: 0.2104, Test Loss: 0.3140, Train Accuracy: 64.6096, Test Accuracy: 62.1212, Avg. duration: 0.0289 s\n",
      "Epoch: 2299, Train Loss: 0.2104, Test Loss: 0.3140, Train Accuracy: 64.6096, Test Accuracy: 62.1212, Avg. duration: 0.0275 s\n",
      "Epoch: 2300, Train Loss: 0.2104, Test Loss: 0.3140, Train Accuracy: 64.6096, Test Accuracy: 62.1212, Avg. duration: 0.0279 s\n",
      "Epoch: 2301, Train Loss: 0.2085, Test Loss: 0.3166, Train Accuracy: 64.4836, Test Accuracy: 63.1313, Avg. duration: 2.7290 s\n",
      "Epoch: 2302, Train Loss: 0.2085, Test Loss: 0.3166, Train Accuracy: 64.4836, Test Accuracy: 63.1313, Avg. duration: 0.0284 s\n",
      "Epoch: 2303, Train Loss: 0.2085, Test Loss: 0.3166, Train Accuracy: 64.4836, Test Accuracy: 63.1313, Avg. duration: 0.0277 s\n",
      "Epoch: 2304, Train Loss: 0.2085, Test Loss: 0.3166, Train Accuracy: 64.4836, Test Accuracy: 63.1313, Avg. duration: 0.0277 s\n",
      "Epoch: 2305, Train Loss: 0.2085, Test Loss: 0.3166, Train Accuracy: 64.4836, Test Accuracy: 63.1313, Avg. duration: 0.0268 s\n",
      "Epoch: 2306, Train Loss: 0.2085, Test Loss: 0.3166, Train Accuracy: 64.4836, Test Accuracy: 63.1313, Avg. duration: 0.0271 s\n",
      "Epoch: 2307, Train Loss: 0.2085, Test Loss: 0.3166, Train Accuracy: 64.4836, Test Accuracy: 63.1313, Avg. duration: 0.0273 s\n",
      "Epoch: 2308, Train Loss: 0.2085, Test Loss: 0.3166, Train Accuracy: 64.4836, Test Accuracy: 63.1313, Avg. duration: 0.0276 s\n",
      "Epoch: 2309, Train Loss: 0.2085, Test Loss: 0.3166, Train Accuracy: 64.4836, Test Accuracy: 63.1313, Avg. duration: 0.0277 s\n",
      "Epoch: 2310, Train Loss: 0.2085, Test Loss: 0.3166, Train Accuracy: 64.4836, Test Accuracy: 63.1313, Avg. duration: 0.0274 s\n",
      "Epoch: 2311, Train Loss: 0.2085, Test Loss: 0.3166, Train Accuracy: 64.4836, Test Accuracy: 63.1313, Avg. duration: 0.0272 s\n",
      "Epoch: 2312, Train Loss: 0.2085, Test Loss: 0.3166, Train Accuracy: 64.4836, Test Accuracy: 63.1313, Avg. duration: 0.0268 s\n",
      "Epoch: 2313, Train Loss: 0.2085, Test Loss: 0.3166, Train Accuracy: 64.4836, Test Accuracy: 63.1313, Avg. duration: 0.0269 s\n",
      "Epoch: 2314, Train Loss: 0.2085, Test Loss: 0.3166, Train Accuracy: 64.4836, Test Accuracy: 63.1313, Avg. duration: 0.0274 s\n",
      "Epoch: 2315, Train Loss: 0.2085, Test Loss: 0.3166, Train Accuracy: 64.4836, Test Accuracy: 63.1313, Avg. duration: 0.0271 s\n",
      "Epoch: 2316, Train Loss: 0.2085, Test Loss: 0.3166, Train Accuracy: 64.4836, Test Accuracy: 63.1313, Avg. duration: 0.0277 s\n",
      "Epoch: 2317, Train Loss: 0.2085, Test Loss: 0.3166, Train Accuracy: 64.4836, Test Accuracy: 63.1313, Avg. duration: 0.0271 s\n",
      "Epoch: 2318, Train Loss: 0.2085, Test Loss: 0.3166, Train Accuracy: 64.4836, Test Accuracy: 63.1313, Avg. duration: 0.0272 s\n",
      "Epoch: 2319, Train Loss: 0.2085, Test Loss: 0.3166, Train Accuracy: 64.4836, Test Accuracy: 63.1313, Avg. duration: 0.0269 s\n",
      "Epoch: 2320, Train Loss: 0.2085, Test Loss: 0.3166, Train Accuracy: 64.4836, Test Accuracy: 63.1313, Avg. duration: 0.0275 s\n",
      "Epoch: 2321, Train Loss: 0.2085, Test Loss: 0.3166, Train Accuracy: 64.4836, Test Accuracy: 63.1313, Avg. duration: 0.0274 s\n",
      "Epoch: 2322, Train Loss: 0.2085, Test Loss: 0.3166, Train Accuracy: 64.4836, Test Accuracy: 63.1313, Avg. duration: 0.0273 s\n",
      "Epoch: 2323, Train Loss: 0.2085, Test Loss: 0.3166, Train Accuracy: 64.4836, Test Accuracy: 63.1313, Avg. duration: 0.0271 s\n",
      "Epoch: 2324, Train Loss: 0.2085, Test Loss: 0.3166, Train Accuracy: 64.4836, Test Accuracy: 63.1313, Avg. duration: 0.0270 s\n",
      "Epoch: 2325, Train Loss: 0.2085, Test Loss: 0.3166, Train Accuracy: 64.4836, Test Accuracy: 63.1313, Avg. duration: 0.0279 s\n",
      "Epoch: 2326, Train Loss: 0.2085, Test Loss: 0.3166, Train Accuracy: 64.4836, Test Accuracy: 63.1313, Avg. duration: 0.3230 s\n",
      "Epoch: 2327, Train Loss: 0.2085, Test Loss: 0.3166, Train Accuracy: 64.4836, Test Accuracy: 63.1313, Avg. duration: 0.0282 s\n",
      "Epoch: 2328, Train Loss: 0.2085, Test Loss: 0.3166, Train Accuracy: 64.4836, Test Accuracy: 63.1313, Avg. duration: 0.0280 s\n",
      "Epoch: 2329, Train Loss: 0.2085, Test Loss: 0.3166, Train Accuracy: 64.4836, Test Accuracy: 63.1313, Avg. duration: 0.0272 s\n",
      "Epoch: 2330, Train Loss: 0.2085, Test Loss: 0.3166, Train Accuracy: 64.4836, Test Accuracy: 63.1313, Avg. duration: 0.0271 s\n",
      "Epoch: 2331, Train Loss: 0.2085, Test Loss: 0.3166, Train Accuracy: 64.4836, Test Accuracy: 63.1313, Avg. duration: 0.0273 s\n",
      "Epoch: 2332, Train Loss: 0.2085, Test Loss: 0.3166, Train Accuracy: 64.4836, Test Accuracy: 63.1313, Avg. duration: 0.0271 s\n",
      "Epoch: 2333, Train Loss: 0.2085, Test Loss: 0.3166, Train Accuracy: 64.4836, Test Accuracy: 63.1313, Avg. duration: 0.0277 s\n",
      "Epoch: 2334, Train Loss: 0.2085, Test Loss: 0.3166, Train Accuracy: 64.4836, Test Accuracy: 63.1313, Avg. duration: 0.0278 s\n",
      "Epoch: 2335, Train Loss: 0.2085, Test Loss: 0.3166, Train Accuracy: 64.4836, Test Accuracy: 63.1313, Avg. duration: 0.0275 s\n",
      "Epoch: 2336, Train Loss: 0.2085, Test Loss: 0.3166, Train Accuracy: 64.4836, Test Accuracy: 63.1313, Avg. duration: 0.0274 s\n",
      "Epoch: 2337, Train Loss: 0.2085, Test Loss: 0.3166, Train Accuracy: 64.4836, Test Accuracy: 63.1313, Avg. duration: 0.0272 s\n",
      "Epoch: 2338, Train Loss: 0.2085, Test Loss: 0.3166, Train Accuracy: 64.4836, Test Accuracy: 63.1313, Avg. duration: 0.0274 s\n",
      "Epoch: 2339, Train Loss: 0.2085, Test Loss: 0.3166, Train Accuracy: 64.4836, Test Accuracy: 63.1313, Avg. duration: 0.0276 s\n",
      "Epoch: 2340, Train Loss: 0.2085, Test Loss: 0.3166, Train Accuracy: 64.4836, Test Accuracy: 63.1313, Avg. duration: 0.0273 s\n",
      "Epoch: 2341, Train Loss: 0.2085, Test Loss: 0.3166, Train Accuracy: 64.4836, Test Accuracy: 63.1313, Avg. duration: 0.0271 s\n",
      "Epoch: 2342, Train Loss: 0.2085, Test Loss: 0.3166, Train Accuracy: 64.4836, Test Accuracy: 63.1313, Avg. duration: 0.0282 s\n",
      "Epoch: 2343, Train Loss: 0.2085, Test Loss: 0.3166, Train Accuracy: 64.4836, Test Accuracy: 63.1313, Avg. duration: 0.0277 s\n",
      "Epoch: 2344, Train Loss: 0.2085, Test Loss: 0.3166, Train Accuracy: 64.4836, Test Accuracy: 63.1313, Avg. duration: 0.0278 s\n",
      "Epoch: 2345, Train Loss: 0.2085, Test Loss: 0.3166, Train Accuracy: 64.4836, Test Accuracy: 63.1313, Avg. duration: 0.0278 s\n",
      "Epoch: 2346, Train Loss: 0.2085, Test Loss: 0.3166, Train Accuracy: 64.4836, Test Accuracy: 63.1313, Avg. duration: 0.0277 s\n",
      "Epoch: 2347, Train Loss: 0.2085, Test Loss: 0.3166, Train Accuracy: 64.4836, Test Accuracy: 63.1313, Avg. duration: 0.0273 s\n",
      "Epoch: 2348, Train Loss: 0.2085, Test Loss: 0.3166, Train Accuracy: 64.4836, Test Accuracy: 63.1313, Avg. duration: 0.0273 s\n",
      "Epoch: 2349, Train Loss: 0.2085, Test Loss: 0.3166, Train Accuracy: 64.4836, Test Accuracy: 63.1313, Avg. duration: 0.0276 s\n",
      "Epoch: 2350, Train Loss: 0.2085, Test Loss: 0.3166, Train Accuracy: 64.4836, Test Accuracy: 63.1313, Avg. duration: 0.0280 s\n",
      "Epoch: 2351, Train Loss: 0.2085, Test Loss: 0.3166, Train Accuracy: 64.4836, Test Accuracy: 63.1313, Avg. duration: 0.0279 s\n",
      "Epoch: 2352, Train Loss: 0.2085, Test Loss: 0.3166, Train Accuracy: 64.4836, Test Accuracy: 63.1313, Avg. duration: 0.0281 s\n",
      "Epoch: 2353, Train Loss: 0.2085, Test Loss: 0.3166, Train Accuracy: 64.4836, Test Accuracy: 63.1313, Avg. duration: 0.0274 s\n",
      "Epoch: 2354, Train Loss: 0.2085, Test Loss: 0.3166, Train Accuracy: 64.4836, Test Accuracy: 63.1313, Avg. duration: 0.0276 s\n",
      "Epoch: 2355, Train Loss: 0.2085, Test Loss: 0.3166, Train Accuracy: 64.4836, Test Accuracy: 63.1313, Avg. duration: 0.0273 s\n",
      "Epoch: 2356, Train Loss: 0.2085, Test Loss: 0.3166, Train Accuracy: 64.4836, Test Accuracy: 63.1313, Avg. duration: 0.0277 s\n",
      "Epoch: 2357, Train Loss: 0.2085, Test Loss: 0.3166, Train Accuracy: 64.4836, Test Accuracy: 63.1313, Avg. duration: 0.0278 s\n",
      "Epoch: 2358, Train Loss: 0.2085, Test Loss: 0.3166, Train Accuracy: 64.4836, Test Accuracy: 63.1313, Avg. duration: 0.0277 s\n",
      "Epoch: 2359, Train Loss: 0.2085, Test Loss: 0.3166, Train Accuracy: 64.4836, Test Accuracy: 63.1313, Avg. duration: 0.0277 s\n",
      "Epoch: 2360, Train Loss: 0.2085, Test Loss: 0.3166, Train Accuracy: 64.4836, Test Accuracy: 63.1313, Avg. duration: 0.0277 s\n",
      "Epoch: 2361, Train Loss: 0.2085, Test Loss: 0.3166, Train Accuracy: 64.4836, Test Accuracy: 63.1313, Avg. duration: 0.0278 s\n",
      "Epoch: 2362, Train Loss: 0.2085, Test Loss: 0.3166, Train Accuracy: 64.4836, Test Accuracy: 63.1313, Avg. duration: 0.0278 s\n",
      "Epoch: 2363, Train Loss: 0.2085, Test Loss: 0.3166, Train Accuracy: 64.4836, Test Accuracy: 63.1313, Avg. duration: 0.0277 s\n",
      "Epoch: 2364, Train Loss: 0.2085, Test Loss: 0.3166, Train Accuracy: 64.4836, Test Accuracy: 63.1313, Avg. duration: 0.0277 s\n",
      "Epoch: 2365, Train Loss: 0.2085, Test Loss: 0.3166, Train Accuracy: 64.4836, Test Accuracy: 63.1313, Avg. duration: 0.0275 s\n",
      "Epoch: 2366, Train Loss: 0.2085, Test Loss: 0.3166, Train Accuracy: 64.4836, Test Accuracy: 63.1313, Avg. duration: 0.0281 s\n",
      "Epoch: 2367, Train Loss: 0.2085, Test Loss: 0.3166, Train Accuracy: 64.4836, Test Accuracy: 63.1313, Avg. duration: 0.0278 s\n",
      "Epoch: 2368, Train Loss: 0.2085, Test Loss: 0.3166, Train Accuracy: 64.4836, Test Accuracy: 63.1313, Avg. duration: 0.0276 s\n",
      "Epoch: 2369, Train Loss: 0.2085, Test Loss: 0.3166, Train Accuracy: 64.4836, Test Accuracy: 63.1313, Avg. duration: 0.0277 s\n",
      "Epoch: 2370, Train Loss: 0.2085, Test Loss: 0.3166, Train Accuracy: 64.4836, Test Accuracy: 63.1313, Avg. duration: 0.0278 s\n",
      "Epoch: 2371, Train Loss: 0.2085, Test Loss: 0.3166, Train Accuracy: 64.4836, Test Accuracy: 63.1313, Avg. duration: 0.0277 s\n",
      "Epoch: 2372, Train Loss: 0.2085, Test Loss: 0.3166, Train Accuracy: 64.4836, Test Accuracy: 63.1313, Avg. duration: 0.0276 s\n",
      "Epoch: 2373, Train Loss: 0.2085, Test Loss: 0.3166, Train Accuracy: 64.4836, Test Accuracy: 63.1313, Avg. duration: 0.0278 s\n",
      "Epoch: 2374, Train Loss: 0.2085, Test Loss: 0.3166, Train Accuracy: 64.4836, Test Accuracy: 63.1313, Avg. duration: 0.0284 s\n",
      "Epoch: 2375, Train Loss: 0.2085, Test Loss: 0.3166, Train Accuracy: 64.4836, Test Accuracy: 63.1313, Avg. duration: 0.0280 s\n",
      "Epoch: 2376, Train Loss: 0.2085, Test Loss: 0.3166, Train Accuracy: 64.4836, Test Accuracy: 63.1313, Avg. duration: 0.0278 s\n",
      "Epoch: 2377, Train Loss: 0.2085, Test Loss: 0.3166, Train Accuracy: 64.4836, Test Accuracy: 63.1313, Avg. duration: 0.0277 s\n",
      "Epoch: 2378, Train Loss: 0.2085, Test Loss: 0.3166, Train Accuracy: 64.4836, Test Accuracy: 63.1313, Avg. duration: 0.0275 s\n",
      "Epoch: 2379, Train Loss: 0.2085, Test Loss: 0.3166, Train Accuracy: 64.4836, Test Accuracy: 63.1313, Avg. duration: 0.0277 s\n",
      "Epoch: 2380, Train Loss: 0.2085, Test Loss: 0.3166, Train Accuracy: 64.4836, Test Accuracy: 63.1313, Avg. duration: 0.0277 s\n",
      "Epoch: 2381, Train Loss: 0.2085, Test Loss: 0.3166, Train Accuracy: 64.4836, Test Accuracy: 63.1313, Avg. duration: 0.0279 s\n",
      "Epoch: 2382, Train Loss: 0.2085, Test Loss: 0.3166, Train Accuracy: 64.4836, Test Accuracy: 63.1313, Avg. duration: 0.0284 s\n",
      "Epoch: 2383, Train Loss: 0.2085, Test Loss: 0.3166, Train Accuracy: 64.4836, Test Accuracy: 63.1313, Avg. duration: 0.0270 s\n",
      "Epoch: 2384, Train Loss: 0.2085, Test Loss: 0.3166, Train Accuracy: 64.4836, Test Accuracy: 63.1313, Avg. duration: 0.0273 s\n",
      "Epoch: 2385, Train Loss: 0.2085, Test Loss: 0.3166, Train Accuracy: 64.4836, Test Accuracy: 63.1313, Avg. duration: 0.0274 s\n",
      "Epoch: 2386, Train Loss: 0.2085, Test Loss: 0.3166, Train Accuracy: 64.4836, Test Accuracy: 63.1313, Avg. duration: 0.0278 s\n",
      "Epoch: 2387, Train Loss: 0.2085, Test Loss: 0.3166, Train Accuracy: 64.4836, Test Accuracy: 63.1313, Avg. duration: 0.0278 s\n",
      "Epoch: 2388, Train Loss: 0.2085, Test Loss: 0.3166, Train Accuracy: 64.4836, Test Accuracy: 63.1313, Avg. duration: 0.0280 s\n",
      "Epoch: 2389, Train Loss: 0.2085, Test Loss: 0.3166, Train Accuracy: 64.4836, Test Accuracy: 63.1313, Avg. duration: 0.0276 s\n",
      "Epoch: 2390, Train Loss: 0.2085, Test Loss: 0.3166, Train Accuracy: 64.4836, Test Accuracy: 63.1313, Avg. duration: 0.0280 s\n",
      "Epoch: 2391, Train Loss: 0.2085, Test Loss: 0.3166, Train Accuracy: 64.4836, Test Accuracy: 63.1313, Avg. duration: 0.0278 s\n",
      "Epoch: 2392, Train Loss: 0.2085, Test Loss: 0.3166, Train Accuracy: 64.4836, Test Accuracy: 63.1313, Avg. duration: 0.0277 s\n",
      "Epoch: 2393, Train Loss: 0.2085, Test Loss: 0.3166, Train Accuracy: 64.4836, Test Accuracy: 63.1313, Avg. duration: 0.3145 s\n",
      "Epoch: 2394, Train Loss: 0.2085, Test Loss: 0.3166, Train Accuracy: 64.4836, Test Accuracy: 63.1313, Avg. duration: 0.0292 s\n",
      "Epoch: 2395, Train Loss: 0.2085, Test Loss: 0.3166, Train Accuracy: 64.4836, Test Accuracy: 63.1313, Avg. duration: 0.0279 s\n",
      "Epoch: 2396, Train Loss: 0.2085, Test Loss: 0.3166, Train Accuracy: 64.4836, Test Accuracy: 63.1313, Avg. duration: 0.0277 s\n",
      "Epoch: 2397, Train Loss: 0.2085, Test Loss: 0.3166, Train Accuracy: 64.4836, Test Accuracy: 63.1313, Avg. duration: 0.0284 s\n",
      "Epoch: 2398, Train Loss: 0.2085, Test Loss: 0.3166, Train Accuracy: 64.4836, Test Accuracy: 63.1313, Avg. duration: 0.0280 s\n",
      "Epoch: 2399, Train Loss: 0.2085, Test Loss: 0.3166, Train Accuracy: 64.4836, Test Accuracy: 63.1313, Avg. duration: 0.0283 s\n",
      "Epoch: 2400, Train Loss: 0.2085, Test Loss: 0.3166, Train Accuracy: 64.4836, Test Accuracy: 63.1313, Avg. duration: 0.0277 s\n",
      "Epoch: 2401, Train Loss: 0.2062, Test Loss: 0.3181, Train Accuracy: 64.7355, Test Accuracy: 62.6263, Avg. duration: 2.7318 s\n",
      "Epoch: 2402, Train Loss: 0.2062, Test Loss: 0.3181, Train Accuracy: 64.7355, Test Accuracy: 62.6263, Avg. duration: 0.0294 s\n",
      "Epoch: 2403, Train Loss: 0.2062, Test Loss: 0.3181, Train Accuracy: 64.7355, Test Accuracy: 62.6263, Avg. duration: 0.0278 s\n",
      "Epoch: 2404, Train Loss: 0.2062, Test Loss: 0.3181, Train Accuracy: 64.7355, Test Accuracy: 62.6263, Avg. duration: 0.0276 s\n",
      "Epoch: 2405, Train Loss: 0.2062, Test Loss: 0.3181, Train Accuracy: 64.7355, Test Accuracy: 62.6263, Avg. duration: 0.0276 s\n",
      "Epoch: 2406, Train Loss: 0.2062, Test Loss: 0.3181, Train Accuracy: 64.7355, Test Accuracy: 62.6263, Avg. duration: 0.0270 s\n",
      "Epoch: 2407, Train Loss: 0.2062, Test Loss: 0.3181, Train Accuracy: 64.7355, Test Accuracy: 62.6263, Avg. duration: 0.0268 s\n",
      "Epoch: 2408, Train Loss: 0.2062, Test Loss: 0.3181, Train Accuracy: 64.7355, Test Accuracy: 62.6263, Avg. duration: 0.0274 s\n",
      "Epoch: 2409, Train Loss: 0.2062, Test Loss: 0.3181, Train Accuracy: 64.7355, Test Accuracy: 62.6263, Avg. duration: 0.0279 s\n",
      "Epoch: 2410, Train Loss: 0.2062, Test Loss: 0.3181, Train Accuracy: 64.7355, Test Accuracy: 62.6263, Avg. duration: 0.0274 s\n",
      "Epoch: 2411, Train Loss: 0.2062, Test Loss: 0.3181, Train Accuracy: 64.7355, Test Accuracy: 62.6263, Avg. duration: 0.0271 s\n",
      "Epoch: 2412, Train Loss: 0.2062, Test Loss: 0.3181, Train Accuracy: 64.7355, Test Accuracy: 62.6263, Avg. duration: 0.0268 s\n",
      "Epoch: 2413, Train Loss: 0.2062, Test Loss: 0.3181, Train Accuracy: 64.7355, Test Accuracy: 62.6263, Avg. duration: 0.0268 s\n",
      "Epoch: 2414, Train Loss: 0.2062, Test Loss: 0.3181, Train Accuracy: 64.7355, Test Accuracy: 62.6263, Avg. duration: 0.0268 s\n",
      "Epoch: 2415, Train Loss: 0.2062, Test Loss: 0.3181, Train Accuracy: 64.7355, Test Accuracy: 62.6263, Avg. duration: 0.0274 s\n",
      "Epoch: 2416, Train Loss: 0.2062, Test Loss: 0.3181, Train Accuracy: 64.7355, Test Accuracy: 62.6263, Avg. duration: 0.0268 s\n",
      "Epoch: 2417, Train Loss: 0.2062, Test Loss: 0.3181, Train Accuracy: 64.7355, Test Accuracy: 62.6263, Avg. duration: 0.0278 s\n",
      "Epoch: 2418, Train Loss: 0.2062, Test Loss: 0.3181, Train Accuracy: 64.7355, Test Accuracy: 62.6263, Avg. duration: 0.0268 s\n",
      "Epoch: 2419, Train Loss: 0.2062, Test Loss: 0.3181, Train Accuracy: 64.7355, Test Accuracy: 62.6263, Avg. duration: 0.0268 s\n",
      "Epoch: 2420, Train Loss: 0.2062, Test Loss: 0.3181, Train Accuracy: 64.7355, Test Accuracy: 62.6263, Avg. duration: 0.0273 s\n",
      "Epoch: 2421, Train Loss: 0.2062, Test Loss: 0.3181, Train Accuracy: 64.7355, Test Accuracy: 62.6263, Avg. duration: 0.0271 s\n",
      "Epoch: 2422, Train Loss: 0.2062, Test Loss: 0.3181, Train Accuracy: 64.7355, Test Accuracy: 62.6263, Avg. duration: 0.0271 s\n",
      "Epoch: 2423, Train Loss: 0.2062, Test Loss: 0.3181, Train Accuracy: 64.7355, Test Accuracy: 62.6263, Avg. duration: 0.0272 s\n",
      "Epoch: 2424, Train Loss: 0.2062, Test Loss: 0.3181, Train Accuracy: 64.7355, Test Accuracy: 62.6263, Avg. duration: 0.0269 s\n",
      "Epoch: 2425, Train Loss: 0.2062, Test Loss: 0.3181, Train Accuracy: 64.7355, Test Accuracy: 62.6263, Avg. duration: 0.0271 s\n",
      "Epoch: 2426, Train Loss: 0.2062, Test Loss: 0.3181, Train Accuracy: 64.7355, Test Accuracy: 62.6263, Avg. duration: 0.0270 s\n",
      "Epoch: 2427, Train Loss: 0.2062, Test Loss: 0.3181, Train Accuracy: 64.7355, Test Accuracy: 62.6263, Avg. duration: 0.0270 s\n",
      "Epoch: 2428, Train Loss: 0.2062, Test Loss: 0.3181, Train Accuracy: 64.7355, Test Accuracy: 62.6263, Avg. duration: 0.0274 s\n",
      "Epoch: 2429, Train Loss: 0.2062, Test Loss: 0.3181, Train Accuracy: 64.7355, Test Accuracy: 62.6263, Avg. duration: 0.0271 s\n",
      "Epoch: 2430, Train Loss: 0.2062, Test Loss: 0.3181, Train Accuracy: 64.7355, Test Accuracy: 62.6263, Avg. duration: 0.0269 s\n",
      "Epoch: 2431, Train Loss: 0.2062, Test Loss: 0.3181, Train Accuracy: 64.7355, Test Accuracy: 62.6263, Avg. duration: 0.0272 s\n",
      "Epoch: 2432, Train Loss: 0.2062, Test Loss: 0.3181, Train Accuracy: 64.7355, Test Accuracy: 62.6263, Avg. duration: 0.0270 s\n",
      "Epoch: 2433, Train Loss: 0.2062, Test Loss: 0.3181, Train Accuracy: 64.7355, Test Accuracy: 62.6263, Avg. duration: 0.0276 s\n",
      "Epoch: 2434, Train Loss: 0.2062, Test Loss: 0.3181, Train Accuracy: 64.7355, Test Accuracy: 62.6263, Avg. duration: 0.0274 s\n",
      "Epoch: 2435, Train Loss: 0.2062, Test Loss: 0.3181, Train Accuracy: 64.7355, Test Accuracy: 62.6263, Avg. duration: 0.0273 s\n",
      "Epoch: 2436, Train Loss: 0.2062, Test Loss: 0.3181, Train Accuracy: 64.7355, Test Accuracy: 62.6263, Avg. duration: 0.0268 s\n",
      "Epoch: 2437, Train Loss: 0.2062, Test Loss: 0.3181, Train Accuracy: 64.7355, Test Accuracy: 62.6263, Avg. duration: 0.0270 s\n",
      "Epoch: 2438, Train Loss: 0.2062, Test Loss: 0.3181, Train Accuracy: 64.7355, Test Accuracy: 62.6263, Avg. duration: 0.0272 s\n",
      "Epoch: 2439, Train Loss: 0.2062, Test Loss: 0.3181, Train Accuracy: 64.7355, Test Accuracy: 62.6263, Avg. duration: 0.0273 s\n",
      "Epoch: 2440, Train Loss: 0.2062, Test Loss: 0.3181, Train Accuracy: 64.7355, Test Accuracy: 62.6263, Avg. duration: 0.0277 s\n",
      "Epoch: 2441, Train Loss: 0.2062, Test Loss: 0.3181, Train Accuracy: 64.7355, Test Accuracy: 62.6263, Avg. duration: 0.0279 s\n",
      "Epoch: 2442, Train Loss: 0.2062, Test Loss: 0.3181, Train Accuracy: 64.7355, Test Accuracy: 62.6263, Avg. duration: 0.0269 s\n",
      "Epoch: 2443, Train Loss: 0.2062, Test Loss: 0.3181, Train Accuracy: 64.7355, Test Accuracy: 62.6263, Avg. duration: 0.0269 s\n",
      "Epoch: 2444, Train Loss: 0.2062, Test Loss: 0.3181, Train Accuracy: 64.7355, Test Accuracy: 62.6263, Avg. duration: 0.0274 s\n",
      "Epoch: 2445, Train Loss: 0.2062, Test Loss: 0.3181, Train Accuracy: 64.7355, Test Accuracy: 62.6263, Avg. duration: 0.0271 s\n",
      "Epoch: 2446, Train Loss: 0.2062, Test Loss: 0.3181, Train Accuracy: 64.7355, Test Accuracy: 62.6263, Avg. duration: 0.0275 s\n",
      "Epoch: 2447, Train Loss: 0.2062, Test Loss: 0.3181, Train Accuracy: 64.7355, Test Accuracy: 62.6263, Avg. duration: 0.0276 s\n",
      "Epoch: 2448, Train Loss: 0.2062, Test Loss: 0.3181, Train Accuracy: 64.7355, Test Accuracy: 62.6263, Avg. duration: 0.0270 s\n",
      "Epoch: 2449, Train Loss: 0.2062, Test Loss: 0.3181, Train Accuracy: 64.7355, Test Accuracy: 62.6263, Avg. duration: 0.0276 s\n",
      "Epoch: 2450, Train Loss: 0.2062, Test Loss: 0.3181, Train Accuracy: 64.7355, Test Accuracy: 62.6263, Avg. duration: 0.0271 s\n",
      "Epoch: 2451, Train Loss: 0.2062, Test Loss: 0.3181, Train Accuracy: 64.7355, Test Accuracy: 62.6263, Avg. duration: 0.0273 s\n",
      "Epoch: 2452, Train Loss: 0.2062, Test Loss: 0.3181, Train Accuracy: 64.7355, Test Accuracy: 62.6263, Avg. duration: 0.0275 s\n",
      "Epoch: 2453, Train Loss: 0.2062, Test Loss: 0.3181, Train Accuracy: 64.7355, Test Accuracy: 62.6263, Avg. duration: 0.0278 s\n",
      "Epoch: 2454, Train Loss: 0.2062, Test Loss: 0.3181, Train Accuracy: 64.7355, Test Accuracy: 62.6263, Avg. duration: 0.0270 s\n",
      "Epoch: 2455, Train Loss: 0.2062, Test Loss: 0.3181, Train Accuracy: 64.7355, Test Accuracy: 62.6263, Avg. duration: 0.0269 s\n",
      "Epoch: 2456, Train Loss: 0.2062, Test Loss: 0.3181, Train Accuracy: 64.7355, Test Accuracy: 62.6263, Avg. duration: 0.0272 s\n",
      "Epoch: 2457, Train Loss: 0.2062, Test Loss: 0.3181, Train Accuracy: 64.7355, Test Accuracy: 62.6263, Avg. duration: 0.0278 s\n",
      "Epoch: 2458, Train Loss: 0.2062, Test Loss: 0.3181, Train Accuracy: 64.7355, Test Accuracy: 62.6263, Avg. duration: 0.0276 s\n",
      "Epoch: 2459, Train Loss: 0.2062, Test Loss: 0.3181, Train Accuracy: 64.7355, Test Accuracy: 62.6263, Avg. duration: 0.0274 s\n",
      "Epoch: 2460, Train Loss: 0.2062, Test Loss: 0.3181, Train Accuracy: 64.7355, Test Accuracy: 62.6263, Avg. duration: 0.0271 s\n",
      "Epoch: 2461, Train Loss: 0.2062, Test Loss: 0.3181, Train Accuracy: 64.7355, Test Accuracy: 62.6263, Avg. duration: 0.0269 s\n",
      "Epoch: 2462, Train Loss: 0.2062, Test Loss: 0.3181, Train Accuracy: 64.7355, Test Accuracy: 62.6263, Avg. duration: 0.0269 s\n",
      "Epoch: 2463, Train Loss: 0.2062, Test Loss: 0.3181, Train Accuracy: 64.7355, Test Accuracy: 62.6263, Avg. duration: 0.0269 s\n",
      "Epoch: 2464, Train Loss: 0.2062, Test Loss: 0.3181, Train Accuracy: 64.7355, Test Accuracy: 62.6263, Avg. duration: 0.0273 s\n",
      "Epoch: 2465, Train Loss: 0.2062, Test Loss: 0.3181, Train Accuracy: 64.7355, Test Accuracy: 62.6263, Avg. duration: 0.0280 s\n",
      "Epoch: 2466, Train Loss: 0.2062, Test Loss: 0.3181, Train Accuracy: 64.7355, Test Accuracy: 62.6263, Avg. duration: 0.0274 s\n",
      "Epoch: 2467, Train Loss: 0.2062, Test Loss: 0.3181, Train Accuracy: 64.7355, Test Accuracy: 62.6263, Avg. duration: 0.0270 s\n",
      "Epoch: 2468, Train Loss: 0.2062, Test Loss: 0.3181, Train Accuracy: 64.7355, Test Accuracy: 62.6263, Avg. duration: 0.0276 s\n",
      "Epoch: 2469, Train Loss: 0.2062, Test Loss: 0.3181, Train Accuracy: 64.7355, Test Accuracy: 62.6263, Avg. duration: 0.3150 s\n",
      "Epoch: 2470, Train Loss: 0.2062, Test Loss: 0.3181, Train Accuracy: 64.7355, Test Accuracy: 62.6263, Avg. duration: 0.0289 s\n",
      "Epoch: 2471, Train Loss: 0.2062, Test Loss: 0.3181, Train Accuracy: 64.7355, Test Accuracy: 62.6263, Avg. duration: 0.0286 s\n",
      "Epoch: 2472, Train Loss: 0.2062, Test Loss: 0.3181, Train Accuracy: 64.7355, Test Accuracy: 62.6263, Avg. duration: 0.0277 s\n",
      "Epoch: 2473, Train Loss: 0.2062, Test Loss: 0.3181, Train Accuracy: 64.7355, Test Accuracy: 62.6263, Avg. duration: 0.0279 s\n",
      "Epoch: 2474, Train Loss: 0.2062, Test Loss: 0.3181, Train Accuracy: 64.7355, Test Accuracy: 62.6263, Avg. duration: 0.0276 s\n",
      "Epoch: 2475, Train Loss: 0.2062, Test Loss: 0.3181, Train Accuracy: 64.7355, Test Accuracy: 62.6263, Avg. duration: 0.0278 s\n",
      "Epoch: 2476, Train Loss: 0.2062, Test Loss: 0.3181, Train Accuracy: 64.7355, Test Accuracy: 62.6263, Avg. duration: 0.0277 s\n",
      "Epoch: 2477, Train Loss: 0.2062, Test Loss: 0.3181, Train Accuracy: 64.7355, Test Accuracy: 62.6263, Avg. duration: 0.0288 s\n",
      "Epoch: 2478, Train Loss: 0.2062, Test Loss: 0.3181, Train Accuracy: 64.7355, Test Accuracy: 62.6263, Avg. duration: 0.0277 s\n",
      "Epoch: 2479, Train Loss: 0.2062, Test Loss: 0.3181, Train Accuracy: 64.7355, Test Accuracy: 62.6263, Avg. duration: 0.0277 s\n",
      "Epoch: 2480, Train Loss: 0.2062, Test Loss: 0.3181, Train Accuracy: 64.7355, Test Accuracy: 62.6263, Avg. duration: 0.0277 s\n",
      "Epoch: 2481, Train Loss: 0.2062, Test Loss: 0.3181, Train Accuracy: 64.7355, Test Accuracy: 62.6263, Avg. duration: 0.0278 s\n",
      "Epoch: 2482, Train Loss: 0.2062, Test Loss: 0.3181, Train Accuracy: 64.7355, Test Accuracy: 62.6263, Avg. duration: 0.0278 s\n",
      "Epoch: 2483, Train Loss: 0.2062, Test Loss: 0.3181, Train Accuracy: 64.7355, Test Accuracy: 62.6263, Avg. duration: 0.0277 s\n",
      "Epoch: 2484, Train Loss: 0.2062, Test Loss: 0.3181, Train Accuracy: 64.7355, Test Accuracy: 62.6263, Avg. duration: 0.0273 s\n",
      "Epoch: 2485, Train Loss: 0.2062, Test Loss: 0.3181, Train Accuracy: 64.7355, Test Accuracy: 62.6263, Avg. duration: 0.0281 s\n",
      "Epoch: 2486, Train Loss: 0.2062, Test Loss: 0.3181, Train Accuracy: 64.7355, Test Accuracy: 62.6263, Avg. duration: 0.0277 s\n",
      "Epoch: 2487, Train Loss: 0.2062, Test Loss: 0.3181, Train Accuracy: 64.7355, Test Accuracy: 62.6263, Avg. duration: 0.0276 s\n",
      "Epoch: 2488, Train Loss: 0.2062, Test Loss: 0.3181, Train Accuracy: 64.7355, Test Accuracy: 62.6263, Avg. duration: 0.0279 s\n",
      "Epoch: 2489, Train Loss: 0.2062, Test Loss: 0.3181, Train Accuracy: 64.7355, Test Accuracy: 62.6263, Avg. duration: 0.0278 s\n",
      "Epoch: 2490, Train Loss: 0.2062, Test Loss: 0.3181, Train Accuracy: 64.7355, Test Accuracy: 62.6263, Avg. duration: 0.0275 s\n",
      "Epoch: 2491, Train Loss: 0.2062, Test Loss: 0.3181, Train Accuracy: 64.7355, Test Accuracy: 62.6263, Avg. duration: 0.0278 s\n",
      "Epoch: 2492, Train Loss: 0.2062, Test Loss: 0.3181, Train Accuracy: 64.7355, Test Accuracy: 62.6263, Avg. duration: 0.0278 s\n",
      "Epoch: 2493, Train Loss: 0.2062, Test Loss: 0.3181, Train Accuracy: 64.7355, Test Accuracy: 62.6263, Avg. duration: 0.0285 s\n",
      "Epoch: 2494, Train Loss: 0.2062, Test Loss: 0.3181, Train Accuracy: 64.7355, Test Accuracy: 62.6263, Avg. duration: 0.0280 s\n",
      "Epoch: 2495, Train Loss: 0.2062, Test Loss: 0.3181, Train Accuracy: 64.7355, Test Accuracy: 62.6263, Avg. duration: 0.0277 s\n",
      "Epoch: 2496, Train Loss: 0.2062, Test Loss: 0.3181, Train Accuracy: 64.7355, Test Accuracy: 62.6263, Avg. duration: 0.0278 s\n",
      "Epoch: 2497, Train Loss: 0.2062, Test Loss: 0.3181, Train Accuracy: 64.7355, Test Accuracy: 62.6263, Avg. duration: 0.0277 s\n",
      "Epoch: 2498, Train Loss: 0.2062, Test Loss: 0.3181, Train Accuracy: 64.7355, Test Accuracy: 62.6263, Avg. duration: 0.0276 s\n",
      "Epoch: 2499, Train Loss: 0.2062, Test Loss: 0.3181, Train Accuracy: 64.7355, Test Accuracy: 62.6263, Avg. duration: 0.0279 s\n",
      "Epoch: 2500, Train Loss: 0.2062, Test Loss: 0.3181, Train Accuracy: 64.7355, Test Accuracy: 62.6263, Avg. duration: 0.0277 s\n",
      "Epoch: 2501, Train Loss: 0.2045, Test Loss: 0.3170, Train Accuracy: 63.7280, Test Accuracy: 63.1313, Avg. duration: 2.7272 s\n",
      "Epoch: 2502, Train Loss: 0.2045, Test Loss: 0.3170, Train Accuracy: 63.7280, Test Accuracy: 63.1313, Avg. duration: 0.0288 s\n",
      "Epoch: 2503, Train Loss: 0.2045, Test Loss: 0.3170, Train Accuracy: 63.7280, Test Accuracy: 63.1313, Avg. duration: 0.0272 s\n",
      "Epoch: 2504, Train Loss: 0.2045, Test Loss: 0.3170, Train Accuracy: 63.7280, Test Accuracy: 63.1313, Avg. duration: 0.0278 s\n",
      "Epoch: 2505, Train Loss: 0.2045, Test Loss: 0.3170, Train Accuracy: 63.7280, Test Accuracy: 63.1313, Avg. duration: 0.0272 s\n",
      "Epoch: 2506, Train Loss: 0.2045, Test Loss: 0.3170, Train Accuracy: 63.7280, Test Accuracy: 63.1313, Avg. duration: 0.0275 s\n",
      "Epoch: 2507, Train Loss: 0.2045, Test Loss: 0.3170, Train Accuracy: 63.7280, Test Accuracy: 63.1313, Avg. duration: 0.0280 s\n",
      "Epoch: 2508, Train Loss: 0.2045, Test Loss: 0.3170, Train Accuracy: 63.7280, Test Accuracy: 63.1313, Avg. duration: 0.0270 s\n",
      "Epoch: 2509, Train Loss: 0.2045, Test Loss: 0.3170, Train Accuracy: 63.7280, Test Accuracy: 63.1313, Avg. duration: 0.0276 s\n",
      "Epoch: 2510, Train Loss: 0.2045, Test Loss: 0.3170, Train Accuracy: 63.7280, Test Accuracy: 63.1313, Avg. duration: 0.0272 s\n",
      "Epoch: 2511, Train Loss: 0.2045, Test Loss: 0.3170, Train Accuracy: 63.7280, Test Accuracy: 63.1313, Avg. duration: 0.0273 s\n",
      "Epoch: 2512, Train Loss: 0.2045, Test Loss: 0.3170, Train Accuracy: 63.7280, Test Accuracy: 63.1313, Avg. duration: 0.0276 s\n",
      "Epoch: 2513, Train Loss: 0.2045, Test Loss: 0.3170, Train Accuracy: 63.7280, Test Accuracy: 63.1313, Avg. duration: 0.0275 s\n",
      "Epoch: 2514, Train Loss: 0.2045, Test Loss: 0.3170, Train Accuracy: 63.7280, Test Accuracy: 63.1313, Avg. duration: 0.0270 s\n",
      "Epoch: 2515, Train Loss: 0.2045, Test Loss: 0.3170, Train Accuracy: 63.7280, Test Accuracy: 63.1313, Avg. duration: 0.0272 s\n",
      "Epoch: 2516, Train Loss: 0.2045, Test Loss: 0.3170, Train Accuracy: 63.7280, Test Accuracy: 63.1313, Avg. duration: 0.0272 s\n",
      "Epoch: 2517, Train Loss: 0.2045, Test Loss: 0.3170, Train Accuracy: 63.7280, Test Accuracy: 63.1313, Avg. duration: 0.0277 s\n",
      "Epoch: 2518, Train Loss: 0.2045, Test Loss: 0.3170, Train Accuracy: 63.7280, Test Accuracy: 63.1313, Avg. duration: 0.0278 s\n",
      "Epoch: 2519, Train Loss: 0.2045, Test Loss: 0.3170, Train Accuracy: 63.7280, Test Accuracy: 63.1313, Avg. duration: 0.0272 s\n",
      "Epoch: 2520, Train Loss: 0.2045, Test Loss: 0.3170, Train Accuracy: 63.7280, Test Accuracy: 63.1313, Avg. duration: 0.0270 s\n",
      "Epoch: 2521, Train Loss: 0.2045, Test Loss: 0.3170, Train Accuracy: 63.7280, Test Accuracy: 63.1313, Avg. duration: 0.0270 s\n",
      "Epoch: 2522, Train Loss: 0.2045, Test Loss: 0.3170, Train Accuracy: 63.7280, Test Accuracy: 63.1313, Avg. duration: 0.0269 s\n",
      "Epoch: 2523, Train Loss: 0.2045, Test Loss: 0.3170, Train Accuracy: 63.7280, Test Accuracy: 63.1313, Avg. duration: 0.0276 s\n",
      "Epoch: 2524, Train Loss: 0.2045, Test Loss: 0.3170, Train Accuracy: 63.7280, Test Accuracy: 63.1313, Avg. duration: 0.0278 s\n",
      "Epoch: 2525, Train Loss: 0.2045, Test Loss: 0.3170, Train Accuracy: 63.7280, Test Accuracy: 63.1313, Avg. duration: 0.0279 s\n",
      "Epoch: 2526, Train Loss: 0.2045, Test Loss: 0.3170, Train Accuracy: 63.7280, Test Accuracy: 63.1313, Avg. duration: 0.0271 s\n",
      "Epoch: 2527, Train Loss: 0.2045, Test Loss: 0.3170, Train Accuracy: 63.7280, Test Accuracy: 63.1313, Avg. duration: 0.0271 s\n",
      "Epoch: 2528, Train Loss: 0.2045, Test Loss: 0.3170, Train Accuracy: 63.7280, Test Accuracy: 63.1313, Avg. duration: 0.0273 s\n",
      "Epoch: 2529, Train Loss: 0.2045, Test Loss: 0.3170, Train Accuracy: 63.7280, Test Accuracy: 63.1313, Avg. duration: 0.0271 s\n",
      "Epoch: 2530, Train Loss: 0.2045, Test Loss: 0.3170, Train Accuracy: 63.7280, Test Accuracy: 63.1313, Avg. duration: 0.0272 s\n",
      "Epoch: 2531, Train Loss: 0.2045, Test Loss: 0.3170, Train Accuracy: 63.7280, Test Accuracy: 63.1313, Avg. duration: 0.0272 s\n",
      "Epoch: 2532, Train Loss: 0.2045, Test Loss: 0.3170, Train Accuracy: 63.7280, Test Accuracy: 63.1313, Avg. duration: 0.0269 s\n",
      "Epoch: 2533, Train Loss: 0.2045, Test Loss: 0.3170, Train Accuracy: 63.7280, Test Accuracy: 63.1313, Avg. duration: 0.0277 s\n",
      "Epoch: 2534, Train Loss: 0.2045, Test Loss: 0.3170, Train Accuracy: 63.7280, Test Accuracy: 63.1313, Avg. duration: 0.0273 s\n",
      "Epoch: 2535, Train Loss: 0.2045, Test Loss: 0.3170, Train Accuracy: 63.7280, Test Accuracy: 63.1313, Avg. duration: 0.0272 s\n",
      "Epoch: 2536, Train Loss: 0.2045, Test Loss: 0.3170, Train Accuracy: 63.7280, Test Accuracy: 63.1313, Avg. duration: 0.3165 s\n",
      "Epoch: 2537, Train Loss: 0.2045, Test Loss: 0.3170, Train Accuracy: 63.7280, Test Accuracy: 63.1313, Avg. duration: 0.0281 s\n",
      "Epoch: 2538, Train Loss: 0.2045, Test Loss: 0.3170, Train Accuracy: 63.7280, Test Accuracy: 63.1313, Avg. duration: 0.0271 s\n",
      "Epoch: 2539, Train Loss: 0.2045, Test Loss: 0.3170, Train Accuracy: 63.7280, Test Accuracy: 63.1313, Avg. duration: 0.0273 s\n",
      "Epoch: 2540, Train Loss: 0.2045, Test Loss: 0.3170, Train Accuracy: 63.7280, Test Accuracy: 63.1313, Avg. duration: 0.0272 s\n",
      "Epoch: 2541, Train Loss: 0.2045, Test Loss: 0.3170, Train Accuracy: 63.7280, Test Accuracy: 63.1313, Avg. duration: 0.0275 s\n",
      "Epoch: 2542, Train Loss: 0.2045, Test Loss: 0.3170, Train Accuracy: 63.7280, Test Accuracy: 63.1313, Avg. duration: 0.0275 s\n",
      "Epoch: 2543, Train Loss: 0.2045, Test Loss: 0.3170, Train Accuracy: 63.7280, Test Accuracy: 63.1313, Avg. duration: 0.0268 s\n",
      "Epoch: 2544, Train Loss: 0.2045, Test Loss: 0.3170, Train Accuracy: 63.7280, Test Accuracy: 63.1313, Avg. duration: 0.0277 s\n",
      "Epoch: 2545, Train Loss: 0.2045, Test Loss: 0.3170, Train Accuracy: 63.7280, Test Accuracy: 63.1313, Avg. duration: 0.0270 s\n",
      "Epoch: 2546, Train Loss: 0.2045, Test Loss: 0.3170, Train Accuracy: 63.7280, Test Accuracy: 63.1313, Avg. duration: 0.0274 s\n",
      "Epoch: 2547, Train Loss: 0.2045, Test Loss: 0.3170, Train Accuracy: 63.7280, Test Accuracy: 63.1313, Avg. duration: 0.0270 s\n",
      "Epoch: 2548, Train Loss: 0.2045, Test Loss: 0.3170, Train Accuracy: 63.7280, Test Accuracy: 63.1313, Avg. duration: 0.0276 s\n",
      "Epoch: 2549, Train Loss: 0.2045, Test Loss: 0.3170, Train Accuracy: 63.7280, Test Accuracy: 63.1313, Avg. duration: 0.0269 s\n",
      "Epoch: 2550, Train Loss: 0.2045, Test Loss: 0.3170, Train Accuracy: 63.7280, Test Accuracy: 63.1313, Avg. duration: 0.0275 s\n",
      "Epoch: 2551, Train Loss: 0.2045, Test Loss: 0.3170, Train Accuracy: 63.7280, Test Accuracy: 63.1313, Avg. duration: 0.0270 s\n",
      "Epoch: 2552, Train Loss: 0.2045, Test Loss: 0.3170, Train Accuracy: 63.7280, Test Accuracy: 63.1313, Avg. duration: 0.0276 s\n",
      "Epoch: 2553, Train Loss: 0.2045, Test Loss: 0.3170, Train Accuracy: 63.7280, Test Accuracy: 63.1313, Avg. duration: 0.0278 s\n",
      "Epoch: 2554, Train Loss: 0.2045, Test Loss: 0.3170, Train Accuracy: 63.7280, Test Accuracy: 63.1313, Avg. duration: 0.0277 s\n",
      "Epoch: 2555, Train Loss: 0.2045, Test Loss: 0.3170, Train Accuracy: 63.7280, Test Accuracy: 63.1313, Avg. duration: 0.0275 s\n",
      "Epoch: 2556, Train Loss: 0.2045, Test Loss: 0.3170, Train Accuracy: 63.7280, Test Accuracy: 63.1313, Avg. duration: 0.0272 s\n",
      "Epoch: 2557, Train Loss: 0.2045, Test Loss: 0.3170, Train Accuracy: 63.7280, Test Accuracy: 63.1313, Avg. duration: 0.0273 s\n",
      "Epoch: 2558, Train Loss: 0.2045, Test Loss: 0.3170, Train Accuracy: 63.7280, Test Accuracy: 63.1313, Avg. duration: 0.0275 s\n",
      "Epoch: 2559, Train Loss: 0.2045, Test Loss: 0.3170, Train Accuracy: 63.7280, Test Accuracy: 63.1313, Avg. duration: 0.0281 s\n",
      "Epoch: 2560, Train Loss: 0.2045, Test Loss: 0.3170, Train Accuracy: 63.7280, Test Accuracy: 63.1313, Avg. duration: 0.0280 s\n",
      "Epoch: 2561, Train Loss: 0.2045, Test Loss: 0.3170, Train Accuracy: 63.7280, Test Accuracy: 63.1313, Avg. duration: 0.0273 s\n",
      "Epoch: 2562, Train Loss: 0.2045, Test Loss: 0.3170, Train Accuracy: 63.7280, Test Accuracy: 63.1313, Avg. duration: 0.0275 s\n",
      "Epoch: 2563, Train Loss: 0.2045, Test Loss: 0.3170, Train Accuracy: 63.7280, Test Accuracy: 63.1313, Avg. duration: 0.0276 s\n",
      "Epoch: 2564, Train Loss: 0.2045, Test Loss: 0.3170, Train Accuracy: 63.7280, Test Accuracy: 63.1313, Avg. duration: 0.0271 s\n",
      "Epoch: 2565, Train Loss: 0.2045, Test Loss: 0.3170, Train Accuracy: 63.7280, Test Accuracy: 63.1313, Avg. duration: 0.0277 s\n",
      "Epoch: 2566, Train Loss: 0.2045, Test Loss: 0.3170, Train Accuracy: 63.7280, Test Accuracy: 63.1313, Avg. duration: 0.0279 s\n",
      "Epoch: 2567, Train Loss: 0.2045, Test Loss: 0.3170, Train Accuracy: 63.7280, Test Accuracy: 63.1313, Avg. duration: 0.0274 s\n",
      "Epoch: 2568, Train Loss: 0.2045, Test Loss: 0.3170, Train Accuracy: 63.7280, Test Accuracy: 63.1313, Avg. duration: 0.0278 s\n",
      "Epoch: 2569, Train Loss: 0.2045, Test Loss: 0.3170, Train Accuracy: 63.7280, Test Accuracy: 63.1313, Avg. duration: 0.0274 s\n",
      "Epoch: 2570, Train Loss: 0.2045, Test Loss: 0.3170, Train Accuracy: 63.7280, Test Accuracy: 63.1313, Avg. duration: 0.0274 s\n",
      "Epoch: 2571, Train Loss: 0.2045, Test Loss: 0.3170, Train Accuracy: 63.7280, Test Accuracy: 63.1313, Avg. duration: 0.0275 s\n",
      "Epoch: 2572, Train Loss: 0.2045, Test Loss: 0.3170, Train Accuracy: 63.7280, Test Accuracy: 63.1313, Avg. duration: 0.0279 s\n",
      "Epoch: 2573, Train Loss: 0.2045, Test Loss: 0.3170, Train Accuracy: 63.7280, Test Accuracy: 63.1313, Avg. duration: 0.0274 s\n",
      "Epoch: 2574, Train Loss: 0.2045, Test Loss: 0.3170, Train Accuracy: 63.7280, Test Accuracy: 63.1313, Avg. duration: 0.0273 s\n",
      "Epoch: 2575, Train Loss: 0.2045, Test Loss: 0.3170, Train Accuracy: 63.7280, Test Accuracy: 63.1313, Avg. duration: 0.0274 s\n",
      "Epoch: 2576, Train Loss: 0.2045, Test Loss: 0.3170, Train Accuracy: 63.7280, Test Accuracy: 63.1313, Avg. duration: 0.0278 s\n",
      "Epoch: 2577, Train Loss: 0.2045, Test Loss: 0.3170, Train Accuracy: 63.7280, Test Accuracy: 63.1313, Avg. duration: 0.0280 s\n",
      "Epoch: 2578, Train Loss: 0.2045, Test Loss: 0.3170, Train Accuracy: 63.7280, Test Accuracy: 63.1313, Avg. duration: 0.0282 s\n",
      "Epoch: 2579, Train Loss: 0.2045, Test Loss: 0.3170, Train Accuracy: 63.7280, Test Accuracy: 63.1313, Avg. duration: 0.0275 s\n",
      "Epoch: 2580, Train Loss: 0.2045, Test Loss: 0.3170, Train Accuracy: 63.7280, Test Accuracy: 63.1313, Avg. duration: 0.0275 s\n",
      "Epoch: 2581, Train Loss: 0.2045, Test Loss: 0.3170, Train Accuracy: 63.7280, Test Accuracy: 63.1313, Avg. duration: 0.0273 s\n",
      "Epoch: 2582, Train Loss: 0.2045, Test Loss: 0.3170, Train Accuracy: 63.7280, Test Accuracy: 63.1313, Avg. duration: 0.0277 s\n",
      "Epoch: 2583, Train Loss: 0.2045, Test Loss: 0.3170, Train Accuracy: 63.7280, Test Accuracy: 63.1313, Avg. duration: 0.0278 s\n",
      "Epoch: 2584, Train Loss: 0.2045, Test Loss: 0.3170, Train Accuracy: 63.7280, Test Accuracy: 63.1313, Avg. duration: 0.0286 s\n",
      "Epoch: 2585, Train Loss: 0.2045, Test Loss: 0.3170, Train Accuracy: 63.7280, Test Accuracy: 63.1313, Avg. duration: 0.0278 s\n",
      "Epoch: 2586, Train Loss: 0.2045, Test Loss: 0.3170, Train Accuracy: 63.7280, Test Accuracy: 63.1313, Avg. duration: 0.0272 s\n",
      "Epoch: 2587, Train Loss: 0.2045, Test Loss: 0.3170, Train Accuracy: 63.7280, Test Accuracy: 63.1313, Avg. duration: 0.0274 s\n",
      "Epoch: 2588, Train Loss: 0.2045, Test Loss: 0.3170, Train Accuracy: 63.7280, Test Accuracy: 63.1313, Avg. duration: 0.0276 s\n",
      "Epoch: 2589, Train Loss: 0.2045, Test Loss: 0.3170, Train Accuracy: 63.7280, Test Accuracy: 63.1313, Avg. duration: 0.0277 s\n",
      "Epoch: 2590, Train Loss: 0.2045, Test Loss: 0.3170, Train Accuracy: 63.7280, Test Accuracy: 63.1313, Avg. duration: 0.0278 s\n",
      "Epoch: 2591, Train Loss: 0.2045, Test Loss: 0.3170, Train Accuracy: 63.7280, Test Accuracy: 63.1313, Avg. duration: 0.0275 s\n",
      "Epoch: 2592, Train Loss: 0.2045, Test Loss: 0.3170, Train Accuracy: 63.7280, Test Accuracy: 63.1313, Avg. duration: 0.0281 s\n",
      "Epoch: 2593, Train Loss: 0.2045, Test Loss: 0.3170, Train Accuracy: 63.7280, Test Accuracy: 63.1313, Avg. duration: 0.0276 s\n",
      "Epoch: 2594, Train Loss: 0.2045, Test Loss: 0.3170, Train Accuracy: 63.7280, Test Accuracy: 63.1313, Avg. duration: 0.0275 s\n",
      "Epoch: 2595, Train Loss: 0.2045, Test Loss: 0.3170, Train Accuracy: 63.7280, Test Accuracy: 63.1313, Avg. duration: 0.0278 s\n",
      "Epoch: 2596, Train Loss: 0.2045, Test Loss: 0.3170, Train Accuracy: 63.7280, Test Accuracy: 63.1313, Avg. duration: 0.0279 s\n",
      "Epoch: 2597, Train Loss: 0.2045, Test Loss: 0.3170, Train Accuracy: 63.7280, Test Accuracy: 63.1313, Avg. duration: 0.0273 s\n",
      "Epoch: 2598, Train Loss: 0.2045, Test Loss: 0.3170, Train Accuracy: 63.7280, Test Accuracy: 63.1313, Avg. duration: 0.0274 s\n",
      "Epoch: 2599, Train Loss: 0.2045, Test Loss: 0.3170, Train Accuracy: 63.7280, Test Accuracy: 63.1313, Avg. duration: 0.0275 s\n",
      "Epoch: 2600, Train Loss: 0.2045, Test Loss: 0.3170, Train Accuracy: 63.7280, Test Accuracy: 63.1313, Avg. duration: 0.0280 s\n",
      "Epoch: 2601, Train Loss: 0.2025, Test Loss: 0.3211, Train Accuracy: 64.4836, Test Accuracy: 62.1212, Avg. duration: 2.7282 s\n",
      "Epoch: 2602, Train Loss: 0.2025, Test Loss: 0.3211, Train Accuracy: 64.4836, Test Accuracy: 62.1212, Avg. duration: 0.0294 s\n",
      "Epoch: 2603, Train Loss: 0.2025, Test Loss: 0.3211, Train Accuracy: 64.4836, Test Accuracy: 62.1212, Avg. duration: 0.0276 s\n",
      "Epoch: 2604, Train Loss: 0.2025, Test Loss: 0.3211, Train Accuracy: 64.4836, Test Accuracy: 62.1212, Avg. duration: 0.0270 s\n",
      "Epoch: 2605, Train Loss: 0.2025, Test Loss: 0.3211, Train Accuracy: 64.4836, Test Accuracy: 62.1212, Avg. duration: 0.0276 s\n",
      "Epoch: 2606, Train Loss: 0.2025, Test Loss: 0.3211, Train Accuracy: 64.4836, Test Accuracy: 62.1212, Avg. duration: 0.0271 s\n",
      "Epoch: 2607, Train Loss: 0.2025, Test Loss: 0.3211, Train Accuracy: 64.4836, Test Accuracy: 62.1212, Avg. duration: 0.0277 s\n",
      "Epoch: 2608, Train Loss: 0.2025, Test Loss: 0.3211, Train Accuracy: 64.4836, Test Accuracy: 62.1212, Avg. duration: 0.0276 s\n",
      "Epoch: 2609, Train Loss: 0.2025, Test Loss: 0.3211, Train Accuracy: 64.4836, Test Accuracy: 62.1212, Avg. duration: 0.0279 s\n",
      "Epoch: 2610, Train Loss: 0.2025, Test Loss: 0.3211, Train Accuracy: 64.4836, Test Accuracy: 62.1212, Avg. duration: 0.0275 s\n",
      "Epoch: 2611, Train Loss: 0.2025, Test Loss: 0.3211, Train Accuracy: 64.4836, Test Accuracy: 62.1212, Avg. duration: 0.0270 s\n",
      "Epoch: 2612, Train Loss: 0.2025, Test Loss: 0.3211, Train Accuracy: 64.4836, Test Accuracy: 62.1212, Avg. duration: 0.3135 s\n",
      "Epoch: 2613, Train Loss: 0.2025, Test Loss: 0.3211, Train Accuracy: 64.4836, Test Accuracy: 62.1212, Avg. duration: 0.0281 s\n",
      "Epoch: 2614, Train Loss: 0.2025, Test Loss: 0.3211, Train Accuracy: 64.4836, Test Accuracy: 62.1212, Avg. duration: 0.0277 s\n",
      "Epoch: 2615, Train Loss: 0.2025, Test Loss: 0.3211, Train Accuracy: 64.4836, Test Accuracy: 62.1212, Avg. duration: 0.0271 s\n",
      "Epoch: 2616, Train Loss: 0.2025, Test Loss: 0.3211, Train Accuracy: 64.4836, Test Accuracy: 62.1212, Avg. duration: 0.0275 s\n",
      "Epoch: 2617, Train Loss: 0.2025, Test Loss: 0.3211, Train Accuracy: 64.4836, Test Accuracy: 62.1212, Avg. duration: 0.0271 s\n",
      "Epoch: 2618, Train Loss: 0.2025, Test Loss: 0.3211, Train Accuracy: 64.4836, Test Accuracy: 62.1212, Avg. duration: 0.0273 s\n",
      "Epoch: 2619, Train Loss: 0.2025, Test Loss: 0.3211, Train Accuracy: 64.4836, Test Accuracy: 62.1212, Avg. duration: 0.0278 s\n",
      "Epoch: 2620, Train Loss: 0.2025, Test Loss: 0.3211, Train Accuracy: 64.4836, Test Accuracy: 62.1212, Avg. duration: 0.0279 s\n",
      "Epoch: 2621, Train Loss: 0.2025, Test Loss: 0.3211, Train Accuracy: 64.4836, Test Accuracy: 62.1212, Avg. duration: 0.0274 s\n",
      "Epoch: 2622, Train Loss: 0.2025, Test Loss: 0.3211, Train Accuracy: 64.4836, Test Accuracy: 62.1212, Avg. duration: 0.0271 s\n",
      "Epoch: 2623, Train Loss: 0.2025, Test Loss: 0.3211, Train Accuracy: 64.4836, Test Accuracy: 62.1212, Avg. duration: 0.0274 s\n",
      "Epoch: 2624, Train Loss: 0.2025, Test Loss: 0.3211, Train Accuracy: 64.4836, Test Accuracy: 62.1212, Avg. duration: 0.0275 s\n",
      "Epoch: 2625, Train Loss: 0.2025, Test Loss: 0.3211, Train Accuracy: 64.4836, Test Accuracy: 62.1212, Avg. duration: 0.0272 s\n",
      "Epoch: 2626, Train Loss: 0.2025, Test Loss: 0.3211, Train Accuracy: 64.4836, Test Accuracy: 62.1212, Avg. duration: 0.0277 s\n",
      "Epoch: 2627, Train Loss: 0.2025, Test Loss: 0.3211, Train Accuracy: 64.4836, Test Accuracy: 62.1212, Avg. duration: 0.0272 s\n",
      "Epoch: 2628, Train Loss: 0.2025, Test Loss: 0.3211, Train Accuracy: 64.4836, Test Accuracy: 62.1212, Avg. duration: 0.0278 s\n",
      "Epoch: 2629, Train Loss: 0.2025, Test Loss: 0.3211, Train Accuracy: 64.4836, Test Accuracy: 62.1212, Avg. duration: 0.0274 s\n",
      "Epoch: 2630, Train Loss: 0.2025, Test Loss: 0.3211, Train Accuracy: 64.4836, Test Accuracy: 62.1212, Avg. duration: 0.0272 s\n",
      "Epoch: 2631, Train Loss: 0.2025, Test Loss: 0.3211, Train Accuracy: 64.4836, Test Accuracy: 62.1212, Avg. duration: 0.0277 s\n",
      "Epoch: 2632, Train Loss: 0.2025, Test Loss: 0.3211, Train Accuracy: 64.4836, Test Accuracy: 62.1212, Avg. duration: 0.0275 s\n",
      "Epoch: 2633, Train Loss: 0.2025, Test Loss: 0.3211, Train Accuracy: 64.4836, Test Accuracy: 62.1212, Avg. duration: 0.0272 s\n",
      "Epoch: 2634, Train Loss: 0.2025, Test Loss: 0.3211, Train Accuracy: 64.4836, Test Accuracy: 62.1212, Avg. duration: 0.0273 s\n",
      "Epoch: 2635, Train Loss: 0.2025, Test Loss: 0.3211, Train Accuracy: 64.4836, Test Accuracy: 62.1212, Avg. duration: 0.0272 s\n",
      "Epoch: 2636, Train Loss: 0.2025, Test Loss: 0.3211, Train Accuracy: 64.4836, Test Accuracy: 62.1212, Avg. duration: 0.0276 s\n",
      "Epoch: 2637, Train Loss: 0.2025, Test Loss: 0.3211, Train Accuracy: 64.4836, Test Accuracy: 62.1212, Avg. duration: 0.0277 s\n",
      "Epoch: 2638, Train Loss: 0.2025, Test Loss: 0.3211, Train Accuracy: 64.4836, Test Accuracy: 62.1212, Avg. duration: 0.0275 s\n",
      "Epoch: 2639, Train Loss: 0.2025, Test Loss: 0.3211, Train Accuracy: 64.4836, Test Accuracy: 62.1212, Avg. duration: 0.0270 s\n",
      "Epoch: 2640, Train Loss: 0.2025, Test Loss: 0.3211, Train Accuracy: 64.4836, Test Accuracy: 62.1212, Avg. duration: 0.0273 s\n",
      "Epoch: 2641, Train Loss: 0.2025, Test Loss: 0.3211, Train Accuracy: 64.4836, Test Accuracy: 62.1212, Avg. duration: 0.0273 s\n",
      "Epoch: 2642, Train Loss: 0.2025, Test Loss: 0.3211, Train Accuracy: 64.4836, Test Accuracy: 62.1212, Avg. duration: 0.0273 s\n",
      "Epoch: 2643, Train Loss: 0.2025, Test Loss: 0.3211, Train Accuracy: 64.4836, Test Accuracy: 62.1212, Avg. duration: 0.0280 s\n",
      "Epoch: 2644, Train Loss: 0.2025, Test Loss: 0.3211, Train Accuracy: 64.4836, Test Accuracy: 62.1212, Avg. duration: 0.0278 s\n",
      "Epoch: 2645, Train Loss: 0.2025, Test Loss: 0.3211, Train Accuracy: 64.4836, Test Accuracy: 62.1212, Avg. duration: 0.0277 s\n",
      "Epoch: 2646, Train Loss: 0.2025, Test Loss: 0.3211, Train Accuracy: 64.4836, Test Accuracy: 62.1212, Avg. duration: 0.0273 s\n",
      "Epoch: 2647, Train Loss: 0.2025, Test Loss: 0.3211, Train Accuracy: 64.4836, Test Accuracy: 62.1212, Avg. duration: 0.0272 s\n",
      "Epoch: 2648, Train Loss: 0.2025, Test Loss: 0.3211, Train Accuracy: 64.4836, Test Accuracy: 62.1212, Avg. duration: 0.0274 s\n",
      "Epoch: 2649, Train Loss: 0.2025, Test Loss: 0.3211, Train Accuracy: 64.4836, Test Accuracy: 62.1212, Avg. duration: 0.0278 s\n",
      "Epoch: 2650, Train Loss: 0.2025, Test Loss: 0.3211, Train Accuracy: 64.4836, Test Accuracy: 62.1212, Avg. duration: 0.0273 s\n",
      "Epoch: 2651, Train Loss: 0.2025, Test Loss: 0.3211, Train Accuracy: 64.4836, Test Accuracy: 62.1212, Avg. duration: 0.0268 s\n",
      "Epoch: 2652, Train Loss: 0.2025, Test Loss: 0.3211, Train Accuracy: 64.4836, Test Accuracy: 62.1212, Avg. duration: 0.0280 s\n",
      "Epoch: 2653, Train Loss: 0.2025, Test Loss: 0.3211, Train Accuracy: 64.4836, Test Accuracy: 62.1212, Avg. duration: 0.0275 s\n",
      "Epoch: 2654, Train Loss: 0.2025, Test Loss: 0.3211, Train Accuracy: 64.4836, Test Accuracy: 62.1212, Avg. duration: 0.0279 s\n",
      "Epoch: 2655, Train Loss: 0.2025, Test Loss: 0.3211, Train Accuracy: 64.4836, Test Accuracy: 62.1212, Avg. duration: 0.0278 s\n",
      "Epoch: 2656, Train Loss: 0.2025, Test Loss: 0.3211, Train Accuracy: 64.4836, Test Accuracy: 62.1212, Avg. duration: 0.0278 s\n",
      "Epoch: 2657, Train Loss: 0.2025, Test Loss: 0.3211, Train Accuracy: 64.4836, Test Accuracy: 62.1212, Avg. duration: 0.0271 s\n",
      "Epoch: 2658, Train Loss: 0.2025, Test Loss: 0.3211, Train Accuracy: 64.4836, Test Accuracy: 62.1212, Avg. duration: 0.0273 s\n",
      "Epoch: 2659, Train Loss: 0.2025, Test Loss: 0.3211, Train Accuracy: 64.4836, Test Accuracy: 62.1212, Avg. duration: 0.0277 s\n",
      "Epoch: 2660, Train Loss: 0.2025, Test Loss: 0.3211, Train Accuracy: 64.4836, Test Accuracy: 62.1212, Avg. duration: 0.0279 s\n",
      "Epoch: 2661, Train Loss: 0.2025, Test Loss: 0.3211, Train Accuracy: 64.4836, Test Accuracy: 62.1212, Avg. duration: 0.0275 s\n",
      "Epoch: 2662, Train Loss: 0.2025, Test Loss: 0.3211, Train Accuracy: 64.4836, Test Accuracy: 62.1212, Avg. duration: 0.0275 s\n",
      "Epoch: 2663, Train Loss: 0.2025, Test Loss: 0.3211, Train Accuracy: 64.4836, Test Accuracy: 62.1212, Avg. duration: 0.0274 s\n",
      "Epoch: 2664, Train Loss: 0.2025, Test Loss: 0.3211, Train Accuracy: 64.4836, Test Accuracy: 62.1212, Avg. duration: 0.0272 s\n",
      "Epoch: 2665, Train Loss: 0.2025, Test Loss: 0.3211, Train Accuracy: 64.4836, Test Accuracy: 62.1212, Avg. duration: 0.0275 s\n",
      "Epoch: 2666, Train Loss: 0.2025, Test Loss: 0.3211, Train Accuracy: 64.4836, Test Accuracy: 62.1212, Avg. duration: 0.0278 s\n",
      "Epoch: 2667, Train Loss: 0.2025, Test Loss: 0.3211, Train Accuracy: 64.4836, Test Accuracy: 62.1212, Avg. duration: 0.0278 s\n",
      "Epoch: 2668, Train Loss: 0.2025, Test Loss: 0.3211, Train Accuracy: 64.4836, Test Accuracy: 62.1212, Avg. duration: 0.0277 s\n",
      "Epoch: 2669, Train Loss: 0.2025, Test Loss: 0.3211, Train Accuracy: 64.4836, Test Accuracy: 62.1212, Avg. duration: 0.0274 s\n",
      "Epoch: 2670, Train Loss: 0.2025, Test Loss: 0.3211, Train Accuracy: 64.4836, Test Accuracy: 62.1212, Avg. duration: 0.0272 s\n",
      "Epoch: 2671, Train Loss: 0.2025, Test Loss: 0.3211, Train Accuracy: 64.4836, Test Accuracy: 62.1212, Avg. duration: 0.0275 s\n",
      "Epoch: 2672, Train Loss: 0.2025, Test Loss: 0.3211, Train Accuracy: 64.4836, Test Accuracy: 62.1212, Avg. duration: 0.0279 s\n",
      "Epoch: 2673, Train Loss: 0.2025, Test Loss: 0.3211, Train Accuracy: 64.4836, Test Accuracy: 62.1212, Avg. duration: 0.0279 s\n",
      "Epoch: 2674, Train Loss: 0.2025, Test Loss: 0.3211, Train Accuracy: 64.4836, Test Accuracy: 62.1212, Avg. duration: 0.0277 s\n",
      "Epoch: 2675, Train Loss: 0.2025, Test Loss: 0.3211, Train Accuracy: 64.4836, Test Accuracy: 62.1212, Avg. duration: 0.0277 s\n",
      "Epoch: 2676, Train Loss: 0.2025, Test Loss: 0.3211, Train Accuracy: 64.4836, Test Accuracy: 62.1212, Avg. duration: 0.0277 s\n",
      "Epoch: 2677, Train Loss: 0.2025, Test Loss: 0.3211, Train Accuracy: 64.4836, Test Accuracy: 62.1212, Avg. duration: 0.0279 s\n",
      "Epoch: 2678, Train Loss: 0.2025, Test Loss: 0.3211, Train Accuracy: 64.4836, Test Accuracy: 62.1212, Avg. duration: 0.0276 s\n",
      "Epoch: 2679, Train Loss: 0.2025, Test Loss: 0.3211, Train Accuracy: 64.4836, Test Accuracy: 62.1212, Avg. duration: 0.3147 s\n",
      "Epoch: 2680, Train Loss: 0.2025, Test Loss: 0.3211, Train Accuracy: 64.4836, Test Accuracy: 62.1212, Avg. duration: 0.0287 s\n",
      "Epoch: 2681, Train Loss: 0.2025, Test Loss: 0.3211, Train Accuracy: 64.4836, Test Accuracy: 62.1212, Avg. duration: 0.0276 s\n",
      "Epoch: 2682, Train Loss: 0.2025, Test Loss: 0.3211, Train Accuracy: 64.4836, Test Accuracy: 62.1212, Avg. duration: 0.0281 s\n",
      "Epoch: 2683, Train Loss: 0.2025, Test Loss: 0.3211, Train Accuracy: 64.4836, Test Accuracy: 62.1212, Avg. duration: 0.0277 s\n",
      "Epoch: 2684, Train Loss: 0.2025, Test Loss: 0.3211, Train Accuracy: 64.4836, Test Accuracy: 62.1212, Avg. duration: 0.0278 s\n",
      "Epoch: 2685, Train Loss: 0.2025, Test Loss: 0.3211, Train Accuracy: 64.4836, Test Accuracy: 62.1212, Avg. duration: 0.0279 s\n",
      "Epoch: 2686, Train Loss: 0.2025, Test Loss: 0.3211, Train Accuracy: 64.4836, Test Accuracy: 62.1212, Avg. duration: 0.0277 s\n",
      "Epoch: 2687, Train Loss: 0.2025, Test Loss: 0.3211, Train Accuracy: 64.4836, Test Accuracy: 62.1212, Avg. duration: 0.0282 s\n",
      "Epoch: 2688, Train Loss: 0.2025, Test Loss: 0.3211, Train Accuracy: 64.4836, Test Accuracy: 62.1212, Avg. duration: 0.0278 s\n",
      "Epoch: 2689, Train Loss: 0.2025, Test Loss: 0.3211, Train Accuracy: 64.4836, Test Accuracy: 62.1212, Avg. duration: 0.0276 s\n",
      "Epoch: 2690, Train Loss: 0.2025, Test Loss: 0.3211, Train Accuracy: 64.4836, Test Accuracy: 62.1212, Avg. duration: 0.0279 s\n",
      "Epoch: 2691, Train Loss: 0.2025, Test Loss: 0.3211, Train Accuracy: 64.4836, Test Accuracy: 62.1212, Avg. duration: 0.0280 s\n",
      "Epoch: 2692, Train Loss: 0.2025, Test Loss: 0.3211, Train Accuracy: 64.4836, Test Accuracy: 62.1212, Avg. duration: 0.0276 s\n",
      "Epoch: 2693, Train Loss: 0.2025, Test Loss: 0.3211, Train Accuracy: 64.4836, Test Accuracy: 62.1212, Avg. duration: 0.0278 s\n",
      "Epoch: 2694, Train Loss: 0.2025, Test Loss: 0.3211, Train Accuracy: 64.4836, Test Accuracy: 62.1212, Avg. duration: 0.0277 s\n",
      "Epoch: 2695, Train Loss: 0.2025, Test Loss: 0.3211, Train Accuracy: 64.4836, Test Accuracy: 62.1212, Avg. duration: 0.0284 s\n",
      "Epoch: 2696, Train Loss: 0.2025, Test Loss: 0.3211, Train Accuracy: 64.4836, Test Accuracy: 62.1212, Avg. duration: 0.0279 s\n",
      "Epoch: 2697, Train Loss: 0.2025, Test Loss: 0.3211, Train Accuracy: 64.4836, Test Accuracy: 62.1212, Avg. duration: 0.0279 s\n",
      "Epoch: 2698, Train Loss: 0.2025, Test Loss: 0.3211, Train Accuracy: 64.4836, Test Accuracy: 62.1212, Avg. duration: 0.0275 s\n",
      "Epoch: 2699, Train Loss: 0.2025, Test Loss: 0.3211, Train Accuracy: 64.4836, Test Accuracy: 62.1212, Avg. duration: 0.0278 s\n",
      "Epoch: 2700, Train Loss: 0.2025, Test Loss: 0.3211, Train Accuracy: 64.4836, Test Accuracy: 62.1212, Avg. duration: 0.0278 s\n",
      "Epoch: 2701, Train Loss: 0.2013, Test Loss: 0.3246, Train Accuracy: 64.6096, Test Accuracy: 61.1111, Avg. duration: 2.7279 s\n",
      "Epoch: 2702, Train Loss: 0.2013, Test Loss: 0.3246, Train Accuracy: 64.6096, Test Accuracy: 61.1111, Avg. duration: 0.0286 s\n",
      "Epoch: 2703, Train Loss: 0.2013, Test Loss: 0.3246, Train Accuracy: 64.6096, Test Accuracy: 61.1111, Avg. duration: 0.0278 s\n",
      "Epoch: 2704, Train Loss: 0.2013, Test Loss: 0.3246, Train Accuracy: 64.6096, Test Accuracy: 61.1111, Avg. duration: 0.0269 s\n",
      "Epoch: 2705, Train Loss: 0.2013, Test Loss: 0.3246, Train Accuracy: 64.6096, Test Accuracy: 61.1111, Avg. duration: 0.0271 s\n",
      "Epoch: 2706, Train Loss: 0.2013, Test Loss: 0.3246, Train Accuracy: 64.6096, Test Accuracy: 61.1111, Avg. duration: 0.0271 s\n",
      "Epoch: 2707, Train Loss: 0.2013, Test Loss: 0.3246, Train Accuracy: 64.6096, Test Accuracy: 61.1111, Avg. duration: 0.0272 s\n",
      "Epoch: 2708, Train Loss: 0.2013, Test Loss: 0.3246, Train Accuracy: 64.6096, Test Accuracy: 61.1111, Avg. duration: 0.0272 s\n",
      "Epoch: 2709, Train Loss: 0.2013, Test Loss: 0.3246, Train Accuracy: 64.6096, Test Accuracy: 61.1111, Avg. duration: 0.0286 s\n",
      "Epoch: 2710, Train Loss: 0.2013, Test Loss: 0.3246, Train Accuracy: 64.6096, Test Accuracy: 61.1111, Avg. duration: 0.0273 s\n",
      "Epoch: 2711, Train Loss: 0.2013, Test Loss: 0.3246, Train Accuracy: 64.6096, Test Accuracy: 61.1111, Avg. duration: 0.0270 s\n",
      "Epoch: 2712, Train Loss: 0.2013, Test Loss: 0.3246, Train Accuracy: 64.6096, Test Accuracy: 61.1111, Avg. duration: 0.0272 s\n",
      "Epoch: 2713, Train Loss: 0.2013, Test Loss: 0.3246, Train Accuracy: 64.6096, Test Accuracy: 61.1111, Avg. duration: 0.0272 s\n",
      "Epoch: 2714, Train Loss: 0.2013, Test Loss: 0.3246, Train Accuracy: 64.6096, Test Accuracy: 61.1111, Avg. duration: 0.0270 s\n",
      "Epoch: 2715, Train Loss: 0.2013, Test Loss: 0.3246, Train Accuracy: 64.6096, Test Accuracy: 61.1111, Avg. duration: 0.0275 s\n",
      "Epoch: 2716, Train Loss: 0.2013, Test Loss: 0.3246, Train Accuracy: 64.6096, Test Accuracy: 61.1111, Avg. duration: 0.0270 s\n",
      "Epoch: 2717, Train Loss: 0.2013, Test Loss: 0.3246, Train Accuracy: 64.6096, Test Accuracy: 61.1111, Avg. duration: 0.0277 s\n",
      "Epoch: 2718, Train Loss: 0.2013, Test Loss: 0.3246, Train Accuracy: 64.6096, Test Accuracy: 61.1111, Avg. duration: 0.0275 s\n",
      "Epoch: 2719, Train Loss: 0.2013, Test Loss: 0.3246, Train Accuracy: 64.6096, Test Accuracy: 61.1111, Avg. duration: 0.0271 s\n",
      "Epoch: 2720, Train Loss: 0.2013, Test Loss: 0.3246, Train Accuracy: 64.6096, Test Accuracy: 61.1111, Avg. duration: 0.0277 s\n",
      "Epoch: 2721, Train Loss: 0.2013, Test Loss: 0.3246, Train Accuracy: 64.6096, Test Accuracy: 61.1111, Avg. duration: 0.0276 s\n",
      "Epoch: 2722, Train Loss: 0.2013, Test Loss: 0.3246, Train Accuracy: 64.6096, Test Accuracy: 61.1111, Avg. duration: 0.0270 s\n",
      "Epoch: 2723, Train Loss: 0.2013, Test Loss: 0.3246, Train Accuracy: 64.6096, Test Accuracy: 61.1111, Avg. duration: 0.0267 s\n",
      "Epoch: 2724, Train Loss: 0.2013, Test Loss: 0.3246, Train Accuracy: 64.6096, Test Accuracy: 61.1111, Avg. duration: 0.0267 s\n",
      "Epoch: 2725, Train Loss: 0.2013, Test Loss: 0.3246, Train Accuracy: 64.6096, Test Accuracy: 61.1111, Avg. duration: 0.0276 s\n",
      "Epoch: 2726, Train Loss: 0.2013, Test Loss: 0.3246, Train Accuracy: 64.6096, Test Accuracy: 61.1111, Avg. duration: 0.0277 s\n",
      "Epoch: 2727, Train Loss: 0.2013, Test Loss: 0.3246, Train Accuracy: 64.6096, Test Accuracy: 61.1111, Avg. duration: 0.0276 s\n",
      "Epoch: 2728, Train Loss: 0.2013, Test Loss: 0.3246, Train Accuracy: 64.6096, Test Accuracy: 61.1111, Avg. duration: 0.0272 s\n",
      "Epoch: 2729, Train Loss: 0.2013, Test Loss: 0.3246, Train Accuracy: 64.6096, Test Accuracy: 61.1111, Avg. duration: 0.0268 s\n",
      "Epoch: 2730, Train Loss: 0.2013, Test Loss: 0.3246, Train Accuracy: 64.6096, Test Accuracy: 61.1111, Avg. duration: 0.0271 s\n",
      "Epoch: 2731, Train Loss: 0.2013, Test Loss: 0.3246, Train Accuracy: 64.6096, Test Accuracy: 61.1111, Avg. duration: 0.0271 s\n",
      "Epoch: 2732, Train Loss: 0.2013, Test Loss: 0.3246, Train Accuracy: 64.6096, Test Accuracy: 61.1111, Avg. duration: 0.0274 s\n",
      "Epoch: 2733, Train Loss: 0.2013, Test Loss: 0.3246, Train Accuracy: 64.6096, Test Accuracy: 61.1111, Avg. duration: 0.0282 s\n",
      "Epoch: 2734, Train Loss: 0.2013, Test Loss: 0.3246, Train Accuracy: 64.6096, Test Accuracy: 61.1111, Avg. duration: 0.0273 s\n",
      "Epoch: 2735, Train Loss: 0.2013, Test Loss: 0.3246, Train Accuracy: 64.6096, Test Accuracy: 61.1111, Avg. duration: 0.0272 s\n",
      "Epoch: 2736, Train Loss: 0.2013, Test Loss: 0.3246, Train Accuracy: 64.6096, Test Accuracy: 61.1111, Avg. duration: 0.0269 s\n",
      "Epoch: 2737, Train Loss: 0.2013, Test Loss: 0.3246, Train Accuracy: 64.6096, Test Accuracy: 61.1111, Avg. duration: 0.0275 s\n",
      "Epoch: 2738, Train Loss: 0.2013, Test Loss: 0.3246, Train Accuracy: 64.6096, Test Accuracy: 61.1111, Avg. duration: 0.0271 s\n",
      "Epoch: 2739, Train Loss: 0.2013, Test Loss: 0.3246, Train Accuracy: 64.6096, Test Accuracy: 61.1111, Avg. duration: 0.0275 s\n",
      "Epoch: 2740, Train Loss: 0.2013, Test Loss: 0.3246, Train Accuracy: 64.6096, Test Accuracy: 61.1111, Avg. duration: 0.0271 s\n",
      "Epoch: 2741, Train Loss: 0.2013, Test Loss: 0.3246, Train Accuracy: 64.6096, Test Accuracy: 61.1111, Avg. duration: 0.0271 s\n",
      "Epoch: 2742, Train Loss: 0.2013, Test Loss: 0.3246, Train Accuracy: 64.6096, Test Accuracy: 61.1111, Avg. duration: 0.0276 s\n",
      "Epoch: 2743, Train Loss: 0.2013, Test Loss: 0.3246, Train Accuracy: 64.6096, Test Accuracy: 61.1111, Avg. duration: 0.0290 s\n",
      "Epoch: 2744, Train Loss: 0.2013, Test Loss: 0.3246, Train Accuracy: 64.6096, Test Accuracy: 61.1111, Avg. duration: 0.0283 s\n",
      "Epoch: 2745, Train Loss: 0.2013, Test Loss: 0.3246, Train Accuracy: 64.6096, Test Accuracy: 61.1111, Avg. duration: 0.0280 s\n",
      "Epoch: 2746, Train Loss: 0.2013, Test Loss: 0.3246, Train Accuracy: 64.6096, Test Accuracy: 61.1111, Avg. duration: 0.0273 s\n",
      "Epoch: 2747, Train Loss: 0.2013, Test Loss: 0.3246, Train Accuracy: 64.6096, Test Accuracy: 61.1111, Avg. duration: 0.0272 s\n",
      "Epoch: 2748, Train Loss: 0.2013, Test Loss: 0.3246, Train Accuracy: 64.6096, Test Accuracy: 61.1111, Avg. duration: 0.0272 s\n",
      "Epoch: 2749, Train Loss: 0.2013, Test Loss: 0.3246, Train Accuracy: 64.6096, Test Accuracy: 61.1111, Avg. duration: 0.0279 s\n",
      "Epoch: 2750, Train Loss: 0.2013, Test Loss: 0.3246, Train Accuracy: 64.6096, Test Accuracy: 61.1111, Avg. duration: 0.0277 s\n",
      "Epoch: 2751, Train Loss: 0.2013, Test Loss: 0.3246, Train Accuracy: 64.6096, Test Accuracy: 61.1111, Avg. duration: 0.0274 s\n",
      "Epoch: 2752, Train Loss: 0.2013, Test Loss: 0.3246, Train Accuracy: 64.6096, Test Accuracy: 61.1111, Avg. duration: 0.0269 s\n",
      "Epoch: 2753, Train Loss: 0.2013, Test Loss: 0.3246, Train Accuracy: 64.6096, Test Accuracy: 61.1111, Avg. duration: 0.0271 s\n",
      "Epoch: 2754, Train Loss: 0.2013, Test Loss: 0.3246, Train Accuracy: 64.6096, Test Accuracy: 61.1111, Avg. duration: 0.0272 s\n",
      "Epoch: 2755, Train Loss: 0.2013, Test Loss: 0.3246, Train Accuracy: 64.6096, Test Accuracy: 61.1111, Avg. duration: 0.3089 s\n",
      "Epoch: 2756, Train Loss: 0.2013, Test Loss: 0.3246, Train Accuracy: 64.6096, Test Accuracy: 61.1111, Avg. duration: 0.0287 s\n",
      "Epoch: 2757, Train Loss: 0.2013, Test Loss: 0.3246, Train Accuracy: 64.6096, Test Accuracy: 61.1111, Avg. duration: 0.0282 s\n",
      "Epoch: 2758, Train Loss: 0.2013, Test Loss: 0.3246, Train Accuracy: 64.6096, Test Accuracy: 61.1111, Avg. duration: 0.0277 s\n",
      "Epoch: 2759, Train Loss: 0.2013, Test Loss: 0.3246, Train Accuracy: 64.6096, Test Accuracy: 61.1111, Avg. duration: 0.0275 s\n",
      "Epoch: 2760, Train Loss: 0.2013, Test Loss: 0.3246, Train Accuracy: 64.6096, Test Accuracy: 61.1111, Avg. duration: 0.0275 s\n",
      "Epoch: 2761, Train Loss: 0.2013, Test Loss: 0.3246, Train Accuracy: 64.6096, Test Accuracy: 61.1111, Avg. duration: 0.0280 s\n",
      "Epoch: 2762, Train Loss: 0.2013, Test Loss: 0.3246, Train Accuracy: 64.6096, Test Accuracy: 61.1111, Avg. duration: 0.0280 s\n",
      "Epoch: 2763, Train Loss: 0.2013, Test Loss: 0.3246, Train Accuracy: 64.6096, Test Accuracy: 61.1111, Avg. duration: 0.0287 s\n",
      "Epoch: 2764, Train Loss: 0.2013, Test Loss: 0.3246, Train Accuracy: 64.6096, Test Accuracy: 61.1111, Avg. duration: 0.0276 s\n",
      "Epoch: 2765, Train Loss: 0.2013, Test Loss: 0.3246, Train Accuracy: 64.6096, Test Accuracy: 61.1111, Avg. duration: 0.0276 s\n",
      "Epoch: 2766, Train Loss: 0.2013, Test Loss: 0.3246, Train Accuracy: 64.6096, Test Accuracy: 61.1111, Avg. duration: 0.0278 s\n",
      "Epoch: 2767, Train Loss: 0.2013, Test Loss: 0.3246, Train Accuracy: 64.6096, Test Accuracy: 61.1111, Avg. duration: 0.0279 s\n",
      "Epoch: 2768, Train Loss: 0.2013, Test Loss: 0.3246, Train Accuracy: 64.6096, Test Accuracy: 61.1111, Avg. duration: 0.0280 s\n",
      "Epoch: 2769, Train Loss: 0.2013, Test Loss: 0.3246, Train Accuracy: 64.6096, Test Accuracy: 61.1111, Avg. duration: 0.0278 s\n",
      "Epoch: 2770, Train Loss: 0.2013, Test Loss: 0.3246, Train Accuracy: 64.6096, Test Accuracy: 61.1111, Avg. duration: 0.0273 s\n",
      "Epoch: 2771, Train Loss: 0.2013, Test Loss: 0.3246, Train Accuracy: 64.6096, Test Accuracy: 61.1111, Avg. duration: 0.0280 s\n",
      "Epoch: 2772, Train Loss: 0.2013, Test Loss: 0.3246, Train Accuracy: 64.6096, Test Accuracy: 61.1111, Avg. duration: 0.0277 s\n",
      "Epoch: 2773, Train Loss: 0.2013, Test Loss: 0.3246, Train Accuracy: 64.6096, Test Accuracy: 61.1111, Avg. duration: 0.0276 s\n",
      "Epoch: 2774, Train Loss: 0.2013, Test Loss: 0.3246, Train Accuracy: 64.6096, Test Accuracy: 61.1111, Avg. duration: 0.0278 s\n",
      "Epoch: 2775, Train Loss: 0.2013, Test Loss: 0.3246, Train Accuracy: 64.6096, Test Accuracy: 61.1111, Avg. duration: 0.0278 s\n",
      "Epoch: 2776, Train Loss: 0.2013, Test Loss: 0.3246, Train Accuracy: 64.6096, Test Accuracy: 61.1111, Avg. duration: 0.0276 s\n",
      "Epoch: 2777, Train Loss: 0.2013, Test Loss: 0.3246, Train Accuracy: 64.6096, Test Accuracy: 61.1111, Avg. duration: 0.0279 s\n",
      "Epoch: 2778, Train Loss: 0.2013, Test Loss: 0.3246, Train Accuracy: 64.6096, Test Accuracy: 61.1111, Avg. duration: 0.0277 s\n",
      "Epoch: 2779, Train Loss: 0.2013, Test Loss: 0.3246, Train Accuracy: 64.6096, Test Accuracy: 61.1111, Avg. duration: 0.0284 s\n",
      "Epoch: 2780, Train Loss: 0.2013, Test Loss: 0.3246, Train Accuracy: 64.6096, Test Accuracy: 61.1111, Avg. duration: 0.0278 s\n",
      "Epoch: 2781, Train Loss: 0.2013, Test Loss: 0.3246, Train Accuracy: 64.6096, Test Accuracy: 61.1111, Avg. duration: 0.0278 s\n",
      "Epoch: 2782, Train Loss: 0.2013, Test Loss: 0.3246, Train Accuracy: 64.6096, Test Accuracy: 61.1111, Avg. duration: 0.0278 s\n",
      "Epoch: 2783, Train Loss: 0.2013, Test Loss: 0.3246, Train Accuracy: 64.6096, Test Accuracy: 61.1111, Avg. duration: 0.0278 s\n",
      "Epoch: 2784, Train Loss: 0.2013, Test Loss: 0.3246, Train Accuracy: 64.6096, Test Accuracy: 61.1111, Avg. duration: 0.0276 s\n",
      "Epoch: 2785, Train Loss: 0.2013, Test Loss: 0.3246, Train Accuracy: 64.6096, Test Accuracy: 61.1111, Avg. duration: 0.0278 s\n",
      "Epoch: 2786, Train Loss: 0.2013, Test Loss: 0.3246, Train Accuracy: 64.6096, Test Accuracy: 61.1111, Avg. duration: 0.0279 s\n",
      "Epoch: 2787, Train Loss: 0.2013, Test Loss: 0.3246, Train Accuracy: 64.6096, Test Accuracy: 61.1111, Avg. duration: 0.0288 s\n",
      "Epoch: 2788, Train Loss: 0.2013, Test Loss: 0.3246, Train Accuracy: 64.6096, Test Accuracy: 61.1111, Avg. duration: 0.0275 s\n",
      "Epoch: 2789, Train Loss: 0.2013, Test Loss: 0.3246, Train Accuracy: 64.6096, Test Accuracy: 61.1111, Avg. duration: 0.0278 s\n",
      "Epoch: 2790, Train Loss: 0.2013, Test Loss: 0.3246, Train Accuracy: 64.6096, Test Accuracy: 61.1111, Avg. duration: 0.0278 s\n",
      "Epoch: 2791, Train Loss: 0.2013, Test Loss: 0.3246, Train Accuracy: 64.6096, Test Accuracy: 61.1111, Avg. duration: 0.0276 s\n",
      "Epoch: 2792, Train Loss: 0.2013, Test Loss: 0.3246, Train Accuracy: 64.6096, Test Accuracy: 61.1111, Avg. duration: 0.0278 s\n",
      "Epoch: 2793, Train Loss: 0.2013, Test Loss: 0.3246, Train Accuracy: 64.6096, Test Accuracy: 61.1111, Avg. duration: 0.0281 s\n",
      "Epoch: 2794, Train Loss: 0.2013, Test Loss: 0.3246, Train Accuracy: 64.6096, Test Accuracy: 61.1111, Avg. duration: 0.0274 s\n",
      "Epoch: 2795, Train Loss: 0.2013, Test Loss: 0.3246, Train Accuracy: 64.6096, Test Accuracy: 61.1111, Avg. duration: 0.0281 s\n",
      "Epoch: 2796, Train Loss: 0.2013, Test Loss: 0.3246, Train Accuracy: 64.6096, Test Accuracy: 61.1111, Avg. duration: 0.0274 s\n",
      "Epoch: 2797, Train Loss: 0.2013, Test Loss: 0.3246, Train Accuracy: 64.6096, Test Accuracy: 61.1111, Avg. duration: 0.0275 s\n",
      "Epoch: 2798, Train Loss: 0.2013, Test Loss: 0.3246, Train Accuracy: 64.6096, Test Accuracy: 61.1111, Avg. duration: 0.0282 s\n",
      "Epoch: 2799, Train Loss: 0.2013, Test Loss: 0.3246, Train Accuracy: 64.6096, Test Accuracy: 61.1111, Avg. duration: 0.0278 s\n",
      "Epoch: 2800, Train Loss: 0.2013, Test Loss: 0.3246, Train Accuracy: 64.6096, Test Accuracy: 61.1111, Avg. duration: 0.0276 s\n",
      "Epoch: 2801, Train Loss: 0.1989, Test Loss: 0.3296, Train Accuracy: 64.2317, Test Accuracy: 62.6263, Avg. duration: 2.7291 s\n",
      "Epoch: 2802, Train Loss: 0.1989, Test Loss: 0.3296, Train Accuracy: 64.2317, Test Accuracy: 62.6263, Avg. duration: 0.0285 s\n",
      "Epoch: 2803, Train Loss: 0.1989, Test Loss: 0.3296, Train Accuracy: 64.2317, Test Accuracy: 62.6263, Avg. duration: 0.0275 s\n",
      "Epoch: 2804, Train Loss: 0.1989, Test Loss: 0.3296, Train Accuracy: 64.2317, Test Accuracy: 62.6263, Avg. duration: 0.0278 s\n",
      "Epoch: 2805, Train Loss: 0.1989, Test Loss: 0.3296, Train Accuracy: 64.2317, Test Accuracy: 62.6263, Avg. duration: 0.0274 s\n",
      "Epoch: 2806, Train Loss: 0.1989, Test Loss: 0.3296, Train Accuracy: 64.2317, Test Accuracy: 62.6263, Avg. duration: 0.0271 s\n",
      "Epoch: 2807, Train Loss: 0.1989, Test Loss: 0.3296, Train Accuracy: 64.2317, Test Accuracy: 62.6263, Avg. duration: 0.0269 s\n",
      "Epoch: 2808, Train Loss: 0.1989, Test Loss: 0.3296, Train Accuracy: 64.2317, Test Accuracy: 62.6263, Avg. duration: 0.0274 s\n",
      "Epoch: 2809, Train Loss: 0.1989, Test Loss: 0.3296, Train Accuracy: 64.2317, Test Accuracy: 62.6263, Avg. duration: 0.0280 s\n",
      "Epoch: 2810, Train Loss: 0.1989, Test Loss: 0.3296, Train Accuracy: 64.2317, Test Accuracy: 62.6263, Avg. duration: 0.0278 s\n",
      "Epoch: 2811, Train Loss: 0.1989, Test Loss: 0.3296, Train Accuracy: 64.2317, Test Accuracy: 62.6263, Avg. duration: 0.0272 s\n",
      "Epoch: 2812, Train Loss: 0.1989, Test Loss: 0.3296, Train Accuracy: 64.2317, Test Accuracy: 62.6263, Avg. duration: 0.0269 s\n",
      "Epoch: 2813, Train Loss: 0.1989, Test Loss: 0.3296, Train Accuracy: 64.2317, Test Accuracy: 62.6263, Avg. duration: 0.0271 s\n",
      "Epoch: 2814, Train Loss: 0.1989, Test Loss: 0.3296, Train Accuracy: 64.2317, Test Accuracy: 62.6263, Avg. duration: 0.0273 s\n",
      "Epoch: 2815, Train Loss: 0.1989, Test Loss: 0.3296, Train Accuracy: 64.2317, Test Accuracy: 62.6263, Avg. duration: 0.0271 s\n",
      "Epoch: 2816, Train Loss: 0.1989, Test Loss: 0.3296, Train Accuracy: 64.2317, Test Accuracy: 62.6263, Avg. duration: 0.0271 s\n",
      "Epoch: 2817, Train Loss: 0.1989, Test Loss: 0.3296, Train Accuracy: 64.2317, Test Accuracy: 62.6263, Avg. duration: 0.0275 s\n",
      "Epoch: 2818, Train Loss: 0.1989, Test Loss: 0.3296, Train Accuracy: 64.2317, Test Accuracy: 62.6263, Avg. duration: 0.0275 s\n",
      "Epoch: 2819, Train Loss: 0.1989, Test Loss: 0.3296, Train Accuracy: 64.2317, Test Accuracy: 62.6263, Avg. duration: 0.0271 s\n",
      "Epoch: 2820, Train Loss: 0.1989, Test Loss: 0.3296, Train Accuracy: 64.2317, Test Accuracy: 62.6263, Avg. duration: 0.0273 s\n",
      "Epoch: 2821, Train Loss: 0.1989, Test Loss: 0.3296, Train Accuracy: 64.2317, Test Accuracy: 62.6263, Avg. duration: 0.0274 s\n",
      "Epoch: 2822, Train Loss: 0.1989, Test Loss: 0.3296, Train Accuracy: 64.2317, Test Accuracy: 62.6263, Avg. duration: 0.3138 s\n",
      "Epoch: 2823, Train Loss: 0.1989, Test Loss: 0.3296, Train Accuracy: 64.2317, Test Accuracy: 62.6263, Avg. duration: 0.0283 s\n",
      "Epoch: 2824, Train Loss: 0.1989, Test Loss: 0.3296, Train Accuracy: 64.2317, Test Accuracy: 62.6263, Avg. duration: 0.0276 s\n",
      "Epoch: 2825, Train Loss: 0.1989, Test Loss: 0.3296, Train Accuracy: 64.2317, Test Accuracy: 62.6263, Avg. duration: 0.0271 s\n",
      "Epoch: 2826, Train Loss: 0.1989, Test Loss: 0.3296, Train Accuracy: 64.2317, Test Accuracy: 62.6263, Avg. duration: 0.0271 s\n",
      "Epoch: 2827, Train Loss: 0.1989, Test Loss: 0.3296, Train Accuracy: 64.2317, Test Accuracy: 62.6263, Avg. duration: 0.0274 s\n",
      "Epoch: 2828, Train Loss: 0.1989, Test Loss: 0.3296, Train Accuracy: 64.2317, Test Accuracy: 62.6263, Avg. duration: 0.0275 s\n",
      "Epoch: 2829, Train Loss: 0.1989, Test Loss: 0.3296, Train Accuracy: 64.2317, Test Accuracy: 62.6263, Avg. duration: 0.0270 s\n",
      "Epoch: 2830, Train Loss: 0.1989, Test Loss: 0.3296, Train Accuracy: 64.2317, Test Accuracy: 62.6263, Avg. duration: 0.0275 s\n",
      "Epoch: 2831, Train Loss: 0.1989, Test Loss: 0.3296, Train Accuracy: 64.2317, Test Accuracy: 62.6263, Avg. duration: 0.0273 s\n",
      "Epoch: 2832, Train Loss: 0.1989, Test Loss: 0.3296, Train Accuracy: 64.2317, Test Accuracy: 62.6263, Avg. duration: 0.0273 s\n",
      "Epoch: 2833, Train Loss: 0.1989, Test Loss: 0.3296, Train Accuracy: 64.2317, Test Accuracy: 62.6263, Avg. duration: 0.0275 s\n",
      "Epoch: 2834, Train Loss: 0.1989, Test Loss: 0.3296, Train Accuracy: 64.2317, Test Accuracy: 62.6263, Avg. duration: 0.0279 s\n",
      "Epoch: 2835, Train Loss: 0.1989, Test Loss: 0.3296, Train Accuracy: 64.2317, Test Accuracy: 62.6263, Avg. duration: 0.0270 s\n",
      "Epoch: 2836, Train Loss: 0.1989, Test Loss: 0.3296, Train Accuracy: 64.2317, Test Accuracy: 62.6263, Avg. duration: 0.0274 s\n",
      "Epoch: 2837, Train Loss: 0.1989, Test Loss: 0.3296, Train Accuracy: 64.2317, Test Accuracy: 62.6263, Avg. duration: 0.0275 s\n",
      "Epoch: 2838, Train Loss: 0.1989, Test Loss: 0.3296, Train Accuracy: 64.2317, Test Accuracy: 62.6263, Avg. duration: 0.0282 s\n",
      "Epoch: 2839, Train Loss: 0.1989, Test Loss: 0.3296, Train Accuracy: 64.2317, Test Accuracy: 62.6263, Avg. duration: 0.0277 s\n",
      "Epoch: 2840, Train Loss: 0.1989, Test Loss: 0.3296, Train Accuracy: 64.2317, Test Accuracy: 62.6263, Avg. duration: 0.0278 s\n",
      "Epoch: 2841, Train Loss: 0.1989, Test Loss: 0.3296, Train Accuracy: 64.2317, Test Accuracy: 62.6263, Avg. duration: 0.0270 s\n",
      "Epoch: 2842, Train Loss: 0.1989, Test Loss: 0.3296, Train Accuracy: 64.2317, Test Accuracy: 62.6263, Avg. duration: 0.0273 s\n",
      "Epoch: 2843, Train Loss: 0.1989, Test Loss: 0.3296, Train Accuracy: 64.2317, Test Accuracy: 62.6263, Avg. duration: 0.0286 s\n",
      "Epoch: 2844, Train Loss: 0.1989, Test Loss: 0.3296, Train Accuracy: 64.2317, Test Accuracy: 62.6263, Avg. duration: 0.0280 s\n",
      "Epoch: 2845, Train Loss: 0.1989, Test Loss: 0.3296, Train Accuracy: 64.2317, Test Accuracy: 62.6263, Avg. duration: 0.0279 s\n",
      "Epoch: 2846, Train Loss: 0.1989, Test Loss: 0.3296, Train Accuracy: 64.2317, Test Accuracy: 62.6263, Avg. duration: 0.0282 s\n",
      "Epoch: 2847, Train Loss: 0.1989, Test Loss: 0.3296, Train Accuracy: 64.2317, Test Accuracy: 62.6263, Avg. duration: 0.0273 s\n",
      "Epoch: 2848, Train Loss: 0.1989, Test Loss: 0.3296, Train Accuracy: 64.2317, Test Accuracy: 62.6263, Avg. duration: 0.0272 s\n",
      "Epoch: 2849, Train Loss: 0.1989, Test Loss: 0.3296, Train Accuracy: 64.2317, Test Accuracy: 62.6263, Avg. duration: 0.0273 s\n",
      "Epoch: 2850, Train Loss: 0.1989, Test Loss: 0.3296, Train Accuracy: 64.2317, Test Accuracy: 62.6263, Avg. duration: 0.0274 s\n",
      "Epoch: 2851, Train Loss: 0.1989, Test Loss: 0.3296, Train Accuracy: 64.2317, Test Accuracy: 62.6263, Avg. duration: 0.0275 s\n",
      "Epoch: 2852, Train Loss: 0.1989, Test Loss: 0.3296, Train Accuracy: 64.2317, Test Accuracy: 62.6263, Avg. duration: 0.0279 s\n",
      "Epoch: 2853, Train Loss: 0.1989, Test Loss: 0.3296, Train Accuracy: 64.2317, Test Accuracy: 62.6263, Avg. duration: 0.0270 s\n",
      "Epoch: 2854, Train Loss: 0.1989, Test Loss: 0.3296, Train Accuracy: 64.2317, Test Accuracy: 62.6263, Avg. duration: 0.0278 s\n",
      "Epoch: 2855, Train Loss: 0.1989, Test Loss: 0.3296, Train Accuracy: 64.2317, Test Accuracy: 62.6263, Avg. duration: 0.0272 s\n",
      "Epoch: 2856, Train Loss: 0.1989, Test Loss: 0.3296, Train Accuracy: 64.2317, Test Accuracy: 62.6263, Avg. duration: 0.0275 s\n",
      "Epoch: 2857, Train Loss: 0.1989, Test Loss: 0.3296, Train Accuracy: 64.2317, Test Accuracy: 62.6263, Avg. duration: 0.0277 s\n",
      "Epoch: 2858, Train Loss: 0.1989, Test Loss: 0.3296, Train Accuracy: 64.2317, Test Accuracy: 62.6263, Avg. duration: 0.0277 s\n",
      "Epoch: 2859, Train Loss: 0.1989, Test Loss: 0.3296, Train Accuracy: 64.2317, Test Accuracy: 62.6263, Avg. duration: 0.0277 s\n",
      "Epoch: 2860, Train Loss: 0.1989, Test Loss: 0.3296, Train Accuracy: 64.2317, Test Accuracy: 62.6263, Avg. duration: 0.0271 s\n",
      "Epoch: 2861, Train Loss: 0.1989, Test Loss: 0.3296, Train Accuracy: 64.2317, Test Accuracy: 62.6263, Avg. duration: 0.0275 s\n",
      "Epoch: 2862, Train Loss: 0.1989, Test Loss: 0.3296, Train Accuracy: 64.2317, Test Accuracy: 62.6263, Avg. duration: 0.0278 s\n",
      "Epoch: 2863, Train Loss: 0.1989, Test Loss: 0.3296, Train Accuracy: 64.2317, Test Accuracy: 62.6263, Avg. duration: 0.0277 s\n",
      "Epoch: 2864, Train Loss: 0.1989, Test Loss: 0.3296, Train Accuracy: 64.2317, Test Accuracy: 62.6263, Avg. duration: 0.0278 s\n",
      "Epoch: 2865, Train Loss: 0.1989, Test Loss: 0.3296, Train Accuracy: 64.2317, Test Accuracy: 62.6263, Avg. duration: 0.0274 s\n",
      "Epoch: 2866, Train Loss: 0.1989, Test Loss: 0.3296, Train Accuracy: 64.2317, Test Accuracy: 62.6263, Avg. duration: 0.0275 s\n",
      "Epoch: 2867, Train Loss: 0.1989, Test Loss: 0.3296, Train Accuracy: 64.2317, Test Accuracy: 62.6263, Avg. duration: 0.0276 s\n",
      "Epoch: 2868, Train Loss: 0.1989, Test Loss: 0.3296, Train Accuracy: 64.2317, Test Accuracy: 62.6263, Avg. duration: 0.0275 s\n",
      "Epoch: 2869, Train Loss: 0.1989, Test Loss: 0.3296, Train Accuracy: 64.2317, Test Accuracy: 62.6263, Avg. duration: 0.0277 s\n",
      "Epoch: 2870, Train Loss: 0.1989, Test Loss: 0.3296, Train Accuracy: 64.2317, Test Accuracy: 62.6263, Avg. duration: 0.0282 s\n",
      "Epoch: 2871, Train Loss: 0.1989, Test Loss: 0.3296, Train Accuracy: 64.2317, Test Accuracy: 62.6263, Avg. duration: 0.0275 s\n",
      "Epoch: 2872, Train Loss: 0.1989, Test Loss: 0.3296, Train Accuracy: 64.2317, Test Accuracy: 62.6263, Avg. duration: 0.0275 s\n",
      "Epoch: 2873, Train Loss: 0.1989, Test Loss: 0.3296, Train Accuracy: 64.2317, Test Accuracy: 62.6263, Avg. duration: 0.0275 s\n",
      "Epoch: 2874, Train Loss: 0.1989, Test Loss: 0.3296, Train Accuracy: 64.2317, Test Accuracy: 62.6263, Avg. duration: 0.0275 s\n",
      "Epoch: 2875, Train Loss: 0.1989, Test Loss: 0.3296, Train Accuracy: 64.2317, Test Accuracy: 62.6263, Avg. duration: 0.0275 s\n",
      "Epoch: 2876, Train Loss: 0.1989, Test Loss: 0.3296, Train Accuracy: 64.2317, Test Accuracy: 62.6263, Avg. duration: 0.0278 s\n",
      "Epoch: 2877, Train Loss: 0.1989, Test Loss: 0.3296, Train Accuracy: 64.2317, Test Accuracy: 62.6263, Avg. duration: 0.0272 s\n",
      "Epoch: 2878, Train Loss: 0.1989, Test Loss: 0.3296, Train Accuracy: 64.2317, Test Accuracy: 62.6263, Avg. duration: 0.0281 s\n",
      "Epoch: 2879, Train Loss: 0.1989, Test Loss: 0.3296, Train Accuracy: 64.2317, Test Accuracy: 62.6263, Avg. duration: 0.0278 s\n",
      "Epoch: 2880, Train Loss: 0.1989, Test Loss: 0.3296, Train Accuracy: 64.2317, Test Accuracy: 62.6263, Avg. duration: 0.0277 s\n",
      "Epoch: 2881, Train Loss: 0.1989, Test Loss: 0.3296, Train Accuracy: 64.2317, Test Accuracy: 62.6263, Avg. duration: 0.0278 s\n",
      "Epoch: 2882, Train Loss: 0.1989, Test Loss: 0.3296, Train Accuracy: 64.2317, Test Accuracy: 62.6263, Avg. duration: 0.0277 s\n",
      "Epoch: 2883, Train Loss: 0.1989, Test Loss: 0.3296, Train Accuracy: 64.2317, Test Accuracy: 62.6263, Avg. duration: 0.0275 s\n",
      "Epoch: 2884, Train Loss: 0.1989, Test Loss: 0.3296, Train Accuracy: 64.2317, Test Accuracy: 62.6263, Avg. duration: 0.0273 s\n",
      "Epoch: 2885, Train Loss: 0.1989, Test Loss: 0.3296, Train Accuracy: 64.2317, Test Accuracy: 62.6263, Avg. duration: 0.0274 s\n",
      "Epoch: 2886, Train Loss: 0.1989, Test Loss: 0.3296, Train Accuracy: 64.2317, Test Accuracy: 62.6263, Avg. duration: 0.0282 s\n",
      "Epoch: 2887, Train Loss: 0.1989, Test Loss: 0.3296, Train Accuracy: 64.2317, Test Accuracy: 62.6263, Avg. duration: 0.0278 s\n",
      "Epoch: 2888, Train Loss: 0.1989, Test Loss: 0.3296, Train Accuracy: 64.2317, Test Accuracy: 62.6263, Avg. duration: 0.0279 s\n",
      "Epoch: 2889, Train Loss: 0.1989, Test Loss: 0.3296, Train Accuracy: 64.2317, Test Accuracy: 62.6263, Avg. duration: 0.0278 s\n",
      "Epoch: 2890, Train Loss: 0.1989, Test Loss: 0.3296, Train Accuracy: 64.2317, Test Accuracy: 62.6263, Avg. duration: 0.0278 s\n",
      "Epoch: 2891, Train Loss: 0.1989, Test Loss: 0.3296, Train Accuracy: 64.2317, Test Accuracy: 62.6263, Avg. duration: 0.0277 s\n",
      "Epoch: 2892, Train Loss: 0.1989, Test Loss: 0.3296, Train Accuracy: 64.2317, Test Accuracy: 62.6263, Avg. duration: 0.0280 s\n",
      "Epoch: 2893, Train Loss: 0.1989, Test Loss: 0.3296, Train Accuracy: 64.2317, Test Accuracy: 62.6263, Avg. duration: 0.0277 s\n",
      "Epoch: 2894, Train Loss: 0.1989, Test Loss: 0.3296, Train Accuracy: 64.2317, Test Accuracy: 62.6263, Avg. duration: 0.0285 s\n",
      "Epoch: 2895, Train Loss: 0.1989, Test Loss: 0.3296, Train Accuracy: 64.2317, Test Accuracy: 62.6263, Avg. duration: 0.0280 s\n",
      "Epoch: 2896, Train Loss: 0.1989, Test Loss: 0.3296, Train Accuracy: 64.2317, Test Accuracy: 62.6263, Avg. duration: 0.0276 s\n",
      "Epoch: 2897, Train Loss: 0.1989, Test Loss: 0.3296, Train Accuracy: 64.2317, Test Accuracy: 62.6263, Avg. duration: 0.0278 s\n",
      "Epoch: 2898, Train Loss: 0.1989, Test Loss: 0.3296, Train Accuracy: 64.2317, Test Accuracy: 62.6263, Avg. duration: 0.3235 s\n",
      "Epoch: 2899, Train Loss: 0.1989, Test Loss: 0.3296, Train Accuracy: 64.2317, Test Accuracy: 62.6263, Avg. duration: 0.0287 s\n",
      "Epoch: 2900, Train Loss: 0.1989, Test Loss: 0.3296, Train Accuracy: 64.2317, Test Accuracy: 62.6263, Avg. duration: 0.0281 s\n",
      "Epoch: 2901, Train Loss: 0.1973, Test Loss: 0.3293, Train Accuracy: 63.9798, Test Accuracy: 62.1212, Avg. duration: 2.7184 s\n",
      "Epoch: 2902, Train Loss: 0.1973, Test Loss: 0.3293, Train Accuracy: 63.9798, Test Accuracy: 62.1212, Avg. duration: 0.0292 s\n",
      "Epoch: 2903, Train Loss: 0.1973, Test Loss: 0.3293, Train Accuracy: 63.9798, Test Accuracy: 62.1212, Avg. duration: 0.0275 s\n",
      "Epoch: 2904, Train Loss: 0.1973, Test Loss: 0.3293, Train Accuracy: 63.9798, Test Accuracy: 62.1212, Avg. duration: 0.0288 s\n",
      "Epoch: 2905, Train Loss: 0.1973, Test Loss: 0.3293, Train Accuracy: 63.9798, Test Accuracy: 62.1212, Avg. duration: 0.0282 s\n",
      "Epoch: 2906, Train Loss: 0.1973, Test Loss: 0.3293, Train Accuracy: 63.9798, Test Accuracy: 62.1212, Avg. duration: 0.0279 s\n",
      "Epoch: 2907, Train Loss: 0.1973, Test Loss: 0.3293, Train Accuracy: 63.9798, Test Accuracy: 62.1212, Avg. duration: 0.0269 s\n",
      "Epoch: 2908, Train Loss: 0.1973, Test Loss: 0.3293, Train Accuracy: 63.9798, Test Accuracy: 62.1212, Avg. duration: 0.0271 s\n",
      "Epoch: 2909, Train Loss: 0.1973, Test Loss: 0.3293, Train Accuracy: 63.9798, Test Accuracy: 62.1212, Avg. duration: 0.0281 s\n",
      "Epoch: 2910, Train Loss: 0.1973, Test Loss: 0.3293, Train Accuracy: 63.9798, Test Accuracy: 62.1212, Avg. duration: 0.0279 s\n",
      "Epoch: 2911, Train Loss: 0.1973, Test Loss: 0.3293, Train Accuracy: 63.9798, Test Accuracy: 62.1212, Avg. duration: 0.0371 s\n",
      "Epoch: 2912, Train Loss: 0.1973, Test Loss: 0.3293, Train Accuracy: 63.9798, Test Accuracy: 62.1212, Avg. duration: 0.0275 s\n",
      "Epoch: 2913, Train Loss: 0.1973, Test Loss: 0.3293, Train Accuracy: 63.9798, Test Accuracy: 62.1212, Avg. duration: 0.0270 s\n",
      "Epoch: 2914, Train Loss: 0.1973, Test Loss: 0.3293, Train Accuracy: 63.9798, Test Accuracy: 62.1212, Avg. duration: 0.0270 s\n",
      "Epoch: 2915, Train Loss: 0.1973, Test Loss: 0.3293, Train Accuracy: 63.9798, Test Accuracy: 62.1212, Avg. duration: 0.0274 s\n",
      "Epoch: 2916, Train Loss: 0.1973, Test Loss: 0.3293, Train Accuracy: 63.9798, Test Accuracy: 62.1212, Avg. duration: 0.0276 s\n",
      "Epoch: 2917, Train Loss: 0.1973, Test Loss: 0.3293, Train Accuracy: 63.9798, Test Accuracy: 62.1212, Avg. duration: 0.0276 s\n",
      "Epoch: 2918, Train Loss: 0.1973, Test Loss: 0.3293, Train Accuracy: 63.9798, Test Accuracy: 62.1212, Avg. duration: 0.0269 s\n",
      "Epoch: 2919, Train Loss: 0.1973, Test Loss: 0.3293, Train Accuracy: 63.9798, Test Accuracy: 62.1212, Avg. duration: 0.0272 s\n",
      "Epoch: 2920, Train Loss: 0.1973, Test Loss: 0.3293, Train Accuracy: 63.9798, Test Accuracy: 62.1212, Avg. duration: 0.0271 s\n",
      "Epoch: 2921, Train Loss: 0.1973, Test Loss: 0.3293, Train Accuracy: 63.9798, Test Accuracy: 62.1212, Avg. duration: 0.0273 s\n",
      "Epoch: 2922, Train Loss: 0.1973, Test Loss: 0.3293, Train Accuracy: 63.9798, Test Accuracy: 62.1212, Avg. duration: 0.0270 s\n",
      "Epoch: 2923, Train Loss: 0.1973, Test Loss: 0.3293, Train Accuracy: 63.9798, Test Accuracy: 62.1212, Avg. duration: 0.0271 s\n",
      "Epoch: 2924, Train Loss: 0.1973, Test Loss: 0.3293, Train Accuracy: 63.9798, Test Accuracy: 62.1212, Avg. duration: 0.0276 s\n",
      "Epoch: 2925, Train Loss: 0.1973, Test Loss: 0.3293, Train Accuracy: 63.9798, Test Accuracy: 62.1212, Avg. duration: 0.0270 s\n",
      "Epoch: 2926, Train Loss: 0.1973, Test Loss: 0.3293, Train Accuracy: 63.9798, Test Accuracy: 62.1212, Avg. duration: 0.0274 s\n",
      "Epoch: 2927, Train Loss: 0.1973, Test Loss: 0.3293, Train Accuracy: 63.9798, Test Accuracy: 62.1212, Avg. duration: 0.0269 s\n",
      "Epoch: 2928, Train Loss: 0.1973, Test Loss: 0.3293, Train Accuracy: 63.9798, Test Accuracy: 62.1212, Avg. duration: 0.0274 s\n",
      "Epoch: 2929, Train Loss: 0.1973, Test Loss: 0.3293, Train Accuracy: 63.9798, Test Accuracy: 62.1212, Avg. duration: 0.0271 s\n",
      "Epoch: 2930, Train Loss: 0.1973, Test Loss: 0.3293, Train Accuracy: 63.9798, Test Accuracy: 62.1212, Avg. duration: 0.0274 s\n",
      "Epoch: 2931, Train Loss: 0.1973, Test Loss: 0.3293, Train Accuracy: 63.9798, Test Accuracy: 62.1212, Avg. duration: 0.0269 s\n",
      "Epoch: 2932, Train Loss: 0.1973, Test Loss: 0.3293, Train Accuracy: 63.9798, Test Accuracy: 62.1212, Avg. duration: 0.0274 s\n",
      "Epoch: 2933, Train Loss: 0.1973, Test Loss: 0.3293, Train Accuracy: 63.9798, Test Accuracy: 62.1212, Avg. duration: 0.0271 s\n",
      "Epoch: 2934, Train Loss: 0.1973, Test Loss: 0.3293, Train Accuracy: 63.9798, Test Accuracy: 62.1212, Avg. duration: 0.0273 s\n",
      "Epoch: 2935, Train Loss: 0.1973, Test Loss: 0.3293, Train Accuracy: 63.9798, Test Accuracy: 62.1212, Avg. duration: 0.0272 s\n",
      "Epoch: 2936, Train Loss: 0.1973, Test Loss: 0.3293, Train Accuracy: 63.9798, Test Accuracy: 62.1212, Avg. duration: 0.0273 s\n",
      "Epoch: 2937, Train Loss: 0.1973, Test Loss: 0.3293, Train Accuracy: 63.9798, Test Accuracy: 62.1212, Avg. duration: 0.0270 s\n",
      "Epoch: 2938, Train Loss: 0.1973, Test Loss: 0.3293, Train Accuracy: 63.9798, Test Accuracy: 62.1212, Avg. duration: 0.0268 s\n",
      "Epoch: 2939, Train Loss: 0.1973, Test Loss: 0.3293, Train Accuracy: 63.9798, Test Accuracy: 62.1212, Avg. duration: 0.0270 s\n",
      "Epoch: 2940, Train Loss: 0.1973, Test Loss: 0.3293, Train Accuracy: 63.9798, Test Accuracy: 62.1212, Avg. duration: 0.0275 s\n",
      "Epoch: 2941, Train Loss: 0.1973, Test Loss: 0.3293, Train Accuracy: 63.9798, Test Accuracy: 62.1212, Avg. duration: 0.0276 s\n",
      "Epoch: 2942, Train Loss: 0.1973, Test Loss: 0.3293, Train Accuracy: 63.9798, Test Accuracy: 62.1212, Avg. duration: 0.0275 s\n",
      "Epoch: 2943, Train Loss: 0.1973, Test Loss: 0.3293, Train Accuracy: 63.9798, Test Accuracy: 62.1212, Avg. duration: 0.0268 s\n",
      "Epoch: 2944, Train Loss: 0.1973, Test Loss: 0.3293, Train Accuracy: 63.9798, Test Accuracy: 62.1212, Avg. duration: 0.0270 s\n",
      "Epoch: 2945, Train Loss: 0.1973, Test Loss: 0.3293, Train Accuracy: 63.9798, Test Accuracy: 62.1212, Avg. duration: 0.0272 s\n",
      "Epoch: 2946, Train Loss: 0.1973, Test Loss: 0.3293, Train Accuracy: 63.9798, Test Accuracy: 62.1212, Avg. duration: 0.0272 s\n",
      "Epoch: 2947, Train Loss: 0.1973, Test Loss: 0.3293, Train Accuracy: 63.9798, Test Accuracy: 62.1212, Avg. duration: 0.0273 s\n",
      "Epoch: 2948, Train Loss: 0.1973, Test Loss: 0.3293, Train Accuracy: 63.9798, Test Accuracy: 62.1212, Avg. duration: 0.0272 s\n",
      "Epoch: 2949, Train Loss: 0.1973, Test Loss: 0.3293, Train Accuracy: 63.9798, Test Accuracy: 62.1212, Avg. duration: 0.0270 s\n",
      "Epoch: 2950, Train Loss: 0.1973, Test Loss: 0.3293, Train Accuracy: 63.9798, Test Accuracy: 62.1212, Avg. duration: 0.0272 s\n",
      "Epoch: 2951, Train Loss: 0.1973, Test Loss: 0.3293, Train Accuracy: 63.9798, Test Accuracy: 62.1212, Avg. duration: 0.0270 s\n",
      "Epoch: 2952, Train Loss: 0.1973, Test Loss: 0.3293, Train Accuracy: 63.9798, Test Accuracy: 62.1212, Avg. duration: 0.0274 s\n",
      "Epoch: 2953, Train Loss: 0.1973, Test Loss: 0.3293, Train Accuracy: 63.9798, Test Accuracy: 62.1212, Avg. duration: 0.0275 s\n",
      "Epoch: 2954, Train Loss: 0.1973, Test Loss: 0.3293, Train Accuracy: 63.9798, Test Accuracy: 62.1212, Avg. duration: 0.0270 s\n",
      "Epoch: 2955, Train Loss: 0.1973, Test Loss: 0.3293, Train Accuracy: 63.9798, Test Accuracy: 62.1212, Avg. duration: 0.0269 s\n",
      "Epoch: 2956, Train Loss: 0.1973, Test Loss: 0.3293, Train Accuracy: 63.9798, Test Accuracy: 62.1212, Avg. duration: 0.0276 s\n",
      "Epoch: 2957, Train Loss: 0.1973, Test Loss: 0.3293, Train Accuracy: 63.9798, Test Accuracy: 62.1212, Avg. duration: 0.0271 s\n",
      "Epoch: 2958, Train Loss: 0.1973, Test Loss: 0.3293, Train Accuracy: 63.9798, Test Accuracy: 62.1212, Avg. duration: 0.0276 s\n",
      "Epoch: 2959, Train Loss: 0.1973, Test Loss: 0.3293, Train Accuracy: 63.9798, Test Accuracy: 62.1212, Avg. duration: 0.0274 s\n",
      "Epoch: 2960, Train Loss: 0.1973, Test Loss: 0.3293, Train Accuracy: 63.9798, Test Accuracy: 62.1212, Avg. duration: 0.0272 s\n",
      "Epoch: 2961, Train Loss: 0.1973, Test Loss: 0.3293, Train Accuracy: 63.9798, Test Accuracy: 62.1212, Avg. duration: 0.0267 s\n",
      "Epoch: 2962, Train Loss: 0.1973, Test Loss: 0.3293, Train Accuracy: 63.9798, Test Accuracy: 62.1212, Avg. duration: 0.0273 s\n",
      "Epoch: 2963, Train Loss: 0.1973, Test Loss: 0.3293, Train Accuracy: 63.9798, Test Accuracy: 62.1212, Avg. duration: 0.0273 s\n",
      "Epoch: 2964, Train Loss: 0.1973, Test Loss: 0.3293, Train Accuracy: 63.9798, Test Accuracy: 62.1212, Avg. duration: 0.0278 s\n",
      "Epoch: 2965, Train Loss: 0.1973, Test Loss: 0.3293, Train Accuracy: 63.9798, Test Accuracy: 62.1212, Avg. duration: 0.3145 s\n",
      "Epoch: 2966, Train Loss: 0.1973, Test Loss: 0.3293, Train Accuracy: 63.9798, Test Accuracy: 62.1212, Avg. duration: 0.0291 s\n",
      "Epoch: 2967, Train Loss: 0.1973, Test Loss: 0.3293, Train Accuracy: 63.9798, Test Accuracy: 62.1212, Avg. duration: 0.0284 s\n",
      "Epoch: 2968, Train Loss: 0.1973, Test Loss: 0.3293, Train Accuracy: 63.9798, Test Accuracy: 62.1212, Avg. duration: 0.0278 s\n",
      "Epoch: 2969, Train Loss: 0.1973, Test Loss: 0.3293, Train Accuracy: 63.9798, Test Accuracy: 62.1212, Avg. duration: 0.0276 s\n",
      "Epoch: 2970, Train Loss: 0.1973, Test Loss: 0.3293, Train Accuracy: 63.9798, Test Accuracy: 62.1212, Avg. duration: 0.0279 s\n",
      "Epoch: 2971, Train Loss: 0.1973, Test Loss: 0.3293, Train Accuracy: 63.9798, Test Accuracy: 62.1212, Avg. duration: 0.0280 s\n",
      "Epoch: 2972, Train Loss: 0.1973, Test Loss: 0.3293, Train Accuracy: 63.9798, Test Accuracy: 62.1212, Avg. duration: 0.0274 s\n",
      "Epoch: 2973, Train Loss: 0.1973, Test Loss: 0.3293, Train Accuracy: 63.9798, Test Accuracy: 62.1212, Avg. duration: 0.0279 s\n",
      "Epoch: 2974, Train Loss: 0.1973, Test Loss: 0.3293, Train Accuracy: 63.9798, Test Accuracy: 62.1212, Avg. duration: 0.0276 s\n",
      "Epoch: 2975, Train Loss: 0.1973, Test Loss: 0.3293, Train Accuracy: 63.9798, Test Accuracy: 62.1212, Avg. duration: 0.0273 s\n",
      "Epoch: 2976, Train Loss: 0.1973, Test Loss: 0.3293, Train Accuracy: 63.9798, Test Accuracy: 62.1212, Avg. duration: 0.0275 s\n",
      "Epoch: 2977, Train Loss: 0.1973, Test Loss: 0.3293, Train Accuracy: 63.9798, Test Accuracy: 62.1212, Avg. duration: 0.0276 s\n",
      "Epoch: 2978, Train Loss: 0.1973, Test Loss: 0.3293, Train Accuracy: 63.9798, Test Accuracy: 62.1212, Avg. duration: 0.0275 s\n",
      "Epoch: 2979, Train Loss: 0.1973, Test Loss: 0.3293, Train Accuracy: 63.9798, Test Accuracy: 62.1212, Avg. duration: 0.0275 s\n",
      "Epoch: 2980, Train Loss: 0.1973, Test Loss: 0.3293, Train Accuracy: 63.9798, Test Accuracy: 62.1212, Avg. duration: 0.0275 s\n",
      "Epoch: 2981, Train Loss: 0.1973, Test Loss: 0.3293, Train Accuracy: 63.9798, Test Accuracy: 62.1212, Avg. duration: 0.0281 s\n",
      "Epoch: 2982, Train Loss: 0.1973, Test Loss: 0.3293, Train Accuracy: 63.9798, Test Accuracy: 62.1212, Avg. duration: 0.0276 s\n",
      "Epoch: 2983, Train Loss: 0.1973, Test Loss: 0.3293, Train Accuracy: 63.9798, Test Accuracy: 62.1212, Avg. duration: 0.0279 s\n",
      "Epoch: 2984, Train Loss: 0.1973, Test Loss: 0.3293, Train Accuracy: 63.9798, Test Accuracy: 62.1212, Avg. duration: 0.0275 s\n",
      "Epoch: 2985, Train Loss: 0.1973, Test Loss: 0.3293, Train Accuracy: 63.9798, Test Accuracy: 62.1212, Avg. duration: 0.0278 s\n",
      "Epoch: 2986, Train Loss: 0.1973, Test Loss: 0.3293, Train Accuracy: 63.9798, Test Accuracy: 62.1212, Avg. duration: 0.0279 s\n",
      "Epoch: 2987, Train Loss: 0.1973, Test Loss: 0.3293, Train Accuracy: 63.9798, Test Accuracy: 62.1212, Avg. duration: 0.0277 s\n",
      "Epoch: 2988, Train Loss: 0.1973, Test Loss: 0.3293, Train Accuracy: 63.9798, Test Accuracy: 62.1212, Avg. duration: 0.0278 s\n",
      "Epoch: 2989, Train Loss: 0.1973, Test Loss: 0.3293, Train Accuracy: 63.9798, Test Accuracy: 62.1212, Avg. duration: 0.0286 s\n",
      "Epoch: 2990, Train Loss: 0.1973, Test Loss: 0.3293, Train Accuracy: 63.9798, Test Accuracy: 62.1212, Avg. duration: 0.0277 s\n",
      "Epoch: 2991, Train Loss: 0.1973, Test Loss: 0.3293, Train Accuracy: 63.9798, Test Accuracy: 62.1212, Avg. duration: 0.0279 s\n",
      "Epoch: 2992, Train Loss: 0.1973, Test Loss: 0.3293, Train Accuracy: 63.9798, Test Accuracy: 62.1212, Avg. duration: 0.0279 s\n",
      "Epoch: 2993, Train Loss: 0.1973, Test Loss: 0.3293, Train Accuracy: 63.9798, Test Accuracy: 62.1212, Avg. duration: 0.0277 s\n",
      "Epoch: 2994, Train Loss: 0.1973, Test Loss: 0.3293, Train Accuracy: 63.9798, Test Accuracy: 62.1212, Avg. duration: 0.0278 s\n",
      "Epoch: 2995, Train Loss: 0.1973, Test Loss: 0.3293, Train Accuracy: 63.9798, Test Accuracy: 62.1212, Avg. duration: 0.0278 s\n",
      "Epoch: 2996, Train Loss: 0.1973, Test Loss: 0.3293, Train Accuracy: 63.9798, Test Accuracy: 62.1212, Avg. duration: 0.0273 s\n",
      "Epoch: 2997, Train Loss: 0.1973, Test Loss: 0.3293, Train Accuracy: 63.9798, Test Accuracy: 62.1212, Avg. duration: 0.0281 s\n",
      "Epoch: 2998, Train Loss: 0.1973, Test Loss: 0.3293, Train Accuracy: 63.9798, Test Accuracy: 62.1212, Avg. duration: 0.0279 s\n",
      "Epoch: 2999, Train Loss: 0.1973, Test Loss: 0.3293, Train Accuracy: 63.9798, Test Accuracy: 62.1212, Avg. duration: 0.0278 s\n",
      "Epoch: 3000, Train Loss: 0.1973, Test Loss: 0.3293, Train Accuracy: 63.9798, Test Accuracy: 62.1212, Avg. duration: 0.0276 s\n",
      "Epoch: 3001, Train Loss: 0.1943, Test Loss: 0.3261, Train Accuracy: 65.1134, Test Accuracy: 62.1212, Avg. duration: 2.7149 s\n",
      "Epoch: 3002, Train Loss: 0.1943, Test Loss: 0.3261, Train Accuracy: 65.1134, Test Accuracy: 62.1212, Avg. duration: 0.0294 s\n",
      "Epoch: 3003, Train Loss: 0.1943, Test Loss: 0.3261, Train Accuracy: 65.1134, Test Accuracy: 62.1212, Avg. duration: 0.0271 s\n",
      "Epoch: 3004, Train Loss: 0.1943, Test Loss: 0.3261, Train Accuracy: 65.1134, Test Accuracy: 62.1212, Avg. duration: 0.0272 s\n",
      "Epoch: 3005, Train Loss: 0.1943, Test Loss: 0.3261, Train Accuracy: 65.1134, Test Accuracy: 62.1212, Avg. duration: 0.0275 s\n",
      "Epoch: 3006, Train Loss: 0.1943, Test Loss: 0.3261, Train Accuracy: 65.1134, Test Accuracy: 62.1212, Avg. duration: 0.0275 s\n",
      "Epoch: 3007, Train Loss: 0.1943, Test Loss: 0.3261, Train Accuracy: 65.1134, Test Accuracy: 62.1212, Avg. duration: 0.0275 s\n",
      "Epoch: 3008, Train Loss: 0.1943, Test Loss: 0.3261, Train Accuracy: 65.1134, Test Accuracy: 62.1212, Avg. duration: 0.0271 s\n",
      "Epoch: 3009, Train Loss: 0.1943, Test Loss: 0.3261, Train Accuracy: 65.1134, Test Accuracy: 62.1212, Avg. duration: 0.0277 s\n",
      "Epoch: 3010, Train Loss: 0.1943, Test Loss: 0.3261, Train Accuracy: 65.1134, Test Accuracy: 62.1212, Avg. duration: 0.0269 s\n",
      "Epoch: 3011, Train Loss: 0.1943, Test Loss: 0.3261, Train Accuracy: 65.1134, Test Accuracy: 62.1212, Avg. duration: 0.0273 s\n",
      "Epoch: 3012, Train Loss: 0.1943, Test Loss: 0.3261, Train Accuracy: 65.1134, Test Accuracy: 62.1212, Avg. duration: 0.0272 s\n",
      "Epoch: 3013, Train Loss: 0.1943, Test Loss: 0.3261, Train Accuracy: 65.1134, Test Accuracy: 62.1212, Avg. duration: 0.0275 s\n",
      "Epoch: 3014, Train Loss: 0.1943, Test Loss: 0.3261, Train Accuracy: 65.1134, Test Accuracy: 62.1212, Avg. duration: 0.0269 s\n",
      "Epoch: 3015, Train Loss: 0.1943, Test Loss: 0.3261, Train Accuracy: 65.1134, Test Accuracy: 62.1212, Avg. duration: 0.0268 s\n",
      "Epoch: 3016, Train Loss: 0.1943, Test Loss: 0.3261, Train Accuracy: 65.1134, Test Accuracy: 62.1212, Avg. duration: 0.0268 s\n",
      "Epoch: 3017, Train Loss: 0.1943, Test Loss: 0.3261, Train Accuracy: 65.1134, Test Accuracy: 62.1212, Avg. duration: 0.0276 s\n",
      "Epoch: 3018, Train Loss: 0.1943, Test Loss: 0.3261, Train Accuracy: 65.1134, Test Accuracy: 62.1212, Avg. duration: 0.0276 s\n",
      "Epoch: 3019, Train Loss: 0.1943, Test Loss: 0.3261, Train Accuracy: 65.1134, Test Accuracy: 62.1212, Avg. duration: 0.0279 s\n",
      "Epoch: 3020, Train Loss: 0.1943, Test Loss: 0.3261, Train Accuracy: 65.1134, Test Accuracy: 62.1212, Avg. duration: 0.0269 s\n",
      "Epoch: 3021, Train Loss: 0.1943, Test Loss: 0.3261, Train Accuracy: 65.1134, Test Accuracy: 62.1212, Avg. duration: 0.0270 s\n",
      "Epoch: 3022, Train Loss: 0.1943, Test Loss: 0.3261, Train Accuracy: 65.1134, Test Accuracy: 62.1212, Avg. duration: 0.0267 s\n",
      "Epoch: 3023, Train Loss: 0.1943, Test Loss: 0.3261, Train Accuracy: 65.1134, Test Accuracy: 62.1212, Avg. duration: 0.0272 s\n",
      "Epoch: 3024, Train Loss: 0.1943, Test Loss: 0.3261, Train Accuracy: 65.1134, Test Accuracy: 62.1212, Avg. duration: 0.0277 s\n",
      "Epoch: 3025, Train Loss: 0.1943, Test Loss: 0.3261, Train Accuracy: 65.1134, Test Accuracy: 62.1212, Avg. duration: 0.0278 s\n",
      "Epoch: 3026, Train Loss: 0.1943, Test Loss: 0.3261, Train Accuracy: 65.1134, Test Accuracy: 62.1212, Avg. duration: 0.0270 s\n",
      "Epoch: 3027, Train Loss: 0.1943, Test Loss: 0.3261, Train Accuracy: 65.1134, Test Accuracy: 62.1212, Avg. duration: 0.0272 s\n",
      "Epoch: 3028, Train Loss: 0.1943, Test Loss: 0.3261, Train Accuracy: 65.1134, Test Accuracy: 62.1212, Avg. duration: 0.0272 s\n",
      "Epoch: 3029, Train Loss: 0.1943, Test Loss: 0.3261, Train Accuracy: 65.1134, Test Accuracy: 62.1212, Avg. duration: 0.0272 s\n",
      "Epoch: 3030, Train Loss: 0.1943, Test Loss: 0.3261, Train Accuracy: 65.1134, Test Accuracy: 62.1212, Avg. duration: 0.0272 s\n",
      "Epoch: 3031, Train Loss: 0.1943, Test Loss: 0.3261, Train Accuracy: 65.1134, Test Accuracy: 62.1212, Avg. duration: 0.0275 s\n",
      "Epoch: 3032, Train Loss: 0.1943, Test Loss: 0.3261, Train Accuracy: 65.1134, Test Accuracy: 62.1212, Avg. duration: 0.0267 s\n",
      "Epoch: 3033, Train Loss: 0.1943, Test Loss: 0.3261, Train Accuracy: 65.1134, Test Accuracy: 62.1212, Avg. duration: 0.0275 s\n",
      "Epoch: 3034, Train Loss: 0.1943, Test Loss: 0.3261, Train Accuracy: 65.1134, Test Accuracy: 62.1212, Avg. duration: 0.0271 s\n",
      "Epoch: 3035, Train Loss: 0.1943, Test Loss: 0.3261, Train Accuracy: 65.1134, Test Accuracy: 62.1212, Avg. duration: 0.0274 s\n",
      "Epoch: 3036, Train Loss: 0.1943, Test Loss: 0.3261, Train Accuracy: 65.1134, Test Accuracy: 62.1212, Avg. duration: 0.0271 s\n",
      "Epoch: 3037, Train Loss: 0.1943, Test Loss: 0.3261, Train Accuracy: 65.1134, Test Accuracy: 62.1212, Avg. duration: 0.0272 s\n",
      "Epoch: 3038, Train Loss: 0.1943, Test Loss: 0.3261, Train Accuracy: 65.1134, Test Accuracy: 62.1212, Avg. duration: 0.0272 s\n",
      "Epoch: 3039, Train Loss: 0.1943, Test Loss: 0.3261, Train Accuracy: 65.1134, Test Accuracy: 62.1212, Avg. duration: 0.0269 s\n",
      "Epoch: 3040, Train Loss: 0.1943, Test Loss: 0.3261, Train Accuracy: 65.1134, Test Accuracy: 62.1212, Avg. duration: 0.0273 s\n",
      "Epoch: 3041, Train Loss: 0.1943, Test Loss: 0.3261, Train Accuracy: 65.1134, Test Accuracy: 62.1212, Avg. duration: 0.3176 s\n",
      "Epoch: 3042, Train Loss: 0.1943, Test Loss: 0.3261, Train Accuracy: 65.1134, Test Accuracy: 62.1212, Avg. duration: 0.0284 s\n",
      "Epoch: 3043, Train Loss: 0.1943, Test Loss: 0.3261, Train Accuracy: 65.1134, Test Accuracy: 62.1212, Avg. duration: 0.0279 s\n",
      "Epoch: 3044, Train Loss: 0.1943, Test Loss: 0.3261, Train Accuracy: 65.1134, Test Accuracy: 62.1212, Avg. duration: 0.0270 s\n",
      "Epoch: 3045, Train Loss: 0.1943, Test Loss: 0.3261, Train Accuracy: 65.1134, Test Accuracy: 62.1212, Avg. duration: 0.0271 s\n",
      "Epoch: 3046, Train Loss: 0.1943, Test Loss: 0.3261, Train Accuracy: 65.1134, Test Accuracy: 62.1212, Avg. duration: 0.0273 s\n",
      "Epoch: 3047, Train Loss: 0.1943, Test Loss: 0.3261, Train Accuracy: 65.1134, Test Accuracy: 62.1212, Avg. duration: 0.0272 s\n",
      "Epoch: 3048, Train Loss: 0.1943, Test Loss: 0.3261, Train Accuracy: 65.1134, Test Accuracy: 62.1212, Avg. duration: 0.0275 s\n",
      "Epoch: 3049, Train Loss: 0.1943, Test Loss: 0.3261, Train Accuracy: 65.1134, Test Accuracy: 62.1212, Avg. duration: 0.0279 s\n",
      "Epoch: 3050, Train Loss: 0.1943, Test Loss: 0.3261, Train Accuracy: 65.1134, Test Accuracy: 62.1212, Avg. duration: 0.0274 s\n",
      "Epoch: 3051, Train Loss: 0.1943, Test Loss: 0.3261, Train Accuracy: 65.1134, Test Accuracy: 62.1212, Avg. duration: 0.0270 s\n",
      "Epoch: 3052, Train Loss: 0.1943, Test Loss: 0.3261, Train Accuracy: 65.1134, Test Accuracy: 62.1212, Avg. duration: 0.0273 s\n",
      "Epoch: 3053, Train Loss: 0.1943, Test Loss: 0.3261, Train Accuracy: 65.1134, Test Accuracy: 62.1212, Avg. duration: 0.0272 s\n",
      "Epoch: 3054, Train Loss: 0.1943, Test Loss: 0.3261, Train Accuracy: 65.1134, Test Accuracy: 62.1212, Avg. duration: 0.0277 s\n",
      "Epoch: 3055, Train Loss: 0.1943, Test Loss: 0.3261, Train Accuracy: 65.1134, Test Accuracy: 62.1212, Avg. duration: 0.0277 s\n",
      "Epoch: 3056, Train Loss: 0.1943, Test Loss: 0.3261, Train Accuracy: 65.1134, Test Accuracy: 62.1212, Avg. duration: 0.0274 s\n",
      "Epoch: 3057, Train Loss: 0.1943, Test Loss: 0.3261, Train Accuracy: 65.1134, Test Accuracy: 62.1212, Avg. duration: 0.0281 s\n",
      "Epoch: 3058, Train Loss: 0.1943, Test Loss: 0.3261, Train Accuracy: 65.1134, Test Accuracy: 62.1212, Avg. duration: 0.0275 s\n",
      "Epoch: 3059, Train Loss: 0.1943, Test Loss: 0.3261, Train Accuracy: 65.1134, Test Accuracy: 62.1212, Avg. duration: 0.0275 s\n",
      "Epoch: 3060, Train Loss: 0.1943, Test Loss: 0.3261, Train Accuracy: 65.1134, Test Accuracy: 62.1212, Avg. duration: 0.0274 s\n",
      "Epoch: 3061, Train Loss: 0.1943, Test Loss: 0.3261, Train Accuracy: 65.1134, Test Accuracy: 62.1212, Avg. duration: 0.0274 s\n",
      "Epoch: 3062, Train Loss: 0.1943, Test Loss: 0.3261, Train Accuracy: 65.1134, Test Accuracy: 62.1212, Avg. duration: 0.0273 s\n",
      "Epoch: 3063, Train Loss: 0.1943, Test Loss: 0.3261, Train Accuracy: 65.1134, Test Accuracy: 62.1212, Avg. duration: 0.0271 s\n",
      "Epoch: 3064, Train Loss: 0.1943, Test Loss: 0.3261, Train Accuracy: 65.1134, Test Accuracy: 62.1212, Avg. duration: 0.0278 s\n",
      "Epoch: 3065, Train Loss: 0.1943, Test Loss: 0.3261, Train Accuracy: 65.1134, Test Accuracy: 62.1212, Avg. duration: 0.0279 s\n",
      "Epoch: 3066, Train Loss: 0.1943, Test Loss: 0.3261, Train Accuracy: 65.1134, Test Accuracy: 62.1212, Avg. duration: 0.0278 s\n",
      "Epoch: 3067, Train Loss: 0.1943, Test Loss: 0.3261, Train Accuracy: 65.1134, Test Accuracy: 62.1212, Avg. duration: 0.0278 s\n",
      "Epoch: 3068, Train Loss: 0.1943, Test Loss: 0.3261, Train Accuracy: 65.1134, Test Accuracy: 62.1212, Avg. duration: 0.0275 s\n",
      "Epoch: 3069, Train Loss: 0.1943, Test Loss: 0.3261, Train Accuracy: 65.1134, Test Accuracy: 62.1212, Avg. duration: 0.0270 s\n",
      "Epoch: 3070, Train Loss: 0.1943, Test Loss: 0.3261, Train Accuracy: 65.1134, Test Accuracy: 62.1212, Avg. duration: 0.0276 s\n",
      "Epoch: 3071, Train Loss: 0.1943, Test Loss: 0.3261, Train Accuracy: 65.1134, Test Accuracy: 62.1212, Avg. duration: 0.0279 s\n",
      "Epoch: 3072, Train Loss: 0.1943, Test Loss: 0.3261, Train Accuracy: 65.1134, Test Accuracy: 62.1212, Avg. duration: 0.0277 s\n",
      "Epoch: 3073, Train Loss: 0.1943, Test Loss: 0.3261, Train Accuracy: 65.1134, Test Accuracy: 62.1212, Avg. duration: 0.0277 s\n",
      "Epoch: 3074, Train Loss: 0.1943, Test Loss: 0.3261, Train Accuracy: 65.1134, Test Accuracy: 62.1212, Avg. duration: 0.0277 s\n",
      "Epoch: 3075, Train Loss: 0.1943, Test Loss: 0.3261, Train Accuracy: 65.1134, Test Accuracy: 62.1212, Avg. duration: 0.0275 s\n",
      "Epoch: 3076, Train Loss: 0.1943, Test Loss: 0.3261, Train Accuracy: 65.1134, Test Accuracy: 62.1212, Avg. duration: 0.0270 s\n",
      "Epoch: 3077, Train Loss: 0.1943, Test Loss: 0.3261, Train Accuracy: 65.1134, Test Accuracy: 62.1212, Avg. duration: 0.0275 s\n",
      "Epoch: 3078, Train Loss: 0.1943, Test Loss: 0.3261, Train Accuracy: 65.1134, Test Accuracy: 62.1212, Avg. duration: 0.0279 s\n",
      "Epoch: 3079, Train Loss: 0.1943, Test Loss: 0.3261, Train Accuracy: 65.1134, Test Accuracy: 62.1212, Avg. duration: 0.0277 s\n",
      "Epoch: 3080, Train Loss: 0.1943, Test Loss: 0.3261, Train Accuracy: 65.1134, Test Accuracy: 62.1212, Avg. duration: 0.0274 s\n",
      "Epoch: 3081, Train Loss: 0.1943, Test Loss: 0.3261, Train Accuracy: 65.1134, Test Accuracy: 62.1212, Avg. duration: 0.0282 s\n",
      "Epoch: 3082, Train Loss: 0.1943, Test Loss: 0.3261, Train Accuracy: 65.1134, Test Accuracy: 62.1212, Avg. duration: 0.0277 s\n",
      "Epoch: 3083, Train Loss: 0.1943, Test Loss: 0.3261, Train Accuracy: 65.1134, Test Accuracy: 62.1212, Avg. duration: 0.0278 s\n",
      "Epoch: 3084, Train Loss: 0.1943, Test Loss: 0.3261, Train Accuracy: 65.1134, Test Accuracy: 62.1212, Avg. duration: 0.0278 s\n",
      "Epoch: 3085, Train Loss: 0.1943, Test Loss: 0.3261, Train Accuracy: 65.1134, Test Accuracy: 62.1212, Avg. duration: 0.0278 s\n",
      "Epoch: 3086, Train Loss: 0.1943, Test Loss: 0.3261, Train Accuracy: 65.1134, Test Accuracy: 62.1212, Avg. duration: 0.0272 s\n",
      "Epoch: 3087, Train Loss: 0.1943, Test Loss: 0.3261, Train Accuracy: 65.1134, Test Accuracy: 62.1212, Avg. duration: 0.0272 s\n",
      "Epoch: 3088, Train Loss: 0.1943, Test Loss: 0.3261, Train Accuracy: 65.1134, Test Accuracy: 62.1212, Avg. duration: 0.0278 s\n",
      "Epoch: 3089, Train Loss: 0.1943, Test Loss: 0.3261, Train Accuracy: 65.1134, Test Accuracy: 62.1212, Avg. duration: 0.0279 s\n",
      "Epoch: 3090, Train Loss: 0.1943, Test Loss: 0.3261, Train Accuracy: 65.1134, Test Accuracy: 62.1212, Avg. duration: 0.0276 s\n",
      "Epoch: 3091, Train Loss: 0.1943, Test Loss: 0.3261, Train Accuracy: 65.1134, Test Accuracy: 62.1212, Avg. duration: 0.0278 s\n",
      "Epoch: 3092, Train Loss: 0.1943, Test Loss: 0.3261, Train Accuracy: 65.1134, Test Accuracy: 62.1212, Avg. duration: 0.0275 s\n",
      "Epoch: 3093, Train Loss: 0.1943, Test Loss: 0.3261, Train Accuracy: 65.1134, Test Accuracy: 62.1212, Avg. duration: 0.0279 s\n",
      "Epoch: 3094, Train Loss: 0.1943, Test Loss: 0.3261, Train Accuracy: 65.1134, Test Accuracy: 62.1212, Avg. duration: 0.0276 s\n",
      "Epoch: 3095, Train Loss: 0.1943, Test Loss: 0.3261, Train Accuracy: 65.1134, Test Accuracy: 62.1212, Avg. duration: 0.0275 s\n",
      "Epoch: 3096, Train Loss: 0.1943, Test Loss: 0.3261, Train Accuracy: 65.1134, Test Accuracy: 62.1212, Avg. duration: 0.0280 s\n",
      "Epoch: 3097, Train Loss: 0.1943, Test Loss: 0.3261, Train Accuracy: 65.1134, Test Accuracy: 62.1212, Avg. duration: 0.0282 s\n",
      "Epoch: 3098, Train Loss: 0.1943, Test Loss: 0.3261, Train Accuracy: 65.1134, Test Accuracy: 62.1212, Avg. duration: 0.0272 s\n",
      "Epoch: 3099, Train Loss: 0.1943, Test Loss: 0.3261, Train Accuracy: 65.1134, Test Accuracy: 62.1212, Avg. duration: 0.0273 s\n",
      "Epoch: 3100, Train Loss: 0.1943, Test Loss: 0.3261, Train Accuracy: 65.1134, Test Accuracy: 62.1212, Avg. duration: 0.0279 s\n",
      "Epoch: 3101, Train Loss: 0.1921, Test Loss: 0.3298, Train Accuracy: 65.6171, Test Accuracy: 61.1111, Avg. duration: 2.7235 s\n",
      "Epoch: 3102, Train Loss: 0.1921, Test Loss: 0.3298, Train Accuracy: 65.6171, Test Accuracy: 61.1111, Avg. duration: 0.0300 s\n",
      "Epoch: 3103, Train Loss: 0.1921, Test Loss: 0.3298, Train Accuracy: 65.6171, Test Accuracy: 61.1111, Avg. duration: 0.0275 s\n",
      "Epoch: 3104, Train Loss: 0.1921, Test Loss: 0.3298, Train Accuracy: 65.6171, Test Accuracy: 61.1111, Avg. duration: 0.0276 s\n",
      "Epoch: 3105, Train Loss: 0.1921, Test Loss: 0.3298, Train Accuracy: 65.6171, Test Accuracy: 61.1111, Avg. duration: 0.0269 s\n",
      "Epoch: 3106, Train Loss: 0.1921, Test Loss: 0.3298, Train Accuracy: 65.6171, Test Accuracy: 61.1111, Avg. duration: 0.0276 s\n",
      "Epoch: 3107, Train Loss: 0.1921, Test Loss: 0.3298, Train Accuracy: 65.6171, Test Accuracy: 61.1111, Avg. duration: 0.0273 s\n",
      "Epoch: 3108, Train Loss: 0.1921, Test Loss: 0.3298, Train Accuracy: 65.6171, Test Accuracy: 61.1111, Avg. duration: 0.3164 s\n",
      "Epoch: 3109, Train Loss: 0.1921, Test Loss: 0.3298, Train Accuracy: 65.6171, Test Accuracy: 61.1111, Avg. duration: 0.0282 s\n",
      "Epoch: 3110, Train Loss: 0.1921, Test Loss: 0.3298, Train Accuracy: 65.6171, Test Accuracy: 61.1111, Avg. duration: 0.0271 s\n",
      "Epoch: 3111, Train Loss: 0.1921, Test Loss: 0.3298, Train Accuracy: 65.6171, Test Accuracy: 61.1111, Avg. duration: 0.0277 s\n",
      "Epoch: 3112, Train Loss: 0.1921, Test Loss: 0.3298, Train Accuracy: 65.6171, Test Accuracy: 61.1111, Avg. duration: 0.0274 s\n",
      "Epoch: 3113, Train Loss: 0.1921, Test Loss: 0.3298, Train Accuracy: 65.6171, Test Accuracy: 61.1111, Avg. duration: 0.0272 s\n",
      "Epoch: 3114, Train Loss: 0.1921, Test Loss: 0.3298, Train Accuracy: 65.6171, Test Accuracy: 61.1111, Avg. duration: 0.0275 s\n",
      "Epoch: 3115, Train Loss: 0.1921, Test Loss: 0.3298, Train Accuracy: 65.6171, Test Accuracy: 61.1111, Avg. duration: 0.0274 s\n",
      "Epoch: 3116, Train Loss: 0.1921, Test Loss: 0.3298, Train Accuracy: 65.6171, Test Accuracy: 61.1111, Avg. duration: 0.0272 s\n",
      "Epoch: 3117, Train Loss: 0.1921, Test Loss: 0.3298, Train Accuracy: 65.6171, Test Accuracy: 61.1111, Avg. duration: 0.0276 s\n",
      "Epoch: 3118, Train Loss: 0.1921, Test Loss: 0.3298, Train Accuracy: 65.6171, Test Accuracy: 61.1111, Avg. duration: 0.0270 s\n",
      "Epoch: 3119, Train Loss: 0.1921, Test Loss: 0.3298, Train Accuracy: 65.6171, Test Accuracy: 61.1111, Avg. duration: 0.0275 s\n",
      "Epoch: 3120, Train Loss: 0.1921, Test Loss: 0.3298, Train Accuracy: 65.6171, Test Accuracy: 61.1111, Avg. duration: 0.0276 s\n",
      "Epoch: 3121, Train Loss: 0.1921, Test Loss: 0.3298, Train Accuracy: 65.6171, Test Accuracy: 61.1111, Avg. duration: 0.0269 s\n",
      "Epoch: 3122, Train Loss: 0.1921, Test Loss: 0.3298, Train Accuracy: 65.6171, Test Accuracy: 61.1111, Avg. duration: 0.0270 s\n",
      "Epoch: 3123, Train Loss: 0.1921, Test Loss: 0.3298, Train Accuracy: 65.6171, Test Accuracy: 61.1111, Avg. duration: 0.0273 s\n",
      "Epoch: 3124, Train Loss: 0.1921, Test Loss: 0.3298, Train Accuracy: 65.6171, Test Accuracy: 61.1111, Avg. duration: 0.0280 s\n",
      "Epoch: 3125, Train Loss: 0.1921, Test Loss: 0.3298, Train Accuracy: 65.6171, Test Accuracy: 61.1111, Avg. duration: 0.0275 s\n",
      "Epoch: 3126, Train Loss: 0.1921, Test Loss: 0.3298, Train Accuracy: 65.6171, Test Accuracy: 61.1111, Avg. duration: 0.0275 s\n",
      "Epoch: 3127, Train Loss: 0.1921, Test Loss: 0.3298, Train Accuracy: 65.6171, Test Accuracy: 61.1111, Avg. duration: 0.0270 s\n",
      "Epoch: 3128, Train Loss: 0.1921, Test Loss: 0.3298, Train Accuracy: 65.6171, Test Accuracy: 61.1111, Avg. duration: 0.0268 s\n",
      "Epoch: 3129, Train Loss: 0.1921, Test Loss: 0.3298, Train Accuracy: 65.6171, Test Accuracy: 61.1111, Avg. duration: 0.0271 s\n",
      "Epoch: 3130, Train Loss: 0.1921, Test Loss: 0.3298, Train Accuracy: 65.6171, Test Accuracy: 61.1111, Avg. duration: 0.0274 s\n",
      "Epoch: 3131, Train Loss: 0.1921, Test Loss: 0.3298, Train Accuracy: 65.6171, Test Accuracy: 61.1111, Avg. duration: 0.0274 s\n",
      "Epoch: 3132, Train Loss: 0.1921, Test Loss: 0.3298, Train Accuracy: 65.6171, Test Accuracy: 61.1111, Avg. duration: 0.0280 s\n",
      "Epoch: 3133, Train Loss: 0.1921, Test Loss: 0.3298, Train Accuracy: 65.6171, Test Accuracy: 61.1111, Avg. duration: 0.0268 s\n",
      "Epoch: 3134, Train Loss: 0.1921, Test Loss: 0.3298, Train Accuracy: 65.6171, Test Accuracy: 61.1111, Avg. duration: 0.0272 s\n",
      "Epoch: 3135, Train Loss: 0.1921, Test Loss: 0.3298, Train Accuracy: 65.6171, Test Accuracy: 61.1111, Avg. duration: 0.0271 s\n",
      "Epoch: 3136, Train Loss: 0.1921, Test Loss: 0.3298, Train Accuracy: 65.6171, Test Accuracy: 61.1111, Avg. duration: 0.0270 s\n",
      "Epoch: 3137, Train Loss: 0.1921, Test Loss: 0.3298, Train Accuracy: 65.6171, Test Accuracy: 61.1111, Avg. duration: 0.0274 s\n",
      "Epoch: 3138, Train Loss: 0.1921, Test Loss: 0.3298, Train Accuracy: 65.6171, Test Accuracy: 61.1111, Avg. duration: 0.0280 s\n",
      "Epoch: 3139, Train Loss: 0.1921, Test Loss: 0.3298, Train Accuracy: 65.6171, Test Accuracy: 61.1111, Avg. duration: 0.0272 s\n",
      "Epoch: 3140, Train Loss: 0.1921, Test Loss: 0.3298, Train Accuracy: 65.6171, Test Accuracy: 61.1111, Avg. duration: 0.0271 s\n",
      "Epoch: 3141, Train Loss: 0.1921, Test Loss: 0.3298, Train Accuracy: 65.6171, Test Accuracy: 61.1111, Avg. duration: 0.0275 s\n",
      "Epoch: 3142, Train Loss: 0.1921, Test Loss: 0.3298, Train Accuracy: 65.6171, Test Accuracy: 61.1111, Avg. duration: 0.0270 s\n",
      "Epoch: 3143, Train Loss: 0.1921, Test Loss: 0.3298, Train Accuracy: 65.6171, Test Accuracy: 61.1111, Avg. duration: 0.0275 s\n",
      "Epoch: 3144, Train Loss: 0.1921, Test Loss: 0.3298, Train Accuracy: 65.6171, Test Accuracy: 61.1111, Avg. duration: 0.0279 s\n",
      "Epoch: 3145, Train Loss: 0.1921, Test Loss: 0.3298, Train Accuracy: 65.6171, Test Accuracy: 61.1111, Avg. duration: 0.0268 s\n",
      "Epoch: 3146, Train Loss: 0.1921, Test Loss: 0.3298, Train Accuracy: 65.6171, Test Accuracy: 61.1111, Avg. duration: 0.0269 s\n",
      "Epoch: 3147, Train Loss: 0.1921, Test Loss: 0.3298, Train Accuracy: 65.6171, Test Accuracy: 61.1111, Avg. duration: 0.0272 s\n",
      "Epoch: 3148, Train Loss: 0.1921, Test Loss: 0.3298, Train Accuracy: 65.6171, Test Accuracy: 61.1111, Avg. duration: 0.0273 s\n",
      "Epoch: 3149, Train Loss: 0.1921, Test Loss: 0.3298, Train Accuracy: 65.6171, Test Accuracy: 61.1111, Avg. duration: 0.0276 s\n",
      "Epoch: 3150, Train Loss: 0.1921, Test Loss: 0.3298, Train Accuracy: 65.6171, Test Accuracy: 61.1111, Avg. duration: 0.0276 s\n",
      "Epoch: 3151, Train Loss: 0.1921, Test Loss: 0.3298, Train Accuracy: 65.6171, Test Accuracy: 61.1111, Avg. duration: 0.0270 s\n",
      "Epoch: 3152, Train Loss: 0.1921, Test Loss: 0.3298, Train Accuracy: 65.6171, Test Accuracy: 61.1111, Avg. duration: 0.0268 s\n",
      "Epoch: 3153, Train Loss: 0.1921, Test Loss: 0.3298, Train Accuracy: 65.6171, Test Accuracy: 61.1111, Avg. duration: 0.0273 s\n",
      "Epoch: 3154, Train Loss: 0.1921, Test Loss: 0.3298, Train Accuracy: 65.6171, Test Accuracy: 61.1111, Avg. duration: 0.0270 s\n",
      "Epoch: 3155, Train Loss: 0.1921, Test Loss: 0.3298, Train Accuracy: 65.6171, Test Accuracy: 61.1111, Avg. duration: 0.0270 s\n",
      "Epoch: 3156, Train Loss: 0.1921, Test Loss: 0.3298, Train Accuracy: 65.6171, Test Accuracy: 61.1111, Avg. duration: 0.0277 s\n",
      "Epoch: 3157, Train Loss: 0.1921, Test Loss: 0.3298, Train Accuracy: 65.6171, Test Accuracy: 61.1111, Avg. duration: 0.0275 s\n",
      "Epoch: 3158, Train Loss: 0.1921, Test Loss: 0.3298, Train Accuracy: 65.6171, Test Accuracy: 61.1111, Avg. duration: 0.0271 s\n",
      "Epoch: 3159, Train Loss: 0.1921, Test Loss: 0.3298, Train Accuracy: 65.6171, Test Accuracy: 61.1111, Avg. duration: 0.0275 s\n",
      "Epoch: 3160, Train Loss: 0.1921, Test Loss: 0.3298, Train Accuracy: 65.6171, Test Accuracy: 61.1111, Avg. duration: 0.0278 s\n",
      "Epoch: 3161, Train Loss: 0.1921, Test Loss: 0.3298, Train Accuracy: 65.6171, Test Accuracy: 61.1111, Avg. duration: 0.0277 s\n",
      "Epoch: 3162, Train Loss: 0.1921, Test Loss: 0.3298, Train Accuracy: 65.6171, Test Accuracy: 61.1111, Avg. duration: 0.0278 s\n",
      "Epoch: 3163, Train Loss: 0.1921, Test Loss: 0.3298, Train Accuracy: 65.6171, Test Accuracy: 61.1111, Avg. duration: 0.0274 s\n",
      "Epoch: 3164, Train Loss: 0.1921, Test Loss: 0.3298, Train Accuracy: 65.6171, Test Accuracy: 61.1111, Avg. duration: 0.0280 s\n",
      "Epoch: 3165, Train Loss: 0.1921, Test Loss: 0.3298, Train Accuracy: 65.6171, Test Accuracy: 61.1111, Avg. duration: 0.0277 s\n",
      "Epoch: 3166, Train Loss: 0.1921, Test Loss: 0.3298, Train Accuracy: 65.6171, Test Accuracy: 61.1111, Avg. duration: 0.0277 s\n",
      "Epoch: 3167, Train Loss: 0.1921, Test Loss: 0.3298, Train Accuracy: 65.6171, Test Accuracy: 61.1111, Avg. duration: 0.0278 s\n",
      "Epoch: 3168, Train Loss: 0.1921, Test Loss: 0.3298, Train Accuracy: 65.6171, Test Accuracy: 61.1111, Avg. duration: 0.0276 s\n",
      "Epoch: 3169, Train Loss: 0.1921, Test Loss: 0.3298, Train Accuracy: 65.6171, Test Accuracy: 61.1111, Avg. duration: 0.0272 s\n",
      "Epoch: 3170, Train Loss: 0.1921, Test Loss: 0.3298, Train Accuracy: 65.6171, Test Accuracy: 61.1111, Avg. duration: 0.0275 s\n",
      "Epoch: 3171, Train Loss: 0.1921, Test Loss: 0.3298, Train Accuracy: 65.6171, Test Accuracy: 61.1111, Avg. duration: 0.0277 s\n",
      "Epoch: 3172, Train Loss: 0.1921, Test Loss: 0.3298, Train Accuracy: 65.6171, Test Accuracy: 61.1111, Avg. duration: 0.0279 s\n",
      "Epoch: 3173, Train Loss: 0.1921, Test Loss: 0.3298, Train Accuracy: 65.6171, Test Accuracy: 61.1111, Avg. duration: 0.0280 s\n",
      "Epoch: 3174, Train Loss: 0.1921, Test Loss: 0.3298, Train Accuracy: 65.6171, Test Accuracy: 61.1111, Avg. duration: 0.0278 s\n",
      "Epoch: 3175, Train Loss: 0.1921, Test Loss: 0.3298, Train Accuracy: 65.6171, Test Accuracy: 61.1111, Avg. duration: 0.0276 s\n",
      "Epoch: 3176, Train Loss: 0.1921, Test Loss: 0.3298, Train Accuracy: 65.6171, Test Accuracy: 61.1111, Avg. duration: 0.0270 s\n",
      "Epoch: 3177, Train Loss: 0.1921, Test Loss: 0.3298, Train Accuracy: 65.6171, Test Accuracy: 61.1111, Avg. duration: 0.0272 s\n",
      "Epoch: 3178, Train Loss: 0.1921, Test Loss: 0.3298, Train Accuracy: 65.6171, Test Accuracy: 61.1111, Avg. duration: 0.0279 s\n",
      "Epoch: 3179, Train Loss: 0.1921, Test Loss: 0.3298, Train Accuracy: 65.6171, Test Accuracy: 61.1111, Avg. duration: 0.0277 s\n",
      "Epoch: 3180, Train Loss: 0.1921, Test Loss: 0.3298, Train Accuracy: 65.6171, Test Accuracy: 61.1111, Avg. duration: 0.0279 s\n",
      "Epoch: 3181, Train Loss: 0.1921, Test Loss: 0.3298, Train Accuracy: 65.6171, Test Accuracy: 61.1111, Avg. duration: 0.0272 s\n",
      "Epoch: 3182, Train Loss: 0.1921, Test Loss: 0.3298, Train Accuracy: 65.6171, Test Accuracy: 61.1111, Avg. duration: 0.0273 s\n",
      "Epoch: 3183, Train Loss: 0.1921, Test Loss: 0.3298, Train Accuracy: 65.6171, Test Accuracy: 61.1111, Avg. duration: 0.0276 s\n",
      "Epoch: 3184, Train Loss: 0.1921, Test Loss: 0.3298, Train Accuracy: 65.6171, Test Accuracy: 61.1111, Avg. duration: 0.3168 s\n",
      "Epoch: 3185, Train Loss: 0.1921, Test Loss: 0.3298, Train Accuracy: 65.6171, Test Accuracy: 61.1111, Avg. duration: 0.0286 s\n",
      "Epoch: 3186, Train Loss: 0.1921, Test Loss: 0.3298, Train Accuracy: 65.6171, Test Accuracy: 61.1111, Avg. duration: 0.0281 s\n",
      "Epoch: 3187, Train Loss: 0.1921, Test Loss: 0.3298, Train Accuracy: 65.6171, Test Accuracy: 61.1111, Avg. duration: 0.0278 s\n",
      "Epoch: 3188, Train Loss: 0.1921, Test Loss: 0.3298, Train Accuracy: 65.6171, Test Accuracy: 61.1111, Avg. duration: 0.0278 s\n",
      "Epoch: 3189, Train Loss: 0.1921, Test Loss: 0.3298, Train Accuracy: 65.6171, Test Accuracy: 61.1111, Avg. duration: 0.0275 s\n",
      "Epoch: 3190, Train Loss: 0.1921, Test Loss: 0.3298, Train Accuracy: 65.6171, Test Accuracy: 61.1111, Avg. duration: 0.0279 s\n",
      "Epoch: 3191, Train Loss: 0.1921, Test Loss: 0.3298, Train Accuracy: 65.6171, Test Accuracy: 61.1111, Avg. duration: 0.0279 s\n",
      "Epoch: 3192, Train Loss: 0.1921, Test Loss: 0.3298, Train Accuracy: 65.6171, Test Accuracy: 61.1111, Avg. duration: 0.0286 s\n",
      "Epoch: 3193, Train Loss: 0.1921, Test Loss: 0.3298, Train Accuracy: 65.6171, Test Accuracy: 61.1111, Avg. duration: 0.0276 s\n",
      "Epoch: 3194, Train Loss: 0.1921, Test Loss: 0.3298, Train Accuracy: 65.6171, Test Accuracy: 61.1111, Avg. duration: 0.0276 s\n",
      "Epoch: 3195, Train Loss: 0.1921, Test Loss: 0.3298, Train Accuracy: 65.6171, Test Accuracy: 61.1111, Avg. duration: 0.0278 s\n",
      "Epoch: 3196, Train Loss: 0.1921, Test Loss: 0.3298, Train Accuracy: 65.6171, Test Accuracy: 61.1111, Avg. duration: 0.0275 s\n",
      "Epoch: 3197, Train Loss: 0.1921, Test Loss: 0.3298, Train Accuracy: 65.6171, Test Accuracy: 61.1111, Avg. duration: 0.0282 s\n",
      "Epoch: 3198, Train Loss: 0.1921, Test Loss: 0.3298, Train Accuracy: 65.6171, Test Accuracy: 61.1111, Avg. duration: 0.0277 s\n",
      "Epoch: 3199, Train Loss: 0.1921, Test Loss: 0.3298, Train Accuracy: 65.6171, Test Accuracy: 61.1111, Avg. duration: 0.0277 s\n",
      "Epoch: 3200, Train Loss: 0.1921, Test Loss: 0.3298, Train Accuracy: 65.6171, Test Accuracy: 61.1111, Avg. duration: 0.0284 s\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "mode": "lines",
         "name": "Train Loss",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160,
          161,
          162,
          163,
          164,
          165,
          166,
          167,
          168,
          169,
          170,
          171,
          172,
          173,
          174,
          175,
          176,
          177,
          178,
          179,
          180,
          181,
          182,
          183,
          184,
          185,
          186,
          187,
          188,
          189,
          190,
          191,
          192,
          193,
          194,
          195,
          196,
          197,
          198,
          199,
          200,
          201,
          202,
          203,
          204,
          205,
          206,
          207,
          208,
          209,
          210,
          211,
          212,
          213,
          214,
          215,
          216,
          217,
          218,
          219,
          220,
          221,
          222,
          223,
          224,
          225,
          226,
          227,
          228,
          229,
          230,
          231,
          232,
          233,
          234,
          235,
          236,
          237,
          238,
          239,
          240,
          241,
          242,
          243,
          244,
          245,
          246,
          247,
          248,
          249,
          250,
          251,
          252,
          253,
          254,
          255,
          256,
          257,
          258,
          259,
          260,
          261,
          262,
          263,
          264,
          265,
          266,
          267,
          268,
          269,
          270,
          271,
          272,
          273,
          274,
          275,
          276,
          277,
          278,
          279,
          280,
          281,
          282,
          283,
          284,
          285,
          286,
          287,
          288,
          289,
          290,
          291,
          292,
          293,
          294,
          295,
          296,
          297,
          298,
          299,
          300,
          301,
          302,
          303,
          304,
          305,
          306,
          307,
          308,
          309,
          310,
          311,
          312,
          313,
          314,
          315,
          316,
          317,
          318,
          319,
          320,
          321,
          322,
          323,
          324,
          325,
          326,
          327,
          328,
          329,
          330,
          331,
          332,
          333,
          334,
          335,
          336,
          337,
          338,
          339,
          340,
          341,
          342,
          343,
          344,
          345,
          346,
          347,
          348,
          349,
          350,
          351,
          352,
          353,
          354,
          355,
          356,
          357,
          358,
          359,
          360,
          361,
          362,
          363,
          364,
          365,
          366,
          367,
          368,
          369,
          370,
          371,
          372,
          373,
          374,
          375,
          376,
          377,
          378,
          379,
          380,
          381,
          382,
          383,
          384,
          385,
          386,
          387,
          388,
          389,
          390,
          391,
          392,
          393,
          394,
          395,
          396,
          397,
          398,
          399,
          400,
          401,
          402,
          403,
          404,
          405,
          406,
          407,
          408,
          409,
          410,
          411,
          412,
          413,
          414,
          415,
          416,
          417,
          418,
          419,
          420,
          421,
          422,
          423,
          424,
          425,
          426,
          427,
          428,
          429,
          430,
          431,
          432,
          433,
          434,
          435,
          436,
          437,
          438,
          439,
          440,
          441,
          442,
          443,
          444,
          445,
          446,
          447,
          448,
          449,
          450,
          451,
          452,
          453,
          454,
          455,
          456,
          457,
          458,
          459,
          460,
          461,
          462,
          463,
          464,
          465,
          466,
          467,
          468,
          469,
          470,
          471,
          472,
          473,
          474,
          475,
          476,
          477,
          478,
          479,
          480,
          481,
          482,
          483,
          484,
          485,
          486,
          487,
          488,
          489,
          490,
          491,
          492,
          493,
          494,
          495,
          496,
          497,
          498,
          499,
          500,
          501,
          502,
          503,
          504,
          505,
          506,
          507,
          508,
          509,
          510,
          511,
          512,
          513,
          514,
          515,
          516,
          517,
          518,
          519,
          520,
          521,
          522,
          523,
          524,
          525,
          526,
          527,
          528,
          529,
          530,
          531,
          532,
          533,
          534,
          535,
          536,
          537,
          538,
          539,
          540,
          541,
          542,
          543,
          544,
          545,
          546,
          547,
          548,
          549,
          550,
          551,
          552,
          553,
          554,
          555,
          556,
          557,
          558,
          559,
          560,
          561,
          562,
          563,
          564,
          565,
          566,
          567,
          568,
          569,
          570,
          571,
          572,
          573,
          574,
          575,
          576,
          577,
          578,
          579,
          580,
          581,
          582,
          583,
          584,
          585,
          586,
          587,
          588,
          589,
          590,
          591,
          592,
          593,
          594,
          595,
          596,
          597,
          598,
          599,
          600,
          601,
          602,
          603,
          604,
          605,
          606,
          607,
          608,
          609,
          610,
          611,
          612,
          613,
          614,
          615,
          616,
          617,
          618,
          619,
          620,
          621,
          622,
          623,
          624,
          625,
          626,
          627,
          628,
          629,
          630,
          631,
          632,
          633,
          634,
          635,
          636,
          637,
          638,
          639,
          640,
          641,
          642,
          643,
          644,
          645,
          646,
          647,
          648,
          649,
          650,
          651,
          652,
          653,
          654,
          655,
          656,
          657,
          658,
          659,
          660,
          661,
          662,
          663,
          664,
          665,
          666,
          667,
          668,
          669,
          670,
          671,
          672,
          673,
          674,
          675,
          676,
          677,
          678,
          679,
          680,
          681,
          682,
          683,
          684,
          685,
          686,
          687,
          688,
          689,
          690,
          691,
          692,
          693,
          694,
          695,
          696,
          697,
          698,
          699,
          700,
          701,
          702,
          703,
          704,
          705,
          706,
          707,
          708,
          709,
          710,
          711,
          712,
          713,
          714,
          715,
          716,
          717,
          718,
          719,
          720,
          721,
          722,
          723,
          724,
          725,
          726,
          727,
          728,
          729,
          730,
          731,
          732,
          733,
          734,
          735,
          736,
          737,
          738,
          739,
          740,
          741,
          742,
          743,
          744,
          745,
          746,
          747,
          748,
          749,
          750,
          751,
          752,
          753,
          754,
          755,
          756,
          757,
          758,
          759,
          760,
          761,
          762,
          763,
          764,
          765,
          766,
          767,
          768,
          769,
          770,
          771,
          772,
          773,
          774,
          775,
          776,
          777,
          778,
          779,
          780,
          781,
          782,
          783,
          784,
          785,
          786,
          787,
          788,
          789,
          790,
          791,
          792,
          793,
          794,
          795,
          796,
          797,
          798,
          799,
          800,
          801,
          802,
          803,
          804,
          805,
          806,
          807,
          808,
          809,
          810,
          811,
          812,
          813,
          814,
          815,
          816,
          817,
          818,
          819,
          820,
          821,
          822,
          823,
          824,
          825,
          826,
          827,
          828,
          829,
          830,
          831,
          832,
          833,
          834,
          835,
          836,
          837,
          838,
          839,
          840,
          841,
          842,
          843,
          844,
          845,
          846,
          847,
          848,
          849,
          850,
          851,
          852,
          853,
          854,
          855,
          856,
          857,
          858,
          859,
          860,
          861,
          862,
          863,
          864,
          865,
          866,
          867,
          868,
          869,
          870,
          871,
          872,
          873,
          874,
          875,
          876,
          877,
          878,
          879,
          880,
          881,
          882,
          883,
          884,
          885,
          886,
          887,
          888,
          889,
          890,
          891,
          892,
          893,
          894,
          895,
          896,
          897,
          898,
          899,
          900,
          901,
          902,
          903,
          904,
          905,
          906,
          907,
          908,
          909,
          910,
          911,
          912,
          913,
          914,
          915,
          916,
          917,
          918,
          919,
          920,
          921,
          922,
          923,
          924,
          925,
          926,
          927,
          928,
          929,
          930,
          931,
          932,
          933,
          934,
          935,
          936,
          937,
          938,
          939,
          940,
          941,
          942,
          943,
          944,
          945,
          946,
          947,
          948,
          949,
          950,
          951,
          952,
          953,
          954,
          955,
          956,
          957,
          958,
          959,
          960,
          961,
          962,
          963,
          964,
          965,
          966,
          967,
          968,
          969,
          970,
          971,
          972,
          973,
          974,
          975,
          976,
          977,
          978,
          979,
          980,
          981,
          982,
          983,
          984,
          985,
          986,
          987,
          988,
          989,
          990,
          991,
          992,
          993,
          994,
          995,
          996,
          997,
          998,
          999,
          1000,
          1001,
          1002,
          1003,
          1004,
          1005,
          1006,
          1007,
          1008,
          1009,
          1010,
          1011,
          1012,
          1013,
          1014,
          1015,
          1016,
          1017,
          1018,
          1019,
          1020,
          1021,
          1022,
          1023,
          1024,
          1025,
          1026,
          1027,
          1028,
          1029,
          1030,
          1031,
          1032,
          1033,
          1034,
          1035,
          1036,
          1037,
          1038,
          1039,
          1040,
          1041,
          1042,
          1043,
          1044,
          1045,
          1046,
          1047,
          1048,
          1049,
          1050,
          1051,
          1052,
          1053,
          1054,
          1055,
          1056,
          1057,
          1058,
          1059,
          1060,
          1061,
          1062,
          1063,
          1064,
          1065,
          1066,
          1067,
          1068,
          1069,
          1070,
          1071,
          1072,
          1073,
          1074,
          1075,
          1076,
          1077,
          1078,
          1079,
          1080,
          1081,
          1082,
          1083,
          1084,
          1085,
          1086,
          1087,
          1088,
          1089,
          1090,
          1091,
          1092,
          1093,
          1094,
          1095,
          1096,
          1097,
          1098,
          1099,
          1100,
          1101,
          1102,
          1103,
          1104,
          1105,
          1106,
          1107,
          1108,
          1109,
          1110,
          1111,
          1112,
          1113,
          1114,
          1115,
          1116,
          1117,
          1118,
          1119,
          1120,
          1121,
          1122,
          1123,
          1124,
          1125,
          1126,
          1127,
          1128,
          1129,
          1130,
          1131,
          1132,
          1133,
          1134,
          1135,
          1136,
          1137,
          1138,
          1139,
          1140,
          1141,
          1142,
          1143,
          1144,
          1145,
          1146,
          1147,
          1148,
          1149,
          1150,
          1151,
          1152,
          1153,
          1154,
          1155,
          1156,
          1157,
          1158,
          1159,
          1160,
          1161,
          1162,
          1163,
          1164,
          1165,
          1166,
          1167,
          1168,
          1169,
          1170,
          1171,
          1172,
          1173,
          1174,
          1175,
          1176,
          1177,
          1178,
          1179,
          1180,
          1181,
          1182,
          1183,
          1184,
          1185,
          1186,
          1187,
          1188,
          1189,
          1190,
          1191,
          1192,
          1193,
          1194,
          1195,
          1196,
          1197,
          1198,
          1199,
          1200,
          1201,
          1202,
          1203,
          1204,
          1205,
          1206,
          1207,
          1208,
          1209,
          1210,
          1211,
          1212,
          1213,
          1214,
          1215,
          1216,
          1217,
          1218,
          1219,
          1220,
          1221,
          1222,
          1223,
          1224,
          1225,
          1226,
          1227,
          1228,
          1229,
          1230,
          1231,
          1232,
          1233,
          1234,
          1235,
          1236,
          1237,
          1238,
          1239,
          1240,
          1241,
          1242,
          1243,
          1244,
          1245,
          1246,
          1247,
          1248,
          1249,
          1250,
          1251,
          1252,
          1253,
          1254,
          1255,
          1256,
          1257,
          1258,
          1259,
          1260,
          1261,
          1262,
          1263,
          1264,
          1265,
          1266,
          1267,
          1268,
          1269,
          1270,
          1271,
          1272,
          1273,
          1274,
          1275,
          1276,
          1277,
          1278,
          1279,
          1280,
          1281,
          1282,
          1283,
          1284,
          1285,
          1286,
          1287,
          1288,
          1289,
          1290,
          1291,
          1292,
          1293,
          1294,
          1295,
          1296,
          1297,
          1298,
          1299,
          1300,
          1301,
          1302,
          1303,
          1304,
          1305,
          1306,
          1307,
          1308,
          1309,
          1310,
          1311,
          1312,
          1313,
          1314,
          1315,
          1316,
          1317,
          1318,
          1319,
          1320,
          1321,
          1322,
          1323,
          1324,
          1325,
          1326,
          1327,
          1328,
          1329,
          1330,
          1331,
          1332,
          1333,
          1334,
          1335,
          1336,
          1337,
          1338,
          1339,
          1340,
          1341,
          1342,
          1343,
          1344,
          1345,
          1346,
          1347,
          1348,
          1349,
          1350,
          1351,
          1352,
          1353,
          1354,
          1355,
          1356,
          1357,
          1358,
          1359,
          1360,
          1361,
          1362,
          1363,
          1364,
          1365,
          1366,
          1367,
          1368,
          1369,
          1370,
          1371,
          1372,
          1373,
          1374,
          1375,
          1376,
          1377,
          1378,
          1379,
          1380,
          1381,
          1382,
          1383,
          1384,
          1385,
          1386,
          1387,
          1388,
          1389,
          1390,
          1391,
          1392,
          1393,
          1394,
          1395,
          1396,
          1397,
          1398,
          1399,
          1400,
          1401,
          1402,
          1403,
          1404,
          1405,
          1406,
          1407,
          1408,
          1409,
          1410,
          1411,
          1412,
          1413,
          1414,
          1415,
          1416,
          1417,
          1418,
          1419,
          1420,
          1421,
          1422,
          1423,
          1424,
          1425,
          1426,
          1427,
          1428,
          1429,
          1430,
          1431,
          1432,
          1433,
          1434,
          1435,
          1436,
          1437,
          1438,
          1439,
          1440,
          1441,
          1442,
          1443,
          1444,
          1445,
          1446,
          1447,
          1448,
          1449,
          1450,
          1451,
          1452,
          1453,
          1454,
          1455,
          1456,
          1457,
          1458,
          1459,
          1460,
          1461,
          1462,
          1463,
          1464,
          1465,
          1466,
          1467,
          1468,
          1469,
          1470,
          1471,
          1472,
          1473,
          1474,
          1475,
          1476,
          1477,
          1478,
          1479,
          1480,
          1481,
          1482,
          1483,
          1484,
          1485,
          1486,
          1487,
          1488,
          1489,
          1490,
          1491,
          1492,
          1493,
          1494,
          1495,
          1496,
          1497,
          1498,
          1499,
          1500,
          1501,
          1502,
          1503,
          1504,
          1505,
          1506,
          1507,
          1508,
          1509,
          1510,
          1511,
          1512,
          1513,
          1514,
          1515,
          1516,
          1517,
          1518,
          1519,
          1520,
          1521,
          1522,
          1523,
          1524,
          1525,
          1526,
          1527,
          1528,
          1529,
          1530,
          1531,
          1532,
          1533,
          1534,
          1535,
          1536,
          1537,
          1538,
          1539,
          1540,
          1541,
          1542,
          1543,
          1544,
          1545,
          1546,
          1547,
          1548,
          1549,
          1550,
          1551,
          1552,
          1553,
          1554,
          1555,
          1556,
          1557,
          1558,
          1559,
          1560,
          1561,
          1562,
          1563,
          1564,
          1565,
          1566,
          1567,
          1568,
          1569,
          1570,
          1571,
          1572,
          1573,
          1574,
          1575,
          1576,
          1577,
          1578,
          1579,
          1580,
          1581,
          1582,
          1583,
          1584,
          1585,
          1586,
          1587,
          1588,
          1589,
          1590,
          1591,
          1592,
          1593,
          1594,
          1595,
          1596,
          1597,
          1598,
          1599,
          1600,
          1601,
          1602,
          1603,
          1604,
          1605,
          1606,
          1607,
          1608,
          1609,
          1610,
          1611,
          1612,
          1613,
          1614,
          1615,
          1616,
          1617,
          1618,
          1619,
          1620,
          1621,
          1622,
          1623,
          1624,
          1625,
          1626,
          1627,
          1628,
          1629,
          1630,
          1631,
          1632,
          1633,
          1634,
          1635,
          1636,
          1637,
          1638,
          1639,
          1640,
          1641,
          1642,
          1643,
          1644,
          1645,
          1646,
          1647,
          1648,
          1649,
          1650,
          1651,
          1652,
          1653,
          1654,
          1655,
          1656,
          1657,
          1658,
          1659,
          1660,
          1661,
          1662,
          1663,
          1664,
          1665,
          1666,
          1667,
          1668,
          1669,
          1670,
          1671,
          1672,
          1673,
          1674,
          1675,
          1676,
          1677,
          1678,
          1679,
          1680,
          1681,
          1682,
          1683,
          1684,
          1685,
          1686,
          1687,
          1688,
          1689,
          1690,
          1691,
          1692,
          1693,
          1694,
          1695,
          1696,
          1697,
          1698,
          1699,
          1700,
          1701,
          1702,
          1703,
          1704,
          1705,
          1706,
          1707,
          1708,
          1709,
          1710,
          1711,
          1712,
          1713,
          1714,
          1715,
          1716,
          1717,
          1718,
          1719,
          1720,
          1721,
          1722,
          1723,
          1724,
          1725,
          1726,
          1727,
          1728,
          1729,
          1730,
          1731,
          1732,
          1733,
          1734,
          1735,
          1736,
          1737,
          1738,
          1739,
          1740,
          1741,
          1742,
          1743,
          1744,
          1745,
          1746,
          1747,
          1748,
          1749,
          1750,
          1751,
          1752,
          1753,
          1754,
          1755,
          1756,
          1757,
          1758,
          1759,
          1760,
          1761,
          1762,
          1763,
          1764,
          1765,
          1766,
          1767,
          1768,
          1769,
          1770,
          1771,
          1772,
          1773,
          1774,
          1775,
          1776,
          1777,
          1778,
          1779,
          1780,
          1781,
          1782,
          1783,
          1784,
          1785,
          1786,
          1787,
          1788,
          1789,
          1790,
          1791,
          1792,
          1793,
          1794,
          1795,
          1796,
          1797,
          1798,
          1799,
          1800,
          1801,
          1802,
          1803,
          1804,
          1805,
          1806,
          1807,
          1808,
          1809,
          1810,
          1811,
          1812,
          1813,
          1814,
          1815,
          1816,
          1817,
          1818,
          1819,
          1820,
          1821,
          1822,
          1823,
          1824,
          1825,
          1826,
          1827,
          1828,
          1829,
          1830,
          1831,
          1832,
          1833,
          1834,
          1835,
          1836,
          1837,
          1838,
          1839,
          1840,
          1841,
          1842,
          1843,
          1844,
          1845,
          1846,
          1847,
          1848,
          1849,
          1850,
          1851,
          1852,
          1853,
          1854,
          1855,
          1856,
          1857,
          1858,
          1859,
          1860,
          1861,
          1862,
          1863,
          1864,
          1865,
          1866,
          1867,
          1868,
          1869,
          1870,
          1871,
          1872,
          1873,
          1874,
          1875,
          1876,
          1877,
          1878,
          1879,
          1880,
          1881,
          1882,
          1883,
          1884,
          1885,
          1886,
          1887,
          1888,
          1889,
          1890,
          1891,
          1892,
          1893,
          1894,
          1895,
          1896,
          1897,
          1898,
          1899,
          1900,
          1901,
          1902,
          1903,
          1904,
          1905,
          1906,
          1907,
          1908,
          1909,
          1910,
          1911,
          1912,
          1913,
          1914,
          1915,
          1916,
          1917,
          1918,
          1919,
          1920,
          1921,
          1922,
          1923,
          1924,
          1925,
          1926,
          1927,
          1928,
          1929,
          1930,
          1931,
          1932,
          1933,
          1934,
          1935,
          1936,
          1937,
          1938,
          1939,
          1940,
          1941,
          1942,
          1943,
          1944,
          1945,
          1946,
          1947,
          1948,
          1949,
          1950,
          1951,
          1952,
          1953,
          1954,
          1955,
          1956,
          1957,
          1958,
          1959,
          1960,
          1961,
          1962,
          1963,
          1964,
          1965,
          1966,
          1967,
          1968,
          1969,
          1970,
          1971,
          1972,
          1973,
          1974,
          1975,
          1976,
          1977,
          1978,
          1979,
          1980,
          1981,
          1982,
          1983,
          1984,
          1985,
          1986,
          1987,
          1988,
          1989,
          1990,
          1991,
          1992,
          1993,
          1994,
          1995,
          1996,
          1997,
          1998,
          1999,
          2000,
          2001,
          2002,
          2003,
          2004,
          2005,
          2006,
          2007,
          2008,
          2009,
          2010,
          2011,
          2012,
          2013,
          2014,
          2015,
          2016,
          2017,
          2018,
          2019,
          2020,
          2021,
          2022,
          2023,
          2024,
          2025,
          2026,
          2027,
          2028,
          2029,
          2030,
          2031,
          2032,
          2033,
          2034,
          2035,
          2036,
          2037,
          2038,
          2039,
          2040,
          2041,
          2042,
          2043,
          2044,
          2045,
          2046,
          2047,
          2048,
          2049,
          2050,
          2051,
          2052,
          2053,
          2054,
          2055,
          2056,
          2057,
          2058,
          2059,
          2060,
          2061,
          2062,
          2063,
          2064,
          2065,
          2066,
          2067,
          2068,
          2069,
          2070,
          2071,
          2072,
          2073,
          2074,
          2075,
          2076,
          2077,
          2078,
          2079,
          2080,
          2081,
          2082,
          2083,
          2084,
          2085,
          2086,
          2087,
          2088,
          2089,
          2090,
          2091,
          2092,
          2093,
          2094,
          2095,
          2096,
          2097,
          2098,
          2099,
          2100,
          2101,
          2102,
          2103,
          2104,
          2105,
          2106,
          2107,
          2108,
          2109,
          2110,
          2111,
          2112,
          2113,
          2114,
          2115,
          2116,
          2117,
          2118,
          2119,
          2120,
          2121,
          2122,
          2123,
          2124,
          2125,
          2126,
          2127,
          2128,
          2129,
          2130,
          2131,
          2132,
          2133,
          2134,
          2135,
          2136,
          2137,
          2138,
          2139,
          2140,
          2141,
          2142,
          2143,
          2144,
          2145,
          2146,
          2147,
          2148,
          2149,
          2150,
          2151,
          2152,
          2153,
          2154,
          2155,
          2156,
          2157,
          2158,
          2159,
          2160,
          2161,
          2162,
          2163,
          2164,
          2165,
          2166,
          2167,
          2168,
          2169,
          2170,
          2171,
          2172,
          2173,
          2174,
          2175,
          2176,
          2177,
          2178,
          2179,
          2180,
          2181,
          2182,
          2183,
          2184,
          2185,
          2186,
          2187,
          2188,
          2189,
          2190,
          2191,
          2192,
          2193,
          2194,
          2195,
          2196,
          2197,
          2198,
          2199,
          2200,
          2201,
          2202,
          2203,
          2204,
          2205,
          2206,
          2207,
          2208,
          2209,
          2210,
          2211,
          2212,
          2213,
          2214,
          2215,
          2216,
          2217,
          2218,
          2219,
          2220,
          2221,
          2222,
          2223,
          2224,
          2225,
          2226,
          2227,
          2228,
          2229,
          2230,
          2231,
          2232,
          2233,
          2234,
          2235,
          2236,
          2237,
          2238,
          2239,
          2240,
          2241,
          2242,
          2243,
          2244,
          2245,
          2246,
          2247,
          2248,
          2249,
          2250,
          2251,
          2252,
          2253,
          2254,
          2255,
          2256,
          2257,
          2258,
          2259,
          2260,
          2261,
          2262,
          2263,
          2264,
          2265,
          2266,
          2267,
          2268,
          2269,
          2270,
          2271,
          2272,
          2273,
          2274,
          2275,
          2276,
          2277,
          2278,
          2279,
          2280,
          2281,
          2282,
          2283,
          2284,
          2285,
          2286,
          2287,
          2288,
          2289,
          2290,
          2291,
          2292,
          2293,
          2294,
          2295,
          2296,
          2297,
          2298,
          2299,
          2300,
          2301,
          2302,
          2303,
          2304,
          2305,
          2306,
          2307,
          2308,
          2309,
          2310,
          2311,
          2312,
          2313,
          2314,
          2315,
          2316,
          2317,
          2318,
          2319,
          2320,
          2321,
          2322,
          2323,
          2324,
          2325,
          2326,
          2327,
          2328,
          2329,
          2330,
          2331,
          2332,
          2333,
          2334,
          2335,
          2336,
          2337,
          2338,
          2339,
          2340,
          2341,
          2342,
          2343,
          2344,
          2345,
          2346,
          2347,
          2348,
          2349,
          2350,
          2351,
          2352,
          2353,
          2354,
          2355,
          2356,
          2357,
          2358,
          2359,
          2360,
          2361,
          2362,
          2363,
          2364,
          2365,
          2366,
          2367,
          2368,
          2369,
          2370,
          2371,
          2372,
          2373,
          2374,
          2375,
          2376,
          2377,
          2378,
          2379,
          2380,
          2381,
          2382,
          2383,
          2384,
          2385,
          2386,
          2387,
          2388,
          2389,
          2390,
          2391,
          2392,
          2393,
          2394,
          2395,
          2396,
          2397,
          2398,
          2399,
          2400,
          2401,
          2402,
          2403,
          2404,
          2405,
          2406,
          2407,
          2408,
          2409,
          2410,
          2411,
          2412,
          2413,
          2414,
          2415,
          2416,
          2417,
          2418,
          2419,
          2420,
          2421,
          2422,
          2423,
          2424,
          2425,
          2426,
          2427,
          2428,
          2429,
          2430,
          2431,
          2432,
          2433,
          2434,
          2435,
          2436,
          2437,
          2438,
          2439,
          2440,
          2441,
          2442,
          2443,
          2444,
          2445,
          2446,
          2447,
          2448,
          2449,
          2450,
          2451,
          2452,
          2453,
          2454,
          2455,
          2456,
          2457,
          2458,
          2459,
          2460,
          2461,
          2462,
          2463,
          2464,
          2465,
          2466,
          2467,
          2468,
          2469,
          2470,
          2471,
          2472,
          2473,
          2474,
          2475,
          2476,
          2477,
          2478,
          2479,
          2480,
          2481,
          2482,
          2483,
          2484,
          2485,
          2486,
          2487,
          2488,
          2489,
          2490,
          2491,
          2492,
          2493,
          2494,
          2495,
          2496,
          2497,
          2498,
          2499,
          2500,
          2501,
          2502,
          2503,
          2504,
          2505,
          2506,
          2507,
          2508,
          2509,
          2510,
          2511,
          2512,
          2513,
          2514,
          2515,
          2516,
          2517,
          2518,
          2519,
          2520,
          2521,
          2522,
          2523,
          2524,
          2525,
          2526,
          2527,
          2528,
          2529,
          2530,
          2531,
          2532,
          2533,
          2534,
          2535,
          2536,
          2537,
          2538,
          2539,
          2540,
          2541,
          2542,
          2543,
          2544,
          2545,
          2546,
          2547,
          2548,
          2549,
          2550,
          2551,
          2552,
          2553,
          2554,
          2555,
          2556,
          2557,
          2558,
          2559,
          2560,
          2561,
          2562,
          2563,
          2564,
          2565,
          2566,
          2567,
          2568,
          2569,
          2570,
          2571,
          2572,
          2573,
          2574,
          2575,
          2576,
          2577,
          2578,
          2579,
          2580,
          2581,
          2582,
          2583,
          2584,
          2585,
          2586,
          2587,
          2588,
          2589,
          2590,
          2591,
          2592,
          2593,
          2594,
          2595,
          2596,
          2597,
          2598,
          2599,
          2600,
          2601,
          2602,
          2603,
          2604,
          2605,
          2606,
          2607,
          2608,
          2609,
          2610,
          2611,
          2612,
          2613,
          2614,
          2615,
          2616,
          2617,
          2618,
          2619,
          2620,
          2621,
          2622,
          2623,
          2624,
          2625,
          2626,
          2627,
          2628,
          2629,
          2630,
          2631,
          2632,
          2633,
          2634,
          2635,
          2636,
          2637,
          2638,
          2639,
          2640,
          2641,
          2642,
          2643,
          2644,
          2645,
          2646,
          2647,
          2648,
          2649,
          2650,
          2651,
          2652,
          2653,
          2654,
          2655,
          2656,
          2657,
          2658,
          2659,
          2660,
          2661,
          2662,
          2663,
          2664,
          2665,
          2666,
          2667,
          2668,
          2669,
          2670,
          2671,
          2672,
          2673,
          2674,
          2675,
          2676,
          2677,
          2678,
          2679,
          2680,
          2681,
          2682,
          2683,
          2684,
          2685,
          2686,
          2687,
          2688,
          2689,
          2690,
          2691,
          2692,
          2693,
          2694,
          2695,
          2696,
          2697,
          2698,
          2699,
          2700,
          2701,
          2702,
          2703,
          2704,
          2705,
          2706,
          2707,
          2708,
          2709,
          2710,
          2711,
          2712,
          2713,
          2714,
          2715,
          2716,
          2717,
          2718,
          2719,
          2720,
          2721,
          2722,
          2723,
          2724,
          2725,
          2726,
          2727,
          2728,
          2729,
          2730,
          2731,
          2732,
          2733,
          2734,
          2735,
          2736,
          2737,
          2738,
          2739,
          2740,
          2741,
          2742,
          2743,
          2744,
          2745,
          2746,
          2747,
          2748,
          2749,
          2750,
          2751,
          2752,
          2753,
          2754,
          2755,
          2756,
          2757,
          2758,
          2759,
          2760,
          2761,
          2762,
          2763,
          2764,
          2765,
          2766,
          2767,
          2768,
          2769,
          2770,
          2771,
          2772,
          2773,
          2774,
          2775,
          2776,
          2777,
          2778,
          2779,
          2780,
          2781,
          2782,
          2783,
          2784,
          2785,
          2786,
          2787,
          2788,
          2789,
          2790,
          2791,
          2792,
          2793,
          2794,
          2795,
          2796,
          2797,
          2798,
          2799,
          2800,
          2801,
          2802,
          2803,
          2804,
          2805,
          2806,
          2807,
          2808,
          2809,
          2810,
          2811,
          2812,
          2813,
          2814,
          2815,
          2816,
          2817,
          2818,
          2819,
          2820,
          2821,
          2822,
          2823,
          2824,
          2825,
          2826,
          2827,
          2828,
          2829,
          2830,
          2831,
          2832,
          2833,
          2834,
          2835,
          2836,
          2837,
          2838,
          2839,
          2840,
          2841,
          2842,
          2843,
          2844,
          2845,
          2846,
          2847,
          2848,
          2849,
          2850,
          2851,
          2852,
          2853,
          2854,
          2855,
          2856,
          2857,
          2858,
          2859,
          2860,
          2861,
          2862,
          2863,
          2864,
          2865,
          2866,
          2867,
          2868,
          2869,
          2870,
          2871,
          2872,
          2873,
          2874,
          2875,
          2876,
          2877,
          2878,
          2879,
          2880,
          2881,
          2882,
          2883,
          2884,
          2885,
          2886,
          2887,
          2888,
          2889,
          2890,
          2891,
          2892,
          2893,
          2894,
          2895,
          2896,
          2897,
          2898,
          2899,
          2900,
          2901,
          2902,
          2903,
          2904,
          2905,
          2906,
          2907,
          2908,
          2909,
          2910,
          2911,
          2912,
          2913,
          2914,
          2915,
          2916,
          2917,
          2918,
          2919,
          2920,
          2921,
          2922,
          2923,
          2924,
          2925,
          2926,
          2927,
          2928,
          2929,
          2930,
          2931,
          2932,
          2933,
          2934,
          2935,
          2936,
          2937,
          2938,
          2939,
          2940,
          2941,
          2942,
          2943,
          2944,
          2945,
          2946,
          2947,
          2948,
          2949,
          2950,
          2951,
          2952,
          2953,
          2954,
          2955,
          2956,
          2957,
          2958,
          2959,
          2960,
          2961,
          2962,
          2963,
          2964,
          2965,
          2966,
          2967,
          2968,
          2969,
          2970,
          2971,
          2972,
          2973,
          2974,
          2975,
          2976,
          2977,
          2978,
          2979,
          2980,
          2981,
          2982,
          2983,
          2984,
          2985,
          2986,
          2987,
          2988,
          2989,
          2990,
          2991,
          2992,
          2993,
          2994,
          2995,
          2996,
          2997,
          2998,
          2999,
          3000,
          3001,
          3002,
          3003,
          3004,
          3005,
          3006,
          3007,
          3008,
          3009,
          3010,
          3011,
          3012,
          3013,
          3014,
          3015,
          3016,
          3017,
          3018,
          3019,
          3020,
          3021,
          3022,
          3023,
          3024,
          3025,
          3026,
          3027,
          3028,
          3029,
          3030,
          3031,
          3032,
          3033,
          3034,
          3035,
          3036,
          3037,
          3038,
          3039,
          3040,
          3041,
          3042,
          3043,
          3044,
          3045,
          3046,
          3047,
          3048,
          3049,
          3050,
          3051,
          3052,
          3053,
          3054,
          3055,
          3056,
          3057,
          3058,
          3059,
          3060,
          3061,
          3062,
          3063,
          3064,
          3065,
          3066,
          3067,
          3068,
          3069,
          3070,
          3071,
          3072,
          3073,
          3074,
          3075,
          3076,
          3077,
          3078,
          3079,
          3080,
          3081,
          3082,
          3083,
          3084,
          3085,
          3086,
          3087,
          3088,
          3089,
          3090,
          3091,
          3092,
          3093,
          3094,
          3095,
          3096,
          3097,
          3098,
          3099,
          3100,
          3101,
          3102,
          3103,
          3104,
          3105,
          3106,
          3107,
          3108,
          3109,
          3110,
          3111,
          3112,
          3113,
          3114,
          3115,
          3116,
          3117,
          3118,
          3119,
          3120,
          3121,
          3122,
          3123,
          3124,
          3125,
          3126,
          3127,
          3128,
          3129,
          3130,
          3131,
          3132,
          3133,
          3134,
          3135,
          3136,
          3137,
          3138,
          3139,
          3140,
          3141,
          3142,
          3143,
          3144,
          3145,
          3146,
          3147,
          3148,
          3149,
          3150,
          3151,
          3152,
          3153,
          3154,
          3155,
          3156,
          3157,
          3158,
          3159,
          3160,
          3161,
          3162,
          3163,
          3164,
          3165,
          3166,
          3167,
          3168,
          3169,
          3170,
          3171,
          3172,
          3173,
          3174,
          3175,
          3176,
          3177,
          3178,
          3179,
          3180,
          3181,
          3182,
          3183,
          3184,
          3185,
          3186,
          3187,
          3188,
          3189,
          3190,
          3191,
          3192,
          3193,
          3194,
          3195,
          3196,
          3197,
          3198,
          3199,
          3200
         ],
         "y": [
          0.6857435011893735,
          0.6857435011893735,
          0.6857435011893735,
          0.6857435011893735,
          0.6857435011893735,
          0.6857435011893735,
          0.6857435011893735,
          0.6857435011893735,
          0.6857435011893735,
          0.6857435011893735,
          0.6857435011893735,
          0.6857435011893735,
          0.6857435011893735,
          0.6857435011893735,
          0.6857435011893735,
          0.6857435011893735,
          0.6857435011893735,
          0.6857435011893735,
          0.6857435011893735,
          0.6857435011893735,
          0.6857435011893735,
          0.6857435011893735,
          0.6857435011893735,
          0.6857435011893735,
          0.6857435011893735,
          0.6857435011893735,
          0.6857435011893735,
          0.6857435011893735,
          0.6857435011893735,
          0.6857435011893735,
          0.6857435011893735,
          0.6857435011893735,
          0.6857435011893735,
          0.6857435011893735,
          0.6857435011893735,
          0.6857435011893735,
          0.6857435011893735,
          0.6857435011893735,
          0.6857435011893735,
          0.6857435011893735,
          0.6857435011893735,
          0.6857435011893735,
          0.6857435011893735,
          0.6857435011893735,
          0.6857435011893735,
          0.6857435011893735,
          0.6857435011893735,
          0.6857435011893735,
          0.6857435011893735,
          0.6857435011893735,
          0.6857435011893735,
          0.6857435011893735,
          0.6857435011893735,
          0.6857435011893735,
          0.6857435011893735,
          0.6857435011893735,
          0.6857435011893735,
          0.6857435011893735,
          0.6857435011893735,
          0.6857435011893735,
          0.6857435011893735,
          0.6857435011893735,
          0.6857435011893735,
          0.6857435011893735,
          0.6857435011893735,
          0.6857435011893735,
          0.6857435011893735,
          0.6857435011893735,
          0.6857435011893735,
          0.6857435011893735,
          0.6857435011893735,
          0.6857435011893735,
          0.6857435011893735,
          0.6857435011893735,
          0.6857435011893735,
          0.6857435011893735,
          0.6857435011893735,
          0.6857435011893735,
          0.6857435011893735,
          0.6857435011893735,
          0.6857435011893735,
          0.6857435011893735,
          0.6857435011893735,
          0.6857435011893735,
          0.6857435011893735,
          0.6857435011893735,
          0.6857435011893735,
          0.6857435011893735,
          0.6857435011893735,
          0.6857435011893735,
          0.6857435011893735,
          0.6857435011893735,
          0.6857435011893735,
          0.6857435011893735,
          0.6857435011893735,
          0.6857435011893735,
          0.6857435011893735,
          0.6857435011893735,
          0.6857435011893735,
          0.6857435011893735,
          0.5352773523000386,
          0.5352773523000386,
          0.5352773523000386,
          0.5352773523000386,
          0.5352773523000386,
          0.5352773523000386,
          0.5352773523000386,
          0.5352773523000386,
          0.5352773523000386,
          0.5352773523000386,
          0.5352773523000386,
          0.5352773523000386,
          0.5352773523000386,
          0.5352773523000386,
          0.5352773523000386,
          0.5352773523000386,
          0.5352773523000386,
          0.5352773523000386,
          0.5352773523000386,
          0.5352773523000386,
          0.5352773523000386,
          0.5352773523000386,
          0.5352773523000386,
          0.5352773523000386,
          0.5352773523000386,
          0.5352773523000386,
          0.5352773523000386,
          0.5352773523000386,
          0.5352773523000386,
          0.5352773523000386,
          0.5352773523000386,
          0.5352773523000386,
          0.5352773523000386,
          0.5352773523000386,
          0.5352773523000386,
          0.5352773523000386,
          0.5352773523000386,
          0.5352773523000386,
          0.5352773523000386,
          0.5352773523000386,
          0.5352773523000386,
          0.5352773523000386,
          0.5352773523000386,
          0.5352773523000386,
          0.5352773523000386,
          0.5352773523000386,
          0.5352773523000386,
          0.5352773523000386,
          0.5352773523000386,
          0.5352773523000386,
          0.5352773523000386,
          0.5352773523000386,
          0.5352773523000386,
          0.5352773523000386,
          0.5352773523000386,
          0.5352773523000386,
          0.5352773523000386,
          0.5352773523000386,
          0.5352773523000386,
          0.5352773523000386,
          0.5352773523000386,
          0.5352773523000386,
          0.5352773523000386,
          0.5352773523000386,
          0.5352773523000386,
          0.5352773523000386,
          0.5352773523000386,
          0.5352773523000386,
          0.5352773523000386,
          0.5352773523000386,
          0.5352773523000386,
          0.5352773523000386,
          0.5352773523000386,
          0.5352773523000386,
          0.5352773523000386,
          0.5352773523000386,
          0.5352773523000386,
          0.5352773523000386,
          0.5352773523000386,
          0.5352773523000386,
          0.5352773523000386,
          0.5352773523000386,
          0.5352773523000386,
          0.5352773523000386,
          0.5352773523000386,
          0.5352773523000386,
          0.5352773523000386,
          0.5352773523000386,
          0.5352773523000386,
          0.5352773523000386,
          0.5352773523000386,
          0.5352773523000386,
          0.5352773523000386,
          0.5352773523000386,
          0.5352773523000386,
          0.5352773523000386,
          0.5352773523000386,
          0.5352773523000386,
          0.5352773523000386,
          0.5352773523000386,
          0.342379690023457,
          0.342379690023457,
          0.342379690023457,
          0.342379690023457,
          0.342379690023457,
          0.342379690023457,
          0.342379690023457,
          0.342379690023457,
          0.342379690023457,
          0.342379690023457,
          0.342379690023457,
          0.342379690023457,
          0.342379690023457,
          0.342379690023457,
          0.342379690023457,
          0.342379690023457,
          0.342379690023457,
          0.342379690023457,
          0.342379690023457,
          0.342379690023457,
          0.342379690023457,
          0.342379690023457,
          0.342379690023457,
          0.342379690023457,
          0.342379690023457,
          0.342379690023457,
          0.342379690023457,
          0.342379690023457,
          0.342379690023457,
          0.342379690023457,
          0.342379690023457,
          0.342379690023457,
          0.342379690023457,
          0.342379690023457,
          0.342379690023457,
          0.342379690023457,
          0.342379690023457,
          0.342379690023457,
          0.342379690023457,
          0.342379690023457,
          0.342379690023457,
          0.342379690023457,
          0.342379690023457,
          0.342379690023457,
          0.342379690023457,
          0.342379690023457,
          0.342379690023457,
          0.342379690023457,
          0.342379690023457,
          0.342379690023457,
          0.342379690023457,
          0.342379690023457,
          0.342379690023457,
          0.342379690023457,
          0.342379690023457,
          0.342379690023457,
          0.342379690023457,
          0.342379690023457,
          0.342379690023457,
          0.342379690023457,
          0.342379690023457,
          0.342379690023457,
          0.342379690023457,
          0.342379690023457,
          0.342379690023457,
          0.342379690023457,
          0.342379690023457,
          0.342379690023457,
          0.342379690023457,
          0.342379690023457,
          0.342379690023457,
          0.342379690023457,
          0.342379690023457,
          0.342379690023457,
          0.342379690023457,
          0.342379690023457,
          0.342379690023457,
          0.342379690023457,
          0.342379690023457,
          0.342379690023457,
          0.342379690023457,
          0.342379690023457,
          0.342379690023457,
          0.342379690023457,
          0.342379690023457,
          0.342379690023457,
          0.342379690023457,
          0.342379690023457,
          0.342379690023457,
          0.342379690023457,
          0.342379690023457,
          0.342379690023457,
          0.342379690023457,
          0.342379690023457,
          0.342379690023457,
          0.342379690023457,
          0.342379690023457,
          0.342379690023457,
          0.342379690023457,
          0.342379690023457,
          0.31480810103822665,
          0.31480810103822665,
          0.31480810103822665,
          0.31480810103822665,
          0.31480810103822665,
          0.31480810103822665,
          0.31480810103822665,
          0.31480810103822665,
          0.31480810103822665,
          0.31480810103822665,
          0.31480810103822665,
          0.31480810103822665,
          0.31480810103822665,
          0.31480810103822665,
          0.31480810103822665,
          0.31480810103822665,
          0.31480810103822665,
          0.31480810103822665,
          0.31480810103822665,
          0.31480810103822665,
          0.31480810103822665,
          0.31480810103822665,
          0.31480810103822665,
          0.31480810103822665,
          0.31480810103822665,
          0.31480810103822665,
          0.31480810103822665,
          0.31480810103822665,
          0.31480810103822665,
          0.31480810103822665,
          0.31480810103822665,
          0.31480810103822665,
          0.31480810103822665,
          0.31480810103822665,
          0.31480810103822665,
          0.31480810103822665,
          0.31480810103822665,
          0.31480810103822665,
          0.31480810103822665,
          0.31480810103822665,
          0.31480810103822665,
          0.31480810103822665,
          0.31480810103822665,
          0.31480810103822665,
          0.31480810103822665,
          0.31480810103822665,
          0.31480810103822665,
          0.31480810103822665,
          0.31480810103822665,
          0.31480810103822665,
          0.31480810103822665,
          0.31480810103822665,
          0.31480810103822665,
          0.31480810103822665,
          0.31480810103822665,
          0.31480810103822665,
          0.31480810103822665,
          0.31480810103822665,
          0.31480810103822665,
          0.31480810103822665,
          0.31480810103822665,
          0.31480810103822665,
          0.31480810103822665,
          0.31480810103822665,
          0.31480810103822665,
          0.31480810103822665,
          0.31480810103822665,
          0.31480810103822665,
          0.31480810103822665,
          0.31480810103822665,
          0.31480810103822665,
          0.31480810103822665,
          0.31480810103822665,
          0.31480810103822665,
          0.31480810103822665,
          0.31480810103822665,
          0.31480810103822665,
          0.31480810103822665,
          0.31480810103822665,
          0.31480810103822665,
          0.31480810103822665,
          0.31480810103822665,
          0.31480810103822665,
          0.31480810103822665,
          0.31480810103822665,
          0.31480810103822665,
          0.31480810103822665,
          0.31480810103822665,
          0.31480810103822665,
          0.31480810103822665,
          0.31480810103822665,
          0.31480810103822665,
          0.31480810103822665,
          0.31480810103822665,
          0.31480810103822665,
          0.31480810103822665,
          0.31480810103822665,
          0.31480810103822665,
          0.31480810103822665,
          0.31480810103822665,
          0.3038393459321051,
          0.3038393459321051,
          0.3038393459321051,
          0.3038393459321051,
          0.3038393459321051,
          0.3038393459321051,
          0.3038393459321051,
          0.3038393459321051,
          0.3038393459321051,
          0.3038393459321051,
          0.3038393459321051,
          0.3038393459321051,
          0.3038393459321051,
          0.3038393459321051,
          0.3038393459321051,
          0.3038393459321051,
          0.3038393459321051,
          0.3038393459321051,
          0.3038393459321051,
          0.3038393459321051,
          0.3038393459321051,
          0.3038393459321051,
          0.3038393459321051,
          0.3038393459321051,
          0.3038393459321051,
          0.3038393459321051,
          0.3038393459321051,
          0.3038393459321051,
          0.3038393459321051,
          0.3038393459321051,
          0.3038393459321051,
          0.3038393459321051,
          0.3038393459321051,
          0.3038393459321051,
          0.3038393459321051,
          0.3038393459321051,
          0.3038393459321051,
          0.3038393459321051,
          0.3038393459321051,
          0.3038393459321051,
          0.3038393459321051,
          0.3038393459321051,
          0.3038393459321051,
          0.3038393459321051,
          0.3038393459321051,
          0.3038393459321051,
          0.3038393459321051,
          0.3038393459321051,
          0.3038393459321051,
          0.3038393459321051,
          0.3038393459321051,
          0.3038393459321051,
          0.3038393459321051,
          0.3038393459321051,
          0.3038393459321051,
          0.3038393459321051,
          0.3038393459321051,
          0.3038393459321051,
          0.3038393459321051,
          0.3038393459321051,
          0.3038393459321051,
          0.3038393459321051,
          0.3038393459321051,
          0.3038393459321051,
          0.3038393459321051,
          0.3038393459321051,
          0.3038393459321051,
          0.3038393459321051,
          0.3038393459321051,
          0.3038393459321051,
          0.3038393459321051,
          0.3038393459321051,
          0.3038393459321051,
          0.3038393459321051,
          0.3038393459321051,
          0.3038393459321051,
          0.3038393459321051,
          0.3038393459321051,
          0.3038393459321051,
          0.3038393459321051,
          0.3038393459321051,
          0.3038393459321051,
          0.3038393459321051,
          0.3038393459321051,
          0.3038393459321051,
          0.3038393459321051,
          0.3038393459321051,
          0.3038393459321051,
          0.3038393459321051,
          0.3038393459321051,
          0.3038393459321051,
          0.3038393459321051,
          0.3038393459321051,
          0.3038393459321051,
          0.3038393459321051,
          0.3038393459321051,
          0.3038393459321051,
          0.3038393459321051,
          0.3038393459321051,
          0.3038393459321051,
          0.2950196630981633,
          0.2950196630981633,
          0.2950196630981633,
          0.2950196630981633,
          0.2950196630981633,
          0.2950196630981633,
          0.2950196630981633,
          0.2950196630981633,
          0.2950196630981633,
          0.2950196630981633,
          0.2950196630981633,
          0.2950196630981633,
          0.2950196630981633,
          0.2950196630981633,
          0.2950196630981633,
          0.2950196630981633,
          0.2950196630981633,
          0.2950196630981633,
          0.2950196630981633,
          0.2950196630981633,
          0.2950196630981633,
          0.2950196630981633,
          0.2950196630981633,
          0.2950196630981633,
          0.2950196630981633,
          0.2950196630981633,
          0.2950196630981633,
          0.2950196630981633,
          0.2950196630981633,
          0.2950196630981633,
          0.2950196630981633,
          0.2950196630981633,
          0.2950196630981633,
          0.2950196630981633,
          0.2950196630981633,
          0.2950196630981633,
          0.2950196630981633,
          0.2950196630981633,
          0.2950196630981633,
          0.2950196630981633,
          0.2950196630981633,
          0.2950196630981633,
          0.2950196630981633,
          0.2950196630981633,
          0.2950196630981633,
          0.2950196630981633,
          0.2950196630981633,
          0.2950196630981633,
          0.2950196630981633,
          0.2950196630981633,
          0.2950196630981633,
          0.2950196630981633,
          0.2950196630981633,
          0.2950196630981633,
          0.2950196630981633,
          0.2950196630981633,
          0.2950196630981633,
          0.2950196630981633,
          0.2950196630981633,
          0.2950196630981633,
          0.2950196630981633,
          0.2950196630981633,
          0.2950196630981633,
          0.2950196630981633,
          0.2950196630981633,
          0.2950196630981633,
          0.2950196630981633,
          0.2950196630981633,
          0.2950196630981633,
          0.2950196630981633,
          0.2950196630981633,
          0.2950196630981633,
          0.2950196630981633,
          0.2950196630981633,
          0.2950196630981633,
          0.2950196630981633,
          0.2950196630981633,
          0.2950196630981633,
          0.2950196630981633,
          0.2950196630981633,
          0.2950196630981633,
          0.2950196630981633,
          0.2950196630981633,
          0.2950196630981633,
          0.2950196630981633,
          0.2950196630981633,
          0.2950196630981633,
          0.2950196630981633,
          0.2950196630981633,
          0.2950196630981633,
          0.2950196630981633,
          0.2950196630981633,
          0.2950196630981633,
          0.2950196630981633,
          0.2950196630981633,
          0.2950196630981633,
          0.2950196630981633,
          0.2950196630981633,
          0.2950196630981633,
          0.2950196630981633,
          0.28533773118766975,
          0.28533773118766975,
          0.28533773118766975,
          0.28533773118766975,
          0.28533773118766975,
          0.28533773118766975,
          0.28533773118766975,
          0.28533773118766975,
          0.28533773118766975,
          0.28533773118766975,
          0.28533773118766975,
          0.28533773118766975,
          0.28533773118766975,
          0.28533773118766975,
          0.28533773118766975,
          0.28533773118766975,
          0.28533773118766975,
          0.28533773118766975,
          0.28533773118766975,
          0.28533773118766975,
          0.28533773118766975,
          0.28533773118766975,
          0.28533773118766975,
          0.28533773118766975,
          0.28533773118766975,
          0.28533773118766975,
          0.28533773118766975,
          0.28533773118766975,
          0.28533773118766975,
          0.28533773118766975,
          0.28533773118766975,
          0.28533773118766975,
          0.28533773118766975,
          0.28533773118766975,
          0.28533773118766975,
          0.28533773118766975,
          0.28533773118766975,
          0.28533773118766975,
          0.28533773118766975,
          0.28533773118766975,
          0.28533773118766975,
          0.28533773118766975,
          0.28533773118766975,
          0.28533773118766975,
          0.28533773118766975,
          0.28533773118766975,
          0.28533773118766975,
          0.28533773118766975,
          0.28533773118766975,
          0.28533773118766975,
          0.28533773118766975,
          0.28533773118766975,
          0.28533773118766975,
          0.28533773118766975,
          0.28533773118766975,
          0.28533773118766975,
          0.28533773118766975,
          0.28533773118766975,
          0.28533773118766975,
          0.28533773118766975,
          0.28533773118766975,
          0.28533773118766975,
          0.28533773118766975,
          0.28533773118766975,
          0.28533773118766975,
          0.28533773118766975,
          0.28533773118766975,
          0.28533773118766975,
          0.28533773118766975,
          0.28533773118766975,
          0.28533773118766975,
          0.28533773118766975,
          0.28533773118766975,
          0.28533773118766975,
          0.28533773118766975,
          0.28533773118766975,
          0.28533773118766975,
          0.28533773118766975,
          0.28533773118766975,
          0.28533773118766975,
          0.28533773118766975,
          0.28533773118766975,
          0.28533773118766975,
          0.28533773118766975,
          0.28533773118766975,
          0.28533773118766975,
          0.28533773118766975,
          0.28533773118766975,
          0.28533773118766975,
          0.28533773118766975,
          0.28533773118766975,
          0.28533773118766975,
          0.28533773118766975,
          0.28533773118766975,
          0.28533773118766975,
          0.28533773118766975,
          0.28533773118766975,
          0.28533773118766975,
          0.28533773118766975,
          0.28533773118766975,
          0.2729056730530455,
          0.2729056730530455,
          0.2729056730530455,
          0.2729056730530455,
          0.2729056730530455,
          0.2729056730530455,
          0.2729056730530455,
          0.2729056730530455,
          0.2729056730530455,
          0.2729056730530455,
          0.2729056730530455,
          0.2729056730530455,
          0.2729056730530455,
          0.2729056730530455,
          0.2729056730530455,
          0.2729056730530455,
          0.2729056730530455,
          0.2729056730530455,
          0.2729056730530455,
          0.2729056730530455,
          0.2729056730530455,
          0.2729056730530455,
          0.2729056730530455,
          0.2729056730530455,
          0.2729056730530455,
          0.2729056730530455,
          0.2729056730530455,
          0.2729056730530455,
          0.2729056730530455,
          0.2729056730530455,
          0.2729056730530455,
          0.2729056730530455,
          0.2729056730530455,
          0.2729056730530455,
          0.2729056730530455,
          0.2729056730530455,
          0.2729056730530455,
          0.2729056730530455,
          0.2729056730530455,
          0.2729056730530455,
          0.2729056730530455,
          0.2729056730530455,
          0.2729056730530455,
          0.2729056730530455,
          0.2729056730530455,
          0.2729056730530455,
          0.2729056730530455,
          0.2729056730530455,
          0.2729056730530455,
          0.2729056730530455,
          0.2729056730530455,
          0.2729056730530455,
          0.2729056730530455,
          0.2729056730530455,
          0.2729056730530455,
          0.2729056730530455,
          0.2729056730530455,
          0.2729056730530455,
          0.2729056730530455,
          0.2729056730530455,
          0.2729056730530455,
          0.2729056730530455,
          0.2729056730530455,
          0.2729056730530455,
          0.2729056730530455,
          0.2729056730530455,
          0.2729056730530455,
          0.2729056730530455,
          0.2729056730530455,
          0.2729056730530455,
          0.2729056730530455,
          0.2729056730530455,
          0.2729056730530455,
          0.2729056730530455,
          0.2729056730530455,
          0.2729056730530455,
          0.2729056730530455,
          0.2729056730530455,
          0.2729056730530455,
          0.2729056730530455,
          0.2729056730530455,
          0.2729056730530455,
          0.2729056730530455,
          0.2729056730530455,
          0.2729056730530455,
          0.2729056730530455,
          0.2729056730530455,
          0.2729056730530455,
          0.2729056730530455,
          0.2729056730530455,
          0.2729056730530455,
          0.2729056730530455,
          0.2729056730530455,
          0.2729056730530455,
          0.2729056730530455,
          0.2729056730530455,
          0.2729056730530455,
          0.2729056730530455,
          0.2729056730530455,
          0.2729056730530455,
          0.2635200216824682,
          0.2635200216824682,
          0.2635200216824682,
          0.2635200216824682,
          0.2635200216824682,
          0.2635200216824682,
          0.2635200216824682,
          0.2635200216824682,
          0.2635200216824682,
          0.2635200216824682,
          0.2635200216824682,
          0.2635200216824682,
          0.2635200216824682,
          0.2635200216824682,
          0.2635200216824682,
          0.2635200216824682,
          0.2635200216824682,
          0.2635200216824682,
          0.2635200216824682,
          0.2635200216824682,
          0.2635200216824682,
          0.2635200216824682,
          0.2635200216824682,
          0.2635200216824682,
          0.2635200216824682,
          0.2635200216824682,
          0.2635200216824682,
          0.2635200216824682,
          0.2635200216824682,
          0.2635200216824682,
          0.2635200216824682,
          0.2635200216824682,
          0.2635200216824682,
          0.2635200216824682,
          0.2635200216824682,
          0.2635200216824682,
          0.2635200216824682,
          0.2635200216824682,
          0.2635200216824682,
          0.2635200216824682,
          0.2635200216824682,
          0.2635200216824682,
          0.2635200216824682,
          0.2635200216824682,
          0.2635200216824682,
          0.2635200216824682,
          0.2635200216824682,
          0.2635200216824682,
          0.2635200216824682,
          0.2635200216824682,
          0.2635200216824682,
          0.2635200216824682,
          0.2635200216824682,
          0.2635200216824682,
          0.2635200216824682,
          0.2635200216824682,
          0.2635200216824682,
          0.2635200216824682,
          0.2635200216824682,
          0.2635200216824682,
          0.2635200216824682,
          0.2635200216824682,
          0.2635200216824682,
          0.2635200216824682,
          0.2635200216824682,
          0.2635200216824682,
          0.2635200216824682,
          0.2635200216824682,
          0.2635200216824682,
          0.2635200216824682,
          0.2635200216824682,
          0.2635200216824682,
          0.2635200216824682,
          0.2635200216824682,
          0.2635200216824682,
          0.2635200216824682,
          0.2635200216824682,
          0.2635200216824682,
          0.2635200216824682,
          0.2635200216824682,
          0.2635200216824682,
          0.2635200216824682,
          0.2635200216824682,
          0.2635200216824682,
          0.2635200216824682,
          0.2635200216824682,
          0.2635200216824682,
          0.2635200216824682,
          0.2635200216824682,
          0.2635200216824682,
          0.2635200216824682,
          0.2635200216824682,
          0.2635200216824682,
          0.2635200216824682,
          0.2635200216824682,
          0.2635200216824682,
          0.2635200216824682,
          0.2635200216824682,
          0.2635200216824682,
          0.2635200216824682,
          0.25503699126862234,
          0.25503699126862234,
          0.25503699126862234,
          0.25503699126862234,
          0.25503699126862234,
          0.25503699126862234,
          0.25503699126862234,
          0.25503699126862234,
          0.25503699126862234,
          0.25503699126862234,
          0.25503699126862234,
          0.25503699126862234,
          0.25503699126862234,
          0.25503699126862234,
          0.25503699126862234,
          0.25503699126862234,
          0.25503699126862234,
          0.25503699126862234,
          0.25503699126862234,
          0.25503699126862234,
          0.25503699126862234,
          0.25503699126862234,
          0.25503699126862234,
          0.25503699126862234,
          0.25503699126862234,
          0.25503699126862234,
          0.25503699126862234,
          0.25503699126862234,
          0.25503699126862234,
          0.25503699126862234,
          0.25503699126862234,
          0.25503699126862234,
          0.25503699126862234,
          0.25503699126862234,
          0.25503699126862234,
          0.25503699126862234,
          0.25503699126862234,
          0.25503699126862234,
          0.25503699126862234,
          0.25503699126862234,
          0.25503699126862234,
          0.25503699126862234,
          0.25503699126862234,
          0.25503699126862234,
          0.25503699126862234,
          0.25503699126862234,
          0.25503699126862234,
          0.25503699126862234,
          0.25503699126862234,
          0.25503699126862234,
          0.25503699126862234,
          0.25503699126862234,
          0.25503699126862234,
          0.25503699126862234,
          0.25503699126862234,
          0.25503699126862234,
          0.25503699126862234,
          0.25503699126862234,
          0.25503699126862234,
          0.25503699126862234,
          0.25503699126862234,
          0.25503699126862234,
          0.25503699126862234,
          0.25503699126862234,
          0.25503699126862234,
          0.25503699126862234,
          0.25503699126862234,
          0.25503699126862234,
          0.25503699126862234,
          0.25503699126862234,
          0.25503699126862234,
          0.25503699126862234,
          0.25503699126862234,
          0.25503699126862234,
          0.25503699126862234,
          0.25503699126862234,
          0.25503699126862234,
          0.25503699126862234,
          0.25503699126862234,
          0.25503699126862234,
          0.25503699126862234,
          0.25503699126862234,
          0.25503699126862234,
          0.25503699126862234,
          0.25503699126862234,
          0.25503699126862234,
          0.25503699126862234,
          0.25503699126862234,
          0.25503699126862234,
          0.25503699126862234,
          0.25503699126862234,
          0.25503699126862234,
          0.25503699126862234,
          0.25503699126862234,
          0.25503699126862234,
          0.25503699126862234,
          0.25503699126862234,
          0.25503699126862234,
          0.25503699126862234,
          0.25503699126862234,
          0.25032728089365347,
          0.25032728089365347,
          0.25032728089365347,
          0.25032728089365347,
          0.25032728089365347,
          0.25032728089365347,
          0.25032728089365347,
          0.25032728089365347,
          0.25032728089365347,
          0.25032728089365347,
          0.25032728089365347,
          0.25032728089365347,
          0.25032728089365347,
          0.25032728089365347,
          0.25032728089365347,
          0.25032728089365347,
          0.25032728089365347,
          0.25032728089365347,
          0.25032728089365347,
          0.25032728089365347,
          0.25032728089365347,
          0.25032728089365347,
          0.25032728089365347,
          0.25032728089365347,
          0.25032728089365347,
          0.25032728089365347,
          0.25032728089365347,
          0.25032728089365347,
          0.25032728089365347,
          0.25032728089365347,
          0.25032728089365347,
          0.25032728089365347,
          0.25032728089365347,
          0.25032728089365347,
          0.25032728089365347,
          0.25032728089365347,
          0.25032728089365347,
          0.25032728089365347,
          0.25032728089365347,
          0.25032728089365347,
          0.25032728089365347,
          0.25032728089365347,
          0.25032728089365347,
          0.25032728089365347,
          0.25032728089365347,
          0.25032728089365347,
          0.25032728089365347,
          0.25032728089365347,
          0.25032728089365347,
          0.25032728089365347,
          0.25032728089365347,
          0.25032728089365347,
          0.25032728089365347,
          0.25032728089365347,
          0.25032728089365347,
          0.25032728089365347,
          0.25032728089365347,
          0.25032728089365347,
          0.25032728089365347,
          0.25032728089365347,
          0.25032728089365347,
          0.25032728089365347,
          0.25032728089365347,
          0.25032728089365347,
          0.25032728089365347,
          0.25032728089365347,
          0.25032728089365347,
          0.25032728089365347,
          0.25032728089365347,
          0.25032728089365347,
          0.25032728089365347,
          0.25032728089365347,
          0.25032728089365347,
          0.25032728089365347,
          0.25032728089365347,
          0.25032728089365347,
          0.25032728089365347,
          0.25032728089365347,
          0.25032728089365347,
          0.25032728089365347,
          0.25032728089365347,
          0.25032728089365347,
          0.25032728089365347,
          0.25032728089365347,
          0.25032728089365347,
          0.25032728089365347,
          0.25032728089365347,
          0.25032728089365347,
          0.25032728089365347,
          0.25032728089365347,
          0.25032728089365347,
          0.25032728089365347,
          0.25032728089365347,
          0.25032728089365347,
          0.25032728089365347,
          0.25032728089365347,
          0.25032728089365347,
          0.25032728089365347,
          0.25032728089365347,
          0.25032728089365347,
          0.2454555338530192,
          0.2454555338530192,
          0.2454555338530192,
          0.2454555338530192,
          0.2454555338530192,
          0.2454555338530192,
          0.2454555338530192,
          0.2454555338530192,
          0.2454555338530192,
          0.2454555338530192,
          0.2454555338530192,
          0.2454555338530192,
          0.2454555338530192,
          0.2454555338530192,
          0.2454555338530192,
          0.2454555338530192,
          0.2454555338530192,
          0.2454555338530192,
          0.2454555338530192,
          0.2454555338530192,
          0.2454555338530192,
          0.2454555338530192,
          0.2454555338530192,
          0.2454555338530192,
          0.2454555338530192,
          0.2454555338530192,
          0.2454555338530192,
          0.2454555338530192,
          0.2454555338530192,
          0.2454555338530192,
          0.2454555338530192,
          0.2454555338530192,
          0.2454555338530192,
          0.2454555338530192,
          0.2454555338530192,
          0.2454555338530192,
          0.2454555338530192,
          0.2454555338530192,
          0.2454555338530192,
          0.2454555338530192,
          0.2454555338530192,
          0.2454555338530192,
          0.2454555338530192,
          0.2454555338530192,
          0.2454555338530192,
          0.2454555338530192,
          0.2454555338530192,
          0.2454555338530192,
          0.2454555338530192,
          0.2454555338530192,
          0.2454555338530192,
          0.2454555338530192,
          0.2454555338530192,
          0.2454555338530192,
          0.2454555338530192,
          0.2454555338530192,
          0.2454555338530192,
          0.2454555338530192,
          0.2454555338530192,
          0.2454555338530192,
          0.2454555338530192,
          0.2454555338530192,
          0.2454555338530192,
          0.2454555338530192,
          0.2454555338530192,
          0.2454555338530192,
          0.2454555338530192,
          0.2454555338530192,
          0.2454555338530192,
          0.2454555338530192,
          0.2454555338530192,
          0.2454555338530192,
          0.2454555338530192,
          0.2454555338530192,
          0.2454555338530192,
          0.2454555338530192,
          0.2454555338530192,
          0.2454555338530192,
          0.2454555338530192,
          0.2454555338530192,
          0.2454555338530192,
          0.2454555338530192,
          0.2454555338530192,
          0.2454555338530192,
          0.2454555338530192,
          0.2454555338530192,
          0.2454555338530192,
          0.2454555338530192,
          0.2454555338530192,
          0.2454555338530192,
          0.2454555338530192,
          0.2454555338530192,
          0.2454555338530192,
          0.2454555338530192,
          0.2454555338530192,
          0.2454555338530192,
          0.2454555338530192,
          0.2454555338530192,
          0.2454555338530192,
          0.2454555338530192,
          0.24102565267653162,
          0.24102565267653162,
          0.24102565267653162,
          0.24102565267653162,
          0.24102565267653162,
          0.24102565267653162,
          0.24102565267653162,
          0.24102565267653162,
          0.24102565267653162,
          0.24102565267653162,
          0.24102565267653162,
          0.24102565267653162,
          0.24102565267653162,
          0.24102565267653162,
          0.24102565267653162,
          0.24102565267653162,
          0.24102565267653162,
          0.24102565267653162,
          0.24102565267653162,
          0.24102565267653162,
          0.24102565267653162,
          0.24102565267653162,
          0.24102565267653162,
          0.24102565267653162,
          0.24102565267653162,
          0.24102565267653162,
          0.24102565267653162,
          0.24102565267653162,
          0.24102565267653162,
          0.24102565267653162,
          0.24102565267653162,
          0.24102565267653162,
          0.24102565267653162,
          0.24102565267653162,
          0.24102565267653162,
          0.24102565267653162,
          0.24102565267653162,
          0.24102565267653162,
          0.24102565267653162,
          0.24102565267653162,
          0.24102565267653162,
          0.24102565267653162,
          0.24102565267653162,
          0.24102565267653162,
          0.24102565267653162,
          0.24102565267653162,
          0.24102565267653162,
          0.24102565267653162,
          0.24102565267653162,
          0.24102565267653162,
          0.24102565267653162,
          0.24102565267653162,
          0.24102565267653162,
          0.24102565267653162,
          0.24102565267653162,
          0.24102565267653162,
          0.24102565267653162,
          0.24102565267653162,
          0.24102565267653162,
          0.24102565267653162,
          0.24102565267653162,
          0.24102565267653162,
          0.24102565267653162,
          0.24102565267653162,
          0.24102565267653162,
          0.24102565267653162,
          0.24102565267653162,
          0.24102565267653162,
          0.24102565267653162,
          0.24102565267653162,
          0.24102565267653162,
          0.24102565267653162,
          0.24102565267653162,
          0.24102565267653162,
          0.24102565267653162,
          0.24102565267653162,
          0.24102565267653162,
          0.24102565267653162,
          0.24102565267653162,
          0.24102565267653162,
          0.24102565267653162,
          0.24102565267653162,
          0.24102565267653162,
          0.24102565267653162,
          0.24102565267653162,
          0.24102565267653162,
          0.24102565267653162,
          0.24102565267653162,
          0.24102565267653162,
          0.24102565267653162,
          0.24102565267653162,
          0.24102565267653162,
          0.24102565267653162,
          0.24102565267653162,
          0.24102565267653162,
          0.24102565267653162,
          0.24102565267653162,
          0.24102565267653162,
          0.24102565267653162,
          0.24102565267653162,
          0.23631778385177735,
          0.23631778385177735,
          0.23631778385177735,
          0.23631778385177735,
          0.23631778385177735,
          0.23631778385177735,
          0.23631778385177735,
          0.23631778385177735,
          0.23631778385177735,
          0.23631778385177735,
          0.23631778385177735,
          0.23631778385177735,
          0.23631778385177735,
          0.23631778385177735,
          0.23631778385177735,
          0.23631778385177735,
          0.23631778385177735,
          0.23631778385177735,
          0.23631778385177735,
          0.23631778385177735,
          0.23631778385177735,
          0.23631778385177735,
          0.23631778385177735,
          0.23631778385177735,
          0.23631778385177735,
          0.23631778385177735,
          0.23631778385177735,
          0.23631778385177735,
          0.23631778385177735,
          0.23631778385177735,
          0.23631778385177735,
          0.23631778385177735,
          0.23631778385177735,
          0.23631778385177735,
          0.23631778385177735,
          0.23631778385177735,
          0.23631778385177735,
          0.23631778385177735,
          0.23631778385177735,
          0.23631778385177735,
          0.23631778385177735,
          0.23631778385177735,
          0.23631778385177735,
          0.23631778385177735,
          0.23631778385177735,
          0.23631778385177735,
          0.23631778385177735,
          0.23631778385177735,
          0.23631778385177735,
          0.23631778385177735,
          0.23631778385177735,
          0.23631778385177735,
          0.23631778385177735,
          0.23631778385177735,
          0.23631778385177735,
          0.23631778385177735,
          0.23631778385177735,
          0.23631778385177735,
          0.23631778385177735,
          0.23631778385177735,
          0.23631778385177735,
          0.23631778385177735,
          0.23631778385177735,
          0.23631778385177735,
          0.23631778385177735,
          0.23631778385177735,
          0.23631778385177735,
          0.23631778385177735,
          0.23631778385177735,
          0.23631778385177735,
          0.23631778385177735,
          0.23631778385177735,
          0.23631778385177735,
          0.23631778385177735,
          0.23631778385177735,
          0.23631778385177735,
          0.23631778385177735,
          0.23631778385177735,
          0.23631778385177735,
          0.23631778385177735,
          0.23631778385177735,
          0.23631778385177735,
          0.23631778385177735,
          0.23631778385177735,
          0.23631778385177735,
          0.23631778385177735,
          0.23631778385177735,
          0.23631778385177735,
          0.23631778385177735,
          0.23631778385177735,
          0.23631778385177735,
          0.23631778385177735,
          0.23631778385177735,
          0.23631778385177735,
          0.23631778385177735,
          0.23631778385177735,
          0.23631778385177735,
          0.23631778385177735,
          0.23631778385177735,
          0.23631778385177735,
          0.23289222560488407,
          0.23289222560488407,
          0.23289222560488407,
          0.23289222560488407,
          0.23289222560488407,
          0.23289222560488407,
          0.23289222560488407,
          0.23289222560488407,
          0.23289222560488407,
          0.23289222560488407,
          0.23289222560488407,
          0.23289222560488407,
          0.23289222560488407,
          0.23289222560488407,
          0.23289222560488407,
          0.23289222560488407,
          0.23289222560488407,
          0.23289222560488407,
          0.23289222560488407,
          0.23289222560488407,
          0.23289222560488407,
          0.23289222560488407,
          0.23289222560488407,
          0.23289222560488407,
          0.23289222560488407,
          0.23289222560488407,
          0.23289222560488407,
          0.23289222560488407,
          0.23289222560488407,
          0.23289222560488407,
          0.23289222560488407,
          0.23289222560488407,
          0.23289222560488407,
          0.23289222560488407,
          0.23289222560488407,
          0.23289222560488407,
          0.23289222560488407,
          0.23289222560488407,
          0.23289222560488407,
          0.23289222560488407,
          0.23289222560488407,
          0.23289222560488407,
          0.23289222560488407,
          0.23289222560488407,
          0.23289222560488407,
          0.23289222560488407,
          0.23289222560488407,
          0.23289222560488407,
          0.23289222560488407,
          0.23289222560488407,
          0.23289222560488407,
          0.23289222560488407,
          0.23289222560488407,
          0.23289222560488407,
          0.23289222560488407,
          0.23289222560488407,
          0.23289222560488407,
          0.23289222560488407,
          0.23289222560488407,
          0.23289222560488407,
          0.23289222560488407,
          0.23289222560488407,
          0.23289222560488407,
          0.23289222560488407,
          0.23289222560488407,
          0.23289222560488407,
          0.23289222560488407,
          0.23289222560488407,
          0.23289222560488407,
          0.23289222560488407,
          0.23289222560488407,
          0.23289222560488407,
          0.23289222560488407,
          0.23289222560488407,
          0.23289222560488407,
          0.23289222560488407,
          0.23289222560488407,
          0.23289222560488407,
          0.23289222560488407,
          0.23289222560488407,
          0.23289222560488407,
          0.23289222560488407,
          0.23289222560488407,
          0.23289222560488407,
          0.23289222560488407,
          0.23289222560488407,
          0.23289222560488407,
          0.23289222560488407,
          0.23289222560488407,
          0.23289222560488407,
          0.23289222560488407,
          0.23289222560488407,
          0.23289222560488407,
          0.23289222560488407,
          0.23289222560488407,
          0.23289222560488407,
          0.23289222560488407,
          0.23289222560488407,
          0.23289222560488407,
          0.23289222560488407,
          0.2292886537109917,
          0.2292886537109917,
          0.2292886537109917,
          0.2292886537109917,
          0.2292886537109917,
          0.2292886537109917,
          0.2292886537109917,
          0.2292886537109917,
          0.2292886537109917,
          0.2292886537109917,
          0.2292886537109917,
          0.2292886537109917,
          0.2292886537109917,
          0.2292886537109917,
          0.2292886537109917,
          0.2292886537109917,
          0.2292886537109917,
          0.2292886537109917,
          0.2292886537109917,
          0.2292886537109917,
          0.2292886537109917,
          0.2292886537109917,
          0.2292886537109917,
          0.2292886537109917,
          0.2292886537109917,
          0.2292886537109917,
          0.2292886537109917,
          0.2292886537109917,
          0.2292886537109917,
          0.2292886537109917,
          0.2292886537109917,
          0.2292886537109917,
          0.2292886537109917,
          0.2292886537109917,
          0.2292886537109917,
          0.2292886537109917,
          0.2292886537109917,
          0.2292886537109917,
          0.2292886537109917,
          0.2292886537109917,
          0.2292886537109917,
          0.2292886537109917,
          0.2292886537109917,
          0.2292886537109917,
          0.2292886537109917,
          0.2292886537109917,
          0.2292886537109917,
          0.2292886537109917,
          0.2292886537109917,
          0.2292886537109917,
          0.2292886537109917,
          0.2292886537109917,
          0.2292886537109917,
          0.2292886537109917,
          0.2292886537109917,
          0.2292886537109917,
          0.2292886537109917,
          0.2292886537109917,
          0.2292886537109917,
          0.2292886537109917,
          0.2292886537109917,
          0.2292886537109917,
          0.2292886537109917,
          0.2292886537109917,
          0.2292886537109917,
          0.2292886537109917,
          0.2292886537109917,
          0.2292886537109917,
          0.2292886537109917,
          0.2292886537109917,
          0.2292886537109917,
          0.2292886537109917,
          0.2292886537109917,
          0.2292886537109917,
          0.2292886537109917,
          0.2292886537109917,
          0.2292886537109917,
          0.2292886537109917,
          0.2292886537109917,
          0.2292886537109917,
          0.2292886537109917,
          0.2292886537109917,
          0.2292886537109917,
          0.2292886537109917,
          0.2292886537109917,
          0.2292886537109917,
          0.2292886537109917,
          0.2292886537109917,
          0.2292886537109917,
          0.2292886537109917,
          0.2292886537109917,
          0.2292886537109917,
          0.2292886537109917,
          0.2292886537109917,
          0.2292886537109917,
          0.2292886537109917,
          0.2292886537109917,
          0.2292886537109917,
          0.2292886537109917,
          0.2292886537109917,
          0.22586541024608298,
          0.22586541024608298,
          0.22586541024608298,
          0.22586541024608298,
          0.22586541024608298,
          0.22586541024608298,
          0.22586541024608298,
          0.22586541024608298,
          0.22586541024608298,
          0.22586541024608298,
          0.22586541024608298,
          0.22586541024608298,
          0.22586541024608298,
          0.22586541024608298,
          0.22586541024608298,
          0.22586541024608298,
          0.22586541024608298,
          0.22586541024608298,
          0.22586541024608298,
          0.22586541024608298,
          0.22586541024608298,
          0.22586541024608298,
          0.22586541024608298,
          0.22586541024608298,
          0.22586541024608298,
          0.22586541024608298,
          0.22586541024608298,
          0.22586541024608298,
          0.22586541024608298,
          0.22586541024608298,
          0.22586541024608298,
          0.22586541024608298,
          0.22586541024608298,
          0.22586541024608298,
          0.22586541024608298,
          0.22586541024608298,
          0.22586541024608298,
          0.22586541024608298,
          0.22586541024608298,
          0.22586541024608298,
          0.22586541024608298,
          0.22586541024608298,
          0.22586541024608298,
          0.22586541024608298,
          0.22586541024608298,
          0.22586541024608298,
          0.22586541024608298,
          0.22586541024608298,
          0.22586541024608298,
          0.22586541024608298,
          0.22586541024608298,
          0.22586541024608298,
          0.22586541024608298,
          0.22586541024608298,
          0.22586541024608298,
          0.22586541024608298,
          0.22586541024608298,
          0.22586541024608298,
          0.22586541024608298,
          0.22586541024608298,
          0.22586541024608298,
          0.22586541024608298,
          0.22586541024608298,
          0.22586541024608298,
          0.22586541024608298,
          0.22586541024608298,
          0.22586541024608298,
          0.22586541024608298,
          0.22586541024608298,
          0.22586541024608298,
          0.22586541024608298,
          0.22586541024608298,
          0.22586541024608298,
          0.22586541024608298,
          0.22586541024608298,
          0.22586541024608298,
          0.22586541024608298,
          0.22586541024608298,
          0.22586541024608298,
          0.22586541024608298,
          0.22586541024608298,
          0.22586541024608298,
          0.22586541024608298,
          0.22586541024608298,
          0.22586541024608298,
          0.22586541024608298,
          0.22586541024608298,
          0.22586541024608298,
          0.22586541024608298,
          0.22586541024608298,
          0.22586541024608298,
          0.22586541024608298,
          0.22586541024608298,
          0.22586541024608298,
          0.22586541024608298,
          0.22586541024608298,
          0.22586541024608298,
          0.22586541024608298,
          0.22586541024608298,
          0.22586541024608298,
          0.2230991041106568,
          0.2230991041106568,
          0.2230991041106568,
          0.2230991041106568,
          0.2230991041106568,
          0.2230991041106568,
          0.2230991041106568,
          0.2230991041106568,
          0.2230991041106568,
          0.2230991041106568,
          0.2230991041106568,
          0.2230991041106568,
          0.2230991041106568,
          0.2230991041106568,
          0.2230991041106568,
          0.2230991041106568,
          0.2230991041106568,
          0.2230991041106568,
          0.2230991041106568,
          0.2230991041106568,
          0.2230991041106568,
          0.2230991041106568,
          0.2230991041106568,
          0.2230991041106568,
          0.2230991041106568,
          0.2230991041106568,
          0.2230991041106568,
          0.2230991041106568,
          0.2230991041106568,
          0.2230991041106568,
          0.2230991041106568,
          0.2230991041106568,
          0.2230991041106568,
          0.2230991041106568,
          0.2230991041106568,
          0.2230991041106568,
          0.2230991041106568,
          0.2230991041106568,
          0.2230991041106568,
          0.2230991041106568,
          0.2230991041106568,
          0.2230991041106568,
          0.2230991041106568,
          0.2230991041106568,
          0.2230991041106568,
          0.2230991041106568,
          0.2230991041106568,
          0.2230991041106568,
          0.2230991041106568,
          0.2230991041106568,
          0.2230991041106568,
          0.2230991041106568,
          0.2230991041106568,
          0.2230991041106568,
          0.2230991041106568,
          0.2230991041106568,
          0.2230991041106568,
          0.2230991041106568,
          0.2230991041106568,
          0.2230991041106568,
          0.2230991041106568,
          0.2230991041106568,
          0.2230991041106568,
          0.2230991041106568,
          0.2230991041106568,
          0.2230991041106568,
          0.2230991041106568,
          0.2230991041106568,
          0.2230991041106568,
          0.2230991041106568,
          0.2230991041106568,
          0.2230991041106568,
          0.2230991041106568,
          0.2230991041106568,
          0.2230991041106568,
          0.2230991041106568,
          0.2230991041106568,
          0.2230991041106568,
          0.2230991041106568,
          0.2230991041106568,
          0.2230991041106568,
          0.2230991041106568,
          0.2230991041106568,
          0.2230991041106568,
          0.2230991041106568,
          0.2230991041106568,
          0.2230991041106568,
          0.2230991041106568,
          0.2230991041106568,
          0.2230991041106568,
          0.2230991041106568,
          0.2230991041106568,
          0.2230991041106568,
          0.2230991041106568,
          0.2230991041106568,
          0.2230991041106568,
          0.2230991041106568,
          0.2230991041106568,
          0.2230991041106568,
          0.2230991041106568,
          0.21955646093971024,
          0.21955646093971024,
          0.21955646093971024,
          0.21955646093971024,
          0.21955646093971024,
          0.21955646093971024,
          0.21955646093971024,
          0.21955646093971024,
          0.21955646093971024,
          0.21955646093971024,
          0.21955646093971024,
          0.21955646093971024,
          0.21955646093971024,
          0.21955646093971024,
          0.21955646093971024,
          0.21955646093971024,
          0.21955646093971024,
          0.21955646093971024,
          0.21955646093971024,
          0.21955646093971024,
          0.21955646093971024,
          0.21955646093971024,
          0.21955646093971024,
          0.21955646093971024,
          0.21955646093971024,
          0.21955646093971024,
          0.21955646093971024,
          0.21955646093971024,
          0.21955646093971024,
          0.21955646093971024,
          0.21955646093971024,
          0.21955646093971024,
          0.21955646093971024,
          0.21955646093971024,
          0.21955646093971024,
          0.21955646093971024,
          0.21955646093971024,
          0.21955646093971024,
          0.21955646093971024,
          0.21955646093971024,
          0.21955646093971024,
          0.21955646093971024,
          0.21955646093971024,
          0.21955646093971024,
          0.21955646093971024,
          0.21955646093971024,
          0.21955646093971024,
          0.21955646093971024,
          0.21955646093971024,
          0.21955646093971024,
          0.21955646093971024,
          0.21955646093971024,
          0.21955646093971024,
          0.21955646093971024,
          0.21955646093971024,
          0.21955646093971024,
          0.21955646093971024,
          0.21955646093971024,
          0.21955646093971024,
          0.21955646093971024,
          0.21955646093971024,
          0.21955646093971024,
          0.21955646093971024,
          0.21955646093971024,
          0.21955646093971024,
          0.21955646093971024,
          0.21955646093971024,
          0.21955646093971024,
          0.21955646093971024,
          0.21955646093971024,
          0.21955646093971024,
          0.21955646093971024,
          0.21955646093971024,
          0.21955646093971024,
          0.21955646093971024,
          0.21955646093971024,
          0.21955646093971024,
          0.21955646093971024,
          0.21955646093971024,
          0.21955646093971024,
          0.21955646093971024,
          0.21955646093971024,
          0.21955646093971024,
          0.21955646093971024,
          0.21955646093971024,
          0.21955646093971024,
          0.21955646093971024,
          0.21955646093971024,
          0.21955646093971024,
          0.21955646093971024,
          0.21955646093971024,
          0.21955646093971024,
          0.21955646093971024,
          0.21955646093971024,
          0.21955646093971024,
          0.21955646093971024,
          0.21955646093971024,
          0.21955646093971024,
          0.21955646093971024,
          0.21955646093971024,
          0.21686201926280618,
          0.21686201926280618,
          0.21686201926280618,
          0.21686201926280618,
          0.21686201926280618,
          0.21686201926280618,
          0.21686201926280618,
          0.21686201926280618,
          0.21686201926280618,
          0.21686201926280618,
          0.21686201926280618,
          0.21686201926280618,
          0.21686201926280618,
          0.21686201926280618,
          0.21686201926280618,
          0.21686201926280618,
          0.21686201926280618,
          0.21686201926280618,
          0.21686201926280618,
          0.21686201926280618,
          0.21686201926280618,
          0.21686201926280618,
          0.21686201926280618,
          0.21686201926280618,
          0.21686201926280618,
          0.21686201926280618,
          0.21686201926280618,
          0.21686201926280618,
          0.21686201926280618,
          0.21686201926280618,
          0.21686201926280618,
          0.21686201926280618,
          0.21686201926280618,
          0.21686201926280618,
          0.21686201926280618,
          0.21686201926280618,
          0.21686201926280618,
          0.21686201926280618,
          0.21686201926280618,
          0.21686201926280618,
          0.21686201926280618,
          0.21686201926280618,
          0.21686201926280618,
          0.21686201926280618,
          0.21686201926280618,
          0.21686201926280618,
          0.21686201926280618,
          0.21686201926280618,
          0.21686201926280618,
          0.21686201926280618,
          0.21686201926280618,
          0.21686201926280618,
          0.21686201926280618,
          0.21686201926280618,
          0.21686201926280618,
          0.21686201926280618,
          0.21686201926280618,
          0.21686201926280618,
          0.21686201926280618,
          0.21686201926280618,
          0.21686201926280618,
          0.21686201926280618,
          0.21686201926280618,
          0.21686201926280618,
          0.21686201926280618,
          0.21686201926280618,
          0.21686201926280618,
          0.21686201926280618,
          0.21686201926280618,
          0.21686201926280618,
          0.21686201926280618,
          0.21686201926280618,
          0.21686201926280618,
          0.21686201926280618,
          0.21686201926280618,
          0.21686201926280618,
          0.21686201926280618,
          0.21686201926280618,
          0.21686201926280618,
          0.21686201926280618,
          0.21686201926280618,
          0.21686201926280618,
          0.21686201926280618,
          0.21686201926280618,
          0.21686201926280618,
          0.21686201926280618,
          0.21686201926280618,
          0.21686201926280618,
          0.21686201926280618,
          0.21686201926280618,
          0.21686201926280618,
          0.21686201926280618,
          0.21686201926280618,
          0.21686201926280618,
          0.21686201926280618,
          0.21686201926280618,
          0.21686201926280618,
          0.21686201926280618,
          0.21686201926280618,
          0.21686201926280618,
          0.21461177675295287,
          0.21461177675295287,
          0.21461177675295287,
          0.21461177675295287,
          0.21461177675295287,
          0.21461177675295287,
          0.21461177675295287,
          0.21461177675295287,
          0.21461177675295287,
          0.21461177675295287,
          0.21461177675295287,
          0.21461177675295287,
          0.21461177675295287,
          0.21461177675295287,
          0.21461177675295287,
          0.21461177675295287,
          0.21461177675295287,
          0.21461177675295287,
          0.21461177675295287,
          0.21461177675295287,
          0.21461177675295287,
          0.21461177675295287,
          0.21461177675295287,
          0.21461177675295287,
          0.21461177675295287,
          0.21461177675295287,
          0.21461177675295287,
          0.21461177675295287,
          0.21461177675295287,
          0.21461177675295287,
          0.21461177675295287,
          0.21461177675295287,
          0.21461177675295287,
          0.21461177675295287,
          0.21461177675295287,
          0.21461177675295287,
          0.21461177675295287,
          0.21461177675295287,
          0.21461177675295287,
          0.21461177675295287,
          0.21461177675295287,
          0.21461177675295287,
          0.21461177675295287,
          0.21461177675295287,
          0.21461177675295287,
          0.21461177675295287,
          0.21461177675295287,
          0.21461177675295287,
          0.21461177675295287,
          0.21461177675295287,
          0.21461177675295287,
          0.21461177675295287,
          0.21461177675295287,
          0.21461177675295287,
          0.21461177675295287,
          0.21461177675295287,
          0.21461177675295287,
          0.21461177675295287,
          0.21461177675295287,
          0.21461177675295287,
          0.21461177675295287,
          0.21461177675295287,
          0.21461177675295287,
          0.21461177675295287,
          0.21461177675295287,
          0.21461177675295287,
          0.21461177675295287,
          0.21461177675295287,
          0.21461177675295287,
          0.21461177675295287,
          0.21461177675295287,
          0.21461177675295287,
          0.21461177675295287,
          0.21461177675295287,
          0.21461177675295287,
          0.21461177675295287,
          0.21461177675295287,
          0.21461177675295287,
          0.21461177675295287,
          0.21461177675295287,
          0.21461177675295287,
          0.21461177675295287,
          0.21461177675295287,
          0.21461177675295287,
          0.21461177675295287,
          0.21461177675295287,
          0.21461177675295287,
          0.21461177675295287,
          0.21461177675295287,
          0.21461177675295287,
          0.21461177675295287,
          0.21461177675295287,
          0.21461177675295287,
          0.21461177675295287,
          0.21461177675295287,
          0.21461177675295287,
          0.21461177675295287,
          0.21461177675295287,
          0.21461177675295287,
          0.21461177675295287,
          0.21283292635907988,
          0.21283292635907988,
          0.21283292635907988,
          0.21283292635907988,
          0.21283292635907988,
          0.21283292635907988,
          0.21283292635907988,
          0.21283292635907988,
          0.21283292635907988,
          0.21283292635907988,
          0.21283292635907988,
          0.21283292635907988,
          0.21283292635907988,
          0.21283292635907988,
          0.21283292635907988,
          0.21283292635907988,
          0.21283292635907988,
          0.21283292635907988,
          0.21283292635907988,
          0.21283292635907988,
          0.21283292635907988,
          0.21283292635907988,
          0.21283292635907988,
          0.21283292635907988,
          0.21283292635907988,
          0.21283292635907988,
          0.21283292635907988,
          0.21283292635907988,
          0.21283292635907988,
          0.21283292635907988,
          0.21283292635907988,
          0.21283292635907988,
          0.21283292635907988,
          0.21283292635907988,
          0.21283292635907988,
          0.21283292635907988,
          0.21283292635907988,
          0.21283292635907988,
          0.21283292635907988,
          0.21283292635907988,
          0.21283292635907988,
          0.21283292635907988,
          0.21283292635907988,
          0.21283292635907988,
          0.21283292635907988,
          0.21283292635907988,
          0.21283292635907988,
          0.21283292635907988,
          0.21283292635907988,
          0.21283292635907988,
          0.21283292635907988,
          0.21283292635907988,
          0.21283292635907988,
          0.21283292635907988,
          0.21283292635907988,
          0.21283292635907988,
          0.21283292635907988,
          0.21283292635907988,
          0.21283292635907988,
          0.21283292635907988,
          0.21283292635907988,
          0.21283292635907988,
          0.21283292635907988,
          0.21283292635907988,
          0.21283292635907988,
          0.21283292635907988,
          0.21283292635907988,
          0.21283292635907988,
          0.21283292635907988,
          0.21283292635907988,
          0.21283292635907988,
          0.21283292635907988,
          0.21283292635907988,
          0.21283292635907988,
          0.21283292635907988,
          0.21283292635907988,
          0.21283292635907988,
          0.21283292635907988,
          0.21283292635907988,
          0.21283292635907988,
          0.21283292635907988,
          0.21283292635907988,
          0.21283292635907988,
          0.21283292635907988,
          0.21283292635907988,
          0.21283292635907988,
          0.21283292635907988,
          0.21283292635907988,
          0.21283292635907988,
          0.21283292635907988,
          0.21283292635907988,
          0.21283292635907988,
          0.21283292635907988,
          0.21283292635907988,
          0.21283292635907988,
          0.21283292635907988,
          0.21283292635907988,
          0.21283292635907988,
          0.21283292635907988,
          0.21283292635907988,
          0.21035228847911824,
          0.21035228847911824,
          0.21035228847911824,
          0.21035228847911824,
          0.21035228847911824,
          0.21035228847911824,
          0.21035228847911824,
          0.21035228847911824,
          0.21035228847911824,
          0.21035228847911824,
          0.21035228847911824,
          0.21035228847911824,
          0.21035228847911824,
          0.21035228847911824,
          0.21035228847911824,
          0.21035228847911824,
          0.21035228847911824,
          0.21035228847911824,
          0.21035228847911824,
          0.21035228847911824,
          0.21035228847911824,
          0.21035228847911824,
          0.21035228847911824,
          0.21035228847911824,
          0.21035228847911824,
          0.21035228847911824,
          0.21035228847911824,
          0.21035228847911824,
          0.21035228847911824,
          0.21035228847911824,
          0.21035228847911824,
          0.21035228847911824,
          0.21035228847911824,
          0.21035228847911824,
          0.21035228847911824,
          0.21035228847911824,
          0.21035228847911824,
          0.21035228847911824,
          0.21035228847911824,
          0.21035228847911824,
          0.21035228847911824,
          0.21035228847911824,
          0.21035228847911824,
          0.21035228847911824,
          0.21035228847911824,
          0.21035228847911824,
          0.21035228847911824,
          0.21035228847911824,
          0.21035228847911824,
          0.21035228847911824,
          0.21035228847911824,
          0.21035228847911824,
          0.21035228847911824,
          0.21035228847911824,
          0.21035228847911824,
          0.21035228847911824,
          0.21035228847911824,
          0.21035228847911824,
          0.21035228847911824,
          0.21035228847911824,
          0.21035228847911824,
          0.21035228847911824,
          0.21035228847911824,
          0.21035228847911824,
          0.21035228847911824,
          0.21035228847911824,
          0.21035228847911824,
          0.21035228847911824,
          0.21035228847911824,
          0.21035228847911824,
          0.21035228847911824,
          0.21035228847911824,
          0.21035228847911824,
          0.21035228847911824,
          0.21035228847911824,
          0.21035228847911824,
          0.21035228847911824,
          0.21035228847911824,
          0.21035228847911824,
          0.21035228847911824,
          0.21035228847911824,
          0.21035228847911824,
          0.21035228847911824,
          0.21035228847911824,
          0.21035228847911824,
          0.21035228847911824,
          0.21035228847911824,
          0.21035228847911824,
          0.21035228847911824,
          0.21035228847911824,
          0.21035228847911824,
          0.21035228847911824,
          0.21035228847911824,
          0.21035228847911824,
          0.21035228847911824,
          0.21035228847911824,
          0.21035228847911824,
          0.21035228847911824,
          0.21035228847911824,
          0.21035228847911824,
          0.20849124738746697,
          0.20849124738746697,
          0.20849124738746697,
          0.20849124738746697,
          0.20849124738746697,
          0.20849124738746697,
          0.20849124738746697,
          0.20849124738746697,
          0.20849124738746697,
          0.20849124738746697,
          0.20849124738746697,
          0.20849124738746697,
          0.20849124738746697,
          0.20849124738746697,
          0.20849124738746697,
          0.20849124738746697,
          0.20849124738746697,
          0.20849124738746697,
          0.20849124738746697,
          0.20849124738746697,
          0.20849124738746697,
          0.20849124738746697,
          0.20849124738746697,
          0.20849124738746697,
          0.20849124738746697,
          0.20849124738746697,
          0.20849124738746697,
          0.20849124738746697,
          0.20849124738746697,
          0.20849124738746697,
          0.20849124738746697,
          0.20849124738746697,
          0.20849124738746697,
          0.20849124738746697,
          0.20849124738746697,
          0.20849124738746697,
          0.20849124738746697,
          0.20849124738746697,
          0.20849124738746697,
          0.20849124738746697,
          0.20849124738746697,
          0.20849124738746697,
          0.20849124738746697,
          0.20849124738746697,
          0.20849124738746697,
          0.20849124738746697,
          0.20849124738746697,
          0.20849124738746697,
          0.20849124738746697,
          0.20849124738746697,
          0.20849124738746697,
          0.20849124738746697,
          0.20849124738746697,
          0.20849124738746697,
          0.20849124738746697,
          0.20849124738746697,
          0.20849124738746697,
          0.20849124738746697,
          0.20849124738746697,
          0.20849124738746697,
          0.20849124738746697,
          0.20849124738746697,
          0.20849124738746697,
          0.20849124738746697,
          0.20849124738746697,
          0.20849124738746697,
          0.20849124738746697,
          0.20849124738746697,
          0.20849124738746697,
          0.20849124738746697,
          0.20849124738746697,
          0.20849124738746697,
          0.20849124738746697,
          0.20849124738746697,
          0.20849124738746697,
          0.20849124738746697,
          0.20849124738746697,
          0.20849124738746697,
          0.20849124738746697,
          0.20849124738746697,
          0.20849124738746697,
          0.20849124738746697,
          0.20849124738746697,
          0.20849124738746697,
          0.20849124738746697,
          0.20849124738746697,
          0.20849124738746697,
          0.20849124738746697,
          0.20849124738746697,
          0.20849124738746697,
          0.20849124738746697,
          0.20849124738746697,
          0.20849124738746697,
          0.20849124738746697,
          0.20849124738746697,
          0.20849124738746697,
          0.20849124738746697,
          0.20849124738746697,
          0.20849124738746697,
          0.20849124738746697,
          0.2062401673319759,
          0.2062401673319759,
          0.2062401673319759,
          0.2062401673319759,
          0.2062401673319759,
          0.2062401673319759,
          0.2062401673319759,
          0.2062401673319759,
          0.2062401673319759,
          0.2062401673319759,
          0.2062401673319759,
          0.2062401673319759,
          0.2062401673319759,
          0.2062401673319759,
          0.2062401673319759,
          0.2062401673319759,
          0.2062401673319759,
          0.2062401673319759,
          0.2062401673319759,
          0.2062401673319759,
          0.2062401673319759,
          0.2062401673319759,
          0.2062401673319759,
          0.2062401673319759,
          0.2062401673319759,
          0.2062401673319759,
          0.2062401673319759,
          0.2062401673319759,
          0.2062401673319759,
          0.2062401673319759,
          0.2062401673319759,
          0.2062401673319759,
          0.2062401673319759,
          0.2062401673319759,
          0.2062401673319759,
          0.2062401673319759,
          0.2062401673319759,
          0.2062401673319759,
          0.2062401673319759,
          0.2062401673319759,
          0.2062401673319759,
          0.2062401673319759,
          0.2062401673319759,
          0.2062401673319759,
          0.2062401673319759,
          0.2062401673319759,
          0.2062401673319759,
          0.2062401673319759,
          0.2062401673319759,
          0.2062401673319759,
          0.2062401673319759,
          0.2062401673319759,
          0.2062401673319759,
          0.2062401673319759,
          0.2062401673319759,
          0.2062401673319759,
          0.2062401673319759,
          0.2062401673319759,
          0.2062401673319759,
          0.2062401673319759,
          0.2062401673319759,
          0.2062401673319759,
          0.2062401673319759,
          0.2062401673319759,
          0.2062401673319759,
          0.2062401673319759,
          0.2062401673319759,
          0.2062401673319759,
          0.2062401673319759,
          0.2062401673319759,
          0.2062401673319759,
          0.2062401673319759,
          0.2062401673319759,
          0.2062401673319759,
          0.2062401673319759,
          0.2062401673319759,
          0.2062401673319759,
          0.2062401673319759,
          0.2062401673319759,
          0.2062401673319759,
          0.2062401673319759,
          0.2062401673319759,
          0.2062401673319759,
          0.2062401673319759,
          0.2062401673319759,
          0.2062401673319759,
          0.2062401673319759,
          0.2062401673319759,
          0.2062401673319759,
          0.2062401673319759,
          0.2062401673319759,
          0.2062401673319759,
          0.2062401673319759,
          0.2062401673319759,
          0.2062401673319759,
          0.2062401673319759,
          0.2062401673319759,
          0.2062401673319759,
          0.2062401673319759,
          0.2062401673319759,
          0.20445410680492987,
          0.20445410680492987,
          0.20445410680492987,
          0.20445410680492987,
          0.20445410680492987,
          0.20445410680492987,
          0.20445410680492987,
          0.20445410680492987,
          0.20445410680492987,
          0.20445410680492987,
          0.20445410680492987,
          0.20445410680492987,
          0.20445410680492987,
          0.20445410680492987,
          0.20445410680492987,
          0.20445410680492987,
          0.20445410680492987,
          0.20445410680492987,
          0.20445410680492987,
          0.20445410680492987,
          0.20445410680492987,
          0.20445410680492987,
          0.20445410680492987,
          0.20445410680492987,
          0.20445410680492987,
          0.20445410680492987,
          0.20445410680492987,
          0.20445410680492987,
          0.20445410680492987,
          0.20445410680492987,
          0.20445410680492987,
          0.20445410680492987,
          0.20445410680492987,
          0.20445410680492987,
          0.20445410680492987,
          0.20445410680492987,
          0.20445410680492987,
          0.20445410680492987,
          0.20445410680492987,
          0.20445410680492987,
          0.20445410680492987,
          0.20445410680492987,
          0.20445410680492987,
          0.20445410680492987,
          0.20445410680492987,
          0.20445410680492987,
          0.20445410680492987,
          0.20445410680492987,
          0.20445410680492987,
          0.20445410680492987,
          0.20445410680492987,
          0.20445410680492987,
          0.20445410680492987,
          0.20445410680492987,
          0.20445410680492987,
          0.20445410680492987,
          0.20445410680492987,
          0.20445410680492987,
          0.20445410680492987,
          0.20445410680492987,
          0.20445410680492987,
          0.20445410680492987,
          0.20445410680492987,
          0.20445410680492987,
          0.20445410680492987,
          0.20445410680492987,
          0.20445410680492987,
          0.20445410680492987,
          0.20445410680492987,
          0.20445410680492987,
          0.20445410680492987,
          0.20445410680492987,
          0.20445410680492987,
          0.20445410680492987,
          0.20445410680492987,
          0.20445410680492987,
          0.20445410680492987,
          0.20445410680492987,
          0.20445410680492987,
          0.20445410680492987,
          0.20445410680492987,
          0.20445410680492987,
          0.20445410680492987,
          0.20445410680492987,
          0.20445410680492987,
          0.20445410680492987,
          0.20445410680492987,
          0.20445410680492987,
          0.20445410680492987,
          0.20445410680492987,
          0.20445410680492987,
          0.20445410680492987,
          0.20445410680492987,
          0.20445410680492987,
          0.20445410680492987,
          0.20445410680492987,
          0.20445410680492987,
          0.20445410680492987,
          0.20445410680492987,
          0.20445410680492987,
          0.20251598811441707,
          0.20251598811441707,
          0.20251598811441707,
          0.20251598811441707,
          0.20251598811441707,
          0.20251598811441707,
          0.20251598811441707,
          0.20251598811441707,
          0.20251598811441707,
          0.20251598811441707,
          0.20251598811441707,
          0.20251598811441707,
          0.20251598811441707,
          0.20251598811441707,
          0.20251598811441707,
          0.20251598811441707,
          0.20251598811441707,
          0.20251598811441707,
          0.20251598811441707,
          0.20251598811441707,
          0.20251598811441707,
          0.20251598811441707,
          0.20251598811441707,
          0.20251598811441707,
          0.20251598811441707,
          0.20251598811441707,
          0.20251598811441707,
          0.20251598811441707,
          0.20251598811441707,
          0.20251598811441707,
          0.20251598811441707,
          0.20251598811441707,
          0.20251598811441707,
          0.20251598811441707,
          0.20251598811441707,
          0.20251598811441707,
          0.20251598811441707,
          0.20251598811441707,
          0.20251598811441707,
          0.20251598811441707,
          0.20251598811441707,
          0.20251598811441707,
          0.20251598811441707,
          0.20251598811441707,
          0.20251598811441707,
          0.20251598811441707,
          0.20251598811441707,
          0.20251598811441707,
          0.20251598811441707,
          0.20251598811441707,
          0.20251598811441707,
          0.20251598811441707,
          0.20251598811441707,
          0.20251598811441707,
          0.20251598811441707,
          0.20251598811441707,
          0.20251598811441707,
          0.20251598811441707,
          0.20251598811441707,
          0.20251598811441707,
          0.20251598811441707,
          0.20251598811441707,
          0.20251598811441707,
          0.20251598811441707,
          0.20251598811441707,
          0.20251598811441707,
          0.20251598811441707,
          0.20251598811441707,
          0.20251598811441707,
          0.20251598811441707,
          0.20251598811441707,
          0.20251598811441707,
          0.20251598811441707,
          0.20251598811441707,
          0.20251598811441707,
          0.20251598811441707,
          0.20251598811441707,
          0.20251598811441707,
          0.20251598811441707,
          0.20251598811441707,
          0.20251598811441707,
          0.20251598811441707,
          0.20251598811441707,
          0.20251598811441707,
          0.20251598811441707,
          0.20251598811441707,
          0.20251598811441707,
          0.20251598811441707,
          0.20251598811441707,
          0.20251598811441707,
          0.20251598811441707,
          0.20251598811441707,
          0.20251598811441707,
          0.20251598811441707,
          0.20251598811441707,
          0.20251598811441707,
          0.20251598811441707,
          0.20251598811441707,
          0.20251598811441707,
          0.20251598811441707,
          0.20133157913185246,
          0.20133157913185246,
          0.20133157913185246,
          0.20133157913185246,
          0.20133157913185246,
          0.20133157913185246,
          0.20133157913185246,
          0.20133157913185246,
          0.20133157913185246,
          0.20133157913185246,
          0.20133157913185246,
          0.20133157913185246,
          0.20133157913185246,
          0.20133157913185246,
          0.20133157913185246,
          0.20133157913185246,
          0.20133157913185246,
          0.20133157913185246,
          0.20133157913185246,
          0.20133157913185246,
          0.20133157913185246,
          0.20133157913185246,
          0.20133157913185246,
          0.20133157913185246,
          0.20133157913185246,
          0.20133157913185246,
          0.20133157913185246,
          0.20133157913185246,
          0.20133157913185246,
          0.20133157913185246,
          0.20133157913185246,
          0.20133157913185246,
          0.20133157913185246,
          0.20133157913185246,
          0.20133157913185246,
          0.20133157913185246,
          0.20133157913185246,
          0.20133157913185246,
          0.20133157913185246,
          0.20133157913185246,
          0.20133157913185246,
          0.20133157913185246,
          0.20133157913185246,
          0.20133157913185246,
          0.20133157913185246,
          0.20133157913185246,
          0.20133157913185246,
          0.20133157913185246,
          0.20133157913185246,
          0.20133157913185246,
          0.20133157913185246,
          0.20133157913185246,
          0.20133157913185246,
          0.20133157913185246,
          0.20133157913185246,
          0.20133157913185246,
          0.20133157913185246,
          0.20133157913185246,
          0.20133157913185246,
          0.20133157913185246,
          0.20133157913185246,
          0.20133157913185246,
          0.20133157913185246,
          0.20133157913185246,
          0.20133157913185246,
          0.20133157913185246,
          0.20133157913185246,
          0.20133157913185246,
          0.20133157913185246,
          0.20133157913185246,
          0.20133157913185246,
          0.20133157913185246,
          0.20133157913185246,
          0.20133157913185246,
          0.20133157913185246,
          0.20133157913185246,
          0.20133157913185246,
          0.20133157913185246,
          0.20133157913185246,
          0.20133157913185246,
          0.20133157913185246,
          0.20133157913185246,
          0.20133157913185246,
          0.20133157913185246,
          0.20133157913185246,
          0.20133157913185246,
          0.20133157913185246,
          0.20133157913185246,
          0.20133157913185246,
          0.20133157913185246,
          0.20133157913185246,
          0.20133157913185246,
          0.20133157913185246,
          0.20133157913185246,
          0.20133157913185246,
          0.20133157913185246,
          0.20133157913185246,
          0.20133157913185246,
          0.20133157913185246,
          0.20133157913185246,
          0.1988826961554491,
          0.1988826961554491,
          0.1988826961554491,
          0.1988826961554491,
          0.1988826961554491,
          0.1988826961554491,
          0.1988826961554491,
          0.1988826961554491,
          0.1988826961554491,
          0.1988826961554491,
          0.1988826961554491,
          0.1988826961554491,
          0.1988826961554491,
          0.1988826961554491,
          0.1988826961554491,
          0.1988826961554491,
          0.1988826961554491,
          0.1988826961554491,
          0.1988826961554491,
          0.1988826961554491,
          0.1988826961554491,
          0.1988826961554491,
          0.1988826961554491,
          0.1988826961554491,
          0.1988826961554491,
          0.1988826961554491,
          0.1988826961554491,
          0.1988826961554491,
          0.1988826961554491,
          0.1988826961554491,
          0.1988826961554491,
          0.1988826961554491,
          0.1988826961554491,
          0.1988826961554491,
          0.1988826961554491,
          0.1988826961554491,
          0.1988826961554491,
          0.1988826961554491,
          0.1988826961554491,
          0.1988826961554491,
          0.1988826961554491,
          0.1988826961554491,
          0.1988826961554491,
          0.1988826961554491,
          0.1988826961554491,
          0.1988826961554491,
          0.1988826961554491,
          0.1988826961554491,
          0.1988826961554491,
          0.1988826961554491,
          0.1988826961554491,
          0.1988826961554491,
          0.1988826961554491,
          0.1988826961554491,
          0.1988826961554491,
          0.1988826961554491,
          0.1988826961554491,
          0.1988826961554491,
          0.1988826961554491,
          0.1988826961554491,
          0.1988826961554491,
          0.1988826961554491,
          0.1988826961554491,
          0.1988826961554491,
          0.1988826961554491,
          0.1988826961554491,
          0.1988826961554491,
          0.1988826961554491,
          0.1988826961554491,
          0.1988826961554491,
          0.1988826961554491,
          0.1988826961554491,
          0.1988826961554491,
          0.1988826961554491,
          0.1988826961554491,
          0.1988826961554491,
          0.1988826961554491,
          0.1988826961554491,
          0.1988826961554491,
          0.1988826961554491,
          0.1988826961554491,
          0.1988826961554491,
          0.1988826961554491,
          0.1988826961554491,
          0.1988826961554491,
          0.1988826961554491,
          0.1988826961554491,
          0.1988826961554491,
          0.1988826961554491,
          0.1988826961554491,
          0.1988826961554491,
          0.1988826961554491,
          0.1988826961554491,
          0.1988826961554491,
          0.1988826961554491,
          0.1988826961554491,
          0.1988826961554491,
          0.1988826961554491,
          0.1988826961554491,
          0.1988826961554491,
          0.1972704261984197,
          0.1972704261984197,
          0.1972704261984197,
          0.1972704261984197,
          0.1972704261984197,
          0.1972704261984197,
          0.1972704261984197,
          0.1972704261984197,
          0.1972704261984197,
          0.1972704261984197,
          0.1972704261984197,
          0.1972704261984197,
          0.1972704261984197,
          0.1972704261984197,
          0.1972704261984197,
          0.1972704261984197,
          0.1972704261984197,
          0.1972704261984197,
          0.1972704261984197,
          0.1972704261984197,
          0.1972704261984197,
          0.1972704261984197,
          0.1972704261984197,
          0.1972704261984197,
          0.1972704261984197,
          0.1972704261984197,
          0.1972704261984197,
          0.1972704261984197,
          0.1972704261984197,
          0.1972704261984197,
          0.1972704261984197,
          0.1972704261984197,
          0.1972704261984197,
          0.1972704261984197,
          0.1972704261984197,
          0.1972704261984197,
          0.1972704261984197,
          0.1972704261984197,
          0.1972704261984197,
          0.1972704261984197,
          0.1972704261984197,
          0.1972704261984197,
          0.1972704261984197,
          0.1972704261984197,
          0.1972704261984197,
          0.1972704261984197,
          0.1972704261984197,
          0.1972704261984197,
          0.1972704261984197,
          0.1972704261984197,
          0.1972704261984197,
          0.1972704261984197,
          0.1972704261984197,
          0.1972704261984197,
          0.1972704261984197,
          0.1972704261984197,
          0.1972704261984197,
          0.1972704261984197,
          0.1972704261984197,
          0.1972704261984197,
          0.1972704261984197,
          0.1972704261984197,
          0.1972704261984197,
          0.1972704261984197,
          0.1972704261984197,
          0.1972704261984197,
          0.1972704261984197,
          0.1972704261984197,
          0.1972704261984197,
          0.1972704261984197,
          0.1972704261984197,
          0.1972704261984197,
          0.1972704261984197,
          0.1972704261984197,
          0.1972704261984197,
          0.1972704261984197,
          0.1972704261984197,
          0.1972704261984197,
          0.1972704261984197,
          0.1972704261984197,
          0.1972704261984197,
          0.1972704261984197,
          0.1972704261984197,
          0.1972704261984197,
          0.1972704261984197,
          0.1972704261984197,
          0.1972704261984197,
          0.1972704261984197,
          0.1972704261984197,
          0.1972704261984197,
          0.1972704261984197,
          0.1972704261984197,
          0.1972704261984197,
          0.1972704261984197,
          0.1972704261984197,
          0.1972704261984197,
          0.1972704261984197,
          0.1972704261984197,
          0.1972704261984197,
          0.1972704261984197,
          0.19429511738598018,
          0.19429511738598018,
          0.19429511738598018,
          0.19429511738598018,
          0.19429511738598018,
          0.19429511738598018,
          0.19429511738598018,
          0.19429511738598018,
          0.19429511738598018,
          0.19429511738598018,
          0.19429511738598018,
          0.19429511738598018,
          0.19429511738598018,
          0.19429511738598018,
          0.19429511738598018,
          0.19429511738598018,
          0.19429511738598018,
          0.19429511738598018,
          0.19429511738598018,
          0.19429511738598018,
          0.19429511738598018,
          0.19429511738598018,
          0.19429511738598018,
          0.19429511738598018,
          0.19429511738598018,
          0.19429511738598018,
          0.19429511738598018,
          0.19429511738598018,
          0.19429511738598018,
          0.19429511738598018,
          0.19429511738598018,
          0.19429511738598018,
          0.19429511738598018,
          0.19429511738598018,
          0.19429511738598018,
          0.19429511738598018,
          0.19429511738598018,
          0.19429511738598018,
          0.19429511738598018,
          0.19429511738598018,
          0.19429511738598018,
          0.19429511738598018,
          0.19429511738598018,
          0.19429511738598018,
          0.19429511738598018,
          0.19429511738598018,
          0.19429511738598018,
          0.19429511738598018,
          0.19429511738598018,
          0.19429511738598018,
          0.19429511738598018,
          0.19429511738598018,
          0.19429511738598018,
          0.19429511738598018,
          0.19429511738598018,
          0.19429511738598018,
          0.19429511738598018,
          0.19429511738598018,
          0.19429511738598018,
          0.19429511738598018,
          0.19429511738598018,
          0.19429511738598018,
          0.19429511738598018,
          0.19429511738598018,
          0.19429511738598018,
          0.19429511738598018,
          0.19429511738598018,
          0.19429511738598018,
          0.19429511738598018,
          0.19429511738598018,
          0.19429511738598018,
          0.19429511738598018,
          0.19429511738598018,
          0.19429511738598018,
          0.19429511738598018,
          0.19429511738598018,
          0.19429511738598018,
          0.19429511738598018,
          0.19429511738598018,
          0.19429511738598018,
          0.19429511738598018,
          0.19429511738598018,
          0.19429511738598018,
          0.19429511738598018,
          0.19429511738598018,
          0.19429511738598018,
          0.19429511738598018,
          0.19429511738598018,
          0.19429511738598018,
          0.19429511738598018,
          0.19429511738598018,
          0.19429511738598018,
          0.19429511738598018,
          0.19429511738598018,
          0.19429511738598018,
          0.19429511738598018,
          0.19429511738598018,
          0.19429511738598018,
          0.19429511738598018,
          0.19429511738598018,
          0.1921134990942076,
          0.1921134990942076,
          0.1921134990942076,
          0.1921134990942076,
          0.1921134990942076,
          0.1921134990942076,
          0.1921134990942076,
          0.1921134990942076,
          0.1921134990942076,
          0.1921134990942076,
          0.1921134990942076,
          0.1921134990942076,
          0.1921134990942076,
          0.1921134990942076,
          0.1921134990942076,
          0.1921134990942076,
          0.1921134990942076,
          0.1921134990942076,
          0.1921134990942076,
          0.1921134990942076,
          0.1921134990942076,
          0.1921134990942076,
          0.1921134990942076,
          0.1921134990942076,
          0.1921134990942076,
          0.1921134990942076,
          0.1921134990942076,
          0.1921134990942076,
          0.1921134990942076,
          0.1921134990942076,
          0.1921134990942076,
          0.1921134990942076,
          0.1921134990942076,
          0.1921134990942076,
          0.1921134990942076,
          0.1921134990942076,
          0.1921134990942076,
          0.1921134990942076,
          0.1921134990942076,
          0.1921134990942076,
          0.1921134990942076,
          0.1921134990942076,
          0.1921134990942076,
          0.1921134990942076,
          0.1921134990942076,
          0.1921134990942076,
          0.1921134990942076,
          0.1921134990942076,
          0.1921134990942076,
          0.1921134990942076,
          0.1921134990942076,
          0.1921134990942076,
          0.1921134990942076,
          0.1921134990942076,
          0.1921134990942076,
          0.1921134990942076,
          0.1921134990942076,
          0.1921134990942076,
          0.1921134990942076,
          0.1921134990942076,
          0.1921134990942076,
          0.1921134990942076,
          0.1921134990942076,
          0.1921134990942076,
          0.1921134990942076,
          0.1921134990942076,
          0.1921134990942076,
          0.1921134990942076,
          0.1921134990942076,
          0.1921134990942076,
          0.1921134990942076,
          0.1921134990942076,
          0.1921134990942076,
          0.1921134990942076,
          0.1921134990942076,
          0.1921134990942076,
          0.1921134990942076,
          0.1921134990942076,
          0.1921134990942076,
          0.1921134990942076,
          0.1921134990942076,
          0.1921134990942076,
          0.1921134990942076,
          0.1921134990942076,
          0.1921134990942076,
          0.1921134990942076,
          0.1921134990942076,
          0.1921134990942076,
          0.1921134990942076,
          0.1921134990942076,
          0.1921134990942076,
          0.1921134990942076,
          0.1921134990942076,
          0.1921134990942076,
          0.1921134990942076,
          0.1921134990942076,
          0.1921134990942076,
          0.1921134990942076,
          0.1921134990942076,
          0.1921134990942076
         ]
        },
        {
         "mode": "lines",
         "name": "Test Loss",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160,
          161,
          162,
          163,
          164,
          165,
          166,
          167,
          168,
          169,
          170,
          171,
          172,
          173,
          174,
          175,
          176,
          177,
          178,
          179,
          180,
          181,
          182,
          183,
          184,
          185,
          186,
          187,
          188,
          189,
          190,
          191,
          192,
          193,
          194,
          195,
          196,
          197,
          198,
          199,
          200,
          201,
          202,
          203,
          204,
          205,
          206,
          207,
          208,
          209,
          210,
          211,
          212,
          213,
          214,
          215,
          216,
          217,
          218,
          219,
          220,
          221,
          222,
          223,
          224,
          225,
          226,
          227,
          228,
          229,
          230,
          231,
          232,
          233,
          234,
          235,
          236,
          237,
          238,
          239,
          240,
          241,
          242,
          243,
          244,
          245,
          246,
          247,
          248,
          249,
          250,
          251,
          252,
          253,
          254,
          255,
          256,
          257,
          258,
          259,
          260,
          261,
          262,
          263,
          264,
          265,
          266,
          267,
          268,
          269,
          270,
          271,
          272,
          273,
          274,
          275,
          276,
          277,
          278,
          279,
          280,
          281,
          282,
          283,
          284,
          285,
          286,
          287,
          288,
          289,
          290,
          291,
          292,
          293,
          294,
          295,
          296,
          297,
          298,
          299,
          300,
          301,
          302,
          303,
          304,
          305,
          306,
          307,
          308,
          309,
          310,
          311,
          312,
          313,
          314,
          315,
          316,
          317,
          318,
          319,
          320,
          321,
          322,
          323,
          324,
          325,
          326,
          327,
          328,
          329,
          330,
          331,
          332,
          333,
          334,
          335,
          336,
          337,
          338,
          339,
          340,
          341,
          342,
          343,
          344,
          345,
          346,
          347,
          348,
          349,
          350,
          351,
          352,
          353,
          354,
          355,
          356,
          357,
          358,
          359,
          360,
          361,
          362,
          363,
          364,
          365,
          366,
          367,
          368,
          369,
          370,
          371,
          372,
          373,
          374,
          375,
          376,
          377,
          378,
          379,
          380,
          381,
          382,
          383,
          384,
          385,
          386,
          387,
          388,
          389,
          390,
          391,
          392,
          393,
          394,
          395,
          396,
          397,
          398,
          399,
          400,
          401,
          402,
          403,
          404,
          405,
          406,
          407,
          408,
          409,
          410,
          411,
          412,
          413,
          414,
          415,
          416,
          417,
          418,
          419,
          420,
          421,
          422,
          423,
          424,
          425,
          426,
          427,
          428,
          429,
          430,
          431,
          432,
          433,
          434,
          435,
          436,
          437,
          438,
          439,
          440,
          441,
          442,
          443,
          444,
          445,
          446,
          447,
          448,
          449,
          450,
          451,
          452,
          453,
          454,
          455,
          456,
          457,
          458,
          459,
          460,
          461,
          462,
          463,
          464,
          465,
          466,
          467,
          468,
          469,
          470,
          471,
          472,
          473,
          474,
          475,
          476,
          477,
          478,
          479,
          480,
          481,
          482,
          483,
          484,
          485,
          486,
          487,
          488,
          489,
          490,
          491,
          492,
          493,
          494,
          495,
          496,
          497,
          498,
          499,
          500,
          501,
          502,
          503,
          504,
          505,
          506,
          507,
          508,
          509,
          510,
          511,
          512,
          513,
          514,
          515,
          516,
          517,
          518,
          519,
          520,
          521,
          522,
          523,
          524,
          525,
          526,
          527,
          528,
          529,
          530,
          531,
          532,
          533,
          534,
          535,
          536,
          537,
          538,
          539,
          540,
          541,
          542,
          543,
          544,
          545,
          546,
          547,
          548,
          549,
          550,
          551,
          552,
          553,
          554,
          555,
          556,
          557,
          558,
          559,
          560,
          561,
          562,
          563,
          564,
          565,
          566,
          567,
          568,
          569,
          570,
          571,
          572,
          573,
          574,
          575,
          576,
          577,
          578,
          579,
          580,
          581,
          582,
          583,
          584,
          585,
          586,
          587,
          588,
          589,
          590,
          591,
          592,
          593,
          594,
          595,
          596,
          597,
          598,
          599,
          600,
          601,
          602,
          603,
          604,
          605,
          606,
          607,
          608,
          609,
          610,
          611,
          612,
          613,
          614,
          615,
          616,
          617,
          618,
          619,
          620,
          621,
          622,
          623,
          624,
          625,
          626,
          627,
          628,
          629,
          630,
          631,
          632,
          633,
          634,
          635,
          636,
          637,
          638,
          639,
          640,
          641,
          642,
          643,
          644,
          645,
          646,
          647,
          648,
          649,
          650,
          651,
          652,
          653,
          654,
          655,
          656,
          657,
          658,
          659,
          660,
          661,
          662,
          663,
          664,
          665,
          666,
          667,
          668,
          669,
          670,
          671,
          672,
          673,
          674,
          675,
          676,
          677,
          678,
          679,
          680,
          681,
          682,
          683,
          684,
          685,
          686,
          687,
          688,
          689,
          690,
          691,
          692,
          693,
          694,
          695,
          696,
          697,
          698,
          699,
          700,
          701,
          702,
          703,
          704,
          705,
          706,
          707,
          708,
          709,
          710,
          711,
          712,
          713,
          714,
          715,
          716,
          717,
          718,
          719,
          720,
          721,
          722,
          723,
          724,
          725,
          726,
          727,
          728,
          729,
          730,
          731,
          732,
          733,
          734,
          735,
          736,
          737,
          738,
          739,
          740,
          741,
          742,
          743,
          744,
          745,
          746,
          747,
          748,
          749,
          750,
          751,
          752,
          753,
          754,
          755,
          756,
          757,
          758,
          759,
          760,
          761,
          762,
          763,
          764,
          765,
          766,
          767,
          768,
          769,
          770,
          771,
          772,
          773,
          774,
          775,
          776,
          777,
          778,
          779,
          780,
          781,
          782,
          783,
          784,
          785,
          786,
          787,
          788,
          789,
          790,
          791,
          792,
          793,
          794,
          795,
          796,
          797,
          798,
          799,
          800,
          801,
          802,
          803,
          804,
          805,
          806,
          807,
          808,
          809,
          810,
          811,
          812,
          813,
          814,
          815,
          816,
          817,
          818,
          819,
          820,
          821,
          822,
          823,
          824,
          825,
          826,
          827,
          828,
          829,
          830,
          831,
          832,
          833,
          834,
          835,
          836,
          837,
          838,
          839,
          840,
          841,
          842,
          843,
          844,
          845,
          846,
          847,
          848,
          849,
          850,
          851,
          852,
          853,
          854,
          855,
          856,
          857,
          858,
          859,
          860,
          861,
          862,
          863,
          864,
          865,
          866,
          867,
          868,
          869,
          870,
          871,
          872,
          873,
          874,
          875,
          876,
          877,
          878,
          879,
          880,
          881,
          882,
          883,
          884,
          885,
          886,
          887,
          888,
          889,
          890,
          891,
          892,
          893,
          894,
          895,
          896,
          897,
          898,
          899,
          900,
          901,
          902,
          903,
          904,
          905,
          906,
          907,
          908,
          909,
          910,
          911,
          912,
          913,
          914,
          915,
          916,
          917,
          918,
          919,
          920,
          921,
          922,
          923,
          924,
          925,
          926,
          927,
          928,
          929,
          930,
          931,
          932,
          933,
          934,
          935,
          936,
          937,
          938,
          939,
          940,
          941,
          942,
          943,
          944,
          945,
          946,
          947,
          948,
          949,
          950,
          951,
          952,
          953,
          954,
          955,
          956,
          957,
          958,
          959,
          960,
          961,
          962,
          963,
          964,
          965,
          966,
          967,
          968,
          969,
          970,
          971,
          972,
          973,
          974,
          975,
          976,
          977,
          978,
          979,
          980,
          981,
          982,
          983,
          984,
          985,
          986,
          987,
          988,
          989,
          990,
          991,
          992,
          993,
          994,
          995,
          996,
          997,
          998,
          999,
          1000,
          1001,
          1002,
          1003,
          1004,
          1005,
          1006,
          1007,
          1008,
          1009,
          1010,
          1011,
          1012,
          1013,
          1014,
          1015,
          1016,
          1017,
          1018,
          1019,
          1020,
          1021,
          1022,
          1023,
          1024,
          1025,
          1026,
          1027,
          1028,
          1029,
          1030,
          1031,
          1032,
          1033,
          1034,
          1035,
          1036,
          1037,
          1038,
          1039,
          1040,
          1041,
          1042,
          1043,
          1044,
          1045,
          1046,
          1047,
          1048,
          1049,
          1050,
          1051,
          1052,
          1053,
          1054,
          1055,
          1056,
          1057,
          1058,
          1059,
          1060,
          1061,
          1062,
          1063,
          1064,
          1065,
          1066,
          1067,
          1068,
          1069,
          1070,
          1071,
          1072,
          1073,
          1074,
          1075,
          1076,
          1077,
          1078,
          1079,
          1080,
          1081,
          1082,
          1083,
          1084,
          1085,
          1086,
          1087,
          1088,
          1089,
          1090,
          1091,
          1092,
          1093,
          1094,
          1095,
          1096,
          1097,
          1098,
          1099,
          1100,
          1101,
          1102,
          1103,
          1104,
          1105,
          1106,
          1107,
          1108,
          1109,
          1110,
          1111,
          1112,
          1113,
          1114,
          1115,
          1116,
          1117,
          1118,
          1119,
          1120,
          1121,
          1122,
          1123,
          1124,
          1125,
          1126,
          1127,
          1128,
          1129,
          1130,
          1131,
          1132,
          1133,
          1134,
          1135,
          1136,
          1137,
          1138,
          1139,
          1140,
          1141,
          1142,
          1143,
          1144,
          1145,
          1146,
          1147,
          1148,
          1149,
          1150,
          1151,
          1152,
          1153,
          1154,
          1155,
          1156,
          1157,
          1158,
          1159,
          1160,
          1161,
          1162,
          1163,
          1164,
          1165,
          1166,
          1167,
          1168,
          1169,
          1170,
          1171,
          1172,
          1173,
          1174,
          1175,
          1176,
          1177,
          1178,
          1179,
          1180,
          1181,
          1182,
          1183,
          1184,
          1185,
          1186,
          1187,
          1188,
          1189,
          1190,
          1191,
          1192,
          1193,
          1194,
          1195,
          1196,
          1197,
          1198,
          1199,
          1200,
          1201,
          1202,
          1203,
          1204,
          1205,
          1206,
          1207,
          1208,
          1209,
          1210,
          1211,
          1212,
          1213,
          1214,
          1215,
          1216,
          1217,
          1218,
          1219,
          1220,
          1221,
          1222,
          1223,
          1224,
          1225,
          1226,
          1227,
          1228,
          1229,
          1230,
          1231,
          1232,
          1233,
          1234,
          1235,
          1236,
          1237,
          1238,
          1239,
          1240,
          1241,
          1242,
          1243,
          1244,
          1245,
          1246,
          1247,
          1248,
          1249,
          1250,
          1251,
          1252,
          1253,
          1254,
          1255,
          1256,
          1257,
          1258,
          1259,
          1260,
          1261,
          1262,
          1263,
          1264,
          1265,
          1266,
          1267,
          1268,
          1269,
          1270,
          1271,
          1272,
          1273,
          1274,
          1275,
          1276,
          1277,
          1278,
          1279,
          1280,
          1281,
          1282,
          1283,
          1284,
          1285,
          1286,
          1287,
          1288,
          1289,
          1290,
          1291,
          1292,
          1293,
          1294,
          1295,
          1296,
          1297,
          1298,
          1299,
          1300,
          1301,
          1302,
          1303,
          1304,
          1305,
          1306,
          1307,
          1308,
          1309,
          1310,
          1311,
          1312,
          1313,
          1314,
          1315,
          1316,
          1317,
          1318,
          1319,
          1320,
          1321,
          1322,
          1323,
          1324,
          1325,
          1326,
          1327,
          1328,
          1329,
          1330,
          1331,
          1332,
          1333,
          1334,
          1335,
          1336,
          1337,
          1338,
          1339,
          1340,
          1341,
          1342,
          1343,
          1344,
          1345,
          1346,
          1347,
          1348,
          1349,
          1350,
          1351,
          1352,
          1353,
          1354,
          1355,
          1356,
          1357,
          1358,
          1359,
          1360,
          1361,
          1362,
          1363,
          1364,
          1365,
          1366,
          1367,
          1368,
          1369,
          1370,
          1371,
          1372,
          1373,
          1374,
          1375,
          1376,
          1377,
          1378,
          1379,
          1380,
          1381,
          1382,
          1383,
          1384,
          1385,
          1386,
          1387,
          1388,
          1389,
          1390,
          1391,
          1392,
          1393,
          1394,
          1395,
          1396,
          1397,
          1398,
          1399,
          1400,
          1401,
          1402,
          1403,
          1404,
          1405,
          1406,
          1407,
          1408,
          1409,
          1410,
          1411,
          1412,
          1413,
          1414,
          1415,
          1416,
          1417,
          1418,
          1419,
          1420,
          1421,
          1422,
          1423,
          1424,
          1425,
          1426,
          1427,
          1428,
          1429,
          1430,
          1431,
          1432,
          1433,
          1434,
          1435,
          1436,
          1437,
          1438,
          1439,
          1440,
          1441,
          1442,
          1443,
          1444,
          1445,
          1446,
          1447,
          1448,
          1449,
          1450,
          1451,
          1452,
          1453,
          1454,
          1455,
          1456,
          1457,
          1458,
          1459,
          1460,
          1461,
          1462,
          1463,
          1464,
          1465,
          1466,
          1467,
          1468,
          1469,
          1470,
          1471,
          1472,
          1473,
          1474,
          1475,
          1476,
          1477,
          1478,
          1479,
          1480,
          1481,
          1482,
          1483,
          1484,
          1485,
          1486,
          1487,
          1488,
          1489,
          1490,
          1491,
          1492,
          1493,
          1494,
          1495,
          1496,
          1497,
          1498,
          1499,
          1500,
          1501,
          1502,
          1503,
          1504,
          1505,
          1506,
          1507,
          1508,
          1509,
          1510,
          1511,
          1512,
          1513,
          1514,
          1515,
          1516,
          1517,
          1518,
          1519,
          1520,
          1521,
          1522,
          1523,
          1524,
          1525,
          1526,
          1527,
          1528,
          1529,
          1530,
          1531,
          1532,
          1533,
          1534,
          1535,
          1536,
          1537,
          1538,
          1539,
          1540,
          1541,
          1542,
          1543,
          1544,
          1545,
          1546,
          1547,
          1548,
          1549,
          1550,
          1551,
          1552,
          1553,
          1554,
          1555,
          1556,
          1557,
          1558,
          1559,
          1560,
          1561,
          1562,
          1563,
          1564,
          1565,
          1566,
          1567,
          1568,
          1569,
          1570,
          1571,
          1572,
          1573,
          1574,
          1575,
          1576,
          1577,
          1578,
          1579,
          1580,
          1581,
          1582,
          1583,
          1584,
          1585,
          1586,
          1587,
          1588,
          1589,
          1590,
          1591,
          1592,
          1593,
          1594,
          1595,
          1596,
          1597,
          1598,
          1599,
          1600,
          1601,
          1602,
          1603,
          1604,
          1605,
          1606,
          1607,
          1608,
          1609,
          1610,
          1611,
          1612,
          1613,
          1614,
          1615,
          1616,
          1617,
          1618,
          1619,
          1620,
          1621,
          1622,
          1623,
          1624,
          1625,
          1626,
          1627,
          1628,
          1629,
          1630,
          1631,
          1632,
          1633,
          1634,
          1635,
          1636,
          1637,
          1638,
          1639,
          1640,
          1641,
          1642,
          1643,
          1644,
          1645,
          1646,
          1647,
          1648,
          1649,
          1650,
          1651,
          1652,
          1653,
          1654,
          1655,
          1656,
          1657,
          1658,
          1659,
          1660,
          1661,
          1662,
          1663,
          1664,
          1665,
          1666,
          1667,
          1668,
          1669,
          1670,
          1671,
          1672,
          1673,
          1674,
          1675,
          1676,
          1677,
          1678,
          1679,
          1680,
          1681,
          1682,
          1683,
          1684,
          1685,
          1686,
          1687,
          1688,
          1689,
          1690,
          1691,
          1692,
          1693,
          1694,
          1695,
          1696,
          1697,
          1698,
          1699,
          1700,
          1701,
          1702,
          1703,
          1704,
          1705,
          1706,
          1707,
          1708,
          1709,
          1710,
          1711,
          1712,
          1713,
          1714,
          1715,
          1716,
          1717,
          1718,
          1719,
          1720,
          1721,
          1722,
          1723,
          1724,
          1725,
          1726,
          1727,
          1728,
          1729,
          1730,
          1731,
          1732,
          1733,
          1734,
          1735,
          1736,
          1737,
          1738,
          1739,
          1740,
          1741,
          1742,
          1743,
          1744,
          1745,
          1746,
          1747,
          1748,
          1749,
          1750,
          1751,
          1752,
          1753,
          1754,
          1755,
          1756,
          1757,
          1758,
          1759,
          1760,
          1761,
          1762,
          1763,
          1764,
          1765,
          1766,
          1767,
          1768,
          1769,
          1770,
          1771,
          1772,
          1773,
          1774,
          1775,
          1776,
          1777,
          1778,
          1779,
          1780,
          1781,
          1782,
          1783,
          1784,
          1785,
          1786,
          1787,
          1788,
          1789,
          1790,
          1791,
          1792,
          1793,
          1794,
          1795,
          1796,
          1797,
          1798,
          1799,
          1800,
          1801,
          1802,
          1803,
          1804,
          1805,
          1806,
          1807,
          1808,
          1809,
          1810,
          1811,
          1812,
          1813,
          1814,
          1815,
          1816,
          1817,
          1818,
          1819,
          1820,
          1821,
          1822,
          1823,
          1824,
          1825,
          1826,
          1827,
          1828,
          1829,
          1830,
          1831,
          1832,
          1833,
          1834,
          1835,
          1836,
          1837,
          1838,
          1839,
          1840,
          1841,
          1842,
          1843,
          1844,
          1845,
          1846,
          1847,
          1848,
          1849,
          1850,
          1851,
          1852,
          1853,
          1854,
          1855,
          1856,
          1857,
          1858,
          1859,
          1860,
          1861,
          1862,
          1863,
          1864,
          1865,
          1866,
          1867,
          1868,
          1869,
          1870,
          1871,
          1872,
          1873,
          1874,
          1875,
          1876,
          1877,
          1878,
          1879,
          1880,
          1881,
          1882,
          1883,
          1884,
          1885,
          1886,
          1887,
          1888,
          1889,
          1890,
          1891,
          1892,
          1893,
          1894,
          1895,
          1896,
          1897,
          1898,
          1899,
          1900,
          1901,
          1902,
          1903,
          1904,
          1905,
          1906,
          1907,
          1908,
          1909,
          1910,
          1911,
          1912,
          1913,
          1914,
          1915,
          1916,
          1917,
          1918,
          1919,
          1920,
          1921,
          1922,
          1923,
          1924,
          1925,
          1926,
          1927,
          1928,
          1929,
          1930,
          1931,
          1932,
          1933,
          1934,
          1935,
          1936,
          1937,
          1938,
          1939,
          1940,
          1941,
          1942,
          1943,
          1944,
          1945,
          1946,
          1947,
          1948,
          1949,
          1950,
          1951,
          1952,
          1953,
          1954,
          1955,
          1956,
          1957,
          1958,
          1959,
          1960,
          1961,
          1962,
          1963,
          1964,
          1965,
          1966,
          1967,
          1968,
          1969,
          1970,
          1971,
          1972,
          1973,
          1974,
          1975,
          1976,
          1977,
          1978,
          1979,
          1980,
          1981,
          1982,
          1983,
          1984,
          1985,
          1986,
          1987,
          1988,
          1989,
          1990,
          1991,
          1992,
          1993,
          1994,
          1995,
          1996,
          1997,
          1998,
          1999,
          2000,
          2001,
          2002,
          2003,
          2004,
          2005,
          2006,
          2007,
          2008,
          2009,
          2010,
          2011,
          2012,
          2013,
          2014,
          2015,
          2016,
          2017,
          2018,
          2019,
          2020,
          2021,
          2022,
          2023,
          2024,
          2025,
          2026,
          2027,
          2028,
          2029,
          2030,
          2031,
          2032,
          2033,
          2034,
          2035,
          2036,
          2037,
          2038,
          2039,
          2040,
          2041,
          2042,
          2043,
          2044,
          2045,
          2046,
          2047,
          2048,
          2049,
          2050,
          2051,
          2052,
          2053,
          2054,
          2055,
          2056,
          2057,
          2058,
          2059,
          2060,
          2061,
          2062,
          2063,
          2064,
          2065,
          2066,
          2067,
          2068,
          2069,
          2070,
          2071,
          2072,
          2073,
          2074,
          2075,
          2076,
          2077,
          2078,
          2079,
          2080,
          2081,
          2082,
          2083,
          2084,
          2085,
          2086,
          2087,
          2088,
          2089,
          2090,
          2091,
          2092,
          2093,
          2094,
          2095,
          2096,
          2097,
          2098,
          2099,
          2100,
          2101,
          2102,
          2103,
          2104,
          2105,
          2106,
          2107,
          2108,
          2109,
          2110,
          2111,
          2112,
          2113,
          2114,
          2115,
          2116,
          2117,
          2118,
          2119,
          2120,
          2121,
          2122,
          2123,
          2124,
          2125,
          2126,
          2127,
          2128,
          2129,
          2130,
          2131,
          2132,
          2133,
          2134,
          2135,
          2136,
          2137,
          2138,
          2139,
          2140,
          2141,
          2142,
          2143,
          2144,
          2145,
          2146,
          2147,
          2148,
          2149,
          2150,
          2151,
          2152,
          2153,
          2154,
          2155,
          2156,
          2157,
          2158,
          2159,
          2160,
          2161,
          2162,
          2163,
          2164,
          2165,
          2166,
          2167,
          2168,
          2169,
          2170,
          2171,
          2172,
          2173,
          2174,
          2175,
          2176,
          2177,
          2178,
          2179,
          2180,
          2181,
          2182,
          2183,
          2184,
          2185,
          2186,
          2187,
          2188,
          2189,
          2190,
          2191,
          2192,
          2193,
          2194,
          2195,
          2196,
          2197,
          2198,
          2199,
          2200,
          2201,
          2202,
          2203,
          2204,
          2205,
          2206,
          2207,
          2208,
          2209,
          2210,
          2211,
          2212,
          2213,
          2214,
          2215,
          2216,
          2217,
          2218,
          2219,
          2220,
          2221,
          2222,
          2223,
          2224,
          2225,
          2226,
          2227,
          2228,
          2229,
          2230,
          2231,
          2232,
          2233,
          2234,
          2235,
          2236,
          2237,
          2238,
          2239,
          2240,
          2241,
          2242,
          2243,
          2244,
          2245,
          2246,
          2247,
          2248,
          2249,
          2250,
          2251,
          2252,
          2253,
          2254,
          2255,
          2256,
          2257,
          2258,
          2259,
          2260,
          2261,
          2262,
          2263,
          2264,
          2265,
          2266,
          2267,
          2268,
          2269,
          2270,
          2271,
          2272,
          2273,
          2274,
          2275,
          2276,
          2277,
          2278,
          2279,
          2280,
          2281,
          2282,
          2283,
          2284,
          2285,
          2286,
          2287,
          2288,
          2289,
          2290,
          2291,
          2292,
          2293,
          2294,
          2295,
          2296,
          2297,
          2298,
          2299,
          2300,
          2301,
          2302,
          2303,
          2304,
          2305,
          2306,
          2307,
          2308,
          2309,
          2310,
          2311,
          2312,
          2313,
          2314,
          2315,
          2316,
          2317,
          2318,
          2319,
          2320,
          2321,
          2322,
          2323,
          2324,
          2325,
          2326,
          2327,
          2328,
          2329,
          2330,
          2331,
          2332,
          2333,
          2334,
          2335,
          2336,
          2337,
          2338,
          2339,
          2340,
          2341,
          2342,
          2343,
          2344,
          2345,
          2346,
          2347,
          2348,
          2349,
          2350,
          2351,
          2352,
          2353,
          2354,
          2355,
          2356,
          2357,
          2358,
          2359,
          2360,
          2361,
          2362,
          2363,
          2364,
          2365,
          2366,
          2367,
          2368,
          2369,
          2370,
          2371,
          2372,
          2373,
          2374,
          2375,
          2376,
          2377,
          2378,
          2379,
          2380,
          2381,
          2382,
          2383,
          2384,
          2385,
          2386,
          2387,
          2388,
          2389,
          2390,
          2391,
          2392,
          2393,
          2394,
          2395,
          2396,
          2397,
          2398,
          2399,
          2400,
          2401,
          2402,
          2403,
          2404,
          2405,
          2406,
          2407,
          2408,
          2409,
          2410,
          2411,
          2412,
          2413,
          2414,
          2415,
          2416,
          2417,
          2418,
          2419,
          2420,
          2421,
          2422,
          2423,
          2424,
          2425,
          2426,
          2427,
          2428,
          2429,
          2430,
          2431,
          2432,
          2433,
          2434,
          2435,
          2436,
          2437,
          2438,
          2439,
          2440,
          2441,
          2442,
          2443,
          2444,
          2445,
          2446,
          2447,
          2448,
          2449,
          2450,
          2451,
          2452,
          2453,
          2454,
          2455,
          2456,
          2457,
          2458,
          2459,
          2460,
          2461,
          2462,
          2463,
          2464,
          2465,
          2466,
          2467,
          2468,
          2469,
          2470,
          2471,
          2472,
          2473,
          2474,
          2475,
          2476,
          2477,
          2478,
          2479,
          2480,
          2481,
          2482,
          2483,
          2484,
          2485,
          2486,
          2487,
          2488,
          2489,
          2490,
          2491,
          2492,
          2493,
          2494,
          2495,
          2496,
          2497,
          2498,
          2499,
          2500,
          2501,
          2502,
          2503,
          2504,
          2505,
          2506,
          2507,
          2508,
          2509,
          2510,
          2511,
          2512,
          2513,
          2514,
          2515,
          2516,
          2517,
          2518,
          2519,
          2520,
          2521,
          2522,
          2523,
          2524,
          2525,
          2526,
          2527,
          2528,
          2529,
          2530,
          2531,
          2532,
          2533,
          2534,
          2535,
          2536,
          2537,
          2538,
          2539,
          2540,
          2541,
          2542,
          2543,
          2544,
          2545,
          2546,
          2547,
          2548,
          2549,
          2550,
          2551,
          2552,
          2553,
          2554,
          2555,
          2556,
          2557,
          2558,
          2559,
          2560,
          2561,
          2562,
          2563,
          2564,
          2565,
          2566,
          2567,
          2568,
          2569,
          2570,
          2571,
          2572,
          2573,
          2574,
          2575,
          2576,
          2577,
          2578,
          2579,
          2580,
          2581,
          2582,
          2583,
          2584,
          2585,
          2586,
          2587,
          2588,
          2589,
          2590,
          2591,
          2592,
          2593,
          2594,
          2595,
          2596,
          2597,
          2598,
          2599,
          2600,
          2601,
          2602,
          2603,
          2604,
          2605,
          2606,
          2607,
          2608,
          2609,
          2610,
          2611,
          2612,
          2613,
          2614,
          2615,
          2616,
          2617,
          2618,
          2619,
          2620,
          2621,
          2622,
          2623,
          2624,
          2625,
          2626,
          2627,
          2628,
          2629,
          2630,
          2631,
          2632,
          2633,
          2634,
          2635,
          2636,
          2637,
          2638,
          2639,
          2640,
          2641,
          2642,
          2643,
          2644,
          2645,
          2646,
          2647,
          2648,
          2649,
          2650,
          2651,
          2652,
          2653,
          2654,
          2655,
          2656,
          2657,
          2658,
          2659,
          2660,
          2661,
          2662,
          2663,
          2664,
          2665,
          2666,
          2667,
          2668,
          2669,
          2670,
          2671,
          2672,
          2673,
          2674,
          2675,
          2676,
          2677,
          2678,
          2679,
          2680,
          2681,
          2682,
          2683,
          2684,
          2685,
          2686,
          2687,
          2688,
          2689,
          2690,
          2691,
          2692,
          2693,
          2694,
          2695,
          2696,
          2697,
          2698,
          2699,
          2700,
          2701,
          2702,
          2703,
          2704,
          2705,
          2706,
          2707,
          2708,
          2709,
          2710,
          2711,
          2712,
          2713,
          2714,
          2715,
          2716,
          2717,
          2718,
          2719,
          2720,
          2721,
          2722,
          2723,
          2724,
          2725,
          2726,
          2727,
          2728,
          2729,
          2730,
          2731,
          2732,
          2733,
          2734,
          2735,
          2736,
          2737,
          2738,
          2739,
          2740,
          2741,
          2742,
          2743,
          2744,
          2745,
          2746,
          2747,
          2748,
          2749,
          2750,
          2751,
          2752,
          2753,
          2754,
          2755,
          2756,
          2757,
          2758,
          2759,
          2760,
          2761,
          2762,
          2763,
          2764,
          2765,
          2766,
          2767,
          2768,
          2769,
          2770,
          2771,
          2772,
          2773,
          2774,
          2775,
          2776,
          2777,
          2778,
          2779,
          2780,
          2781,
          2782,
          2783,
          2784,
          2785,
          2786,
          2787,
          2788,
          2789,
          2790,
          2791,
          2792,
          2793,
          2794,
          2795,
          2796,
          2797,
          2798,
          2799,
          2800,
          2801,
          2802,
          2803,
          2804,
          2805,
          2806,
          2807,
          2808,
          2809,
          2810,
          2811,
          2812,
          2813,
          2814,
          2815,
          2816,
          2817,
          2818,
          2819,
          2820,
          2821,
          2822,
          2823,
          2824,
          2825,
          2826,
          2827,
          2828,
          2829,
          2830,
          2831,
          2832,
          2833,
          2834,
          2835,
          2836,
          2837,
          2838,
          2839,
          2840,
          2841,
          2842,
          2843,
          2844,
          2845,
          2846,
          2847,
          2848,
          2849,
          2850,
          2851,
          2852,
          2853,
          2854,
          2855,
          2856,
          2857,
          2858,
          2859,
          2860,
          2861,
          2862,
          2863,
          2864,
          2865,
          2866,
          2867,
          2868,
          2869,
          2870,
          2871,
          2872,
          2873,
          2874,
          2875,
          2876,
          2877,
          2878,
          2879,
          2880,
          2881,
          2882,
          2883,
          2884,
          2885,
          2886,
          2887,
          2888,
          2889,
          2890,
          2891,
          2892,
          2893,
          2894,
          2895,
          2896,
          2897,
          2898,
          2899,
          2900,
          2901,
          2902,
          2903,
          2904,
          2905,
          2906,
          2907,
          2908,
          2909,
          2910,
          2911,
          2912,
          2913,
          2914,
          2915,
          2916,
          2917,
          2918,
          2919,
          2920,
          2921,
          2922,
          2923,
          2924,
          2925,
          2926,
          2927,
          2928,
          2929,
          2930,
          2931,
          2932,
          2933,
          2934,
          2935,
          2936,
          2937,
          2938,
          2939,
          2940,
          2941,
          2942,
          2943,
          2944,
          2945,
          2946,
          2947,
          2948,
          2949,
          2950,
          2951,
          2952,
          2953,
          2954,
          2955,
          2956,
          2957,
          2958,
          2959,
          2960,
          2961,
          2962,
          2963,
          2964,
          2965,
          2966,
          2967,
          2968,
          2969,
          2970,
          2971,
          2972,
          2973,
          2974,
          2975,
          2976,
          2977,
          2978,
          2979,
          2980,
          2981,
          2982,
          2983,
          2984,
          2985,
          2986,
          2987,
          2988,
          2989,
          2990,
          2991,
          2992,
          2993,
          2994,
          2995,
          2996,
          2997,
          2998,
          2999,
          3000,
          3001,
          3002,
          3003,
          3004,
          3005,
          3006,
          3007,
          3008,
          3009,
          3010,
          3011,
          3012,
          3013,
          3014,
          3015,
          3016,
          3017,
          3018,
          3019,
          3020,
          3021,
          3022,
          3023,
          3024,
          3025,
          3026,
          3027,
          3028,
          3029,
          3030,
          3031,
          3032,
          3033,
          3034,
          3035,
          3036,
          3037,
          3038,
          3039,
          3040,
          3041,
          3042,
          3043,
          3044,
          3045,
          3046,
          3047,
          3048,
          3049,
          3050,
          3051,
          3052,
          3053,
          3054,
          3055,
          3056,
          3057,
          3058,
          3059,
          3060,
          3061,
          3062,
          3063,
          3064,
          3065,
          3066,
          3067,
          3068,
          3069,
          3070,
          3071,
          3072,
          3073,
          3074,
          3075,
          3076,
          3077,
          3078,
          3079,
          3080,
          3081,
          3082,
          3083,
          3084,
          3085,
          3086,
          3087,
          3088,
          3089,
          3090,
          3091,
          3092,
          3093,
          3094,
          3095,
          3096,
          3097,
          3098,
          3099,
          3100,
          3101,
          3102,
          3103,
          3104,
          3105,
          3106,
          3107,
          3108,
          3109,
          3110,
          3111,
          3112,
          3113,
          3114,
          3115,
          3116,
          3117,
          3118,
          3119,
          3120,
          3121,
          3122,
          3123,
          3124,
          3125,
          3126,
          3127,
          3128,
          3129,
          3130,
          3131,
          3132,
          3133,
          3134,
          3135,
          3136,
          3137,
          3138,
          3139,
          3140,
          3141,
          3142,
          3143,
          3144,
          3145,
          3146,
          3147,
          3148,
          3149,
          3150,
          3151,
          3152,
          3153,
          3154,
          3155,
          3156,
          3157,
          3158,
          3159,
          3160,
          3161,
          3162,
          3163,
          3164,
          3165,
          3166,
          3167,
          3168,
          3169,
          3170,
          3171,
          3172,
          3173,
          3174,
          3175,
          3176,
          3177,
          3178,
          3179,
          3180,
          3181,
          3182,
          3183,
          3184,
          3185,
          3186,
          3187,
          3188,
          3189,
          3190,
          3191,
          3192,
          3193,
          3194,
          3195,
          3196,
          3197,
          3198,
          3199,
          3200
         ],
         "y": [
          0.6857417180682673,
          0.6857417180682673,
          0.6857417180682673,
          0.6857417180682673,
          0.6857417180682673,
          0.6857417180682673,
          0.6857417180682673,
          0.6857417180682673,
          0.6857417180682673,
          0.6857417180682673,
          0.6857417180682673,
          0.6857417180682673,
          0.6857417180682673,
          0.6857417180682673,
          0.6857417180682673,
          0.6857417180682673,
          0.6857417180682673,
          0.6857417180682673,
          0.6857417180682673,
          0.6857417180682673,
          0.6857417180682673,
          0.6857417180682673,
          0.6857417180682673,
          0.6857417180682673,
          0.6857417180682673,
          0.6857417180682673,
          0.6857417180682673,
          0.6857417180682673,
          0.6857417180682673,
          0.6857417180682673,
          0.6857417180682673,
          0.6857417180682673,
          0.6857417180682673,
          0.6857417180682673,
          0.6857417180682673,
          0.6857417180682673,
          0.6857417180682673,
          0.6857417180682673,
          0.6857417180682673,
          0.6857417180682673,
          0.6857417180682673,
          0.6857417180682673,
          0.6857417180682673,
          0.6857417180682673,
          0.6857417180682673,
          0.6857417180682673,
          0.6857417180682673,
          0.6857417180682673,
          0.6857417180682673,
          0.6857417180682673,
          0.6857417180682673,
          0.6857417180682673,
          0.6857417180682673,
          0.6857417180682673,
          0.6857417180682673,
          0.6857417180682673,
          0.6857417180682673,
          0.6857417180682673,
          0.6857417180682673,
          0.6857417180682673,
          0.6857417180682673,
          0.6857417180682673,
          0.6857417180682673,
          0.6857417180682673,
          0.6857417180682673,
          0.6857417180682673,
          0.6857417180682673,
          0.6857417180682673,
          0.6857417180682673,
          0.6857417180682673,
          0.6857417180682673,
          0.6857417180682673,
          0.6857417180682673,
          0.6857417180682673,
          0.6857417180682673,
          0.6857417180682673,
          0.6857417180682673,
          0.6857417180682673,
          0.6857417180682673,
          0.6857417180682673,
          0.6857417180682673,
          0.6857417180682673,
          0.6857417180682673,
          0.6857417180682673,
          0.6857417180682673,
          0.6857417180682673,
          0.6857417180682673,
          0.6857417180682673,
          0.6857417180682673,
          0.6857417180682673,
          0.6857417180682673,
          0.6857417180682673,
          0.6857417180682673,
          0.6857417180682673,
          0.6857417180682673,
          0.6857417180682673,
          0.6857417180682673,
          0.6857417180682673,
          0.6857417180682673,
          0.6857417180682673,
          0.5382739478590512,
          0.5382739478590512,
          0.5382739478590512,
          0.5382739478590512,
          0.5382739478590512,
          0.5382739478590512,
          0.5382739478590512,
          0.5382739478590512,
          0.5382739478590512,
          0.5382739478590512,
          0.5382739478590512,
          0.5382739478590512,
          0.5382739478590512,
          0.5382739478590512,
          0.5382739478590512,
          0.5382739478590512,
          0.5382739478590512,
          0.5382739478590512,
          0.5382739478590512,
          0.5382739478590512,
          0.5382739478590512,
          0.5382739478590512,
          0.5382739478590512,
          0.5382739478590512,
          0.5382739478590512,
          0.5382739478590512,
          0.5382739478590512,
          0.5382739478590512,
          0.5382739478590512,
          0.5382739478590512,
          0.5382739478590512,
          0.5382739478590512,
          0.5382739478590512,
          0.5382739478590512,
          0.5382739478590512,
          0.5382739478590512,
          0.5382739478590512,
          0.5382739478590512,
          0.5382739478590512,
          0.5382739478590512,
          0.5382739478590512,
          0.5382739478590512,
          0.5382739478590512,
          0.5382739478590512,
          0.5382739478590512,
          0.5382739478590512,
          0.5382739478590512,
          0.5382739478590512,
          0.5382739478590512,
          0.5382739478590512,
          0.5382739478590512,
          0.5382739478590512,
          0.5382739478590512,
          0.5382739478590512,
          0.5382739478590512,
          0.5382739478590512,
          0.5382739478590512,
          0.5382739478590512,
          0.5382739478590512,
          0.5382739478590512,
          0.5382739478590512,
          0.5382739478590512,
          0.5382739478590512,
          0.5382739478590512,
          0.5382739478590512,
          0.5382739478590512,
          0.5382739478590512,
          0.5382739478590512,
          0.5382739478590512,
          0.5382739478590512,
          0.5382739478590512,
          0.5382739478590512,
          0.5382739478590512,
          0.5382739478590512,
          0.5382739478590512,
          0.5382739478590512,
          0.5382739478590512,
          0.5382739478590512,
          0.5382739478590512,
          0.5382739478590512,
          0.5382739478590512,
          0.5382739478590512,
          0.5382739478590512,
          0.5382739478590512,
          0.5382739478590512,
          0.5382739478590512,
          0.5382739478590512,
          0.5382739478590512,
          0.5382739478590512,
          0.5382739478590512,
          0.5382739478590512,
          0.5382739478590512,
          0.5382739478590512,
          0.5382739478590512,
          0.5382739478590512,
          0.5382739478590512,
          0.5382739478590512,
          0.5382739478590512,
          0.5382739478590512,
          0.5382739478590512,
          0.35510677762618853,
          0.35510677762618853,
          0.35510677762618853,
          0.35510677762618853,
          0.35510677762618853,
          0.35510677762618853,
          0.35510677762618853,
          0.35510677762618853,
          0.35510677762618853,
          0.35510677762618853,
          0.35510677762618853,
          0.35510677762618853,
          0.35510677762618853,
          0.35510677762618853,
          0.35510677762618853,
          0.35510677762618853,
          0.35510677762618853,
          0.35510677762618853,
          0.35510677762618853,
          0.35510677762618853,
          0.35510677762618853,
          0.35510677762618853,
          0.35510677762618853,
          0.35510677762618853,
          0.35510677762618853,
          0.35510677762618853,
          0.35510677762618853,
          0.35510677762618853,
          0.35510677762618853,
          0.35510677762618853,
          0.35510677762618853,
          0.35510677762618853,
          0.35510677762618853,
          0.35510677762618853,
          0.35510677762618853,
          0.35510677762618853,
          0.35510677762618853,
          0.35510677762618853,
          0.35510677762618853,
          0.35510677762618853,
          0.35510677762618853,
          0.35510677762618853,
          0.35510677762618853,
          0.35510677762618853,
          0.35510677762618853,
          0.35510677762618853,
          0.35510677762618853,
          0.35510677762618853,
          0.35510677762618853,
          0.35510677762618853,
          0.35510677762618853,
          0.35510677762618853,
          0.35510677762618853,
          0.35510677762618853,
          0.35510677762618853,
          0.35510677762618853,
          0.35510677762618853,
          0.35510677762618853,
          0.35510677762618853,
          0.35510677762618853,
          0.35510677762618853,
          0.35510677762618853,
          0.35510677762618853,
          0.35510677762618853,
          0.35510677762618853,
          0.35510677762618853,
          0.35510677762618853,
          0.35510677762618853,
          0.35510677762618853,
          0.35510677762618853,
          0.35510677762618853,
          0.35510677762618853,
          0.35510677762618853,
          0.35510677762618853,
          0.35510677762618853,
          0.35510677762618853,
          0.35510677762618853,
          0.35510677762618853,
          0.35510677762618853,
          0.35510677762618853,
          0.35510677762618853,
          0.35510677762618853,
          0.35510677762618853,
          0.35510677762618853,
          0.35510677762618853,
          0.35510677762618853,
          0.35510677762618853,
          0.35510677762618853,
          0.35510677762618853,
          0.35510677762618853,
          0.35510677762618853,
          0.35510677762618853,
          0.35510677762618853,
          0.35510677762618853,
          0.35510677762618853,
          0.35510677762618853,
          0.35510677762618853,
          0.35510677762618853,
          0.35510677762618853,
          0.35510677762618853,
          0.3459565170930059,
          0.3459565170930059,
          0.3459565170930059,
          0.3459565170930059,
          0.3459565170930059,
          0.3459565170930059,
          0.3459565170930059,
          0.3459565170930059,
          0.3459565170930059,
          0.3459565170930059,
          0.3459565170930059,
          0.3459565170930059,
          0.3459565170930059,
          0.3459565170930059,
          0.3459565170930059,
          0.3459565170930059,
          0.3459565170930059,
          0.3459565170930059,
          0.3459565170930059,
          0.3459565170930059,
          0.3459565170930059,
          0.3459565170930059,
          0.3459565170930059,
          0.3459565170930059,
          0.3459565170930059,
          0.3459565170930059,
          0.3459565170930059,
          0.3459565170930059,
          0.3459565170930059,
          0.3459565170930059,
          0.3459565170930059,
          0.3459565170930059,
          0.3459565170930059,
          0.3459565170930059,
          0.3459565170930059,
          0.3459565170930059,
          0.3459565170930059,
          0.3459565170930059,
          0.3459565170930059,
          0.3459565170930059,
          0.3459565170930059,
          0.3459565170930059,
          0.3459565170930059,
          0.3459565170930059,
          0.3459565170930059,
          0.3459565170930059,
          0.3459565170930059,
          0.3459565170930059,
          0.3459565170930059,
          0.3459565170930059,
          0.3459565170930059,
          0.3459565170930059,
          0.3459565170930059,
          0.3459565170930059,
          0.3459565170930059,
          0.3459565170930059,
          0.3459565170930059,
          0.3459565170930059,
          0.3459565170930059,
          0.3459565170930059,
          0.3459565170930059,
          0.3459565170930059,
          0.3459565170930059,
          0.3459565170930059,
          0.3459565170930059,
          0.3459565170930059,
          0.3459565170930059,
          0.3459565170930059,
          0.3459565170930059,
          0.3459565170930059,
          0.3459565170930059,
          0.3459565170930059,
          0.3459565170930059,
          0.3459565170930059,
          0.3459565170930059,
          0.3459565170930059,
          0.3459565170930059,
          0.3459565170930059,
          0.3459565170930059,
          0.3459565170930059,
          0.3459565170930059,
          0.3459565170930059,
          0.3459565170930059,
          0.3459565170930059,
          0.3459565170930059,
          0.3459565170930059,
          0.3459565170930059,
          0.3459565170930059,
          0.3459565170930059,
          0.3459565170930059,
          0.3459565170930059,
          0.3459565170930059,
          0.3459565170930059,
          0.3459565170930059,
          0.3459565170930059,
          0.3459565170930059,
          0.3459565170930059,
          0.3459565170930059,
          0.3459565170930059,
          0.3459565170930059,
          0.3450277110969182,
          0.3450277110969182,
          0.3450277110969182,
          0.3450277110969182,
          0.3450277110969182,
          0.3450277110969182,
          0.3450277110969182,
          0.3450277110969182,
          0.3450277110969182,
          0.3450277110969182,
          0.3450277110969182,
          0.3450277110969182,
          0.3450277110969182,
          0.3450277110969182,
          0.3450277110969182,
          0.3450277110969182,
          0.3450277110969182,
          0.3450277110969182,
          0.3450277110969182,
          0.3450277110969182,
          0.3450277110969182,
          0.3450277110969182,
          0.3450277110969182,
          0.3450277110969182,
          0.3450277110969182,
          0.3450277110969182,
          0.3450277110969182,
          0.3450277110969182,
          0.3450277110969182,
          0.3450277110969182,
          0.3450277110969182,
          0.3450277110969182,
          0.3450277110969182,
          0.3450277110969182,
          0.3450277110969182,
          0.3450277110969182,
          0.3450277110969182,
          0.3450277110969182,
          0.3450277110969182,
          0.3450277110969182,
          0.3450277110969182,
          0.3450277110969182,
          0.3450277110969182,
          0.3450277110969182,
          0.3450277110969182,
          0.3450277110969182,
          0.3450277110969182,
          0.3450277110969182,
          0.3450277110969182,
          0.3450277110969182,
          0.3450277110969182,
          0.3450277110969182,
          0.3450277110969182,
          0.3450277110969182,
          0.3450277110969182,
          0.3450277110969182,
          0.3450277110969182,
          0.3450277110969182,
          0.3450277110969182,
          0.3450277110969182,
          0.3450277110969182,
          0.3450277110969182,
          0.3450277110969182,
          0.3450277110969182,
          0.3450277110969182,
          0.3450277110969182,
          0.3450277110969182,
          0.3450277110969182,
          0.3450277110969182,
          0.3450277110969182,
          0.3450277110969182,
          0.3450277110969182,
          0.3450277110969182,
          0.3450277110969182,
          0.3450277110969182,
          0.3450277110969182,
          0.3450277110969182,
          0.3450277110969182,
          0.3450277110969182,
          0.3450277110969182,
          0.3450277110969182,
          0.3450277110969182,
          0.3450277110969182,
          0.3450277110969182,
          0.3450277110969182,
          0.3450277110969182,
          0.3450277110969182,
          0.3450277110969182,
          0.3450277110969182,
          0.3450277110969182,
          0.3450277110969182,
          0.3450277110969182,
          0.3450277110969182,
          0.3450277110969182,
          0.3450277110969182,
          0.3450277110969182,
          0.3450277110969182,
          0.3450277110969182,
          0.3450277110969182,
          0.3450277110969182,
          0.34213770745558614,
          0.34213770745558614,
          0.34213770745558614,
          0.34213770745558614,
          0.34213770745558614,
          0.34213770745558614,
          0.34213770745558614,
          0.34213770745558614,
          0.34213770745558614,
          0.34213770745558614,
          0.34213770745558614,
          0.34213770745558614,
          0.34213770745558614,
          0.34213770745558614,
          0.34213770745558614,
          0.34213770745558614,
          0.34213770745558614,
          0.34213770745558614,
          0.34213770745558614,
          0.34213770745558614,
          0.34213770745558614,
          0.34213770745558614,
          0.34213770745558614,
          0.34213770745558614,
          0.34213770745558614,
          0.34213770745558614,
          0.34213770745558614,
          0.34213770745558614,
          0.34213770745558614,
          0.34213770745558614,
          0.34213770745558614,
          0.34213770745558614,
          0.34213770745558614,
          0.34213770745558614,
          0.34213770745558614,
          0.34213770745558614,
          0.34213770745558614,
          0.34213770745558614,
          0.34213770745558614,
          0.34213770745558614,
          0.34213770745558614,
          0.34213770745558614,
          0.34213770745558614,
          0.34213770745558614,
          0.34213770745558614,
          0.34213770745558614,
          0.34213770745558614,
          0.34213770745558614,
          0.34213770745558614,
          0.34213770745558614,
          0.34213770745558614,
          0.34213770745558614,
          0.34213770745558614,
          0.34213770745558614,
          0.34213770745558614,
          0.34213770745558614,
          0.34213770745558614,
          0.34213770745558614,
          0.34213770745558614,
          0.34213770745558614,
          0.34213770745558614,
          0.34213770745558614,
          0.34213770745558614,
          0.34213770745558614,
          0.34213770745558614,
          0.34213770745558614,
          0.34213770745558614,
          0.34213770745558614,
          0.34213770745558614,
          0.34213770745558614,
          0.34213770745558614,
          0.34213770745558614,
          0.34213770745558614,
          0.34213770745558614,
          0.34213770745558614,
          0.34213770745558614,
          0.34213770745558614,
          0.34213770745558614,
          0.34213770745558614,
          0.34213770745558614,
          0.34213770745558614,
          0.34213770745558614,
          0.34213770745558614,
          0.34213770745558614,
          0.34213770745558614,
          0.34213770745558614,
          0.34213770745558614,
          0.34213770745558614,
          0.34213770745558614,
          0.34213770745558614,
          0.34213770745558614,
          0.34213770745558614,
          0.34213770745558614,
          0.34213770745558614,
          0.34213770745558614,
          0.34213770745558614,
          0.34213770745558614,
          0.34213770745558614,
          0.34213770745558614,
          0.34213770745558614,
          0.3329628069954601,
          0.3329628069954601,
          0.3329628069954601,
          0.3329628069954601,
          0.3329628069954601,
          0.3329628069954601,
          0.3329628069954601,
          0.3329628069954601,
          0.3329628069954601,
          0.3329628069954601,
          0.3329628069954601,
          0.3329628069954601,
          0.3329628069954601,
          0.3329628069954601,
          0.3329628069954601,
          0.3329628069954601,
          0.3329628069954601,
          0.3329628069954601,
          0.3329628069954601,
          0.3329628069954601,
          0.3329628069954601,
          0.3329628069954601,
          0.3329628069954601,
          0.3329628069954601,
          0.3329628069954601,
          0.3329628069954601,
          0.3329628069954601,
          0.3329628069954601,
          0.3329628069954601,
          0.3329628069954601,
          0.3329628069954601,
          0.3329628069954601,
          0.3329628069954601,
          0.3329628069954601,
          0.3329628069954601,
          0.3329628069954601,
          0.3329628069954601,
          0.3329628069954601,
          0.3329628069954601,
          0.3329628069954601,
          0.3329628069954601,
          0.3329628069954601,
          0.3329628069954601,
          0.3329628069954601,
          0.3329628069954601,
          0.3329628069954601,
          0.3329628069954601,
          0.3329628069954601,
          0.3329628069954601,
          0.3329628069954601,
          0.3329628069954601,
          0.3329628069954601,
          0.3329628069954601,
          0.3329628069954601,
          0.3329628069954601,
          0.3329628069954601,
          0.3329628069954601,
          0.3329628069954601,
          0.3329628069954601,
          0.3329628069954601,
          0.3329628069954601,
          0.3329628069954601,
          0.3329628069954601,
          0.3329628069954601,
          0.3329628069954601,
          0.3329628069954601,
          0.3329628069954601,
          0.3329628069954601,
          0.3329628069954601,
          0.3329628069954601,
          0.3329628069954601,
          0.3329628069954601,
          0.3329628069954601,
          0.3329628069954601,
          0.3329628069954601,
          0.3329628069954601,
          0.3329628069954601,
          0.3329628069954601,
          0.3329628069954601,
          0.3329628069954601,
          0.3329628069954601,
          0.3329628069954601,
          0.3329628069954601,
          0.3329628069954601,
          0.3329628069954601,
          0.3329628069954601,
          0.3329628069954601,
          0.3329628069954601,
          0.3329628069954601,
          0.3329628069954601,
          0.3329628069954601,
          0.3329628069954601,
          0.3329628069954601,
          0.3329628069954601,
          0.3329628069954601,
          0.3329628069954601,
          0.3329628069954601,
          0.3329628069954601,
          0.3329628069954601,
          0.3329628069954601,
          0.3190619494199942,
          0.3190619494199942,
          0.3190619494199942,
          0.3190619494199942,
          0.3190619494199942,
          0.3190619494199942,
          0.3190619494199942,
          0.3190619494199942,
          0.3190619494199942,
          0.3190619494199942,
          0.3190619494199942,
          0.3190619494199942,
          0.3190619494199942,
          0.3190619494199942,
          0.3190619494199942,
          0.3190619494199942,
          0.3190619494199942,
          0.3190619494199942,
          0.3190619494199942,
          0.3190619494199942,
          0.3190619494199942,
          0.3190619494199942,
          0.3190619494199942,
          0.3190619494199942,
          0.3190619494199942,
          0.3190619494199942,
          0.3190619494199942,
          0.3190619494199942,
          0.3190619494199942,
          0.3190619494199942,
          0.3190619494199942,
          0.3190619494199942,
          0.3190619494199942,
          0.3190619494199942,
          0.3190619494199942,
          0.3190619494199942,
          0.3190619494199942,
          0.3190619494199942,
          0.3190619494199942,
          0.3190619494199942,
          0.3190619494199942,
          0.3190619494199942,
          0.3190619494199942,
          0.3190619494199942,
          0.3190619494199942,
          0.3190619494199942,
          0.3190619494199942,
          0.3190619494199942,
          0.3190619494199942,
          0.3190619494199942,
          0.3190619494199942,
          0.3190619494199942,
          0.3190619494199942,
          0.3190619494199942,
          0.3190619494199942,
          0.3190619494199942,
          0.3190619494199942,
          0.3190619494199942,
          0.3190619494199942,
          0.3190619494199942,
          0.3190619494199942,
          0.3190619494199942,
          0.3190619494199942,
          0.3190619494199942,
          0.3190619494199942,
          0.3190619494199942,
          0.3190619494199942,
          0.3190619494199942,
          0.3190619494199942,
          0.3190619494199942,
          0.3190619494199942,
          0.3190619494199942,
          0.3190619494199942,
          0.3190619494199942,
          0.3190619494199942,
          0.3190619494199942,
          0.3190619494199942,
          0.3190619494199942,
          0.3190619494199942,
          0.3190619494199942,
          0.3190619494199942,
          0.3190619494199942,
          0.3190619494199942,
          0.3190619494199942,
          0.3190619494199942,
          0.3190619494199942,
          0.3190619494199942,
          0.3190619494199942,
          0.3190619494199942,
          0.3190619494199942,
          0.3190619494199942,
          0.3190619494199942,
          0.3190619494199942,
          0.3190619494199942,
          0.3190619494199942,
          0.3190619494199942,
          0.3190619494199942,
          0.3190619494199942,
          0.3190619494199942,
          0.3190619494199942,
          0.31280468402345457,
          0.31280468402345457,
          0.31280468402345457,
          0.31280468402345457,
          0.31280468402345457,
          0.31280468402345457,
          0.31280468402345457,
          0.31280468402345457,
          0.31280468402345457,
          0.31280468402345457,
          0.31280468402345457,
          0.31280468402345457,
          0.31280468402345457,
          0.31280468402345457,
          0.31280468402345457,
          0.31280468402345457,
          0.31280468402345457,
          0.31280468402345457,
          0.31280468402345457,
          0.31280468402345457,
          0.31280468402345457,
          0.31280468402345457,
          0.31280468402345457,
          0.31280468402345457,
          0.31280468402345457,
          0.31280468402345457,
          0.31280468402345457,
          0.31280468402345457,
          0.31280468402345457,
          0.31280468402345457,
          0.31280468402345457,
          0.31280468402345457,
          0.31280468402345457,
          0.31280468402345457,
          0.31280468402345457,
          0.31280468402345457,
          0.31280468402345457,
          0.31280468402345457,
          0.31280468402345457,
          0.31280468402345457,
          0.31280468402345457,
          0.31280468402345457,
          0.31280468402345457,
          0.31280468402345457,
          0.31280468402345457,
          0.31280468402345457,
          0.31280468402345457,
          0.31280468402345457,
          0.31280468402345457,
          0.31280468402345457,
          0.31280468402345457,
          0.31280468402345457,
          0.31280468402345457,
          0.31280468402345457,
          0.31280468402345457,
          0.31280468402345457,
          0.31280468402345457,
          0.31280468402345457,
          0.31280468402345457,
          0.31280468402345457,
          0.31280468402345457,
          0.31280468402345457,
          0.31280468402345457,
          0.31280468402345457,
          0.31280468402345457,
          0.31280468402345457,
          0.31280468402345457,
          0.31280468402345457,
          0.31280468402345457,
          0.31280468402345457,
          0.31280468402345457,
          0.31280468402345457,
          0.31280468402345457,
          0.31280468402345457,
          0.31280468402345457,
          0.31280468402345457,
          0.31280468402345457,
          0.31280468402345457,
          0.31280468402345457,
          0.31280468402345457,
          0.31280468402345457,
          0.31280468402345457,
          0.31280468402345457,
          0.31280468402345457,
          0.31280468402345457,
          0.31280468402345457,
          0.31280468402345457,
          0.31280468402345457,
          0.31280468402345457,
          0.31280468402345457,
          0.31280468402345457,
          0.31280468402345457,
          0.31280468402345457,
          0.31280468402345457,
          0.31280468402345457,
          0.31280468402345457,
          0.31280468402345457,
          0.31280468402345457,
          0.31280468402345457,
          0.31280468402345457,
          0.3074320829401411,
          0.3074320829401411,
          0.3074320829401411,
          0.3074320829401411,
          0.3074320829401411,
          0.3074320829401411,
          0.3074320829401411,
          0.3074320829401411,
          0.3074320829401411,
          0.3074320829401411,
          0.3074320829401411,
          0.3074320829401411,
          0.3074320829401411,
          0.3074320829401411,
          0.3074320829401411,
          0.3074320829401411,
          0.3074320829401411,
          0.3074320829401411,
          0.3074320829401411,
          0.3074320829401411,
          0.3074320829401411,
          0.3074320829401411,
          0.3074320829401411,
          0.3074320829401411,
          0.3074320829401411,
          0.3074320829401411,
          0.3074320829401411,
          0.3074320829401411,
          0.3074320829401411,
          0.3074320829401411,
          0.3074320829401411,
          0.3074320829401411,
          0.3074320829401411,
          0.3074320829401411,
          0.3074320829401411,
          0.3074320829401411,
          0.3074320829401411,
          0.3074320829401411,
          0.3074320829401411,
          0.3074320829401411,
          0.3074320829401411,
          0.3074320829401411,
          0.3074320829401411,
          0.3074320829401411,
          0.3074320829401411,
          0.3074320829401411,
          0.3074320829401411,
          0.3074320829401411,
          0.3074320829401411,
          0.3074320829401411,
          0.3074320829401411,
          0.3074320829401411,
          0.3074320829401411,
          0.3074320829401411,
          0.3074320829401411,
          0.3074320829401411,
          0.3074320829401411,
          0.3074320829401411,
          0.3074320829401411,
          0.3074320829401411,
          0.3074320829401411,
          0.3074320829401411,
          0.3074320829401411,
          0.3074320829401411,
          0.3074320829401411,
          0.3074320829401411,
          0.3074320829401411,
          0.3074320829401411,
          0.3074320829401411,
          0.3074320829401411,
          0.3074320829401411,
          0.3074320829401411,
          0.3074320829401411,
          0.3074320829401411,
          0.3074320829401411,
          0.3074320829401411,
          0.3074320829401411,
          0.3074320829401411,
          0.3074320829401411,
          0.3074320829401411,
          0.3074320829401411,
          0.3074320829401411,
          0.3074320829401411,
          0.3074320829401411,
          0.3074320829401411,
          0.3074320829401411,
          0.3074320829401411,
          0.3074320829401411,
          0.3074320829401411,
          0.3074320829401411,
          0.3074320829401411,
          0.3074320829401411,
          0.3074320829401411,
          0.3074320829401411,
          0.3074320829401411,
          0.3074320829401411,
          0.3074320829401411,
          0.3074320829401411,
          0.3074320829401411,
          0.3074320829401411,
          0.30537392003826985,
          0.30537392003826985,
          0.30537392003826985,
          0.30537392003826985,
          0.30537392003826985,
          0.30537392003826985,
          0.30537392003826985,
          0.30537392003826985,
          0.30537392003826985,
          0.30537392003826985,
          0.30537392003826985,
          0.30537392003826985,
          0.30537392003826985,
          0.30537392003826985,
          0.30537392003826985,
          0.30537392003826985,
          0.30537392003826985,
          0.30537392003826985,
          0.30537392003826985,
          0.30537392003826985,
          0.30537392003826985,
          0.30537392003826985,
          0.30537392003826985,
          0.30537392003826985,
          0.30537392003826985,
          0.30537392003826985,
          0.30537392003826985,
          0.30537392003826985,
          0.30537392003826985,
          0.30537392003826985,
          0.30537392003826985,
          0.30537392003826985,
          0.30537392003826985,
          0.30537392003826985,
          0.30537392003826985,
          0.30537392003826985,
          0.30537392003826985,
          0.30537392003826985,
          0.30537392003826985,
          0.30537392003826985,
          0.30537392003826985,
          0.30537392003826985,
          0.30537392003826985,
          0.30537392003826985,
          0.30537392003826985,
          0.30537392003826985,
          0.30537392003826985,
          0.30537392003826985,
          0.30537392003826985,
          0.30537392003826985,
          0.30537392003826985,
          0.30537392003826985,
          0.30537392003826985,
          0.30537392003826985,
          0.30537392003826985,
          0.30537392003826985,
          0.30537392003826985,
          0.30537392003826985,
          0.30537392003826985,
          0.30537392003826985,
          0.30537392003826985,
          0.30537392003826985,
          0.30537392003826985,
          0.30537392003826985,
          0.30537392003826985,
          0.30537392003826985,
          0.30537392003826985,
          0.30537392003826985,
          0.30537392003826985,
          0.30537392003826985,
          0.30537392003826985,
          0.30537392003826985,
          0.30537392003826985,
          0.30537392003826985,
          0.30537392003826985,
          0.30537392003826985,
          0.30537392003826985,
          0.30537392003826985,
          0.30537392003826985,
          0.30537392003826985,
          0.30537392003826985,
          0.30537392003826985,
          0.30537392003826985,
          0.30537392003826985,
          0.30537392003826985,
          0.30537392003826985,
          0.30537392003826985,
          0.30537392003826985,
          0.30537392003826985,
          0.30537392003826985,
          0.30537392003826985,
          0.30537392003826985,
          0.30537392003826985,
          0.30537392003826985,
          0.30537392003826985,
          0.30537392003826985,
          0.30537392003826985,
          0.30537392003826985,
          0.30537392003826985,
          0.30537392003826985,
          0.3051408066478531,
          0.3051408066478531,
          0.3051408066478531,
          0.3051408066478531,
          0.3051408066478531,
          0.3051408066478531,
          0.3051408066478531,
          0.3051408066478531,
          0.3051408066478531,
          0.3051408066478531,
          0.3051408066478531,
          0.3051408066478531,
          0.3051408066478531,
          0.3051408066478531,
          0.3051408066478531,
          0.3051408066478531,
          0.3051408066478531,
          0.3051408066478531,
          0.3051408066478531,
          0.3051408066478531,
          0.3051408066478531,
          0.3051408066478531,
          0.3051408066478531,
          0.3051408066478531,
          0.3051408066478531,
          0.3051408066478531,
          0.3051408066478531,
          0.3051408066478531,
          0.3051408066478531,
          0.3051408066478531,
          0.3051408066478531,
          0.3051408066478531,
          0.3051408066478531,
          0.3051408066478531,
          0.3051408066478531,
          0.3051408066478531,
          0.3051408066478531,
          0.3051408066478531,
          0.3051408066478531,
          0.3051408066478531,
          0.3051408066478531,
          0.3051408066478531,
          0.3051408066478531,
          0.3051408066478531,
          0.3051408066478531,
          0.3051408066478531,
          0.3051408066478531,
          0.3051408066478531,
          0.3051408066478531,
          0.3051408066478531,
          0.3051408066478531,
          0.3051408066478531,
          0.3051408066478531,
          0.3051408066478531,
          0.3051408066478531,
          0.3051408066478531,
          0.3051408066478531,
          0.3051408066478531,
          0.3051408066478531,
          0.3051408066478531,
          0.3051408066478531,
          0.3051408066478531,
          0.3051408066478531,
          0.3051408066478531,
          0.3051408066478531,
          0.3051408066478531,
          0.3051408066478531,
          0.3051408066478531,
          0.3051408066478531,
          0.3051408066478531,
          0.3051408066478531,
          0.3051408066478531,
          0.3051408066478531,
          0.3051408066478531,
          0.3051408066478531,
          0.3051408066478531,
          0.3051408066478531,
          0.3051408066478531,
          0.3051408066478531,
          0.3051408066478531,
          0.3051408066478531,
          0.3051408066478531,
          0.3051408066478531,
          0.3051408066478531,
          0.3051408066478531,
          0.3051408066478531,
          0.3051408066478531,
          0.3051408066478531,
          0.3051408066478531,
          0.3051408066478531,
          0.3051408066478531,
          0.3051408066478531,
          0.3051408066478531,
          0.3051408066478531,
          0.3051408066478531,
          0.3051408066478531,
          0.3051408066478531,
          0.3051408066478531,
          0.3051408066478531,
          0.3051408066478531,
          0.3040876231926365,
          0.3040876231926365,
          0.3040876231926365,
          0.3040876231926365,
          0.3040876231926365,
          0.3040876231926365,
          0.3040876231926365,
          0.3040876231926365,
          0.3040876231926365,
          0.3040876231926365,
          0.3040876231926365,
          0.3040876231926365,
          0.3040876231926365,
          0.3040876231926365,
          0.3040876231926365,
          0.3040876231926365,
          0.3040876231926365,
          0.3040876231926365,
          0.3040876231926365,
          0.3040876231926365,
          0.3040876231926365,
          0.3040876231926365,
          0.3040876231926365,
          0.3040876231926365,
          0.3040876231926365,
          0.3040876231926365,
          0.3040876231926365,
          0.3040876231926365,
          0.3040876231926365,
          0.3040876231926365,
          0.3040876231926365,
          0.3040876231926365,
          0.3040876231926365,
          0.3040876231926365,
          0.3040876231926365,
          0.3040876231926365,
          0.3040876231926365,
          0.3040876231926365,
          0.3040876231926365,
          0.3040876231926365,
          0.3040876231926365,
          0.3040876231926365,
          0.3040876231926365,
          0.3040876231926365,
          0.3040876231926365,
          0.3040876231926365,
          0.3040876231926365,
          0.3040876231926365,
          0.3040876231926365,
          0.3040876231926365,
          0.3040876231926365,
          0.3040876231926365,
          0.3040876231926365,
          0.3040876231926365,
          0.3040876231926365,
          0.3040876231926365,
          0.3040876231926365,
          0.3040876231926365,
          0.3040876231926365,
          0.3040876231926365,
          0.3040876231926365,
          0.3040876231926365,
          0.3040876231926365,
          0.3040876231926365,
          0.3040876231926365,
          0.3040876231926365,
          0.3040876231926365,
          0.3040876231926365,
          0.3040876231926365,
          0.3040876231926365,
          0.3040876231926365,
          0.3040876231926365,
          0.3040876231926365,
          0.3040876231926365,
          0.3040876231926365,
          0.3040876231926365,
          0.3040876231926365,
          0.3040876231926365,
          0.3040876231926365,
          0.3040876231926365,
          0.3040876231926365,
          0.3040876231926365,
          0.3040876231926365,
          0.3040876231926365,
          0.3040876231926365,
          0.3040876231926365,
          0.3040876231926365,
          0.3040876231926365,
          0.3040876231926365,
          0.3040876231926365,
          0.3040876231926365,
          0.3040876231926365,
          0.3040876231926365,
          0.3040876231926365,
          0.3040876231926365,
          0.3040876231926365,
          0.3040876231926365,
          0.3040876231926365,
          0.3040876231926365,
          0.3040876231926365,
          0.30356331191095054,
          0.30356331191095054,
          0.30356331191095054,
          0.30356331191095054,
          0.30356331191095054,
          0.30356331191095054,
          0.30356331191095054,
          0.30356331191095054,
          0.30356331191095054,
          0.30356331191095054,
          0.30356331191095054,
          0.30356331191095054,
          0.30356331191095054,
          0.30356331191095054,
          0.30356331191095054,
          0.30356331191095054,
          0.30356331191095054,
          0.30356331191095054,
          0.30356331191095054,
          0.30356331191095054,
          0.30356331191095054,
          0.30356331191095054,
          0.30356331191095054,
          0.30356331191095054,
          0.30356331191095054,
          0.30356331191095054,
          0.30356331191095054,
          0.30356331191095054,
          0.30356331191095054,
          0.30356331191095054,
          0.30356331191095054,
          0.30356331191095054,
          0.30356331191095054,
          0.30356331191095054,
          0.30356331191095054,
          0.30356331191095054,
          0.30356331191095054,
          0.30356331191095054,
          0.30356331191095054,
          0.30356331191095054,
          0.30356331191095054,
          0.30356331191095054,
          0.30356331191095054,
          0.30356331191095054,
          0.30356331191095054,
          0.30356331191095054,
          0.30356331191095054,
          0.30356331191095054,
          0.30356331191095054,
          0.30356331191095054,
          0.30356331191095054,
          0.30356331191095054,
          0.30356331191095054,
          0.30356331191095054,
          0.30356331191095054,
          0.30356331191095054,
          0.30356331191095054,
          0.30356331191095054,
          0.30356331191095054,
          0.30356331191095054,
          0.30356331191095054,
          0.30356331191095054,
          0.30356331191095054,
          0.30356331191095054,
          0.30356331191095054,
          0.30356331191095054,
          0.30356331191095054,
          0.30356331191095054,
          0.30356331191095054,
          0.30356331191095054,
          0.30356331191095054,
          0.30356331191095054,
          0.30356331191095054,
          0.30356331191095054,
          0.30356331191095054,
          0.30356331191095054,
          0.30356331191095054,
          0.30356331191095054,
          0.30356331191095054,
          0.30356331191095054,
          0.30356331191095054,
          0.30356331191095054,
          0.30356331191095054,
          0.30356331191095054,
          0.30356331191095054,
          0.30356331191095054,
          0.30356331191095054,
          0.30356331191095054,
          0.30356331191095054,
          0.30356331191095054,
          0.30356331191095054,
          0.30356331191095054,
          0.30356331191095054,
          0.30356331191095054,
          0.30356331191095054,
          0.30356331191095054,
          0.30356331191095054,
          0.30356331191095054,
          0.30356331191095054,
          0.30356331191095054,
          0.3040799501968741,
          0.3040799501968741,
          0.3040799501968741,
          0.3040799501968741,
          0.3040799501968741,
          0.3040799501968741,
          0.3040799501968741,
          0.3040799501968741,
          0.3040799501968741,
          0.3040799501968741,
          0.3040799501968741,
          0.3040799501968741,
          0.3040799501968741,
          0.3040799501968741,
          0.3040799501968741,
          0.3040799501968741,
          0.3040799501968741,
          0.3040799501968741,
          0.3040799501968741,
          0.3040799501968741,
          0.3040799501968741,
          0.3040799501968741,
          0.3040799501968741,
          0.3040799501968741,
          0.3040799501968741,
          0.3040799501968741,
          0.3040799501968741,
          0.3040799501968741,
          0.3040799501968741,
          0.3040799501968741,
          0.3040799501968741,
          0.3040799501968741,
          0.3040799501968741,
          0.3040799501968741,
          0.3040799501968741,
          0.3040799501968741,
          0.3040799501968741,
          0.3040799501968741,
          0.3040799501968741,
          0.3040799501968741,
          0.3040799501968741,
          0.3040799501968741,
          0.3040799501968741,
          0.3040799501968741,
          0.3040799501968741,
          0.3040799501968741,
          0.3040799501968741,
          0.3040799501968741,
          0.3040799501968741,
          0.3040799501968741,
          0.3040799501968741,
          0.3040799501968741,
          0.3040799501968741,
          0.3040799501968741,
          0.3040799501968741,
          0.3040799501968741,
          0.3040799501968741,
          0.3040799501968741,
          0.3040799501968741,
          0.3040799501968741,
          0.3040799501968741,
          0.3040799501968741,
          0.3040799501968741,
          0.3040799501968741,
          0.3040799501968741,
          0.3040799501968741,
          0.3040799501968741,
          0.3040799501968741,
          0.3040799501968741,
          0.3040799501968741,
          0.3040799501968741,
          0.3040799501968741,
          0.3040799501968741,
          0.3040799501968741,
          0.3040799501968741,
          0.3040799501968741,
          0.3040799501968741,
          0.3040799501968741,
          0.3040799501968741,
          0.3040799501968741,
          0.3040799501968741,
          0.3040799501968741,
          0.3040799501968741,
          0.3040799501968741,
          0.3040799501968741,
          0.3040799501968741,
          0.3040799501968741,
          0.3040799501968741,
          0.3040799501968741,
          0.3040799501968741,
          0.3040799501968741,
          0.3040799501968741,
          0.3040799501968741,
          0.3040799501968741,
          0.3040799501968741,
          0.3040799501968741,
          0.3040799501968741,
          0.3040799501968741,
          0.3040799501968741,
          0.3040799501968741,
          0.3037078626269323,
          0.3037078626269323,
          0.3037078626269323,
          0.3037078626269323,
          0.3037078626269323,
          0.3037078626269323,
          0.3037078626269323,
          0.3037078626269323,
          0.3037078626269323,
          0.3037078626269323,
          0.3037078626269323,
          0.3037078626269323,
          0.3037078626269323,
          0.3037078626269323,
          0.3037078626269323,
          0.3037078626269323,
          0.3037078626269323,
          0.3037078626269323,
          0.3037078626269323,
          0.3037078626269323,
          0.3037078626269323,
          0.3037078626269323,
          0.3037078626269323,
          0.3037078626269323,
          0.3037078626269323,
          0.3037078626269323,
          0.3037078626269323,
          0.3037078626269323,
          0.3037078626269323,
          0.3037078626269323,
          0.3037078626269323,
          0.3037078626269323,
          0.3037078626269323,
          0.3037078626269323,
          0.3037078626269323,
          0.3037078626269323,
          0.3037078626269323,
          0.3037078626269323,
          0.3037078626269323,
          0.3037078626269323,
          0.3037078626269323,
          0.3037078626269323,
          0.3037078626269323,
          0.3037078626269323,
          0.3037078626269323,
          0.3037078626269323,
          0.3037078626269323,
          0.3037078626269323,
          0.3037078626269323,
          0.3037078626269323,
          0.3037078626269323,
          0.3037078626269323,
          0.3037078626269323,
          0.3037078626269323,
          0.3037078626269323,
          0.3037078626269323,
          0.3037078626269323,
          0.3037078626269323,
          0.3037078626269323,
          0.3037078626269323,
          0.3037078626269323,
          0.3037078626269323,
          0.3037078626269323,
          0.3037078626269323,
          0.3037078626269323,
          0.3037078626269323,
          0.3037078626269323,
          0.3037078626269323,
          0.3037078626269323,
          0.3037078626269323,
          0.3037078626269323,
          0.3037078626269323,
          0.3037078626269323,
          0.3037078626269323,
          0.3037078626269323,
          0.3037078626269323,
          0.3037078626269323,
          0.3037078626269323,
          0.3037078626269323,
          0.3037078626269323,
          0.3037078626269323,
          0.3037078626269323,
          0.3037078626269323,
          0.3037078626269323,
          0.3037078626269323,
          0.3037078626269323,
          0.3037078626269323,
          0.3037078626269323,
          0.3037078626269323,
          0.3037078626269323,
          0.3037078626269323,
          0.3037078626269323,
          0.3037078626269323,
          0.3037078626269323,
          0.3037078626269323,
          0.3037078626269323,
          0.3037078626269323,
          0.3037078626269323,
          0.3037078626269323,
          0.3037078626269323,
          0.3074746711799568,
          0.3074746711799568,
          0.3074746711799568,
          0.3074746711799568,
          0.3074746711799568,
          0.3074746711799568,
          0.3074746711799568,
          0.3074746711799568,
          0.3074746711799568,
          0.3074746711799568,
          0.3074746711799568,
          0.3074746711799568,
          0.3074746711799568,
          0.3074746711799568,
          0.3074746711799568,
          0.3074746711799568,
          0.3074746711799568,
          0.3074746711799568,
          0.3074746711799568,
          0.3074746711799568,
          0.3074746711799568,
          0.3074746711799568,
          0.3074746711799568,
          0.3074746711799568,
          0.3074746711799568,
          0.3074746711799568,
          0.3074746711799568,
          0.3074746711799568,
          0.3074746711799568,
          0.3074746711799568,
          0.3074746711799568,
          0.3074746711799568,
          0.3074746711799568,
          0.3074746711799568,
          0.3074746711799568,
          0.3074746711799568,
          0.3074746711799568,
          0.3074746711799568,
          0.3074746711799568,
          0.3074746711799568,
          0.3074746711799568,
          0.3074746711799568,
          0.3074746711799568,
          0.3074746711799568,
          0.3074746711799568,
          0.3074746711799568,
          0.3074746711799568,
          0.3074746711799568,
          0.3074746711799568,
          0.3074746711799568,
          0.3074746711799568,
          0.3074746711799568,
          0.3074746711799568,
          0.3074746711799568,
          0.3074746711799568,
          0.3074746711799568,
          0.3074746711799568,
          0.3074746711799568,
          0.3074746711799568,
          0.3074746711799568,
          0.3074746711799568,
          0.3074746711799568,
          0.3074746711799568,
          0.3074746711799568,
          0.3074746711799568,
          0.3074746711799568,
          0.3074746711799568,
          0.3074746711799568,
          0.3074746711799568,
          0.3074746711799568,
          0.3074746711799568,
          0.3074746711799568,
          0.3074746711799568,
          0.3074746711799568,
          0.3074746711799568,
          0.3074746711799568,
          0.3074746711799568,
          0.3074746711799568,
          0.3074746711799568,
          0.3074746711799568,
          0.3074746711799568,
          0.3074746711799568,
          0.3074746711799568,
          0.3074746711799568,
          0.3074746711799568,
          0.3074746711799568,
          0.3074746711799568,
          0.3074746711799568,
          0.3074746711799568,
          0.3074746711799568,
          0.3074746711799568,
          0.3074746711799568,
          0.3074746711799568,
          0.3074746711799568,
          0.3074746711799568,
          0.3074746711799568,
          0.3074746711799568,
          0.3074746711799568,
          0.3074746711799568,
          0.3074746711799568,
          0.309084055062631,
          0.309084055062631,
          0.309084055062631,
          0.309084055062631,
          0.309084055062631,
          0.309084055062631,
          0.309084055062631,
          0.309084055062631,
          0.309084055062631,
          0.309084055062631,
          0.309084055062631,
          0.309084055062631,
          0.309084055062631,
          0.309084055062631,
          0.309084055062631,
          0.309084055062631,
          0.309084055062631,
          0.309084055062631,
          0.309084055062631,
          0.309084055062631,
          0.309084055062631,
          0.309084055062631,
          0.309084055062631,
          0.309084055062631,
          0.309084055062631,
          0.309084055062631,
          0.309084055062631,
          0.309084055062631,
          0.309084055062631,
          0.309084055062631,
          0.309084055062631,
          0.309084055062631,
          0.309084055062631,
          0.309084055062631,
          0.309084055062631,
          0.309084055062631,
          0.309084055062631,
          0.309084055062631,
          0.309084055062631,
          0.309084055062631,
          0.309084055062631,
          0.309084055062631,
          0.309084055062631,
          0.309084055062631,
          0.309084055062631,
          0.309084055062631,
          0.309084055062631,
          0.309084055062631,
          0.309084055062631,
          0.309084055062631,
          0.309084055062631,
          0.309084055062631,
          0.309084055062631,
          0.309084055062631,
          0.309084055062631,
          0.309084055062631,
          0.309084055062631,
          0.309084055062631,
          0.309084055062631,
          0.309084055062631,
          0.309084055062631,
          0.309084055062631,
          0.309084055062631,
          0.309084055062631,
          0.309084055062631,
          0.309084055062631,
          0.309084055062631,
          0.309084055062631,
          0.309084055062631,
          0.309084055062631,
          0.309084055062631,
          0.309084055062631,
          0.309084055062631,
          0.309084055062631,
          0.309084055062631,
          0.309084055062631,
          0.309084055062631,
          0.309084055062631,
          0.309084055062631,
          0.309084055062631,
          0.309084055062631,
          0.309084055062631,
          0.309084055062631,
          0.309084055062631,
          0.309084055062631,
          0.309084055062631,
          0.309084055062631,
          0.309084055062631,
          0.309084055062631,
          0.309084055062631,
          0.309084055062631,
          0.309084055062631,
          0.309084055062631,
          0.309084055062631,
          0.309084055062631,
          0.309084055062631,
          0.309084055062631,
          0.309084055062631,
          0.309084055062631,
          0.309084055062631,
          0.3087129370178583,
          0.3087129370178583,
          0.3087129370178583,
          0.3087129370178583,
          0.3087129370178583,
          0.3087129370178583,
          0.3087129370178583,
          0.3087129370178583,
          0.3087129370178583,
          0.3087129370178583,
          0.3087129370178583,
          0.3087129370178583,
          0.3087129370178583,
          0.3087129370178583,
          0.3087129370178583,
          0.3087129370178583,
          0.3087129370178583,
          0.3087129370178583,
          0.3087129370178583,
          0.3087129370178583,
          0.3087129370178583,
          0.3087129370178583,
          0.3087129370178583,
          0.3087129370178583,
          0.3087129370178583,
          0.3087129370178583,
          0.3087129370178583,
          0.3087129370178583,
          0.3087129370178583,
          0.3087129370178583,
          0.3087129370178583,
          0.3087129370178583,
          0.3087129370178583,
          0.3087129370178583,
          0.3087129370178583,
          0.3087129370178583,
          0.3087129370178583,
          0.3087129370178583,
          0.3087129370178583,
          0.3087129370178583,
          0.3087129370178583,
          0.3087129370178583,
          0.3087129370178583,
          0.3087129370178583,
          0.3087129370178583,
          0.3087129370178583,
          0.3087129370178583,
          0.3087129370178583,
          0.3087129370178583,
          0.3087129370178583,
          0.3087129370178583,
          0.3087129370178583,
          0.3087129370178583,
          0.3087129370178583,
          0.3087129370178583,
          0.3087129370178583,
          0.3087129370178583,
          0.3087129370178583,
          0.3087129370178583,
          0.3087129370178583,
          0.3087129370178583,
          0.3087129370178583,
          0.3087129370178583,
          0.3087129370178583,
          0.3087129370178583,
          0.3087129370178583,
          0.3087129370178583,
          0.3087129370178583,
          0.3087129370178583,
          0.3087129370178583,
          0.3087129370178583,
          0.3087129370178583,
          0.3087129370178583,
          0.3087129370178583,
          0.3087129370178583,
          0.3087129370178583,
          0.3087129370178583,
          0.3087129370178583,
          0.3087129370178583,
          0.3087129370178583,
          0.3087129370178583,
          0.3087129370178583,
          0.3087129370178583,
          0.3087129370178583,
          0.3087129370178583,
          0.3087129370178583,
          0.3087129370178583,
          0.3087129370178583,
          0.3087129370178583,
          0.3087129370178583,
          0.3087129370178583,
          0.3087129370178583,
          0.3087129370178583,
          0.3087129370178583,
          0.3087129370178583,
          0.3087129370178583,
          0.3087129370178583,
          0.3087129370178583,
          0.3087129370178583,
          0.3087129370178583,
          0.30855018111436044,
          0.30855018111436044,
          0.30855018111436044,
          0.30855018111436044,
          0.30855018111436044,
          0.30855018111436044,
          0.30855018111436044,
          0.30855018111436044,
          0.30855018111436044,
          0.30855018111436044,
          0.30855018111436044,
          0.30855018111436044,
          0.30855018111436044,
          0.30855018111436044,
          0.30855018111436044,
          0.30855018111436044,
          0.30855018111436044,
          0.30855018111436044,
          0.30855018111436044,
          0.30855018111436044,
          0.30855018111436044,
          0.30855018111436044,
          0.30855018111436044,
          0.30855018111436044,
          0.30855018111436044,
          0.30855018111436044,
          0.30855018111436044,
          0.30855018111436044,
          0.30855018111436044,
          0.30855018111436044,
          0.30855018111436044,
          0.30855018111436044,
          0.30855018111436044,
          0.30855018111436044,
          0.30855018111436044,
          0.30855018111436044,
          0.30855018111436044,
          0.30855018111436044,
          0.30855018111436044,
          0.30855018111436044,
          0.30855018111436044,
          0.30855018111436044,
          0.30855018111436044,
          0.30855018111436044,
          0.30855018111436044,
          0.30855018111436044,
          0.30855018111436044,
          0.30855018111436044,
          0.30855018111436044,
          0.30855018111436044,
          0.30855018111436044,
          0.30855018111436044,
          0.30855018111436044,
          0.30855018111436044,
          0.30855018111436044,
          0.30855018111436044,
          0.30855018111436044,
          0.30855018111436044,
          0.30855018111436044,
          0.30855018111436044,
          0.30855018111436044,
          0.30855018111436044,
          0.30855018111436044,
          0.30855018111436044,
          0.30855018111436044,
          0.30855018111436044,
          0.30855018111436044,
          0.30855018111436044,
          0.30855018111436044,
          0.30855018111436044,
          0.30855018111436044,
          0.30855018111436044,
          0.30855018111436044,
          0.30855018111436044,
          0.30855018111436044,
          0.30855018111436044,
          0.30855018111436044,
          0.30855018111436044,
          0.30855018111436044,
          0.30855018111436044,
          0.30855018111436044,
          0.30855018111436044,
          0.30855018111436044,
          0.30855018111436044,
          0.30855018111436044,
          0.30855018111436044,
          0.30855018111436044,
          0.30855018111436044,
          0.30855018111436044,
          0.30855018111436044,
          0.30855018111436044,
          0.30855018111436044,
          0.30855018111436044,
          0.30855018111436044,
          0.30855018111436044,
          0.30855018111436044,
          0.30855018111436044,
          0.30855018111436044,
          0.30855018111436044,
          0.30855018111436044,
          0.3109475322290194,
          0.3109475322290194,
          0.3109475322290194,
          0.3109475322290194,
          0.3109475322290194,
          0.3109475322290194,
          0.3109475322290194,
          0.3109475322290194,
          0.3109475322290194,
          0.3109475322290194,
          0.3109475322290194,
          0.3109475322290194,
          0.3109475322290194,
          0.3109475322290194,
          0.3109475322290194,
          0.3109475322290194,
          0.3109475322290194,
          0.3109475322290194,
          0.3109475322290194,
          0.3109475322290194,
          0.3109475322290194,
          0.3109475322290194,
          0.3109475322290194,
          0.3109475322290194,
          0.3109475322290194,
          0.3109475322290194,
          0.3109475322290194,
          0.3109475322290194,
          0.3109475322290194,
          0.3109475322290194,
          0.3109475322290194,
          0.3109475322290194,
          0.3109475322290194,
          0.3109475322290194,
          0.3109475322290194,
          0.3109475322290194,
          0.3109475322290194,
          0.3109475322290194,
          0.3109475322290194,
          0.3109475322290194,
          0.3109475322290194,
          0.3109475322290194,
          0.3109475322290194,
          0.3109475322290194,
          0.3109475322290194,
          0.3109475322290194,
          0.3109475322290194,
          0.3109475322290194,
          0.3109475322290194,
          0.3109475322290194,
          0.3109475322290194,
          0.3109475322290194,
          0.3109475322290194,
          0.3109475322290194,
          0.3109475322290194,
          0.3109475322290194,
          0.3109475322290194,
          0.3109475322290194,
          0.3109475322290194,
          0.3109475322290194,
          0.3109475322290194,
          0.3109475322290194,
          0.3109475322290194,
          0.3109475322290194,
          0.3109475322290194,
          0.3109475322290194,
          0.3109475322290194,
          0.3109475322290194,
          0.3109475322290194,
          0.3109475322290194,
          0.3109475322290194,
          0.3109475322290194,
          0.3109475322290194,
          0.3109475322290194,
          0.3109475322290194,
          0.3109475322290194,
          0.3109475322290194,
          0.3109475322290194,
          0.3109475322290194,
          0.3109475322290194,
          0.3109475322290194,
          0.3109475322290194,
          0.3109475322290194,
          0.3109475322290194,
          0.3109475322290194,
          0.3109475322290194,
          0.3109475322290194,
          0.3109475322290194,
          0.3109475322290194,
          0.3109475322290194,
          0.3109475322290194,
          0.3109475322290194,
          0.3109475322290194,
          0.3109475322290194,
          0.3109475322290194,
          0.3109475322290194,
          0.3109475322290194,
          0.3109475322290194,
          0.3109475322290194,
          0.3109475322290194,
          0.3105107950723598,
          0.3105107950723598,
          0.3105107950723598,
          0.3105107950723598,
          0.3105107950723598,
          0.3105107950723598,
          0.3105107950723598,
          0.3105107950723598,
          0.3105107950723598,
          0.3105107950723598,
          0.3105107950723598,
          0.3105107950723598,
          0.3105107950723598,
          0.3105107950723598,
          0.3105107950723598,
          0.3105107950723598,
          0.3105107950723598,
          0.3105107950723598,
          0.3105107950723598,
          0.3105107950723598,
          0.3105107950723598,
          0.3105107950723598,
          0.3105107950723598,
          0.3105107950723598,
          0.3105107950723598,
          0.3105107950723598,
          0.3105107950723598,
          0.3105107950723598,
          0.3105107950723598,
          0.3105107950723598,
          0.3105107950723598,
          0.3105107950723598,
          0.3105107950723598,
          0.3105107950723598,
          0.3105107950723598,
          0.3105107950723598,
          0.3105107950723598,
          0.3105107950723598,
          0.3105107950723598,
          0.3105107950723598,
          0.3105107950723598,
          0.3105107950723598,
          0.3105107950723598,
          0.3105107950723598,
          0.3105107950723598,
          0.3105107950723598,
          0.3105107950723598,
          0.3105107950723598,
          0.3105107950723598,
          0.3105107950723598,
          0.3105107950723598,
          0.3105107950723598,
          0.3105107950723598,
          0.3105107950723598,
          0.3105107950723598,
          0.3105107950723598,
          0.3105107950723598,
          0.3105107950723598,
          0.3105107950723598,
          0.3105107950723598,
          0.3105107950723598,
          0.3105107950723598,
          0.3105107950723598,
          0.3105107950723598,
          0.3105107950723598,
          0.3105107950723598,
          0.3105107950723598,
          0.3105107950723598,
          0.3105107950723598,
          0.3105107950723598,
          0.3105107950723598,
          0.3105107950723598,
          0.3105107950723598,
          0.3105107950723598,
          0.3105107950723598,
          0.3105107950723598,
          0.3105107950723598,
          0.3105107950723598,
          0.3105107950723598,
          0.3105107950723598,
          0.3105107950723598,
          0.3105107950723598,
          0.3105107950723598,
          0.3105107950723598,
          0.3105107950723598,
          0.3105107950723598,
          0.3105107950723598,
          0.3105107950723598,
          0.3105107950723598,
          0.3105107950723598,
          0.3105107950723598,
          0.3105107950723598,
          0.3105107950723598,
          0.3105107950723598,
          0.3105107950723598,
          0.3105107950723598,
          0.3105107950723598,
          0.3105107950723598,
          0.3105107950723598,
          0.3105107950723598,
          0.3140126884712822,
          0.3140126884712822,
          0.3140126884712822,
          0.3140126884712822,
          0.3140126884712822,
          0.3140126884712822,
          0.3140126884712822,
          0.3140126884712822,
          0.3140126884712822,
          0.3140126884712822,
          0.3140126884712822,
          0.3140126884712822,
          0.3140126884712822,
          0.3140126884712822,
          0.3140126884712822,
          0.3140126884712822,
          0.3140126884712822,
          0.3140126884712822,
          0.3140126884712822,
          0.3140126884712822,
          0.3140126884712822,
          0.3140126884712822,
          0.3140126884712822,
          0.3140126884712822,
          0.3140126884712822,
          0.3140126884712822,
          0.3140126884712822,
          0.3140126884712822,
          0.3140126884712822,
          0.3140126884712822,
          0.3140126884712822,
          0.3140126884712822,
          0.3140126884712822,
          0.3140126884712822,
          0.3140126884712822,
          0.3140126884712822,
          0.3140126884712822,
          0.3140126884712822,
          0.3140126884712822,
          0.3140126884712822,
          0.3140126884712822,
          0.3140126884712822,
          0.3140126884712822,
          0.3140126884712822,
          0.3140126884712822,
          0.3140126884712822,
          0.3140126884712822,
          0.3140126884712822,
          0.3140126884712822,
          0.3140126884712822,
          0.3140126884712822,
          0.3140126884712822,
          0.3140126884712822,
          0.3140126884712822,
          0.3140126884712822,
          0.3140126884712822,
          0.3140126884712822,
          0.3140126884712822,
          0.3140126884712822,
          0.3140126884712822,
          0.3140126884712822,
          0.3140126884712822,
          0.3140126884712822,
          0.3140126884712822,
          0.3140126884712822,
          0.3140126884712822,
          0.3140126884712822,
          0.3140126884712822,
          0.3140126884712822,
          0.3140126884712822,
          0.3140126884712822,
          0.3140126884712822,
          0.3140126884712822,
          0.3140126884712822,
          0.3140126884712822,
          0.3140126884712822,
          0.3140126884712822,
          0.3140126884712822,
          0.3140126884712822,
          0.3140126884712822,
          0.3140126884712822,
          0.3140126884712822,
          0.3140126884712822,
          0.3140126884712822,
          0.3140126884712822,
          0.3140126884712822,
          0.3140126884712822,
          0.3140126884712822,
          0.3140126884712822,
          0.3140126884712822,
          0.3140126884712822,
          0.3140126884712822,
          0.3140126884712822,
          0.3140126884712822,
          0.3140126884712822,
          0.3140126884712822,
          0.3140126884712822,
          0.3140126884712822,
          0.3140126884712822,
          0.3140126884712822,
          0.3165825681736331,
          0.3165825681736331,
          0.3165825681736331,
          0.3165825681736331,
          0.3165825681736331,
          0.3165825681736331,
          0.3165825681736331,
          0.3165825681736331,
          0.3165825681736331,
          0.3165825681736331,
          0.3165825681736331,
          0.3165825681736331,
          0.3165825681736331,
          0.3165825681736331,
          0.3165825681736331,
          0.3165825681736331,
          0.3165825681736331,
          0.3165825681736331,
          0.3165825681736331,
          0.3165825681736331,
          0.3165825681736331,
          0.3165825681736331,
          0.3165825681736331,
          0.3165825681736331,
          0.3165825681736331,
          0.3165825681736331,
          0.3165825681736331,
          0.3165825681736331,
          0.3165825681736331,
          0.3165825681736331,
          0.3165825681736331,
          0.3165825681736331,
          0.3165825681736331,
          0.3165825681736331,
          0.3165825681736331,
          0.3165825681736331,
          0.3165825681736331,
          0.3165825681736331,
          0.3165825681736331,
          0.3165825681736331,
          0.3165825681736331,
          0.3165825681736331,
          0.3165825681736331,
          0.3165825681736331,
          0.3165825681736331,
          0.3165825681736331,
          0.3165825681736331,
          0.3165825681736331,
          0.3165825681736331,
          0.3165825681736331,
          0.3165825681736331,
          0.3165825681736331,
          0.3165825681736331,
          0.3165825681736331,
          0.3165825681736331,
          0.3165825681736331,
          0.3165825681736331,
          0.3165825681736331,
          0.3165825681736331,
          0.3165825681736331,
          0.3165825681736331,
          0.3165825681736331,
          0.3165825681736331,
          0.3165825681736331,
          0.3165825681736331,
          0.3165825681736331,
          0.3165825681736331,
          0.3165825681736331,
          0.3165825681736331,
          0.3165825681736331,
          0.3165825681736331,
          0.3165825681736331,
          0.3165825681736331,
          0.3165825681736331,
          0.3165825681736331,
          0.3165825681736331,
          0.3165825681736331,
          0.3165825681736331,
          0.3165825681736331,
          0.3165825681736331,
          0.3165825681736331,
          0.3165825681736331,
          0.3165825681736331,
          0.3165825681736331,
          0.3165825681736331,
          0.3165825681736331,
          0.3165825681736331,
          0.3165825681736331,
          0.3165825681736331,
          0.3165825681736331,
          0.3165825681736331,
          0.3165825681736331,
          0.3165825681736331,
          0.3165825681736331,
          0.3165825681736331,
          0.3165825681736331,
          0.3165825681736331,
          0.3165825681736331,
          0.3165825681736331,
          0.3165825681736331,
          0.3180817809204307,
          0.3180817809204307,
          0.3180817809204307,
          0.3180817809204307,
          0.3180817809204307,
          0.3180817809204307,
          0.3180817809204307,
          0.3180817809204307,
          0.3180817809204307,
          0.3180817809204307,
          0.3180817809204307,
          0.3180817809204307,
          0.3180817809204307,
          0.3180817809204307,
          0.3180817809204307,
          0.3180817809204307,
          0.3180817809204307,
          0.3180817809204307,
          0.3180817809204307,
          0.3180817809204307,
          0.3180817809204307,
          0.3180817809204307,
          0.3180817809204307,
          0.3180817809204307,
          0.3180817809204307,
          0.3180817809204307,
          0.3180817809204307,
          0.3180817809204307,
          0.3180817809204307,
          0.3180817809204307,
          0.3180817809204307,
          0.3180817809204307,
          0.3180817809204307,
          0.3180817809204307,
          0.3180817809204307,
          0.3180817809204307,
          0.3180817809204307,
          0.3180817809204307,
          0.3180817809204307,
          0.3180817809204307,
          0.3180817809204307,
          0.3180817809204307,
          0.3180817809204307,
          0.3180817809204307,
          0.3180817809204307,
          0.3180817809204307,
          0.3180817809204307,
          0.3180817809204307,
          0.3180817809204307,
          0.3180817809204307,
          0.3180817809204307,
          0.3180817809204307,
          0.3180817809204307,
          0.3180817809204307,
          0.3180817809204307,
          0.3180817809204307,
          0.3180817809204307,
          0.3180817809204307,
          0.3180817809204307,
          0.3180817809204307,
          0.3180817809204307,
          0.3180817809204307,
          0.3180817809204307,
          0.3180817809204307,
          0.3180817809204307,
          0.3180817809204307,
          0.3180817809204307,
          0.3180817809204307,
          0.3180817809204307,
          0.3180817809204307,
          0.3180817809204307,
          0.3180817809204307,
          0.3180817809204307,
          0.3180817809204307,
          0.3180817809204307,
          0.3180817809204307,
          0.3180817809204307,
          0.3180817809204307,
          0.3180817809204307,
          0.3180817809204307,
          0.3180817809204307,
          0.3180817809204307,
          0.3180817809204307,
          0.3180817809204307,
          0.3180817809204307,
          0.3180817809204307,
          0.3180817809204307,
          0.3180817809204307,
          0.3180817809204307,
          0.3180817809204307,
          0.3180817809204307,
          0.3180817809204307,
          0.3180817809204307,
          0.3180817809204307,
          0.3180817809204307,
          0.3180817809204307,
          0.3180817809204307,
          0.3180817809204307,
          0.3180817809204307,
          0.3180817809204307,
          0.31696801337124464,
          0.31696801337124464,
          0.31696801337124464,
          0.31696801337124464,
          0.31696801337124464,
          0.31696801337124464,
          0.31696801337124464,
          0.31696801337124464,
          0.31696801337124464,
          0.31696801337124464,
          0.31696801337124464,
          0.31696801337124464,
          0.31696801337124464,
          0.31696801337124464,
          0.31696801337124464,
          0.31696801337124464,
          0.31696801337124464,
          0.31696801337124464,
          0.31696801337124464,
          0.31696801337124464,
          0.31696801337124464,
          0.31696801337124464,
          0.31696801337124464,
          0.31696801337124464,
          0.31696801337124464,
          0.31696801337124464,
          0.31696801337124464,
          0.31696801337124464,
          0.31696801337124464,
          0.31696801337124464,
          0.31696801337124464,
          0.31696801337124464,
          0.31696801337124464,
          0.31696801337124464,
          0.31696801337124464,
          0.31696801337124464,
          0.31696801337124464,
          0.31696801337124464,
          0.31696801337124464,
          0.31696801337124464,
          0.31696801337124464,
          0.31696801337124464,
          0.31696801337124464,
          0.31696801337124464,
          0.31696801337124464,
          0.31696801337124464,
          0.31696801337124464,
          0.31696801337124464,
          0.31696801337124464,
          0.31696801337124464,
          0.31696801337124464,
          0.31696801337124464,
          0.31696801337124464,
          0.31696801337124464,
          0.31696801337124464,
          0.31696801337124464,
          0.31696801337124464,
          0.31696801337124464,
          0.31696801337124464,
          0.31696801337124464,
          0.31696801337124464,
          0.31696801337124464,
          0.31696801337124464,
          0.31696801337124464,
          0.31696801337124464,
          0.31696801337124464,
          0.31696801337124464,
          0.31696801337124464,
          0.31696801337124464,
          0.31696801337124464,
          0.31696801337124464,
          0.31696801337124464,
          0.31696801337124464,
          0.31696801337124464,
          0.31696801337124464,
          0.31696801337124464,
          0.31696801337124464,
          0.31696801337124464,
          0.31696801337124464,
          0.31696801337124464,
          0.31696801337124464,
          0.31696801337124464,
          0.31696801337124464,
          0.31696801337124464,
          0.31696801337124464,
          0.31696801337124464,
          0.31696801337124464,
          0.31696801337124464,
          0.31696801337124464,
          0.31696801337124464,
          0.31696801337124464,
          0.31696801337124464,
          0.31696801337124464,
          0.31696801337124464,
          0.31696801337124464,
          0.31696801337124464,
          0.31696801337124464,
          0.31696801337124464,
          0.31696801337124464,
          0.31696801337124464,
          0.3210769454669353,
          0.3210769454669353,
          0.3210769454669353,
          0.3210769454669353,
          0.3210769454669353,
          0.3210769454669353,
          0.3210769454669353,
          0.3210769454669353,
          0.3210769454669353,
          0.3210769454669353,
          0.3210769454669353,
          0.3210769454669353,
          0.3210769454669353,
          0.3210769454669353,
          0.3210769454669353,
          0.3210769454669353,
          0.3210769454669353,
          0.3210769454669353,
          0.3210769454669353,
          0.3210769454669353,
          0.3210769454669353,
          0.3210769454669353,
          0.3210769454669353,
          0.3210769454669353,
          0.3210769454669353,
          0.3210769454669353,
          0.3210769454669353,
          0.3210769454669353,
          0.3210769454669353,
          0.3210769454669353,
          0.3210769454669353,
          0.3210769454669353,
          0.3210769454669353,
          0.3210769454669353,
          0.3210769454669353,
          0.3210769454669353,
          0.3210769454669353,
          0.3210769454669353,
          0.3210769454669353,
          0.3210769454669353,
          0.3210769454669353,
          0.3210769454669353,
          0.3210769454669353,
          0.3210769454669353,
          0.3210769454669353,
          0.3210769454669353,
          0.3210769454669353,
          0.3210769454669353,
          0.3210769454669353,
          0.3210769454669353,
          0.3210769454669353,
          0.3210769454669353,
          0.3210769454669353,
          0.3210769454669353,
          0.3210769454669353,
          0.3210769454669353,
          0.3210769454669353,
          0.3210769454669353,
          0.3210769454669353,
          0.3210769454669353,
          0.3210769454669353,
          0.3210769454669353,
          0.3210769454669353,
          0.3210769454669353,
          0.3210769454669353,
          0.3210769454669353,
          0.3210769454669353,
          0.3210769454669353,
          0.3210769454669353,
          0.3210769454669353,
          0.3210769454669353,
          0.3210769454669353,
          0.3210769454669353,
          0.3210769454669353,
          0.3210769454669353,
          0.3210769454669353,
          0.3210769454669353,
          0.3210769454669353,
          0.3210769454669353,
          0.3210769454669353,
          0.3210769454669353,
          0.3210769454669353,
          0.3210769454669353,
          0.3210769454669353,
          0.3210769454669353,
          0.3210769454669353,
          0.3210769454669353,
          0.3210769454669353,
          0.3210769454669353,
          0.3210769454669353,
          0.3210769454669353,
          0.3210769454669353,
          0.3210769454669353,
          0.3210769454669353,
          0.3210769454669353,
          0.3210769454669353,
          0.3210769454669353,
          0.3210769454669353,
          0.3210769454669353,
          0.3210769454669353,
          0.32455743800271236,
          0.32455743800271236,
          0.32455743800271236,
          0.32455743800271236,
          0.32455743800271236,
          0.32455743800271236,
          0.32455743800271236,
          0.32455743800271236,
          0.32455743800271236,
          0.32455743800271236,
          0.32455743800271236,
          0.32455743800271236,
          0.32455743800271236,
          0.32455743800271236,
          0.32455743800271236,
          0.32455743800271236,
          0.32455743800271236,
          0.32455743800271236,
          0.32455743800271236,
          0.32455743800271236,
          0.32455743800271236,
          0.32455743800271236,
          0.32455743800271236,
          0.32455743800271236,
          0.32455743800271236,
          0.32455743800271236,
          0.32455743800271236,
          0.32455743800271236,
          0.32455743800271236,
          0.32455743800271236,
          0.32455743800271236,
          0.32455743800271236,
          0.32455743800271236,
          0.32455743800271236,
          0.32455743800271236,
          0.32455743800271236,
          0.32455743800271236,
          0.32455743800271236,
          0.32455743800271236,
          0.32455743800271236,
          0.32455743800271236,
          0.32455743800271236,
          0.32455743800271236,
          0.32455743800271236,
          0.32455743800271236,
          0.32455743800271236,
          0.32455743800271236,
          0.32455743800271236,
          0.32455743800271236,
          0.32455743800271236,
          0.32455743800271236,
          0.32455743800271236,
          0.32455743800271236,
          0.32455743800271236,
          0.32455743800271236,
          0.32455743800271236,
          0.32455743800271236,
          0.32455743800271236,
          0.32455743800271236,
          0.32455743800271236,
          0.32455743800271236,
          0.32455743800271236,
          0.32455743800271236,
          0.32455743800271236,
          0.32455743800271236,
          0.32455743800271236,
          0.32455743800271236,
          0.32455743800271236,
          0.32455743800271236,
          0.32455743800271236,
          0.32455743800271236,
          0.32455743800271236,
          0.32455743800271236,
          0.32455743800271236,
          0.32455743800271236,
          0.32455743800271236,
          0.32455743800271236,
          0.32455743800271236,
          0.32455743800271236,
          0.32455743800271236,
          0.32455743800271236,
          0.32455743800271236,
          0.32455743800271236,
          0.32455743800271236,
          0.32455743800271236,
          0.32455743800271236,
          0.32455743800271236,
          0.32455743800271236,
          0.32455743800271236,
          0.32455743800271236,
          0.32455743800271236,
          0.32455743800271236,
          0.32455743800271236,
          0.32455743800271236,
          0.32455743800271236,
          0.32455743800271236,
          0.32455743800271236,
          0.32455743800271236,
          0.32455743800271236,
          0.32455743800271236,
          0.3296116043684269,
          0.3296116043684269,
          0.3296116043684269,
          0.3296116043684269,
          0.3296116043684269,
          0.3296116043684269,
          0.3296116043684269,
          0.3296116043684269,
          0.3296116043684269,
          0.3296116043684269,
          0.3296116043684269,
          0.3296116043684269,
          0.3296116043684269,
          0.3296116043684269,
          0.3296116043684269,
          0.3296116043684269,
          0.3296116043684269,
          0.3296116043684269,
          0.3296116043684269,
          0.3296116043684269,
          0.3296116043684269,
          0.3296116043684269,
          0.3296116043684269,
          0.3296116043684269,
          0.3296116043684269,
          0.3296116043684269,
          0.3296116043684269,
          0.3296116043684269,
          0.3296116043684269,
          0.3296116043684269,
          0.3296116043684269,
          0.3296116043684269,
          0.3296116043684269,
          0.3296116043684269,
          0.3296116043684269,
          0.3296116043684269,
          0.3296116043684269,
          0.3296116043684269,
          0.3296116043684269,
          0.3296116043684269,
          0.3296116043684269,
          0.3296116043684269,
          0.3296116043684269,
          0.3296116043684269,
          0.3296116043684269,
          0.3296116043684269,
          0.3296116043684269,
          0.3296116043684269,
          0.3296116043684269,
          0.3296116043684269,
          0.3296116043684269,
          0.3296116043684269,
          0.3296116043684269,
          0.3296116043684269,
          0.3296116043684269,
          0.3296116043684269,
          0.3296116043684269,
          0.3296116043684269,
          0.3296116043684269,
          0.3296116043684269,
          0.3296116043684269,
          0.3296116043684269,
          0.3296116043684269,
          0.3296116043684269,
          0.3296116043684269,
          0.3296116043684269,
          0.3296116043684269,
          0.3296116043684269,
          0.3296116043684269,
          0.3296116043684269,
          0.3296116043684269,
          0.3296116043684269,
          0.3296116043684269,
          0.3296116043684269,
          0.3296116043684269,
          0.3296116043684269,
          0.3296116043684269,
          0.3296116043684269,
          0.3296116043684269,
          0.3296116043684269,
          0.3296116043684269,
          0.3296116043684269,
          0.3296116043684269,
          0.3296116043684269,
          0.3296116043684269,
          0.3296116043684269,
          0.3296116043684269,
          0.3296116043684269,
          0.3296116043684269,
          0.3296116043684269,
          0.3296116043684269,
          0.3296116043684269,
          0.3296116043684269,
          0.3296116043684269,
          0.3296116043684269,
          0.3296116043684269,
          0.3296116043684269,
          0.3296116043684269,
          0.3296116043684269,
          0.3296116043684269,
          0.3292791443450242,
          0.3292791443450242,
          0.3292791443450242,
          0.3292791443450242,
          0.3292791443450242,
          0.3292791443450242,
          0.3292791443450242,
          0.3292791443450242,
          0.3292791443450242,
          0.3292791443450242,
          0.3292791443450242,
          0.3292791443450242,
          0.3292791443450242,
          0.3292791443450242,
          0.3292791443450242,
          0.3292791443450242,
          0.3292791443450242,
          0.3292791443450242,
          0.3292791443450242,
          0.3292791443450242,
          0.3292791443450242,
          0.3292791443450242,
          0.3292791443450242,
          0.3292791443450242,
          0.3292791443450242,
          0.3292791443450242,
          0.3292791443450242,
          0.3292791443450242,
          0.3292791443450242,
          0.3292791443450242,
          0.3292791443450242,
          0.3292791443450242,
          0.3292791443450242,
          0.3292791443450242,
          0.3292791443450242,
          0.3292791443450242,
          0.3292791443450242,
          0.3292791443450242,
          0.3292791443450242,
          0.3292791443450242,
          0.3292791443450242,
          0.3292791443450242,
          0.3292791443450242,
          0.3292791443450242,
          0.3292791443450242,
          0.3292791443450242,
          0.3292791443450242,
          0.3292791443450242,
          0.3292791443450242,
          0.3292791443450242,
          0.3292791443450242,
          0.3292791443450242,
          0.3292791443450242,
          0.3292791443450242,
          0.3292791443450242,
          0.3292791443450242,
          0.3292791443450242,
          0.3292791443450242,
          0.3292791443450242,
          0.3292791443450242,
          0.3292791443450242,
          0.3292791443450242,
          0.3292791443450242,
          0.3292791443450242,
          0.3292791443450242,
          0.3292791443450242,
          0.3292791443450242,
          0.3292791443450242,
          0.3292791443450242,
          0.3292791443450242,
          0.3292791443450242,
          0.3292791443450242,
          0.3292791443450242,
          0.3292791443450242,
          0.3292791443450242,
          0.3292791443450242,
          0.3292791443450242,
          0.3292791443450242,
          0.3292791443450242,
          0.3292791443450242,
          0.3292791443450242,
          0.3292791443450242,
          0.3292791443450242,
          0.3292791443450242,
          0.3292791443450242,
          0.3292791443450242,
          0.3292791443450242,
          0.3292791443450242,
          0.3292791443450242,
          0.3292791443450242,
          0.3292791443450242,
          0.3292791443450242,
          0.3292791443450242,
          0.3292791443450242,
          0.3292791443450242,
          0.3292791443450242,
          0.3292791443450242,
          0.3292791443450242,
          0.3292791443450242,
          0.3292791443450242,
          0.3260905738993216,
          0.3260905738993216,
          0.3260905738993216,
          0.3260905738993216,
          0.3260905738993216,
          0.3260905738993216,
          0.3260905738993216,
          0.3260905738993216,
          0.3260905738993216,
          0.3260905738993216,
          0.3260905738993216,
          0.3260905738993216,
          0.3260905738993216,
          0.3260905738993216,
          0.3260905738993216,
          0.3260905738993216,
          0.3260905738993216,
          0.3260905738993216,
          0.3260905738993216,
          0.3260905738993216,
          0.3260905738993216,
          0.3260905738993216,
          0.3260905738993216,
          0.3260905738993216,
          0.3260905738993216,
          0.3260905738993216,
          0.3260905738993216,
          0.3260905738993216,
          0.3260905738993216,
          0.3260905738993216,
          0.3260905738993216,
          0.3260905738993216,
          0.3260905738993216,
          0.3260905738993216,
          0.3260905738993216,
          0.3260905738993216,
          0.3260905738993216,
          0.3260905738993216,
          0.3260905738993216,
          0.3260905738993216,
          0.3260905738993216,
          0.3260905738993216,
          0.3260905738993216,
          0.3260905738993216,
          0.3260905738993216,
          0.3260905738993216,
          0.3260905738993216,
          0.3260905738993216,
          0.3260905738993216,
          0.3260905738993216,
          0.3260905738993216,
          0.3260905738993216,
          0.3260905738993216,
          0.3260905738993216,
          0.3260905738993216,
          0.3260905738993216,
          0.3260905738993216,
          0.3260905738993216,
          0.3260905738993216,
          0.3260905738993216,
          0.3260905738993216,
          0.3260905738993216,
          0.3260905738993216,
          0.3260905738993216,
          0.3260905738993216,
          0.3260905738993216,
          0.3260905738993216,
          0.3260905738993216,
          0.3260905738993216,
          0.3260905738993216,
          0.3260905738993216,
          0.3260905738993216,
          0.3260905738993216,
          0.3260905738993216,
          0.3260905738993216,
          0.3260905738993216,
          0.3260905738993216,
          0.3260905738993216,
          0.3260905738993216,
          0.3260905738993216,
          0.3260905738993216,
          0.3260905738993216,
          0.3260905738993216,
          0.3260905738993216,
          0.3260905738993216,
          0.3260905738993216,
          0.3260905738993216,
          0.3260905738993216,
          0.3260905738993216,
          0.3260905738993216,
          0.3260905738993216,
          0.3260905738993216,
          0.3260905738993216,
          0.3260905738993216,
          0.3260905738993216,
          0.3260905738993216,
          0.3260905738993216,
          0.3260905738993216,
          0.3260905738993216,
          0.3260905738993216,
          0.3297554861235345,
          0.3297554861235345,
          0.3297554861235345,
          0.3297554861235345,
          0.3297554861235345,
          0.3297554861235345,
          0.3297554861235345,
          0.3297554861235345,
          0.3297554861235345,
          0.3297554861235345,
          0.3297554861235345,
          0.3297554861235345,
          0.3297554861235345,
          0.3297554861235345,
          0.3297554861235345,
          0.3297554861235345,
          0.3297554861235345,
          0.3297554861235345,
          0.3297554861235345,
          0.3297554861235345,
          0.3297554861235345,
          0.3297554861235345,
          0.3297554861235345,
          0.3297554861235345,
          0.3297554861235345,
          0.3297554861235345,
          0.3297554861235345,
          0.3297554861235345,
          0.3297554861235345,
          0.3297554861235345,
          0.3297554861235345,
          0.3297554861235345,
          0.3297554861235345,
          0.3297554861235345,
          0.3297554861235345,
          0.3297554861235345,
          0.3297554861235345,
          0.3297554861235345,
          0.3297554861235345,
          0.3297554861235345,
          0.3297554861235345,
          0.3297554861235345,
          0.3297554861235345,
          0.3297554861235345,
          0.3297554861235345,
          0.3297554861235345,
          0.3297554861235345,
          0.3297554861235345,
          0.3297554861235345,
          0.3297554861235345,
          0.3297554861235345,
          0.3297554861235345,
          0.3297554861235345,
          0.3297554861235345,
          0.3297554861235345,
          0.3297554861235345,
          0.3297554861235345,
          0.3297554861235345,
          0.3297554861235345,
          0.3297554861235345,
          0.3297554861235345,
          0.3297554861235345,
          0.3297554861235345,
          0.3297554861235345,
          0.3297554861235345,
          0.3297554861235345,
          0.3297554861235345,
          0.3297554861235345,
          0.3297554861235345,
          0.3297554861235345,
          0.3297554861235345,
          0.3297554861235345,
          0.3297554861235345,
          0.3297554861235345,
          0.3297554861235345,
          0.3297554861235345,
          0.3297554861235345,
          0.3297554861235345,
          0.3297554861235345,
          0.3297554861235345,
          0.3297554861235345,
          0.3297554861235345,
          0.3297554861235345,
          0.3297554861235345,
          0.3297554861235345,
          0.3297554861235345,
          0.3297554861235345,
          0.3297554861235345,
          0.3297554861235345,
          0.3297554861235345,
          0.3297554861235345,
          0.3297554861235345,
          0.3297554861235345,
          0.3297554861235345,
          0.3297554861235345,
          0.3297554861235345,
          0.3297554861235345,
          0.3297554861235345,
          0.3297554861235345,
          0.3297554861235345
         ]
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Training and Test Loss"
        },
        "xaxis": {
         "title": {
          "text": "Epoch"
         }
        },
        "yaxis": {
         "title": {
          "text": "BCEWithLogitsLoss"
         }
        }
       }
      },
      "text/html": [
       "<div>                            <div id=\"66e5a385-9fad-46c4-9e97-776b6896bc92\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"66e5a385-9fad-46c4-9e97-776b6896bc92\")) {                    Plotly.newPlot(                        \"66e5a385-9fad-46c4-9e97-776b6896bc92\",                        [{\"mode\":\"lines\",\"name\":\"Train Loss\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500,501,502,503,504,505,506,507,508,509,510,511,512,513,514,515,516,517,518,519,520,521,522,523,524,525,526,527,528,529,530,531,532,533,534,535,536,537,538,539,540,541,542,543,544,545,546,547,548,549,550,551,552,553,554,555,556,557,558,559,560,561,562,563,564,565,566,567,568,569,570,571,572,573,574,575,576,577,578,579,580,581,582,583,584,585,586,587,588,589,590,591,592,593,594,595,596,597,598,599,600,601,602,603,604,605,606,607,608,609,610,611,612,613,614,615,616,617,618,619,620,621,622,623,624,625,626,627,628,629,630,631,632,633,634,635,636,637,638,639,640,641,642,643,644,645,646,647,648,649,650,651,652,653,654,655,656,657,658,659,660,661,662,663,664,665,666,667,668,669,670,671,672,673,674,675,676,677,678,679,680,681,682,683,684,685,686,687,688,689,690,691,692,693,694,695,696,697,698,699,700,701,702,703,704,705,706,707,708,709,710,711,712,713,714,715,716,717,718,719,720,721,722,723,724,725,726,727,728,729,730,731,732,733,734,735,736,737,738,739,740,741,742,743,744,745,746,747,748,749,750,751,752,753,754,755,756,757,758,759,760,761,762,763,764,765,766,767,768,769,770,771,772,773,774,775,776,777,778,779,780,781,782,783,784,785,786,787,788,789,790,791,792,793,794,795,796,797,798,799,800,801,802,803,804,805,806,807,808,809,810,811,812,813,814,815,816,817,818,819,820,821,822,823,824,825,826,827,828,829,830,831,832,833,834,835,836,837,838,839,840,841,842,843,844,845,846,847,848,849,850,851,852,853,854,855,856,857,858,859,860,861,862,863,864,865,866,867,868,869,870,871,872,873,874,875,876,877,878,879,880,881,882,883,884,885,886,887,888,889,890,891,892,893,894,895,896,897,898,899,900,901,902,903,904,905,906,907,908,909,910,911,912,913,914,915,916,917,918,919,920,921,922,923,924,925,926,927,928,929,930,931,932,933,934,935,936,937,938,939,940,941,942,943,944,945,946,947,948,949,950,951,952,953,954,955,956,957,958,959,960,961,962,963,964,965,966,967,968,969,970,971,972,973,974,975,976,977,978,979,980,981,982,983,984,985,986,987,988,989,990,991,992,993,994,995,996,997,998,999,1000,1001,1002,1003,1004,1005,1006,1007,1008,1009,1010,1011,1012,1013,1014,1015,1016,1017,1018,1019,1020,1021,1022,1023,1024,1025,1026,1027,1028,1029,1030,1031,1032,1033,1034,1035,1036,1037,1038,1039,1040,1041,1042,1043,1044,1045,1046,1047,1048,1049,1050,1051,1052,1053,1054,1055,1056,1057,1058,1059,1060,1061,1062,1063,1064,1065,1066,1067,1068,1069,1070,1071,1072,1073,1074,1075,1076,1077,1078,1079,1080,1081,1082,1083,1084,1085,1086,1087,1088,1089,1090,1091,1092,1093,1094,1095,1096,1097,1098,1099,1100,1101,1102,1103,1104,1105,1106,1107,1108,1109,1110,1111,1112,1113,1114,1115,1116,1117,1118,1119,1120,1121,1122,1123,1124,1125,1126,1127,1128,1129,1130,1131,1132,1133,1134,1135,1136,1137,1138,1139,1140,1141,1142,1143,1144,1145,1146,1147,1148,1149,1150,1151,1152,1153,1154,1155,1156,1157,1158,1159,1160,1161,1162,1163,1164,1165,1166,1167,1168,1169,1170,1171,1172,1173,1174,1175,1176,1177,1178,1179,1180,1181,1182,1183,1184,1185,1186,1187,1188,1189,1190,1191,1192,1193,1194,1195,1196,1197,1198,1199,1200,1201,1202,1203,1204,1205,1206,1207,1208,1209,1210,1211,1212,1213,1214,1215,1216,1217,1218,1219,1220,1221,1222,1223,1224,1225,1226,1227,1228,1229,1230,1231,1232,1233,1234,1235,1236,1237,1238,1239,1240,1241,1242,1243,1244,1245,1246,1247,1248,1249,1250,1251,1252,1253,1254,1255,1256,1257,1258,1259,1260,1261,1262,1263,1264,1265,1266,1267,1268,1269,1270,1271,1272,1273,1274,1275,1276,1277,1278,1279,1280,1281,1282,1283,1284,1285,1286,1287,1288,1289,1290,1291,1292,1293,1294,1295,1296,1297,1298,1299,1300,1301,1302,1303,1304,1305,1306,1307,1308,1309,1310,1311,1312,1313,1314,1315,1316,1317,1318,1319,1320,1321,1322,1323,1324,1325,1326,1327,1328,1329,1330,1331,1332,1333,1334,1335,1336,1337,1338,1339,1340,1341,1342,1343,1344,1345,1346,1347,1348,1349,1350,1351,1352,1353,1354,1355,1356,1357,1358,1359,1360,1361,1362,1363,1364,1365,1366,1367,1368,1369,1370,1371,1372,1373,1374,1375,1376,1377,1378,1379,1380,1381,1382,1383,1384,1385,1386,1387,1388,1389,1390,1391,1392,1393,1394,1395,1396,1397,1398,1399,1400,1401,1402,1403,1404,1405,1406,1407,1408,1409,1410,1411,1412,1413,1414,1415,1416,1417,1418,1419,1420,1421,1422,1423,1424,1425,1426,1427,1428,1429,1430,1431,1432,1433,1434,1435,1436,1437,1438,1439,1440,1441,1442,1443,1444,1445,1446,1447,1448,1449,1450,1451,1452,1453,1454,1455,1456,1457,1458,1459,1460,1461,1462,1463,1464,1465,1466,1467,1468,1469,1470,1471,1472,1473,1474,1475,1476,1477,1478,1479,1480,1481,1482,1483,1484,1485,1486,1487,1488,1489,1490,1491,1492,1493,1494,1495,1496,1497,1498,1499,1500,1501,1502,1503,1504,1505,1506,1507,1508,1509,1510,1511,1512,1513,1514,1515,1516,1517,1518,1519,1520,1521,1522,1523,1524,1525,1526,1527,1528,1529,1530,1531,1532,1533,1534,1535,1536,1537,1538,1539,1540,1541,1542,1543,1544,1545,1546,1547,1548,1549,1550,1551,1552,1553,1554,1555,1556,1557,1558,1559,1560,1561,1562,1563,1564,1565,1566,1567,1568,1569,1570,1571,1572,1573,1574,1575,1576,1577,1578,1579,1580,1581,1582,1583,1584,1585,1586,1587,1588,1589,1590,1591,1592,1593,1594,1595,1596,1597,1598,1599,1600,1601,1602,1603,1604,1605,1606,1607,1608,1609,1610,1611,1612,1613,1614,1615,1616,1617,1618,1619,1620,1621,1622,1623,1624,1625,1626,1627,1628,1629,1630,1631,1632,1633,1634,1635,1636,1637,1638,1639,1640,1641,1642,1643,1644,1645,1646,1647,1648,1649,1650,1651,1652,1653,1654,1655,1656,1657,1658,1659,1660,1661,1662,1663,1664,1665,1666,1667,1668,1669,1670,1671,1672,1673,1674,1675,1676,1677,1678,1679,1680,1681,1682,1683,1684,1685,1686,1687,1688,1689,1690,1691,1692,1693,1694,1695,1696,1697,1698,1699,1700,1701,1702,1703,1704,1705,1706,1707,1708,1709,1710,1711,1712,1713,1714,1715,1716,1717,1718,1719,1720,1721,1722,1723,1724,1725,1726,1727,1728,1729,1730,1731,1732,1733,1734,1735,1736,1737,1738,1739,1740,1741,1742,1743,1744,1745,1746,1747,1748,1749,1750,1751,1752,1753,1754,1755,1756,1757,1758,1759,1760,1761,1762,1763,1764,1765,1766,1767,1768,1769,1770,1771,1772,1773,1774,1775,1776,1777,1778,1779,1780,1781,1782,1783,1784,1785,1786,1787,1788,1789,1790,1791,1792,1793,1794,1795,1796,1797,1798,1799,1800,1801,1802,1803,1804,1805,1806,1807,1808,1809,1810,1811,1812,1813,1814,1815,1816,1817,1818,1819,1820,1821,1822,1823,1824,1825,1826,1827,1828,1829,1830,1831,1832,1833,1834,1835,1836,1837,1838,1839,1840,1841,1842,1843,1844,1845,1846,1847,1848,1849,1850,1851,1852,1853,1854,1855,1856,1857,1858,1859,1860,1861,1862,1863,1864,1865,1866,1867,1868,1869,1870,1871,1872,1873,1874,1875,1876,1877,1878,1879,1880,1881,1882,1883,1884,1885,1886,1887,1888,1889,1890,1891,1892,1893,1894,1895,1896,1897,1898,1899,1900,1901,1902,1903,1904,1905,1906,1907,1908,1909,1910,1911,1912,1913,1914,1915,1916,1917,1918,1919,1920,1921,1922,1923,1924,1925,1926,1927,1928,1929,1930,1931,1932,1933,1934,1935,1936,1937,1938,1939,1940,1941,1942,1943,1944,1945,1946,1947,1948,1949,1950,1951,1952,1953,1954,1955,1956,1957,1958,1959,1960,1961,1962,1963,1964,1965,1966,1967,1968,1969,1970,1971,1972,1973,1974,1975,1976,1977,1978,1979,1980,1981,1982,1983,1984,1985,1986,1987,1988,1989,1990,1991,1992,1993,1994,1995,1996,1997,1998,1999,2000,2001,2002,2003,2004,2005,2006,2007,2008,2009,2010,2011,2012,2013,2014,2015,2016,2017,2018,2019,2020,2021,2022,2023,2024,2025,2026,2027,2028,2029,2030,2031,2032,2033,2034,2035,2036,2037,2038,2039,2040,2041,2042,2043,2044,2045,2046,2047,2048,2049,2050,2051,2052,2053,2054,2055,2056,2057,2058,2059,2060,2061,2062,2063,2064,2065,2066,2067,2068,2069,2070,2071,2072,2073,2074,2075,2076,2077,2078,2079,2080,2081,2082,2083,2084,2085,2086,2087,2088,2089,2090,2091,2092,2093,2094,2095,2096,2097,2098,2099,2100,2101,2102,2103,2104,2105,2106,2107,2108,2109,2110,2111,2112,2113,2114,2115,2116,2117,2118,2119,2120,2121,2122,2123,2124,2125,2126,2127,2128,2129,2130,2131,2132,2133,2134,2135,2136,2137,2138,2139,2140,2141,2142,2143,2144,2145,2146,2147,2148,2149,2150,2151,2152,2153,2154,2155,2156,2157,2158,2159,2160,2161,2162,2163,2164,2165,2166,2167,2168,2169,2170,2171,2172,2173,2174,2175,2176,2177,2178,2179,2180,2181,2182,2183,2184,2185,2186,2187,2188,2189,2190,2191,2192,2193,2194,2195,2196,2197,2198,2199,2200,2201,2202,2203,2204,2205,2206,2207,2208,2209,2210,2211,2212,2213,2214,2215,2216,2217,2218,2219,2220,2221,2222,2223,2224,2225,2226,2227,2228,2229,2230,2231,2232,2233,2234,2235,2236,2237,2238,2239,2240,2241,2242,2243,2244,2245,2246,2247,2248,2249,2250,2251,2252,2253,2254,2255,2256,2257,2258,2259,2260,2261,2262,2263,2264,2265,2266,2267,2268,2269,2270,2271,2272,2273,2274,2275,2276,2277,2278,2279,2280,2281,2282,2283,2284,2285,2286,2287,2288,2289,2290,2291,2292,2293,2294,2295,2296,2297,2298,2299,2300,2301,2302,2303,2304,2305,2306,2307,2308,2309,2310,2311,2312,2313,2314,2315,2316,2317,2318,2319,2320,2321,2322,2323,2324,2325,2326,2327,2328,2329,2330,2331,2332,2333,2334,2335,2336,2337,2338,2339,2340,2341,2342,2343,2344,2345,2346,2347,2348,2349,2350,2351,2352,2353,2354,2355,2356,2357,2358,2359,2360,2361,2362,2363,2364,2365,2366,2367,2368,2369,2370,2371,2372,2373,2374,2375,2376,2377,2378,2379,2380,2381,2382,2383,2384,2385,2386,2387,2388,2389,2390,2391,2392,2393,2394,2395,2396,2397,2398,2399,2400,2401,2402,2403,2404,2405,2406,2407,2408,2409,2410,2411,2412,2413,2414,2415,2416,2417,2418,2419,2420,2421,2422,2423,2424,2425,2426,2427,2428,2429,2430,2431,2432,2433,2434,2435,2436,2437,2438,2439,2440,2441,2442,2443,2444,2445,2446,2447,2448,2449,2450,2451,2452,2453,2454,2455,2456,2457,2458,2459,2460,2461,2462,2463,2464,2465,2466,2467,2468,2469,2470,2471,2472,2473,2474,2475,2476,2477,2478,2479,2480,2481,2482,2483,2484,2485,2486,2487,2488,2489,2490,2491,2492,2493,2494,2495,2496,2497,2498,2499,2500,2501,2502,2503,2504,2505,2506,2507,2508,2509,2510,2511,2512,2513,2514,2515,2516,2517,2518,2519,2520,2521,2522,2523,2524,2525,2526,2527,2528,2529,2530,2531,2532,2533,2534,2535,2536,2537,2538,2539,2540,2541,2542,2543,2544,2545,2546,2547,2548,2549,2550,2551,2552,2553,2554,2555,2556,2557,2558,2559,2560,2561,2562,2563,2564,2565,2566,2567,2568,2569,2570,2571,2572,2573,2574,2575,2576,2577,2578,2579,2580,2581,2582,2583,2584,2585,2586,2587,2588,2589,2590,2591,2592,2593,2594,2595,2596,2597,2598,2599,2600,2601,2602,2603,2604,2605,2606,2607,2608,2609,2610,2611,2612,2613,2614,2615,2616,2617,2618,2619,2620,2621,2622,2623,2624,2625,2626,2627,2628,2629,2630,2631,2632,2633,2634,2635,2636,2637,2638,2639,2640,2641,2642,2643,2644,2645,2646,2647,2648,2649,2650,2651,2652,2653,2654,2655,2656,2657,2658,2659,2660,2661,2662,2663,2664,2665,2666,2667,2668,2669,2670,2671,2672,2673,2674,2675,2676,2677,2678,2679,2680,2681,2682,2683,2684,2685,2686,2687,2688,2689,2690,2691,2692,2693,2694,2695,2696,2697,2698,2699,2700,2701,2702,2703,2704,2705,2706,2707,2708,2709,2710,2711,2712,2713,2714,2715,2716,2717,2718,2719,2720,2721,2722,2723,2724,2725,2726,2727,2728,2729,2730,2731,2732,2733,2734,2735,2736,2737,2738,2739,2740,2741,2742,2743,2744,2745,2746,2747,2748,2749,2750,2751,2752,2753,2754,2755,2756,2757,2758,2759,2760,2761,2762,2763,2764,2765,2766,2767,2768,2769,2770,2771,2772,2773,2774,2775,2776,2777,2778,2779,2780,2781,2782,2783,2784,2785,2786,2787,2788,2789,2790,2791,2792,2793,2794,2795,2796,2797,2798,2799,2800,2801,2802,2803,2804,2805,2806,2807,2808,2809,2810,2811,2812,2813,2814,2815,2816,2817,2818,2819,2820,2821,2822,2823,2824,2825,2826,2827,2828,2829,2830,2831,2832,2833,2834,2835,2836,2837,2838,2839,2840,2841,2842,2843,2844,2845,2846,2847,2848,2849,2850,2851,2852,2853,2854,2855,2856,2857,2858,2859,2860,2861,2862,2863,2864,2865,2866,2867,2868,2869,2870,2871,2872,2873,2874,2875,2876,2877,2878,2879,2880,2881,2882,2883,2884,2885,2886,2887,2888,2889,2890,2891,2892,2893,2894,2895,2896,2897,2898,2899,2900,2901,2902,2903,2904,2905,2906,2907,2908,2909,2910,2911,2912,2913,2914,2915,2916,2917,2918,2919,2920,2921,2922,2923,2924,2925,2926,2927,2928,2929,2930,2931,2932,2933,2934,2935,2936,2937,2938,2939,2940,2941,2942,2943,2944,2945,2946,2947,2948,2949,2950,2951,2952,2953,2954,2955,2956,2957,2958,2959,2960,2961,2962,2963,2964,2965,2966,2967,2968,2969,2970,2971,2972,2973,2974,2975,2976,2977,2978,2979,2980,2981,2982,2983,2984,2985,2986,2987,2988,2989,2990,2991,2992,2993,2994,2995,2996,2997,2998,2999,3000,3001,3002,3003,3004,3005,3006,3007,3008,3009,3010,3011,3012,3013,3014,3015,3016,3017,3018,3019,3020,3021,3022,3023,3024,3025,3026,3027,3028,3029,3030,3031,3032,3033,3034,3035,3036,3037,3038,3039,3040,3041,3042,3043,3044,3045,3046,3047,3048,3049,3050,3051,3052,3053,3054,3055,3056,3057,3058,3059,3060,3061,3062,3063,3064,3065,3066,3067,3068,3069,3070,3071,3072,3073,3074,3075,3076,3077,3078,3079,3080,3081,3082,3083,3084,3085,3086,3087,3088,3089,3090,3091,3092,3093,3094,3095,3096,3097,3098,3099,3100,3101,3102,3103,3104,3105,3106,3107,3108,3109,3110,3111,3112,3113,3114,3115,3116,3117,3118,3119,3120,3121,3122,3123,3124,3125,3126,3127,3128,3129,3130,3131,3132,3133,3134,3135,3136,3137,3138,3139,3140,3141,3142,3143,3144,3145,3146,3147,3148,3149,3150,3151,3152,3153,3154,3155,3156,3157,3158,3159,3160,3161,3162,3163,3164,3165,3166,3167,3168,3169,3170,3171,3172,3173,3174,3175,3176,3177,3178,3179,3180,3181,3182,3183,3184,3185,3186,3187,3188,3189,3190,3191,3192,3193,3194,3195,3196,3197,3198,3199,3200],\"y\":[0.6857435011893735,0.6857435011893735,0.6857435011893735,0.6857435011893735,0.6857435011893735,0.6857435011893735,0.6857435011893735,0.6857435011893735,0.6857435011893735,0.6857435011893735,0.6857435011893735,0.6857435011893735,0.6857435011893735,0.6857435011893735,0.6857435011893735,0.6857435011893735,0.6857435011893735,0.6857435011893735,0.6857435011893735,0.6857435011893735,0.6857435011893735,0.6857435011893735,0.6857435011893735,0.6857435011893735,0.6857435011893735,0.6857435011893735,0.6857435011893735,0.6857435011893735,0.6857435011893735,0.6857435011893735,0.6857435011893735,0.6857435011893735,0.6857435011893735,0.6857435011893735,0.6857435011893735,0.6857435011893735,0.6857435011893735,0.6857435011893735,0.6857435011893735,0.6857435011893735,0.6857435011893735,0.6857435011893735,0.6857435011893735,0.6857435011893735,0.6857435011893735,0.6857435011893735,0.6857435011893735,0.6857435011893735,0.6857435011893735,0.6857435011893735,0.6857435011893735,0.6857435011893735,0.6857435011893735,0.6857435011893735,0.6857435011893735,0.6857435011893735,0.6857435011893735,0.6857435011893735,0.6857435011893735,0.6857435011893735,0.6857435011893735,0.6857435011893735,0.6857435011893735,0.6857435011893735,0.6857435011893735,0.6857435011893735,0.6857435011893735,0.6857435011893735,0.6857435011893735,0.6857435011893735,0.6857435011893735,0.6857435011893735,0.6857435011893735,0.6857435011893735,0.6857435011893735,0.6857435011893735,0.6857435011893735,0.6857435011893735,0.6857435011893735,0.6857435011893735,0.6857435011893735,0.6857435011893735,0.6857435011893735,0.6857435011893735,0.6857435011893735,0.6857435011893735,0.6857435011893735,0.6857435011893735,0.6857435011893735,0.6857435011893735,0.6857435011893735,0.6857435011893735,0.6857435011893735,0.6857435011893735,0.6857435011893735,0.6857435011893735,0.6857435011893735,0.6857435011893735,0.6857435011893735,0.6857435011893735,0.5352773523000386,0.5352773523000386,0.5352773523000386,0.5352773523000386,0.5352773523000386,0.5352773523000386,0.5352773523000386,0.5352773523000386,0.5352773523000386,0.5352773523000386,0.5352773523000386,0.5352773523000386,0.5352773523000386,0.5352773523000386,0.5352773523000386,0.5352773523000386,0.5352773523000386,0.5352773523000386,0.5352773523000386,0.5352773523000386,0.5352773523000386,0.5352773523000386,0.5352773523000386,0.5352773523000386,0.5352773523000386,0.5352773523000386,0.5352773523000386,0.5352773523000386,0.5352773523000386,0.5352773523000386,0.5352773523000386,0.5352773523000386,0.5352773523000386,0.5352773523000386,0.5352773523000386,0.5352773523000386,0.5352773523000386,0.5352773523000386,0.5352773523000386,0.5352773523000386,0.5352773523000386,0.5352773523000386,0.5352773523000386,0.5352773523000386,0.5352773523000386,0.5352773523000386,0.5352773523000386,0.5352773523000386,0.5352773523000386,0.5352773523000386,0.5352773523000386,0.5352773523000386,0.5352773523000386,0.5352773523000386,0.5352773523000386,0.5352773523000386,0.5352773523000386,0.5352773523000386,0.5352773523000386,0.5352773523000386,0.5352773523000386,0.5352773523000386,0.5352773523000386,0.5352773523000386,0.5352773523000386,0.5352773523000386,0.5352773523000386,0.5352773523000386,0.5352773523000386,0.5352773523000386,0.5352773523000386,0.5352773523000386,0.5352773523000386,0.5352773523000386,0.5352773523000386,0.5352773523000386,0.5352773523000386,0.5352773523000386,0.5352773523000386,0.5352773523000386,0.5352773523000386,0.5352773523000386,0.5352773523000386,0.5352773523000386,0.5352773523000386,0.5352773523000386,0.5352773523000386,0.5352773523000386,0.5352773523000386,0.5352773523000386,0.5352773523000386,0.5352773523000386,0.5352773523000386,0.5352773523000386,0.5352773523000386,0.5352773523000386,0.5352773523000386,0.5352773523000386,0.5352773523000386,0.5352773523000386,0.342379690023457,0.342379690023457,0.342379690023457,0.342379690023457,0.342379690023457,0.342379690023457,0.342379690023457,0.342379690023457,0.342379690023457,0.342379690023457,0.342379690023457,0.342379690023457,0.342379690023457,0.342379690023457,0.342379690023457,0.342379690023457,0.342379690023457,0.342379690023457,0.342379690023457,0.342379690023457,0.342379690023457,0.342379690023457,0.342379690023457,0.342379690023457,0.342379690023457,0.342379690023457,0.342379690023457,0.342379690023457,0.342379690023457,0.342379690023457,0.342379690023457,0.342379690023457,0.342379690023457,0.342379690023457,0.342379690023457,0.342379690023457,0.342379690023457,0.342379690023457,0.342379690023457,0.342379690023457,0.342379690023457,0.342379690023457,0.342379690023457,0.342379690023457,0.342379690023457,0.342379690023457,0.342379690023457,0.342379690023457,0.342379690023457,0.342379690023457,0.342379690023457,0.342379690023457,0.342379690023457,0.342379690023457,0.342379690023457,0.342379690023457,0.342379690023457,0.342379690023457,0.342379690023457,0.342379690023457,0.342379690023457,0.342379690023457,0.342379690023457,0.342379690023457,0.342379690023457,0.342379690023457,0.342379690023457,0.342379690023457,0.342379690023457,0.342379690023457,0.342379690023457,0.342379690023457,0.342379690023457,0.342379690023457,0.342379690023457,0.342379690023457,0.342379690023457,0.342379690023457,0.342379690023457,0.342379690023457,0.342379690023457,0.342379690023457,0.342379690023457,0.342379690023457,0.342379690023457,0.342379690023457,0.342379690023457,0.342379690023457,0.342379690023457,0.342379690023457,0.342379690023457,0.342379690023457,0.342379690023457,0.342379690023457,0.342379690023457,0.342379690023457,0.342379690023457,0.342379690023457,0.342379690023457,0.342379690023457,0.31480810103822665,0.31480810103822665,0.31480810103822665,0.31480810103822665,0.31480810103822665,0.31480810103822665,0.31480810103822665,0.31480810103822665,0.31480810103822665,0.31480810103822665,0.31480810103822665,0.31480810103822665,0.31480810103822665,0.31480810103822665,0.31480810103822665,0.31480810103822665,0.31480810103822665,0.31480810103822665,0.31480810103822665,0.31480810103822665,0.31480810103822665,0.31480810103822665,0.31480810103822665,0.31480810103822665,0.31480810103822665,0.31480810103822665,0.31480810103822665,0.31480810103822665,0.31480810103822665,0.31480810103822665,0.31480810103822665,0.31480810103822665,0.31480810103822665,0.31480810103822665,0.31480810103822665,0.31480810103822665,0.31480810103822665,0.31480810103822665,0.31480810103822665,0.31480810103822665,0.31480810103822665,0.31480810103822665,0.31480810103822665,0.31480810103822665,0.31480810103822665,0.31480810103822665,0.31480810103822665,0.31480810103822665,0.31480810103822665,0.31480810103822665,0.31480810103822665,0.31480810103822665,0.31480810103822665,0.31480810103822665,0.31480810103822665,0.31480810103822665,0.31480810103822665,0.31480810103822665,0.31480810103822665,0.31480810103822665,0.31480810103822665,0.31480810103822665,0.31480810103822665,0.31480810103822665,0.31480810103822665,0.31480810103822665,0.31480810103822665,0.31480810103822665,0.31480810103822665,0.31480810103822665,0.31480810103822665,0.31480810103822665,0.31480810103822665,0.31480810103822665,0.31480810103822665,0.31480810103822665,0.31480810103822665,0.31480810103822665,0.31480810103822665,0.31480810103822665,0.31480810103822665,0.31480810103822665,0.31480810103822665,0.31480810103822665,0.31480810103822665,0.31480810103822665,0.31480810103822665,0.31480810103822665,0.31480810103822665,0.31480810103822665,0.31480810103822665,0.31480810103822665,0.31480810103822665,0.31480810103822665,0.31480810103822665,0.31480810103822665,0.31480810103822665,0.31480810103822665,0.31480810103822665,0.31480810103822665,0.3038393459321051,0.3038393459321051,0.3038393459321051,0.3038393459321051,0.3038393459321051,0.3038393459321051,0.3038393459321051,0.3038393459321051,0.3038393459321051,0.3038393459321051,0.3038393459321051,0.3038393459321051,0.3038393459321051,0.3038393459321051,0.3038393459321051,0.3038393459321051,0.3038393459321051,0.3038393459321051,0.3038393459321051,0.3038393459321051,0.3038393459321051,0.3038393459321051,0.3038393459321051,0.3038393459321051,0.3038393459321051,0.3038393459321051,0.3038393459321051,0.3038393459321051,0.3038393459321051,0.3038393459321051,0.3038393459321051,0.3038393459321051,0.3038393459321051,0.3038393459321051,0.3038393459321051,0.3038393459321051,0.3038393459321051,0.3038393459321051,0.3038393459321051,0.3038393459321051,0.3038393459321051,0.3038393459321051,0.3038393459321051,0.3038393459321051,0.3038393459321051,0.3038393459321051,0.3038393459321051,0.3038393459321051,0.3038393459321051,0.3038393459321051,0.3038393459321051,0.3038393459321051,0.3038393459321051,0.3038393459321051,0.3038393459321051,0.3038393459321051,0.3038393459321051,0.3038393459321051,0.3038393459321051,0.3038393459321051,0.3038393459321051,0.3038393459321051,0.3038393459321051,0.3038393459321051,0.3038393459321051,0.3038393459321051,0.3038393459321051,0.3038393459321051,0.3038393459321051,0.3038393459321051,0.3038393459321051,0.3038393459321051,0.3038393459321051,0.3038393459321051,0.3038393459321051,0.3038393459321051,0.3038393459321051,0.3038393459321051,0.3038393459321051,0.3038393459321051,0.3038393459321051,0.3038393459321051,0.3038393459321051,0.3038393459321051,0.3038393459321051,0.3038393459321051,0.3038393459321051,0.3038393459321051,0.3038393459321051,0.3038393459321051,0.3038393459321051,0.3038393459321051,0.3038393459321051,0.3038393459321051,0.3038393459321051,0.3038393459321051,0.3038393459321051,0.3038393459321051,0.3038393459321051,0.3038393459321051,0.2950196630981633,0.2950196630981633,0.2950196630981633,0.2950196630981633,0.2950196630981633,0.2950196630981633,0.2950196630981633,0.2950196630981633,0.2950196630981633,0.2950196630981633,0.2950196630981633,0.2950196630981633,0.2950196630981633,0.2950196630981633,0.2950196630981633,0.2950196630981633,0.2950196630981633,0.2950196630981633,0.2950196630981633,0.2950196630981633,0.2950196630981633,0.2950196630981633,0.2950196630981633,0.2950196630981633,0.2950196630981633,0.2950196630981633,0.2950196630981633,0.2950196630981633,0.2950196630981633,0.2950196630981633,0.2950196630981633,0.2950196630981633,0.2950196630981633,0.2950196630981633,0.2950196630981633,0.2950196630981633,0.2950196630981633,0.2950196630981633,0.2950196630981633,0.2950196630981633,0.2950196630981633,0.2950196630981633,0.2950196630981633,0.2950196630981633,0.2950196630981633,0.2950196630981633,0.2950196630981633,0.2950196630981633,0.2950196630981633,0.2950196630981633,0.2950196630981633,0.2950196630981633,0.2950196630981633,0.2950196630981633,0.2950196630981633,0.2950196630981633,0.2950196630981633,0.2950196630981633,0.2950196630981633,0.2950196630981633,0.2950196630981633,0.2950196630981633,0.2950196630981633,0.2950196630981633,0.2950196630981633,0.2950196630981633,0.2950196630981633,0.2950196630981633,0.2950196630981633,0.2950196630981633,0.2950196630981633,0.2950196630981633,0.2950196630981633,0.2950196630981633,0.2950196630981633,0.2950196630981633,0.2950196630981633,0.2950196630981633,0.2950196630981633,0.2950196630981633,0.2950196630981633,0.2950196630981633,0.2950196630981633,0.2950196630981633,0.2950196630981633,0.2950196630981633,0.2950196630981633,0.2950196630981633,0.2950196630981633,0.2950196630981633,0.2950196630981633,0.2950196630981633,0.2950196630981633,0.2950196630981633,0.2950196630981633,0.2950196630981633,0.2950196630981633,0.2950196630981633,0.2950196630981633,0.2950196630981633,0.28533773118766975,0.28533773118766975,0.28533773118766975,0.28533773118766975,0.28533773118766975,0.28533773118766975,0.28533773118766975,0.28533773118766975,0.28533773118766975,0.28533773118766975,0.28533773118766975,0.28533773118766975,0.28533773118766975,0.28533773118766975,0.28533773118766975,0.28533773118766975,0.28533773118766975,0.28533773118766975,0.28533773118766975,0.28533773118766975,0.28533773118766975,0.28533773118766975,0.28533773118766975,0.28533773118766975,0.28533773118766975,0.28533773118766975,0.28533773118766975,0.28533773118766975,0.28533773118766975,0.28533773118766975,0.28533773118766975,0.28533773118766975,0.28533773118766975,0.28533773118766975,0.28533773118766975,0.28533773118766975,0.28533773118766975,0.28533773118766975,0.28533773118766975,0.28533773118766975,0.28533773118766975,0.28533773118766975,0.28533773118766975,0.28533773118766975,0.28533773118766975,0.28533773118766975,0.28533773118766975,0.28533773118766975,0.28533773118766975,0.28533773118766975,0.28533773118766975,0.28533773118766975,0.28533773118766975,0.28533773118766975,0.28533773118766975,0.28533773118766975,0.28533773118766975,0.28533773118766975,0.28533773118766975,0.28533773118766975,0.28533773118766975,0.28533773118766975,0.28533773118766975,0.28533773118766975,0.28533773118766975,0.28533773118766975,0.28533773118766975,0.28533773118766975,0.28533773118766975,0.28533773118766975,0.28533773118766975,0.28533773118766975,0.28533773118766975,0.28533773118766975,0.28533773118766975,0.28533773118766975,0.28533773118766975,0.28533773118766975,0.28533773118766975,0.28533773118766975,0.28533773118766975,0.28533773118766975,0.28533773118766975,0.28533773118766975,0.28533773118766975,0.28533773118766975,0.28533773118766975,0.28533773118766975,0.28533773118766975,0.28533773118766975,0.28533773118766975,0.28533773118766975,0.28533773118766975,0.28533773118766975,0.28533773118766975,0.28533773118766975,0.28533773118766975,0.28533773118766975,0.28533773118766975,0.28533773118766975,0.2729056730530455,0.2729056730530455,0.2729056730530455,0.2729056730530455,0.2729056730530455,0.2729056730530455,0.2729056730530455,0.2729056730530455,0.2729056730530455,0.2729056730530455,0.2729056730530455,0.2729056730530455,0.2729056730530455,0.2729056730530455,0.2729056730530455,0.2729056730530455,0.2729056730530455,0.2729056730530455,0.2729056730530455,0.2729056730530455,0.2729056730530455,0.2729056730530455,0.2729056730530455,0.2729056730530455,0.2729056730530455,0.2729056730530455,0.2729056730530455,0.2729056730530455,0.2729056730530455,0.2729056730530455,0.2729056730530455,0.2729056730530455,0.2729056730530455,0.2729056730530455,0.2729056730530455,0.2729056730530455,0.2729056730530455,0.2729056730530455,0.2729056730530455,0.2729056730530455,0.2729056730530455,0.2729056730530455,0.2729056730530455,0.2729056730530455,0.2729056730530455,0.2729056730530455,0.2729056730530455,0.2729056730530455,0.2729056730530455,0.2729056730530455,0.2729056730530455,0.2729056730530455,0.2729056730530455,0.2729056730530455,0.2729056730530455,0.2729056730530455,0.2729056730530455,0.2729056730530455,0.2729056730530455,0.2729056730530455,0.2729056730530455,0.2729056730530455,0.2729056730530455,0.2729056730530455,0.2729056730530455,0.2729056730530455,0.2729056730530455,0.2729056730530455,0.2729056730530455,0.2729056730530455,0.2729056730530455,0.2729056730530455,0.2729056730530455,0.2729056730530455,0.2729056730530455,0.2729056730530455,0.2729056730530455,0.2729056730530455,0.2729056730530455,0.2729056730530455,0.2729056730530455,0.2729056730530455,0.2729056730530455,0.2729056730530455,0.2729056730530455,0.2729056730530455,0.2729056730530455,0.2729056730530455,0.2729056730530455,0.2729056730530455,0.2729056730530455,0.2729056730530455,0.2729056730530455,0.2729056730530455,0.2729056730530455,0.2729056730530455,0.2729056730530455,0.2729056730530455,0.2729056730530455,0.2729056730530455,0.2635200216824682,0.2635200216824682,0.2635200216824682,0.2635200216824682,0.2635200216824682,0.2635200216824682,0.2635200216824682,0.2635200216824682,0.2635200216824682,0.2635200216824682,0.2635200216824682,0.2635200216824682,0.2635200216824682,0.2635200216824682,0.2635200216824682,0.2635200216824682,0.2635200216824682,0.2635200216824682,0.2635200216824682,0.2635200216824682,0.2635200216824682,0.2635200216824682,0.2635200216824682,0.2635200216824682,0.2635200216824682,0.2635200216824682,0.2635200216824682,0.2635200216824682,0.2635200216824682,0.2635200216824682,0.2635200216824682,0.2635200216824682,0.2635200216824682,0.2635200216824682,0.2635200216824682,0.2635200216824682,0.2635200216824682,0.2635200216824682,0.2635200216824682,0.2635200216824682,0.2635200216824682,0.2635200216824682,0.2635200216824682,0.2635200216824682,0.2635200216824682,0.2635200216824682,0.2635200216824682,0.2635200216824682,0.2635200216824682,0.2635200216824682,0.2635200216824682,0.2635200216824682,0.2635200216824682,0.2635200216824682,0.2635200216824682,0.2635200216824682,0.2635200216824682,0.2635200216824682,0.2635200216824682,0.2635200216824682,0.2635200216824682,0.2635200216824682,0.2635200216824682,0.2635200216824682,0.2635200216824682,0.2635200216824682,0.2635200216824682,0.2635200216824682,0.2635200216824682,0.2635200216824682,0.2635200216824682,0.2635200216824682,0.2635200216824682,0.2635200216824682,0.2635200216824682,0.2635200216824682,0.2635200216824682,0.2635200216824682,0.2635200216824682,0.2635200216824682,0.2635200216824682,0.2635200216824682,0.2635200216824682,0.2635200216824682,0.2635200216824682,0.2635200216824682,0.2635200216824682,0.2635200216824682,0.2635200216824682,0.2635200216824682,0.2635200216824682,0.2635200216824682,0.2635200216824682,0.2635200216824682,0.2635200216824682,0.2635200216824682,0.2635200216824682,0.2635200216824682,0.2635200216824682,0.2635200216824682,0.25503699126862234,0.25503699126862234,0.25503699126862234,0.25503699126862234,0.25503699126862234,0.25503699126862234,0.25503699126862234,0.25503699126862234,0.25503699126862234,0.25503699126862234,0.25503699126862234,0.25503699126862234,0.25503699126862234,0.25503699126862234,0.25503699126862234,0.25503699126862234,0.25503699126862234,0.25503699126862234,0.25503699126862234,0.25503699126862234,0.25503699126862234,0.25503699126862234,0.25503699126862234,0.25503699126862234,0.25503699126862234,0.25503699126862234,0.25503699126862234,0.25503699126862234,0.25503699126862234,0.25503699126862234,0.25503699126862234,0.25503699126862234,0.25503699126862234,0.25503699126862234,0.25503699126862234,0.25503699126862234,0.25503699126862234,0.25503699126862234,0.25503699126862234,0.25503699126862234,0.25503699126862234,0.25503699126862234,0.25503699126862234,0.25503699126862234,0.25503699126862234,0.25503699126862234,0.25503699126862234,0.25503699126862234,0.25503699126862234,0.25503699126862234,0.25503699126862234,0.25503699126862234,0.25503699126862234,0.25503699126862234,0.25503699126862234,0.25503699126862234,0.25503699126862234,0.25503699126862234,0.25503699126862234,0.25503699126862234,0.25503699126862234,0.25503699126862234,0.25503699126862234,0.25503699126862234,0.25503699126862234,0.25503699126862234,0.25503699126862234,0.25503699126862234,0.25503699126862234,0.25503699126862234,0.25503699126862234,0.25503699126862234,0.25503699126862234,0.25503699126862234,0.25503699126862234,0.25503699126862234,0.25503699126862234,0.25503699126862234,0.25503699126862234,0.25503699126862234,0.25503699126862234,0.25503699126862234,0.25503699126862234,0.25503699126862234,0.25503699126862234,0.25503699126862234,0.25503699126862234,0.25503699126862234,0.25503699126862234,0.25503699126862234,0.25503699126862234,0.25503699126862234,0.25503699126862234,0.25503699126862234,0.25503699126862234,0.25503699126862234,0.25503699126862234,0.25503699126862234,0.25503699126862234,0.25503699126862234,0.25032728089365347,0.25032728089365347,0.25032728089365347,0.25032728089365347,0.25032728089365347,0.25032728089365347,0.25032728089365347,0.25032728089365347,0.25032728089365347,0.25032728089365347,0.25032728089365347,0.25032728089365347,0.25032728089365347,0.25032728089365347,0.25032728089365347,0.25032728089365347,0.25032728089365347,0.25032728089365347,0.25032728089365347,0.25032728089365347,0.25032728089365347,0.25032728089365347,0.25032728089365347,0.25032728089365347,0.25032728089365347,0.25032728089365347,0.25032728089365347,0.25032728089365347,0.25032728089365347,0.25032728089365347,0.25032728089365347,0.25032728089365347,0.25032728089365347,0.25032728089365347,0.25032728089365347,0.25032728089365347,0.25032728089365347,0.25032728089365347,0.25032728089365347,0.25032728089365347,0.25032728089365347,0.25032728089365347,0.25032728089365347,0.25032728089365347,0.25032728089365347,0.25032728089365347,0.25032728089365347,0.25032728089365347,0.25032728089365347,0.25032728089365347,0.25032728089365347,0.25032728089365347,0.25032728089365347,0.25032728089365347,0.25032728089365347,0.25032728089365347,0.25032728089365347,0.25032728089365347,0.25032728089365347,0.25032728089365347,0.25032728089365347,0.25032728089365347,0.25032728089365347,0.25032728089365347,0.25032728089365347,0.25032728089365347,0.25032728089365347,0.25032728089365347,0.25032728089365347,0.25032728089365347,0.25032728089365347,0.25032728089365347,0.25032728089365347,0.25032728089365347,0.25032728089365347,0.25032728089365347,0.25032728089365347,0.25032728089365347,0.25032728089365347,0.25032728089365347,0.25032728089365347,0.25032728089365347,0.25032728089365347,0.25032728089365347,0.25032728089365347,0.25032728089365347,0.25032728089365347,0.25032728089365347,0.25032728089365347,0.25032728089365347,0.25032728089365347,0.25032728089365347,0.25032728089365347,0.25032728089365347,0.25032728089365347,0.25032728089365347,0.25032728089365347,0.25032728089365347,0.25032728089365347,0.25032728089365347,0.2454555338530192,0.2454555338530192,0.2454555338530192,0.2454555338530192,0.2454555338530192,0.2454555338530192,0.2454555338530192,0.2454555338530192,0.2454555338530192,0.2454555338530192,0.2454555338530192,0.2454555338530192,0.2454555338530192,0.2454555338530192,0.2454555338530192,0.2454555338530192,0.2454555338530192,0.2454555338530192,0.2454555338530192,0.2454555338530192,0.2454555338530192,0.2454555338530192,0.2454555338530192,0.2454555338530192,0.2454555338530192,0.2454555338530192,0.2454555338530192,0.2454555338530192,0.2454555338530192,0.2454555338530192,0.2454555338530192,0.2454555338530192,0.2454555338530192,0.2454555338530192,0.2454555338530192,0.2454555338530192,0.2454555338530192,0.2454555338530192,0.2454555338530192,0.2454555338530192,0.2454555338530192,0.2454555338530192,0.2454555338530192,0.2454555338530192,0.2454555338530192,0.2454555338530192,0.2454555338530192,0.2454555338530192,0.2454555338530192,0.2454555338530192,0.2454555338530192,0.2454555338530192,0.2454555338530192,0.2454555338530192,0.2454555338530192,0.2454555338530192,0.2454555338530192,0.2454555338530192,0.2454555338530192,0.2454555338530192,0.2454555338530192,0.2454555338530192,0.2454555338530192,0.2454555338530192,0.2454555338530192,0.2454555338530192,0.2454555338530192,0.2454555338530192,0.2454555338530192,0.2454555338530192,0.2454555338530192,0.2454555338530192,0.2454555338530192,0.2454555338530192,0.2454555338530192,0.2454555338530192,0.2454555338530192,0.2454555338530192,0.2454555338530192,0.2454555338530192,0.2454555338530192,0.2454555338530192,0.2454555338530192,0.2454555338530192,0.2454555338530192,0.2454555338530192,0.2454555338530192,0.2454555338530192,0.2454555338530192,0.2454555338530192,0.2454555338530192,0.2454555338530192,0.2454555338530192,0.2454555338530192,0.2454555338530192,0.2454555338530192,0.2454555338530192,0.2454555338530192,0.2454555338530192,0.2454555338530192,0.24102565267653162,0.24102565267653162,0.24102565267653162,0.24102565267653162,0.24102565267653162,0.24102565267653162,0.24102565267653162,0.24102565267653162,0.24102565267653162,0.24102565267653162,0.24102565267653162,0.24102565267653162,0.24102565267653162,0.24102565267653162,0.24102565267653162,0.24102565267653162,0.24102565267653162,0.24102565267653162,0.24102565267653162,0.24102565267653162,0.24102565267653162,0.24102565267653162,0.24102565267653162,0.24102565267653162,0.24102565267653162,0.24102565267653162,0.24102565267653162,0.24102565267653162,0.24102565267653162,0.24102565267653162,0.24102565267653162,0.24102565267653162,0.24102565267653162,0.24102565267653162,0.24102565267653162,0.24102565267653162,0.24102565267653162,0.24102565267653162,0.24102565267653162,0.24102565267653162,0.24102565267653162,0.24102565267653162,0.24102565267653162,0.24102565267653162,0.24102565267653162,0.24102565267653162,0.24102565267653162,0.24102565267653162,0.24102565267653162,0.24102565267653162,0.24102565267653162,0.24102565267653162,0.24102565267653162,0.24102565267653162,0.24102565267653162,0.24102565267653162,0.24102565267653162,0.24102565267653162,0.24102565267653162,0.24102565267653162,0.24102565267653162,0.24102565267653162,0.24102565267653162,0.24102565267653162,0.24102565267653162,0.24102565267653162,0.24102565267653162,0.24102565267653162,0.24102565267653162,0.24102565267653162,0.24102565267653162,0.24102565267653162,0.24102565267653162,0.24102565267653162,0.24102565267653162,0.24102565267653162,0.24102565267653162,0.24102565267653162,0.24102565267653162,0.24102565267653162,0.24102565267653162,0.24102565267653162,0.24102565267653162,0.24102565267653162,0.24102565267653162,0.24102565267653162,0.24102565267653162,0.24102565267653162,0.24102565267653162,0.24102565267653162,0.24102565267653162,0.24102565267653162,0.24102565267653162,0.24102565267653162,0.24102565267653162,0.24102565267653162,0.24102565267653162,0.24102565267653162,0.24102565267653162,0.24102565267653162,0.23631778385177735,0.23631778385177735,0.23631778385177735,0.23631778385177735,0.23631778385177735,0.23631778385177735,0.23631778385177735,0.23631778385177735,0.23631778385177735,0.23631778385177735,0.23631778385177735,0.23631778385177735,0.23631778385177735,0.23631778385177735,0.23631778385177735,0.23631778385177735,0.23631778385177735,0.23631778385177735,0.23631778385177735,0.23631778385177735,0.23631778385177735,0.23631778385177735,0.23631778385177735,0.23631778385177735,0.23631778385177735,0.23631778385177735,0.23631778385177735,0.23631778385177735,0.23631778385177735,0.23631778385177735,0.23631778385177735,0.23631778385177735,0.23631778385177735,0.23631778385177735,0.23631778385177735,0.23631778385177735,0.23631778385177735,0.23631778385177735,0.23631778385177735,0.23631778385177735,0.23631778385177735,0.23631778385177735,0.23631778385177735,0.23631778385177735,0.23631778385177735,0.23631778385177735,0.23631778385177735,0.23631778385177735,0.23631778385177735,0.23631778385177735,0.23631778385177735,0.23631778385177735,0.23631778385177735,0.23631778385177735,0.23631778385177735,0.23631778385177735,0.23631778385177735,0.23631778385177735,0.23631778385177735,0.23631778385177735,0.23631778385177735,0.23631778385177735,0.23631778385177735,0.23631778385177735,0.23631778385177735,0.23631778385177735,0.23631778385177735,0.23631778385177735,0.23631778385177735,0.23631778385177735,0.23631778385177735,0.23631778385177735,0.23631778385177735,0.23631778385177735,0.23631778385177735,0.23631778385177735,0.23631778385177735,0.23631778385177735,0.23631778385177735,0.23631778385177735,0.23631778385177735,0.23631778385177735,0.23631778385177735,0.23631778385177735,0.23631778385177735,0.23631778385177735,0.23631778385177735,0.23631778385177735,0.23631778385177735,0.23631778385177735,0.23631778385177735,0.23631778385177735,0.23631778385177735,0.23631778385177735,0.23631778385177735,0.23631778385177735,0.23631778385177735,0.23631778385177735,0.23631778385177735,0.23631778385177735,0.23289222560488407,0.23289222560488407,0.23289222560488407,0.23289222560488407,0.23289222560488407,0.23289222560488407,0.23289222560488407,0.23289222560488407,0.23289222560488407,0.23289222560488407,0.23289222560488407,0.23289222560488407,0.23289222560488407,0.23289222560488407,0.23289222560488407,0.23289222560488407,0.23289222560488407,0.23289222560488407,0.23289222560488407,0.23289222560488407,0.23289222560488407,0.23289222560488407,0.23289222560488407,0.23289222560488407,0.23289222560488407,0.23289222560488407,0.23289222560488407,0.23289222560488407,0.23289222560488407,0.23289222560488407,0.23289222560488407,0.23289222560488407,0.23289222560488407,0.23289222560488407,0.23289222560488407,0.23289222560488407,0.23289222560488407,0.23289222560488407,0.23289222560488407,0.23289222560488407,0.23289222560488407,0.23289222560488407,0.23289222560488407,0.23289222560488407,0.23289222560488407,0.23289222560488407,0.23289222560488407,0.23289222560488407,0.23289222560488407,0.23289222560488407,0.23289222560488407,0.23289222560488407,0.23289222560488407,0.23289222560488407,0.23289222560488407,0.23289222560488407,0.23289222560488407,0.23289222560488407,0.23289222560488407,0.23289222560488407,0.23289222560488407,0.23289222560488407,0.23289222560488407,0.23289222560488407,0.23289222560488407,0.23289222560488407,0.23289222560488407,0.23289222560488407,0.23289222560488407,0.23289222560488407,0.23289222560488407,0.23289222560488407,0.23289222560488407,0.23289222560488407,0.23289222560488407,0.23289222560488407,0.23289222560488407,0.23289222560488407,0.23289222560488407,0.23289222560488407,0.23289222560488407,0.23289222560488407,0.23289222560488407,0.23289222560488407,0.23289222560488407,0.23289222560488407,0.23289222560488407,0.23289222560488407,0.23289222560488407,0.23289222560488407,0.23289222560488407,0.23289222560488407,0.23289222560488407,0.23289222560488407,0.23289222560488407,0.23289222560488407,0.23289222560488407,0.23289222560488407,0.23289222560488407,0.23289222560488407,0.2292886537109917,0.2292886537109917,0.2292886537109917,0.2292886537109917,0.2292886537109917,0.2292886537109917,0.2292886537109917,0.2292886537109917,0.2292886537109917,0.2292886537109917,0.2292886537109917,0.2292886537109917,0.2292886537109917,0.2292886537109917,0.2292886537109917,0.2292886537109917,0.2292886537109917,0.2292886537109917,0.2292886537109917,0.2292886537109917,0.2292886537109917,0.2292886537109917,0.2292886537109917,0.2292886537109917,0.2292886537109917,0.2292886537109917,0.2292886537109917,0.2292886537109917,0.2292886537109917,0.2292886537109917,0.2292886537109917,0.2292886537109917,0.2292886537109917,0.2292886537109917,0.2292886537109917,0.2292886537109917,0.2292886537109917,0.2292886537109917,0.2292886537109917,0.2292886537109917,0.2292886537109917,0.2292886537109917,0.2292886537109917,0.2292886537109917,0.2292886537109917,0.2292886537109917,0.2292886537109917,0.2292886537109917,0.2292886537109917,0.2292886537109917,0.2292886537109917,0.2292886537109917,0.2292886537109917,0.2292886537109917,0.2292886537109917,0.2292886537109917,0.2292886537109917,0.2292886537109917,0.2292886537109917,0.2292886537109917,0.2292886537109917,0.2292886537109917,0.2292886537109917,0.2292886537109917,0.2292886537109917,0.2292886537109917,0.2292886537109917,0.2292886537109917,0.2292886537109917,0.2292886537109917,0.2292886537109917,0.2292886537109917,0.2292886537109917,0.2292886537109917,0.2292886537109917,0.2292886537109917,0.2292886537109917,0.2292886537109917,0.2292886537109917,0.2292886537109917,0.2292886537109917,0.2292886537109917,0.2292886537109917,0.2292886537109917,0.2292886537109917,0.2292886537109917,0.2292886537109917,0.2292886537109917,0.2292886537109917,0.2292886537109917,0.2292886537109917,0.2292886537109917,0.2292886537109917,0.2292886537109917,0.2292886537109917,0.2292886537109917,0.2292886537109917,0.2292886537109917,0.2292886537109917,0.2292886537109917,0.22586541024608298,0.22586541024608298,0.22586541024608298,0.22586541024608298,0.22586541024608298,0.22586541024608298,0.22586541024608298,0.22586541024608298,0.22586541024608298,0.22586541024608298,0.22586541024608298,0.22586541024608298,0.22586541024608298,0.22586541024608298,0.22586541024608298,0.22586541024608298,0.22586541024608298,0.22586541024608298,0.22586541024608298,0.22586541024608298,0.22586541024608298,0.22586541024608298,0.22586541024608298,0.22586541024608298,0.22586541024608298,0.22586541024608298,0.22586541024608298,0.22586541024608298,0.22586541024608298,0.22586541024608298,0.22586541024608298,0.22586541024608298,0.22586541024608298,0.22586541024608298,0.22586541024608298,0.22586541024608298,0.22586541024608298,0.22586541024608298,0.22586541024608298,0.22586541024608298,0.22586541024608298,0.22586541024608298,0.22586541024608298,0.22586541024608298,0.22586541024608298,0.22586541024608298,0.22586541024608298,0.22586541024608298,0.22586541024608298,0.22586541024608298,0.22586541024608298,0.22586541024608298,0.22586541024608298,0.22586541024608298,0.22586541024608298,0.22586541024608298,0.22586541024608298,0.22586541024608298,0.22586541024608298,0.22586541024608298,0.22586541024608298,0.22586541024608298,0.22586541024608298,0.22586541024608298,0.22586541024608298,0.22586541024608298,0.22586541024608298,0.22586541024608298,0.22586541024608298,0.22586541024608298,0.22586541024608298,0.22586541024608298,0.22586541024608298,0.22586541024608298,0.22586541024608298,0.22586541024608298,0.22586541024608298,0.22586541024608298,0.22586541024608298,0.22586541024608298,0.22586541024608298,0.22586541024608298,0.22586541024608298,0.22586541024608298,0.22586541024608298,0.22586541024608298,0.22586541024608298,0.22586541024608298,0.22586541024608298,0.22586541024608298,0.22586541024608298,0.22586541024608298,0.22586541024608298,0.22586541024608298,0.22586541024608298,0.22586541024608298,0.22586541024608298,0.22586541024608298,0.22586541024608298,0.22586541024608298,0.2230991041106568,0.2230991041106568,0.2230991041106568,0.2230991041106568,0.2230991041106568,0.2230991041106568,0.2230991041106568,0.2230991041106568,0.2230991041106568,0.2230991041106568,0.2230991041106568,0.2230991041106568,0.2230991041106568,0.2230991041106568,0.2230991041106568,0.2230991041106568,0.2230991041106568,0.2230991041106568,0.2230991041106568,0.2230991041106568,0.2230991041106568,0.2230991041106568,0.2230991041106568,0.2230991041106568,0.2230991041106568,0.2230991041106568,0.2230991041106568,0.2230991041106568,0.2230991041106568,0.2230991041106568,0.2230991041106568,0.2230991041106568,0.2230991041106568,0.2230991041106568,0.2230991041106568,0.2230991041106568,0.2230991041106568,0.2230991041106568,0.2230991041106568,0.2230991041106568,0.2230991041106568,0.2230991041106568,0.2230991041106568,0.2230991041106568,0.2230991041106568,0.2230991041106568,0.2230991041106568,0.2230991041106568,0.2230991041106568,0.2230991041106568,0.2230991041106568,0.2230991041106568,0.2230991041106568,0.2230991041106568,0.2230991041106568,0.2230991041106568,0.2230991041106568,0.2230991041106568,0.2230991041106568,0.2230991041106568,0.2230991041106568,0.2230991041106568,0.2230991041106568,0.2230991041106568,0.2230991041106568,0.2230991041106568,0.2230991041106568,0.2230991041106568,0.2230991041106568,0.2230991041106568,0.2230991041106568,0.2230991041106568,0.2230991041106568,0.2230991041106568,0.2230991041106568,0.2230991041106568,0.2230991041106568,0.2230991041106568,0.2230991041106568,0.2230991041106568,0.2230991041106568,0.2230991041106568,0.2230991041106568,0.2230991041106568,0.2230991041106568,0.2230991041106568,0.2230991041106568,0.2230991041106568,0.2230991041106568,0.2230991041106568,0.2230991041106568,0.2230991041106568,0.2230991041106568,0.2230991041106568,0.2230991041106568,0.2230991041106568,0.2230991041106568,0.2230991041106568,0.2230991041106568,0.2230991041106568,0.21955646093971024,0.21955646093971024,0.21955646093971024,0.21955646093971024,0.21955646093971024,0.21955646093971024,0.21955646093971024,0.21955646093971024,0.21955646093971024,0.21955646093971024,0.21955646093971024,0.21955646093971024,0.21955646093971024,0.21955646093971024,0.21955646093971024,0.21955646093971024,0.21955646093971024,0.21955646093971024,0.21955646093971024,0.21955646093971024,0.21955646093971024,0.21955646093971024,0.21955646093971024,0.21955646093971024,0.21955646093971024,0.21955646093971024,0.21955646093971024,0.21955646093971024,0.21955646093971024,0.21955646093971024,0.21955646093971024,0.21955646093971024,0.21955646093971024,0.21955646093971024,0.21955646093971024,0.21955646093971024,0.21955646093971024,0.21955646093971024,0.21955646093971024,0.21955646093971024,0.21955646093971024,0.21955646093971024,0.21955646093971024,0.21955646093971024,0.21955646093971024,0.21955646093971024,0.21955646093971024,0.21955646093971024,0.21955646093971024,0.21955646093971024,0.21955646093971024,0.21955646093971024,0.21955646093971024,0.21955646093971024,0.21955646093971024,0.21955646093971024,0.21955646093971024,0.21955646093971024,0.21955646093971024,0.21955646093971024,0.21955646093971024,0.21955646093971024,0.21955646093971024,0.21955646093971024,0.21955646093971024,0.21955646093971024,0.21955646093971024,0.21955646093971024,0.21955646093971024,0.21955646093971024,0.21955646093971024,0.21955646093971024,0.21955646093971024,0.21955646093971024,0.21955646093971024,0.21955646093971024,0.21955646093971024,0.21955646093971024,0.21955646093971024,0.21955646093971024,0.21955646093971024,0.21955646093971024,0.21955646093971024,0.21955646093971024,0.21955646093971024,0.21955646093971024,0.21955646093971024,0.21955646093971024,0.21955646093971024,0.21955646093971024,0.21955646093971024,0.21955646093971024,0.21955646093971024,0.21955646093971024,0.21955646093971024,0.21955646093971024,0.21955646093971024,0.21955646093971024,0.21955646093971024,0.21955646093971024,0.21686201926280618,0.21686201926280618,0.21686201926280618,0.21686201926280618,0.21686201926280618,0.21686201926280618,0.21686201926280618,0.21686201926280618,0.21686201926280618,0.21686201926280618,0.21686201926280618,0.21686201926280618,0.21686201926280618,0.21686201926280618,0.21686201926280618,0.21686201926280618,0.21686201926280618,0.21686201926280618,0.21686201926280618,0.21686201926280618,0.21686201926280618,0.21686201926280618,0.21686201926280618,0.21686201926280618,0.21686201926280618,0.21686201926280618,0.21686201926280618,0.21686201926280618,0.21686201926280618,0.21686201926280618,0.21686201926280618,0.21686201926280618,0.21686201926280618,0.21686201926280618,0.21686201926280618,0.21686201926280618,0.21686201926280618,0.21686201926280618,0.21686201926280618,0.21686201926280618,0.21686201926280618,0.21686201926280618,0.21686201926280618,0.21686201926280618,0.21686201926280618,0.21686201926280618,0.21686201926280618,0.21686201926280618,0.21686201926280618,0.21686201926280618,0.21686201926280618,0.21686201926280618,0.21686201926280618,0.21686201926280618,0.21686201926280618,0.21686201926280618,0.21686201926280618,0.21686201926280618,0.21686201926280618,0.21686201926280618,0.21686201926280618,0.21686201926280618,0.21686201926280618,0.21686201926280618,0.21686201926280618,0.21686201926280618,0.21686201926280618,0.21686201926280618,0.21686201926280618,0.21686201926280618,0.21686201926280618,0.21686201926280618,0.21686201926280618,0.21686201926280618,0.21686201926280618,0.21686201926280618,0.21686201926280618,0.21686201926280618,0.21686201926280618,0.21686201926280618,0.21686201926280618,0.21686201926280618,0.21686201926280618,0.21686201926280618,0.21686201926280618,0.21686201926280618,0.21686201926280618,0.21686201926280618,0.21686201926280618,0.21686201926280618,0.21686201926280618,0.21686201926280618,0.21686201926280618,0.21686201926280618,0.21686201926280618,0.21686201926280618,0.21686201926280618,0.21686201926280618,0.21686201926280618,0.21686201926280618,0.21461177675295287,0.21461177675295287,0.21461177675295287,0.21461177675295287,0.21461177675295287,0.21461177675295287,0.21461177675295287,0.21461177675295287,0.21461177675295287,0.21461177675295287,0.21461177675295287,0.21461177675295287,0.21461177675295287,0.21461177675295287,0.21461177675295287,0.21461177675295287,0.21461177675295287,0.21461177675295287,0.21461177675295287,0.21461177675295287,0.21461177675295287,0.21461177675295287,0.21461177675295287,0.21461177675295287,0.21461177675295287,0.21461177675295287,0.21461177675295287,0.21461177675295287,0.21461177675295287,0.21461177675295287,0.21461177675295287,0.21461177675295287,0.21461177675295287,0.21461177675295287,0.21461177675295287,0.21461177675295287,0.21461177675295287,0.21461177675295287,0.21461177675295287,0.21461177675295287,0.21461177675295287,0.21461177675295287,0.21461177675295287,0.21461177675295287,0.21461177675295287,0.21461177675295287,0.21461177675295287,0.21461177675295287,0.21461177675295287,0.21461177675295287,0.21461177675295287,0.21461177675295287,0.21461177675295287,0.21461177675295287,0.21461177675295287,0.21461177675295287,0.21461177675295287,0.21461177675295287,0.21461177675295287,0.21461177675295287,0.21461177675295287,0.21461177675295287,0.21461177675295287,0.21461177675295287,0.21461177675295287,0.21461177675295287,0.21461177675295287,0.21461177675295287,0.21461177675295287,0.21461177675295287,0.21461177675295287,0.21461177675295287,0.21461177675295287,0.21461177675295287,0.21461177675295287,0.21461177675295287,0.21461177675295287,0.21461177675295287,0.21461177675295287,0.21461177675295287,0.21461177675295287,0.21461177675295287,0.21461177675295287,0.21461177675295287,0.21461177675295287,0.21461177675295287,0.21461177675295287,0.21461177675295287,0.21461177675295287,0.21461177675295287,0.21461177675295287,0.21461177675295287,0.21461177675295287,0.21461177675295287,0.21461177675295287,0.21461177675295287,0.21461177675295287,0.21461177675295287,0.21461177675295287,0.21461177675295287,0.21283292635907988,0.21283292635907988,0.21283292635907988,0.21283292635907988,0.21283292635907988,0.21283292635907988,0.21283292635907988,0.21283292635907988,0.21283292635907988,0.21283292635907988,0.21283292635907988,0.21283292635907988,0.21283292635907988,0.21283292635907988,0.21283292635907988,0.21283292635907988,0.21283292635907988,0.21283292635907988,0.21283292635907988,0.21283292635907988,0.21283292635907988,0.21283292635907988,0.21283292635907988,0.21283292635907988,0.21283292635907988,0.21283292635907988,0.21283292635907988,0.21283292635907988,0.21283292635907988,0.21283292635907988,0.21283292635907988,0.21283292635907988,0.21283292635907988,0.21283292635907988,0.21283292635907988,0.21283292635907988,0.21283292635907988,0.21283292635907988,0.21283292635907988,0.21283292635907988,0.21283292635907988,0.21283292635907988,0.21283292635907988,0.21283292635907988,0.21283292635907988,0.21283292635907988,0.21283292635907988,0.21283292635907988,0.21283292635907988,0.21283292635907988,0.21283292635907988,0.21283292635907988,0.21283292635907988,0.21283292635907988,0.21283292635907988,0.21283292635907988,0.21283292635907988,0.21283292635907988,0.21283292635907988,0.21283292635907988,0.21283292635907988,0.21283292635907988,0.21283292635907988,0.21283292635907988,0.21283292635907988,0.21283292635907988,0.21283292635907988,0.21283292635907988,0.21283292635907988,0.21283292635907988,0.21283292635907988,0.21283292635907988,0.21283292635907988,0.21283292635907988,0.21283292635907988,0.21283292635907988,0.21283292635907988,0.21283292635907988,0.21283292635907988,0.21283292635907988,0.21283292635907988,0.21283292635907988,0.21283292635907988,0.21283292635907988,0.21283292635907988,0.21283292635907988,0.21283292635907988,0.21283292635907988,0.21283292635907988,0.21283292635907988,0.21283292635907988,0.21283292635907988,0.21283292635907988,0.21283292635907988,0.21283292635907988,0.21283292635907988,0.21283292635907988,0.21283292635907988,0.21283292635907988,0.21283292635907988,0.21035228847911824,0.21035228847911824,0.21035228847911824,0.21035228847911824,0.21035228847911824,0.21035228847911824,0.21035228847911824,0.21035228847911824,0.21035228847911824,0.21035228847911824,0.21035228847911824,0.21035228847911824,0.21035228847911824,0.21035228847911824,0.21035228847911824,0.21035228847911824,0.21035228847911824,0.21035228847911824,0.21035228847911824,0.21035228847911824,0.21035228847911824,0.21035228847911824,0.21035228847911824,0.21035228847911824,0.21035228847911824,0.21035228847911824,0.21035228847911824,0.21035228847911824,0.21035228847911824,0.21035228847911824,0.21035228847911824,0.21035228847911824,0.21035228847911824,0.21035228847911824,0.21035228847911824,0.21035228847911824,0.21035228847911824,0.21035228847911824,0.21035228847911824,0.21035228847911824,0.21035228847911824,0.21035228847911824,0.21035228847911824,0.21035228847911824,0.21035228847911824,0.21035228847911824,0.21035228847911824,0.21035228847911824,0.21035228847911824,0.21035228847911824,0.21035228847911824,0.21035228847911824,0.21035228847911824,0.21035228847911824,0.21035228847911824,0.21035228847911824,0.21035228847911824,0.21035228847911824,0.21035228847911824,0.21035228847911824,0.21035228847911824,0.21035228847911824,0.21035228847911824,0.21035228847911824,0.21035228847911824,0.21035228847911824,0.21035228847911824,0.21035228847911824,0.21035228847911824,0.21035228847911824,0.21035228847911824,0.21035228847911824,0.21035228847911824,0.21035228847911824,0.21035228847911824,0.21035228847911824,0.21035228847911824,0.21035228847911824,0.21035228847911824,0.21035228847911824,0.21035228847911824,0.21035228847911824,0.21035228847911824,0.21035228847911824,0.21035228847911824,0.21035228847911824,0.21035228847911824,0.21035228847911824,0.21035228847911824,0.21035228847911824,0.21035228847911824,0.21035228847911824,0.21035228847911824,0.21035228847911824,0.21035228847911824,0.21035228847911824,0.21035228847911824,0.21035228847911824,0.21035228847911824,0.21035228847911824,0.20849124738746697,0.20849124738746697,0.20849124738746697,0.20849124738746697,0.20849124738746697,0.20849124738746697,0.20849124738746697,0.20849124738746697,0.20849124738746697,0.20849124738746697,0.20849124738746697,0.20849124738746697,0.20849124738746697,0.20849124738746697,0.20849124738746697,0.20849124738746697,0.20849124738746697,0.20849124738746697,0.20849124738746697,0.20849124738746697,0.20849124738746697,0.20849124738746697,0.20849124738746697,0.20849124738746697,0.20849124738746697,0.20849124738746697,0.20849124738746697,0.20849124738746697,0.20849124738746697,0.20849124738746697,0.20849124738746697,0.20849124738746697,0.20849124738746697,0.20849124738746697,0.20849124738746697,0.20849124738746697,0.20849124738746697,0.20849124738746697,0.20849124738746697,0.20849124738746697,0.20849124738746697,0.20849124738746697,0.20849124738746697,0.20849124738746697,0.20849124738746697,0.20849124738746697,0.20849124738746697,0.20849124738746697,0.20849124738746697,0.20849124738746697,0.20849124738746697,0.20849124738746697,0.20849124738746697,0.20849124738746697,0.20849124738746697,0.20849124738746697,0.20849124738746697,0.20849124738746697,0.20849124738746697,0.20849124738746697,0.20849124738746697,0.20849124738746697,0.20849124738746697,0.20849124738746697,0.20849124738746697,0.20849124738746697,0.20849124738746697,0.20849124738746697,0.20849124738746697,0.20849124738746697,0.20849124738746697,0.20849124738746697,0.20849124738746697,0.20849124738746697,0.20849124738746697,0.20849124738746697,0.20849124738746697,0.20849124738746697,0.20849124738746697,0.20849124738746697,0.20849124738746697,0.20849124738746697,0.20849124738746697,0.20849124738746697,0.20849124738746697,0.20849124738746697,0.20849124738746697,0.20849124738746697,0.20849124738746697,0.20849124738746697,0.20849124738746697,0.20849124738746697,0.20849124738746697,0.20849124738746697,0.20849124738746697,0.20849124738746697,0.20849124738746697,0.20849124738746697,0.20849124738746697,0.20849124738746697,0.2062401673319759,0.2062401673319759,0.2062401673319759,0.2062401673319759,0.2062401673319759,0.2062401673319759,0.2062401673319759,0.2062401673319759,0.2062401673319759,0.2062401673319759,0.2062401673319759,0.2062401673319759,0.2062401673319759,0.2062401673319759,0.2062401673319759,0.2062401673319759,0.2062401673319759,0.2062401673319759,0.2062401673319759,0.2062401673319759,0.2062401673319759,0.2062401673319759,0.2062401673319759,0.2062401673319759,0.2062401673319759,0.2062401673319759,0.2062401673319759,0.2062401673319759,0.2062401673319759,0.2062401673319759,0.2062401673319759,0.2062401673319759,0.2062401673319759,0.2062401673319759,0.2062401673319759,0.2062401673319759,0.2062401673319759,0.2062401673319759,0.2062401673319759,0.2062401673319759,0.2062401673319759,0.2062401673319759,0.2062401673319759,0.2062401673319759,0.2062401673319759,0.2062401673319759,0.2062401673319759,0.2062401673319759,0.2062401673319759,0.2062401673319759,0.2062401673319759,0.2062401673319759,0.2062401673319759,0.2062401673319759,0.2062401673319759,0.2062401673319759,0.2062401673319759,0.2062401673319759,0.2062401673319759,0.2062401673319759,0.2062401673319759,0.2062401673319759,0.2062401673319759,0.2062401673319759,0.2062401673319759,0.2062401673319759,0.2062401673319759,0.2062401673319759,0.2062401673319759,0.2062401673319759,0.2062401673319759,0.2062401673319759,0.2062401673319759,0.2062401673319759,0.2062401673319759,0.2062401673319759,0.2062401673319759,0.2062401673319759,0.2062401673319759,0.2062401673319759,0.2062401673319759,0.2062401673319759,0.2062401673319759,0.2062401673319759,0.2062401673319759,0.2062401673319759,0.2062401673319759,0.2062401673319759,0.2062401673319759,0.2062401673319759,0.2062401673319759,0.2062401673319759,0.2062401673319759,0.2062401673319759,0.2062401673319759,0.2062401673319759,0.2062401673319759,0.2062401673319759,0.2062401673319759,0.2062401673319759,0.20445410680492987,0.20445410680492987,0.20445410680492987,0.20445410680492987,0.20445410680492987,0.20445410680492987,0.20445410680492987,0.20445410680492987,0.20445410680492987,0.20445410680492987,0.20445410680492987,0.20445410680492987,0.20445410680492987,0.20445410680492987,0.20445410680492987,0.20445410680492987,0.20445410680492987,0.20445410680492987,0.20445410680492987,0.20445410680492987,0.20445410680492987,0.20445410680492987,0.20445410680492987,0.20445410680492987,0.20445410680492987,0.20445410680492987,0.20445410680492987,0.20445410680492987,0.20445410680492987,0.20445410680492987,0.20445410680492987,0.20445410680492987,0.20445410680492987,0.20445410680492987,0.20445410680492987,0.20445410680492987,0.20445410680492987,0.20445410680492987,0.20445410680492987,0.20445410680492987,0.20445410680492987,0.20445410680492987,0.20445410680492987,0.20445410680492987,0.20445410680492987,0.20445410680492987,0.20445410680492987,0.20445410680492987,0.20445410680492987,0.20445410680492987,0.20445410680492987,0.20445410680492987,0.20445410680492987,0.20445410680492987,0.20445410680492987,0.20445410680492987,0.20445410680492987,0.20445410680492987,0.20445410680492987,0.20445410680492987,0.20445410680492987,0.20445410680492987,0.20445410680492987,0.20445410680492987,0.20445410680492987,0.20445410680492987,0.20445410680492987,0.20445410680492987,0.20445410680492987,0.20445410680492987,0.20445410680492987,0.20445410680492987,0.20445410680492987,0.20445410680492987,0.20445410680492987,0.20445410680492987,0.20445410680492987,0.20445410680492987,0.20445410680492987,0.20445410680492987,0.20445410680492987,0.20445410680492987,0.20445410680492987,0.20445410680492987,0.20445410680492987,0.20445410680492987,0.20445410680492987,0.20445410680492987,0.20445410680492987,0.20445410680492987,0.20445410680492987,0.20445410680492987,0.20445410680492987,0.20445410680492987,0.20445410680492987,0.20445410680492987,0.20445410680492987,0.20445410680492987,0.20445410680492987,0.20445410680492987,0.20251598811441707,0.20251598811441707,0.20251598811441707,0.20251598811441707,0.20251598811441707,0.20251598811441707,0.20251598811441707,0.20251598811441707,0.20251598811441707,0.20251598811441707,0.20251598811441707,0.20251598811441707,0.20251598811441707,0.20251598811441707,0.20251598811441707,0.20251598811441707,0.20251598811441707,0.20251598811441707,0.20251598811441707,0.20251598811441707,0.20251598811441707,0.20251598811441707,0.20251598811441707,0.20251598811441707,0.20251598811441707,0.20251598811441707,0.20251598811441707,0.20251598811441707,0.20251598811441707,0.20251598811441707,0.20251598811441707,0.20251598811441707,0.20251598811441707,0.20251598811441707,0.20251598811441707,0.20251598811441707,0.20251598811441707,0.20251598811441707,0.20251598811441707,0.20251598811441707,0.20251598811441707,0.20251598811441707,0.20251598811441707,0.20251598811441707,0.20251598811441707,0.20251598811441707,0.20251598811441707,0.20251598811441707,0.20251598811441707,0.20251598811441707,0.20251598811441707,0.20251598811441707,0.20251598811441707,0.20251598811441707,0.20251598811441707,0.20251598811441707,0.20251598811441707,0.20251598811441707,0.20251598811441707,0.20251598811441707,0.20251598811441707,0.20251598811441707,0.20251598811441707,0.20251598811441707,0.20251598811441707,0.20251598811441707,0.20251598811441707,0.20251598811441707,0.20251598811441707,0.20251598811441707,0.20251598811441707,0.20251598811441707,0.20251598811441707,0.20251598811441707,0.20251598811441707,0.20251598811441707,0.20251598811441707,0.20251598811441707,0.20251598811441707,0.20251598811441707,0.20251598811441707,0.20251598811441707,0.20251598811441707,0.20251598811441707,0.20251598811441707,0.20251598811441707,0.20251598811441707,0.20251598811441707,0.20251598811441707,0.20251598811441707,0.20251598811441707,0.20251598811441707,0.20251598811441707,0.20251598811441707,0.20251598811441707,0.20251598811441707,0.20251598811441707,0.20251598811441707,0.20251598811441707,0.20251598811441707,0.20133157913185246,0.20133157913185246,0.20133157913185246,0.20133157913185246,0.20133157913185246,0.20133157913185246,0.20133157913185246,0.20133157913185246,0.20133157913185246,0.20133157913185246,0.20133157913185246,0.20133157913185246,0.20133157913185246,0.20133157913185246,0.20133157913185246,0.20133157913185246,0.20133157913185246,0.20133157913185246,0.20133157913185246,0.20133157913185246,0.20133157913185246,0.20133157913185246,0.20133157913185246,0.20133157913185246,0.20133157913185246,0.20133157913185246,0.20133157913185246,0.20133157913185246,0.20133157913185246,0.20133157913185246,0.20133157913185246,0.20133157913185246,0.20133157913185246,0.20133157913185246,0.20133157913185246,0.20133157913185246,0.20133157913185246,0.20133157913185246,0.20133157913185246,0.20133157913185246,0.20133157913185246,0.20133157913185246,0.20133157913185246,0.20133157913185246,0.20133157913185246,0.20133157913185246,0.20133157913185246,0.20133157913185246,0.20133157913185246,0.20133157913185246,0.20133157913185246,0.20133157913185246,0.20133157913185246,0.20133157913185246,0.20133157913185246,0.20133157913185246,0.20133157913185246,0.20133157913185246,0.20133157913185246,0.20133157913185246,0.20133157913185246,0.20133157913185246,0.20133157913185246,0.20133157913185246,0.20133157913185246,0.20133157913185246,0.20133157913185246,0.20133157913185246,0.20133157913185246,0.20133157913185246,0.20133157913185246,0.20133157913185246,0.20133157913185246,0.20133157913185246,0.20133157913185246,0.20133157913185246,0.20133157913185246,0.20133157913185246,0.20133157913185246,0.20133157913185246,0.20133157913185246,0.20133157913185246,0.20133157913185246,0.20133157913185246,0.20133157913185246,0.20133157913185246,0.20133157913185246,0.20133157913185246,0.20133157913185246,0.20133157913185246,0.20133157913185246,0.20133157913185246,0.20133157913185246,0.20133157913185246,0.20133157913185246,0.20133157913185246,0.20133157913185246,0.20133157913185246,0.20133157913185246,0.20133157913185246,0.1988826961554491,0.1988826961554491,0.1988826961554491,0.1988826961554491,0.1988826961554491,0.1988826961554491,0.1988826961554491,0.1988826961554491,0.1988826961554491,0.1988826961554491,0.1988826961554491,0.1988826961554491,0.1988826961554491,0.1988826961554491,0.1988826961554491,0.1988826961554491,0.1988826961554491,0.1988826961554491,0.1988826961554491,0.1988826961554491,0.1988826961554491,0.1988826961554491,0.1988826961554491,0.1988826961554491,0.1988826961554491,0.1988826961554491,0.1988826961554491,0.1988826961554491,0.1988826961554491,0.1988826961554491,0.1988826961554491,0.1988826961554491,0.1988826961554491,0.1988826961554491,0.1988826961554491,0.1988826961554491,0.1988826961554491,0.1988826961554491,0.1988826961554491,0.1988826961554491,0.1988826961554491,0.1988826961554491,0.1988826961554491,0.1988826961554491,0.1988826961554491,0.1988826961554491,0.1988826961554491,0.1988826961554491,0.1988826961554491,0.1988826961554491,0.1988826961554491,0.1988826961554491,0.1988826961554491,0.1988826961554491,0.1988826961554491,0.1988826961554491,0.1988826961554491,0.1988826961554491,0.1988826961554491,0.1988826961554491,0.1988826961554491,0.1988826961554491,0.1988826961554491,0.1988826961554491,0.1988826961554491,0.1988826961554491,0.1988826961554491,0.1988826961554491,0.1988826961554491,0.1988826961554491,0.1988826961554491,0.1988826961554491,0.1988826961554491,0.1988826961554491,0.1988826961554491,0.1988826961554491,0.1988826961554491,0.1988826961554491,0.1988826961554491,0.1988826961554491,0.1988826961554491,0.1988826961554491,0.1988826961554491,0.1988826961554491,0.1988826961554491,0.1988826961554491,0.1988826961554491,0.1988826961554491,0.1988826961554491,0.1988826961554491,0.1988826961554491,0.1988826961554491,0.1988826961554491,0.1988826961554491,0.1988826961554491,0.1988826961554491,0.1988826961554491,0.1988826961554491,0.1988826961554491,0.1988826961554491,0.1972704261984197,0.1972704261984197,0.1972704261984197,0.1972704261984197,0.1972704261984197,0.1972704261984197,0.1972704261984197,0.1972704261984197,0.1972704261984197,0.1972704261984197,0.1972704261984197,0.1972704261984197,0.1972704261984197,0.1972704261984197,0.1972704261984197,0.1972704261984197,0.1972704261984197,0.1972704261984197,0.1972704261984197,0.1972704261984197,0.1972704261984197,0.1972704261984197,0.1972704261984197,0.1972704261984197,0.1972704261984197,0.1972704261984197,0.1972704261984197,0.1972704261984197,0.1972704261984197,0.1972704261984197,0.1972704261984197,0.1972704261984197,0.1972704261984197,0.1972704261984197,0.1972704261984197,0.1972704261984197,0.1972704261984197,0.1972704261984197,0.1972704261984197,0.1972704261984197,0.1972704261984197,0.1972704261984197,0.1972704261984197,0.1972704261984197,0.1972704261984197,0.1972704261984197,0.1972704261984197,0.1972704261984197,0.1972704261984197,0.1972704261984197,0.1972704261984197,0.1972704261984197,0.1972704261984197,0.1972704261984197,0.1972704261984197,0.1972704261984197,0.1972704261984197,0.1972704261984197,0.1972704261984197,0.1972704261984197,0.1972704261984197,0.1972704261984197,0.1972704261984197,0.1972704261984197,0.1972704261984197,0.1972704261984197,0.1972704261984197,0.1972704261984197,0.1972704261984197,0.1972704261984197,0.1972704261984197,0.1972704261984197,0.1972704261984197,0.1972704261984197,0.1972704261984197,0.1972704261984197,0.1972704261984197,0.1972704261984197,0.1972704261984197,0.1972704261984197,0.1972704261984197,0.1972704261984197,0.1972704261984197,0.1972704261984197,0.1972704261984197,0.1972704261984197,0.1972704261984197,0.1972704261984197,0.1972704261984197,0.1972704261984197,0.1972704261984197,0.1972704261984197,0.1972704261984197,0.1972704261984197,0.1972704261984197,0.1972704261984197,0.1972704261984197,0.1972704261984197,0.1972704261984197,0.1972704261984197,0.19429511738598018,0.19429511738598018,0.19429511738598018,0.19429511738598018,0.19429511738598018,0.19429511738598018,0.19429511738598018,0.19429511738598018,0.19429511738598018,0.19429511738598018,0.19429511738598018,0.19429511738598018,0.19429511738598018,0.19429511738598018,0.19429511738598018,0.19429511738598018,0.19429511738598018,0.19429511738598018,0.19429511738598018,0.19429511738598018,0.19429511738598018,0.19429511738598018,0.19429511738598018,0.19429511738598018,0.19429511738598018,0.19429511738598018,0.19429511738598018,0.19429511738598018,0.19429511738598018,0.19429511738598018,0.19429511738598018,0.19429511738598018,0.19429511738598018,0.19429511738598018,0.19429511738598018,0.19429511738598018,0.19429511738598018,0.19429511738598018,0.19429511738598018,0.19429511738598018,0.19429511738598018,0.19429511738598018,0.19429511738598018,0.19429511738598018,0.19429511738598018,0.19429511738598018,0.19429511738598018,0.19429511738598018,0.19429511738598018,0.19429511738598018,0.19429511738598018,0.19429511738598018,0.19429511738598018,0.19429511738598018,0.19429511738598018,0.19429511738598018,0.19429511738598018,0.19429511738598018,0.19429511738598018,0.19429511738598018,0.19429511738598018,0.19429511738598018,0.19429511738598018,0.19429511738598018,0.19429511738598018,0.19429511738598018,0.19429511738598018,0.19429511738598018,0.19429511738598018,0.19429511738598018,0.19429511738598018,0.19429511738598018,0.19429511738598018,0.19429511738598018,0.19429511738598018,0.19429511738598018,0.19429511738598018,0.19429511738598018,0.19429511738598018,0.19429511738598018,0.19429511738598018,0.19429511738598018,0.19429511738598018,0.19429511738598018,0.19429511738598018,0.19429511738598018,0.19429511738598018,0.19429511738598018,0.19429511738598018,0.19429511738598018,0.19429511738598018,0.19429511738598018,0.19429511738598018,0.19429511738598018,0.19429511738598018,0.19429511738598018,0.19429511738598018,0.19429511738598018,0.19429511738598018,0.19429511738598018,0.1921134990942076,0.1921134990942076,0.1921134990942076,0.1921134990942076,0.1921134990942076,0.1921134990942076,0.1921134990942076,0.1921134990942076,0.1921134990942076,0.1921134990942076,0.1921134990942076,0.1921134990942076,0.1921134990942076,0.1921134990942076,0.1921134990942076,0.1921134990942076,0.1921134990942076,0.1921134990942076,0.1921134990942076,0.1921134990942076,0.1921134990942076,0.1921134990942076,0.1921134990942076,0.1921134990942076,0.1921134990942076,0.1921134990942076,0.1921134990942076,0.1921134990942076,0.1921134990942076,0.1921134990942076,0.1921134990942076,0.1921134990942076,0.1921134990942076,0.1921134990942076,0.1921134990942076,0.1921134990942076,0.1921134990942076,0.1921134990942076,0.1921134990942076,0.1921134990942076,0.1921134990942076,0.1921134990942076,0.1921134990942076,0.1921134990942076,0.1921134990942076,0.1921134990942076,0.1921134990942076,0.1921134990942076,0.1921134990942076,0.1921134990942076,0.1921134990942076,0.1921134990942076,0.1921134990942076,0.1921134990942076,0.1921134990942076,0.1921134990942076,0.1921134990942076,0.1921134990942076,0.1921134990942076,0.1921134990942076,0.1921134990942076,0.1921134990942076,0.1921134990942076,0.1921134990942076,0.1921134990942076,0.1921134990942076,0.1921134990942076,0.1921134990942076,0.1921134990942076,0.1921134990942076,0.1921134990942076,0.1921134990942076,0.1921134990942076,0.1921134990942076,0.1921134990942076,0.1921134990942076,0.1921134990942076,0.1921134990942076,0.1921134990942076,0.1921134990942076,0.1921134990942076,0.1921134990942076,0.1921134990942076,0.1921134990942076,0.1921134990942076,0.1921134990942076,0.1921134990942076,0.1921134990942076,0.1921134990942076,0.1921134990942076,0.1921134990942076,0.1921134990942076,0.1921134990942076,0.1921134990942076,0.1921134990942076,0.1921134990942076,0.1921134990942076,0.1921134990942076,0.1921134990942076,0.1921134990942076],\"type\":\"scatter\"},{\"mode\":\"lines\",\"name\":\"Test Loss\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500,501,502,503,504,505,506,507,508,509,510,511,512,513,514,515,516,517,518,519,520,521,522,523,524,525,526,527,528,529,530,531,532,533,534,535,536,537,538,539,540,541,542,543,544,545,546,547,548,549,550,551,552,553,554,555,556,557,558,559,560,561,562,563,564,565,566,567,568,569,570,571,572,573,574,575,576,577,578,579,580,581,582,583,584,585,586,587,588,589,590,591,592,593,594,595,596,597,598,599,600,601,602,603,604,605,606,607,608,609,610,611,612,613,614,615,616,617,618,619,620,621,622,623,624,625,626,627,628,629,630,631,632,633,634,635,636,637,638,639,640,641,642,643,644,645,646,647,648,649,650,651,652,653,654,655,656,657,658,659,660,661,662,663,664,665,666,667,668,669,670,671,672,673,674,675,676,677,678,679,680,681,682,683,684,685,686,687,688,689,690,691,692,693,694,695,696,697,698,699,700,701,702,703,704,705,706,707,708,709,710,711,712,713,714,715,716,717,718,719,720,721,722,723,724,725,726,727,728,729,730,731,732,733,734,735,736,737,738,739,740,741,742,743,744,745,746,747,748,749,750,751,752,753,754,755,756,757,758,759,760,761,762,763,764,765,766,767,768,769,770,771,772,773,774,775,776,777,778,779,780,781,782,783,784,785,786,787,788,789,790,791,792,793,794,795,796,797,798,799,800,801,802,803,804,805,806,807,808,809,810,811,812,813,814,815,816,817,818,819,820,821,822,823,824,825,826,827,828,829,830,831,832,833,834,835,836,837,838,839,840,841,842,843,844,845,846,847,848,849,850,851,852,853,854,855,856,857,858,859,860,861,862,863,864,865,866,867,868,869,870,871,872,873,874,875,876,877,878,879,880,881,882,883,884,885,886,887,888,889,890,891,892,893,894,895,896,897,898,899,900,901,902,903,904,905,906,907,908,909,910,911,912,913,914,915,916,917,918,919,920,921,922,923,924,925,926,927,928,929,930,931,932,933,934,935,936,937,938,939,940,941,942,943,944,945,946,947,948,949,950,951,952,953,954,955,956,957,958,959,960,961,962,963,964,965,966,967,968,969,970,971,972,973,974,975,976,977,978,979,980,981,982,983,984,985,986,987,988,989,990,991,992,993,994,995,996,997,998,999,1000,1001,1002,1003,1004,1005,1006,1007,1008,1009,1010,1011,1012,1013,1014,1015,1016,1017,1018,1019,1020,1021,1022,1023,1024,1025,1026,1027,1028,1029,1030,1031,1032,1033,1034,1035,1036,1037,1038,1039,1040,1041,1042,1043,1044,1045,1046,1047,1048,1049,1050,1051,1052,1053,1054,1055,1056,1057,1058,1059,1060,1061,1062,1063,1064,1065,1066,1067,1068,1069,1070,1071,1072,1073,1074,1075,1076,1077,1078,1079,1080,1081,1082,1083,1084,1085,1086,1087,1088,1089,1090,1091,1092,1093,1094,1095,1096,1097,1098,1099,1100,1101,1102,1103,1104,1105,1106,1107,1108,1109,1110,1111,1112,1113,1114,1115,1116,1117,1118,1119,1120,1121,1122,1123,1124,1125,1126,1127,1128,1129,1130,1131,1132,1133,1134,1135,1136,1137,1138,1139,1140,1141,1142,1143,1144,1145,1146,1147,1148,1149,1150,1151,1152,1153,1154,1155,1156,1157,1158,1159,1160,1161,1162,1163,1164,1165,1166,1167,1168,1169,1170,1171,1172,1173,1174,1175,1176,1177,1178,1179,1180,1181,1182,1183,1184,1185,1186,1187,1188,1189,1190,1191,1192,1193,1194,1195,1196,1197,1198,1199,1200,1201,1202,1203,1204,1205,1206,1207,1208,1209,1210,1211,1212,1213,1214,1215,1216,1217,1218,1219,1220,1221,1222,1223,1224,1225,1226,1227,1228,1229,1230,1231,1232,1233,1234,1235,1236,1237,1238,1239,1240,1241,1242,1243,1244,1245,1246,1247,1248,1249,1250,1251,1252,1253,1254,1255,1256,1257,1258,1259,1260,1261,1262,1263,1264,1265,1266,1267,1268,1269,1270,1271,1272,1273,1274,1275,1276,1277,1278,1279,1280,1281,1282,1283,1284,1285,1286,1287,1288,1289,1290,1291,1292,1293,1294,1295,1296,1297,1298,1299,1300,1301,1302,1303,1304,1305,1306,1307,1308,1309,1310,1311,1312,1313,1314,1315,1316,1317,1318,1319,1320,1321,1322,1323,1324,1325,1326,1327,1328,1329,1330,1331,1332,1333,1334,1335,1336,1337,1338,1339,1340,1341,1342,1343,1344,1345,1346,1347,1348,1349,1350,1351,1352,1353,1354,1355,1356,1357,1358,1359,1360,1361,1362,1363,1364,1365,1366,1367,1368,1369,1370,1371,1372,1373,1374,1375,1376,1377,1378,1379,1380,1381,1382,1383,1384,1385,1386,1387,1388,1389,1390,1391,1392,1393,1394,1395,1396,1397,1398,1399,1400,1401,1402,1403,1404,1405,1406,1407,1408,1409,1410,1411,1412,1413,1414,1415,1416,1417,1418,1419,1420,1421,1422,1423,1424,1425,1426,1427,1428,1429,1430,1431,1432,1433,1434,1435,1436,1437,1438,1439,1440,1441,1442,1443,1444,1445,1446,1447,1448,1449,1450,1451,1452,1453,1454,1455,1456,1457,1458,1459,1460,1461,1462,1463,1464,1465,1466,1467,1468,1469,1470,1471,1472,1473,1474,1475,1476,1477,1478,1479,1480,1481,1482,1483,1484,1485,1486,1487,1488,1489,1490,1491,1492,1493,1494,1495,1496,1497,1498,1499,1500,1501,1502,1503,1504,1505,1506,1507,1508,1509,1510,1511,1512,1513,1514,1515,1516,1517,1518,1519,1520,1521,1522,1523,1524,1525,1526,1527,1528,1529,1530,1531,1532,1533,1534,1535,1536,1537,1538,1539,1540,1541,1542,1543,1544,1545,1546,1547,1548,1549,1550,1551,1552,1553,1554,1555,1556,1557,1558,1559,1560,1561,1562,1563,1564,1565,1566,1567,1568,1569,1570,1571,1572,1573,1574,1575,1576,1577,1578,1579,1580,1581,1582,1583,1584,1585,1586,1587,1588,1589,1590,1591,1592,1593,1594,1595,1596,1597,1598,1599,1600,1601,1602,1603,1604,1605,1606,1607,1608,1609,1610,1611,1612,1613,1614,1615,1616,1617,1618,1619,1620,1621,1622,1623,1624,1625,1626,1627,1628,1629,1630,1631,1632,1633,1634,1635,1636,1637,1638,1639,1640,1641,1642,1643,1644,1645,1646,1647,1648,1649,1650,1651,1652,1653,1654,1655,1656,1657,1658,1659,1660,1661,1662,1663,1664,1665,1666,1667,1668,1669,1670,1671,1672,1673,1674,1675,1676,1677,1678,1679,1680,1681,1682,1683,1684,1685,1686,1687,1688,1689,1690,1691,1692,1693,1694,1695,1696,1697,1698,1699,1700,1701,1702,1703,1704,1705,1706,1707,1708,1709,1710,1711,1712,1713,1714,1715,1716,1717,1718,1719,1720,1721,1722,1723,1724,1725,1726,1727,1728,1729,1730,1731,1732,1733,1734,1735,1736,1737,1738,1739,1740,1741,1742,1743,1744,1745,1746,1747,1748,1749,1750,1751,1752,1753,1754,1755,1756,1757,1758,1759,1760,1761,1762,1763,1764,1765,1766,1767,1768,1769,1770,1771,1772,1773,1774,1775,1776,1777,1778,1779,1780,1781,1782,1783,1784,1785,1786,1787,1788,1789,1790,1791,1792,1793,1794,1795,1796,1797,1798,1799,1800,1801,1802,1803,1804,1805,1806,1807,1808,1809,1810,1811,1812,1813,1814,1815,1816,1817,1818,1819,1820,1821,1822,1823,1824,1825,1826,1827,1828,1829,1830,1831,1832,1833,1834,1835,1836,1837,1838,1839,1840,1841,1842,1843,1844,1845,1846,1847,1848,1849,1850,1851,1852,1853,1854,1855,1856,1857,1858,1859,1860,1861,1862,1863,1864,1865,1866,1867,1868,1869,1870,1871,1872,1873,1874,1875,1876,1877,1878,1879,1880,1881,1882,1883,1884,1885,1886,1887,1888,1889,1890,1891,1892,1893,1894,1895,1896,1897,1898,1899,1900,1901,1902,1903,1904,1905,1906,1907,1908,1909,1910,1911,1912,1913,1914,1915,1916,1917,1918,1919,1920,1921,1922,1923,1924,1925,1926,1927,1928,1929,1930,1931,1932,1933,1934,1935,1936,1937,1938,1939,1940,1941,1942,1943,1944,1945,1946,1947,1948,1949,1950,1951,1952,1953,1954,1955,1956,1957,1958,1959,1960,1961,1962,1963,1964,1965,1966,1967,1968,1969,1970,1971,1972,1973,1974,1975,1976,1977,1978,1979,1980,1981,1982,1983,1984,1985,1986,1987,1988,1989,1990,1991,1992,1993,1994,1995,1996,1997,1998,1999,2000,2001,2002,2003,2004,2005,2006,2007,2008,2009,2010,2011,2012,2013,2014,2015,2016,2017,2018,2019,2020,2021,2022,2023,2024,2025,2026,2027,2028,2029,2030,2031,2032,2033,2034,2035,2036,2037,2038,2039,2040,2041,2042,2043,2044,2045,2046,2047,2048,2049,2050,2051,2052,2053,2054,2055,2056,2057,2058,2059,2060,2061,2062,2063,2064,2065,2066,2067,2068,2069,2070,2071,2072,2073,2074,2075,2076,2077,2078,2079,2080,2081,2082,2083,2084,2085,2086,2087,2088,2089,2090,2091,2092,2093,2094,2095,2096,2097,2098,2099,2100,2101,2102,2103,2104,2105,2106,2107,2108,2109,2110,2111,2112,2113,2114,2115,2116,2117,2118,2119,2120,2121,2122,2123,2124,2125,2126,2127,2128,2129,2130,2131,2132,2133,2134,2135,2136,2137,2138,2139,2140,2141,2142,2143,2144,2145,2146,2147,2148,2149,2150,2151,2152,2153,2154,2155,2156,2157,2158,2159,2160,2161,2162,2163,2164,2165,2166,2167,2168,2169,2170,2171,2172,2173,2174,2175,2176,2177,2178,2179,2180,2181,2182,2183,2184,2185,2186,2187,2188,2189,2190,2191,2192,2193,2194,2195,2196,2197,2198,2199,2200,2201,2202,2203,2204,2205,2206,2207,2208,2209,2210,2211,2212,2213,2214,2215,2216,2217,2218,2219,2220,2221,2222,2223,2224,2225,2226,2227,2228,2229,2230,2231,2232,2233,2234,2235,2236,2237,2238,2239,2240,2241,2242,2243,2244,2245,2246,2247,2248,2249,2250,2251,2252,2253,2254,2255,2256,2257,2258,2259,2260,2261,2262,2263,2264,2265,2266,2267,2268,2269,2270,2271,2272,2273,2274,2275,2276,2277,2278,2279,2280,2281,2282,2283,2284,2285,2286,2287,2288,2289,2290,2291,2292,2293,2294,2295,2296,2297,2298,2299,2300,2301,2302,2303,2304,2305,2306,2307,2308,2309,2310,2311,2312,2313,2314,2315,2316,2317,2318,2319,2320,2321,2322,2323,2324,2325,2326,2327,2328,2329,2330,2331,2332,2333,2334,2335,2336,2337,2338,2339,2340,2341,2342,2343,2344,2345,2346,2347,2348,2349,2350,2351,2352,2353,2354,2355,2356,2357,2358,2359,2360,2361,2362,2363,2364,2365,2366,2367,2368,2369,2370,2371,2372,2373,2374,2375,2376,2377,2378,2379,2380,2381,2382,2383,2384,2385,2386,2387,2388,2389,2390,2391,2392,2393,2394,2395,2396,2397,2398,2399,2400,2401,2402,2403,2404,2405,2406,2407,2408,2409,2410,2411,2412,2413,2414,2415,2416,2417,2418,2419,2420,2421,2422,2423,2424,2425,2426,2427,2428,2429,2430,2431,2432,2433,2434,2435,2436,2437,2438,2439,2440,2441,2442,2443,2444,2445,2446,2447,2448,2449,2450,2451,2452,2453,2454,2455,2456,2457,2458,2459,2460,2461,2462,2463,2464,2465,2466,2467,2468,2469,2470,2471,2472,2473,2474,2475,2476,2477,2478,2479,2480,2481,2482,2483,2484,2485,2486,2487,2488,2489,2490,2491,2492,2493,2494,2495,2496,2497,2498,2499,2500,2501,2502,2503,2504,2505,2506,2507,2508,2509,2510,2511,2512,2513,2514,2515,2516,2517,2518,2519,2520,2521,2522,2523,2524,2525,2526,2527,2528,2529,2530,2531,2532,2533,2534,2535,2536,2537,2538,2539,2540,2541,2542,2543,2544,2545,2546,2547,2548,2549,2550,2551,2552,2553,2554,2555,2556,2557,2558,2559,2560,2561,2562,2563,2564,2565,2566,2567,2568,2569,2570,2571,2572,2573,2574,2575,2576,2577,2578,2579,2580,2581,2582,2583,2584,2585,2586,2587,2588,2589,2590,2591,2592,2593,2594,2595,2596,2597,2598,2599,2600,2601,2602,2603,2604,2605,2606,2607,2608,2609,2610,2611,2612,2613,2614,2615,2616,2617,2618,2619,2620,2621,2622,2623,2624,2625,2626,2627,2628,2629,2630,2631,2632,2633,2634,2635,2636,2637,2638,2639,2640,2641,2642,2643,2644,2645,2646,2647,2648,2649,2650,2651,2652,2653,2654,2655,2656,2657,2658,2659,2660,2661,2662,2663,2664,2665,2666,2667,2668,2669,2670,2671,2672,2673,2674,2675,2676,2677,2678,2679,2680,2681,2682,2683,2684,2685,2686,2687,2688,2689,2690,2691,2692,2693,2694,2695,2696,2697,2698,2699,2700,2701,2702,2703,2704,2705,2706,2707,2708,2709,2710,2711,2712,2713,2714,2715,2716,2717,2718,2719,2720,2721,2722,2723,2724,2725,2726,2727,2728,2729,2730,2731,2732,2733,2734,2735,2736,2737,2738,2739,2740,2741,2742,2743,2744,2745,2746,2747,2748,2749,2750,2751,2752,2753,2754,2755,2756,2757,2758,2759,2760,2761,2762,2763,2764,2765,2766,2767,2768,2769,2770,2771,2772,2773,2774,2775,2776,2777,2778,2779,2780,2781,2782,2783,2784,2785,2786,2787,2788,2789,2790,2791,2792,2793,2794,2795,2796,2797,2798,2799,2800,2801,2802,2803,2804,2805,2806,2807,2808,2809,2810,2811,2812,2813,2814,2815,2816,2817,2818,2819,2820,2821,2822,2823,2824,2825,2826,2827,2828,2829,2830,2831,2832,2833,2834,2835,2836,2837,2838,2839,2840,2841,2842,2843,2844,2845,2846,2847,2848,2849,2850,2851,2852,2853,2854,2855,2856,2857,2858,2859,2860,2861,2862,2863,2864,2865,2866,2867,2868,2869,2870,2871,2872,2873,2874,2875,2876,2877,2878,2879,2880,2881,2882,2883,2884,2885,2886,2887,2888,2889,2890,2891,2892,2893,2894,2895,2896,2897,2898,2899,2900,2901,2902,2903,2904,2905,2906,2907,2908,2909,2910,2911,2912,2913,2914,2915,2916,2917,2918,2919,2920,2921,2922,2923,2924,2925,2926,2927,2928,2929,2930,2931,2932,2933,2934,2935,2936,2937,2938,2939,2940,2941,2942,2943,2944,2945,2946,2947,2948,2949,2950,2951,2952,2953,2954,2955,2956,2957,2958,2959,2960,2961,2962,2963,2964,2965,2966,2967,2968,2969,2970,2971,2972,2973,2974,2975,2976,2977,2978,2979,2980,2981,2982,2983,2984,2985,2986,2987,2988,2989,2990,2991,2992,2993,2994,2995,2996,2997,2998,2999,3000,3001,3002,3003,3004,3005,3006,3007,3008,3009,3010,3011,3012,3013,3014,3015,3016,3017,3018,3019,3020,3021,3022,3023,3024,3025,3026,3027,3028,3029,3030,3031,3032,3033,3034,3035,3036,3037,3038,3039,3040,3041,3042,3043,3044,3045,3046,3047,3048,3049,3050,3051,3052,3053,3054,3055,3056,3057,3058,3059,3060,3061,3062,3063,3064,3065,3066,3067,3068,3069,3070,3071,3072,3073,3074,3075,3076,3077,3078,3079,3080,3081,3082,3083,3084,3085,3086,3087,3088,3089,3090,3091,3092,3093,3094,3095,3096,3097,3098,3099,3100,3101,3102,3103,3104,3105,3106,3107,3108,3109,3110,3111,3112,3113,3114,3115,3116,3117,3118,3119,3120,3121,3122,3123,3124,3125,3126,3127,3128,3129,3130,3131,3132,3133,3134,3135,3136,3137,3138,3139,3140,3141,3142,3143,3144,3145,3146,3147,3148,3149,3150,3151,3152,3153,3154,3155,3156,3157,3158,3159,3160,3161,3162,3163,3164,3165,3166,3167,3168,3169,3170,3171,3172,3173,3174,3175,3176,3177,3178,3179,3180,3181,3182,3183,3184,3185,3186,3187,3188,3189,3190,3191,3192,3193,3194,3195,3196,3197,3198,3199,3200],\"y\":[0.6857417180682673,0.6857417180682673,0.6857417180682673,0.6857417180682673,0.6857417180682673,0.6857417180682673,0.6857417180682673,0.6857417180682673,0.6857417180682673,0.6857417180682673,0.6857417180682673,0.6857417180682673,0.6857417180682673,0.6857417180682673,0.6857417180682673,0.6857417180682673,0.6857417180682673,0.6857417180682673,0.6857417180682673,0.6857417180682673,0.6857417180682673,0.6857417180682673,0.6857417180682673,0.6857417180682673,0.6857417180682673,0.6857417180682673,0.6857417180682673,0.6857417180682673,0.6857417180682673,0.6857417180682673,0.6857417180682673,0.6857417180682673,0.6857417180682673,0.6857417180682673,0.6857417180682673,0.6857417180682673,0.6857417180682673,0.6857417180682673,0.6857417180682673,0.6857417180682673,0.6857417180682673,0.6857417180682673,0.6857417180682673,0.6857417180682673,0.6857417180682673,0.6857417180682673,0.6857417180682673,0.6857417180682673,0.6857417180682673,0.6857417180682673,0.6857417180682673,0.6857417180682673,0.6857417180682673,0.6857417180682673,0.6857417180682673,0.6857417180682673,0.6857417180682673,0.6857417180682673,0.6857417180682673,0.6857417180682673,0.6857417180682673,0.6857417180682673,0.6857417180682673,0.6857417180682673,0.6857417180682673,0.6857417180682673,0.6857417180682673,0.6857417180682673,0.6857417180682673,0.6857417180682673,0.6857417180682673,0.6857417180682673,0.6857417180682673,0.6857417180682673,0.6857417180682673,0.6857417180682673,0.6857417180682673,0.6857417180682673,0.6857417180682673,0.6857417180682673,0.6857417180682673,0.6857417180682673,0.6857417180682673,0.6857417180682673,0.6857417180682673,0.6857417180682673,0.6857417180682673,0.6857417180682673,0.6857417180682673,0.6857417180682673,0.6857417180682673,0.6857417180682673,0.6857417180682673,0.6857417180682673,0.6857417180682673,0.6857417180682673,0.6857417180682673,0.6857417180682673,0.6857417180682673,0.6857417180682673,0.5382739478590512,0.5382739478590512,0.5382739478590512,0.5382739478590512,0.5382739478590512,0.5382739478590512,0.5382739478590512,0.5382739478590512,0.5382739478590512,0.5382739478590512,0.5382739478590512,0.5382739478590512,0.5382739478590512,0.5382739478590512,0.5382739478590512,0.5382739478590512,0.5382739478590512,0.5382739478590512,0.5382739478590512,0.5382739478590512,0.5382739478590512,0.5382739478590512,0.5382739478590512,0.5382739478590512,0.5382739478590512,0.5382739478590512,0.5382739478590512,0.5382739478590512,0.5382739478590512,0.5382739478590512,0.5382739478590512,0.5382739478590512,0.5382739478590512,0.5382739478590512,0.5382739478590512,0.5382739478590512,0.5382739478590512,0.5382739478590512,0.5382739478590512,0.5382739478590512,0.5382739478590512,0.5382739478590512,0.5382739478590512,0.5382739478590512,0.5382739478590512,0.5382739478590512,0.5382739478590512,0.5382739478590512,0.5382739478590512,0.5382739478590512,0.5382739478590512,0.5382739478590512,0.5382739478590512,0.5382739478590512,0.5382739478590512,0.5382739478590512,0.5382739478590512,0.5382739478590512,0.5382739478590512,0.5382739478590512,0.5382739478590512,0.5382739478590512,0.5382739478590512,0.5382739478590512,0.5382739478590512,0.5382739478590512,0.5382739478590512,0.5382739478590512,0.5382739478590512,0.5382739478590512,0.5382739478590512,0.5382739478590512,0.5382739478590512,0.5382739478590512,0.5382739478590512,0.5382739478590512,0.5382739478590512,0.5382739478590512,0.5382739478590512,0.5382739478590512,0.5382739478590512,0.5382739478590512,0.5382739478590512,0.5382739478590512,0.5382739478590512,0.5382739478590512,0.5382739478590512,0.5382739478590512,0.5382739478590512,0.5382739478590512,0.5382739478590512,0.5382739478590512,0.5382739478590512,0.5382739478590512,0.5382739478590512,0.5382739478590512,0.5382739478590512,0.5382739478590512,0.5382739478590512,0.5382739478590512,0.35510677762618853,0.35510677762618853,0.35510677762618853,0.35510677762618853,0.35510677762618853,0.35510677762618853,0.35510677762618853,0.35510677762618853,0.35510677762618853,0.35510677762618853,0.35510677762618853,0.35510677762618853,0.35510677762618853,0.35510677762618853,0.35510677762618853,0.35510677762618853,0.35510677762618853,0.35510677762618853,0.35510677762618853,0.35510677762618853,0.35510677762618853,0.35510677762618853,0.35510677762618853,0.35510677762618853,0.35510677762618853,0.35510677762618853,0.35510677762618853,0.35510677762618853,0.35510677762618853,0.35510677762618853,0.35510677762618853,0.35510677762618853,0.35510677762618853,0.35510677762618853,0.35510677762618853,0.35510677762618853,0.35510677762618853,0.35510677762618853,0.35510677762618853,0.35510677762618853,0.35510677762618853,0.35510677762618853,0.35510677762618853,0.35510677762618853,0.35510677762618853,0.35510677762618853,0.35510677762618853,0.35510677762618853,0.35510677762618853,0.35510677762618853,0.35510677762618853,0.35510677762618853,0.35510677762618853,0.35510677762618853,0.35510677762618853,0.35510677762618853,0.35510677762618853,0.35510677762618853,0.35510677762618853,0.35510677762618853,0.35510677762618853,0.35510677762618853,0.35510677762618853,0.35510677762618853,0.35510677762618853,0.35510677762618853,0.35510677762618853,0.35510677762618853,0.35510677762618853,0.35510677762618853,0.35510677762618853,0.35510677762618853,0.35510677762618853,0.35510677762618853,0.35510677762618853,0.35510677762618853,0.35510677762618853,0.35510677762618853,0.35510677762618853,0.35510677762618853,0.35510677762618853,0.35510677762618853,0.35510677762618853,0.35510677762618853,0.35510677762618853,0.35510677762618853,0.35510677762618853,0.35510677762618853,0.35510677762618853,0.35510677762618853,0.35510677762618853,0.35510677762618853,0.35510677762618853,0.35510677762618853,0.35510677762618853,0.35510677762618853,0.35510677762618853,0.35510677762618853,0.35510677762618853,0.35510677762618853,0.3459565170930059,0.3459565170930059,0.3459565170930059,0.3459565170930059,0.3459565170930059,0.3459565170930059,0.3459565170930059,0.3459565170930059,0.3459565170930059,0.3459565170930059,0.3459565170930059,0.3459565170930059,0.3459565170930059,0.3459565170930059,0.3459565170930059,0.3459565170930059,0.3459565170930059,0.3459565170930059,0.3459565170930059,0.3459565170930059,0.3459565170930059,0.3459565170930059,0.3459565170930059,0.3459565170930059,0.3459565170930059,0.3459565170930059,0.3459565170930059,0.3459565170930059,0.3459565170930059,0.3459565170930059,0.3459565170930059,0.3459565170930059,0.3459565170930059,0.3459565170930059,0.3459565170930059,0.3459565170930059,0.3459565170930059,0.3459565170930059,0.3459565170930059,0.3459565170930059,0.3459565170930059,0.3459565170930059,0.3459565170930059,0.3459565170930059,0.3459565170930059,0.3459565170930059,0.3459565170930059,0.3459565170930059,0.3459565170930059,0.3459565170930059,0.3459565170930059,0.3459565170930059,0.3459565170930059,0.3459565170930059,0.3459565170930059,0.3459565170930059,0.3459565170930059,0.3459565170930059,0.3459565170930059,0.3459565170930059,0.3459565170930059,0.3459565170930059,0.3459565170930059,0.3459565170930059,0.3459565170930059,0.3459565170930059,0.3459565170930059,0.3459565170930059,0.3459565170930059,0.3459565170930059,0.3459565170930059,0.3459565170930059,0.3459565170930059,0.3459565170930059,0.3459565170930059,0.3459565170930059,0.3459565170930059,0.3459565170930059,0.3459565170930059,0.3459565170930059,0.3459565170930059,0.3459565170930059,0.3459565170930059,0.3459565170930059,0.3459565170930059,0.3459565170930059,0.3459565170930059,0.3459565170930059,0.3459565170930059,0.3459565170930059,0.3459565170930059,0.3459565170930059,0.3459565170930059,0.3459565170930059,0.3459565170930059,0.3459565170930059,0.3459565170930059,0.3459565170930059,0.3459565170930059,0.3459565170930059,0.3450277110969182,0.3450277110969182,0.3450277110969182,0.3450277110969182,0.3450277110969182,0.3450277110969182,0.3450277110969182,0.3450277110969182,0.3450277110969182,0.3450277110969182,0.3450277110969182,0.3450277110969182,0.3450277110969182,0.3450277110969182,0.3450277110969182,0.3450277110969182,0.3450277110969182,0.3450277110969182,0.3450277110969182,0.3450277110969182,0.3450277110969182,0.3450277110969182,0.3450277110969182,0.3450277110969182,0.3450277110969182,0.3450277110969182,0.3450277110969182,0.3450277110969182,0.3450277110969182,0.3450277110969182,0.3450277110969182,0.3450277110969182,0.3450277110969182,0.3450277110969182,0.3450277110969182,0.3450277110969182,0.3450277110969182,0.3450277110969182,0.3450277110969182,0.3450277110969182,0.3450277110969182,0.3450277110969182,0.3450277110969182,0.3450277110969182,0.3450277110969182,0.3450277110969182,0.3450277110969182,0.3450277110969182,0.3450277110969182,0.3450277110969182,0.3450277110969182,0.3450277110969182,0.3450277110969182,0.3450277110969182,0.3450277110969182,0.3450277110969182,0.3450277110969182,0.3450277110969182,0.3450277110969182,0.3450277110969182,0.3450277110969182,0.3450277110969182,0.3450277110969182,0.3450277110969182,0.3450277110969182,0.3450277110969182,0.3450277110969182,0.3450277110969182,0.3450277110969182,0.3450277110969182,0.3450277110969182,0.3450277110969182,0.3450277110969182,0.3450277110969182,0.3450277110969182,0.3450277110969182,0.3450277110969182,0.3450277110969182,0.3450277110969182,0.3450277110969182,0.3450277110969182,0.3450277110969182,0.3450277110969182,0.3450277110969182,0.3450277110969182,0.3450277110969182,0.3450277110969182,0.3450277110969182,0.3450277110969182,0.3450277110969182,0.3450277110969182,0.3450277110969182,0.3450277110969182,0.3450277110969182,0.3450277110969182,0.3450277110969182,0.3450277110969182,0.3450277110969182,0.3450277110969182,0.3450277110969182,0.34213770745558614,0.34213770745558614,0.34213770745558614,0.34213770745558614,0.34213770745558614,0.34213770745558614,0.34213770745558614,0.34213770745558614,0.34213770745558614,0.34213770745558614,0.34213770745558614,0.34213770745558614,0.34213770745558614,0.34213770745558614,0.34213770745558614,0.34213770745558614,0.34213770745558614,0.34213770745558614,0.34213770745558614,0.34213770745558614,0.34213770745558614,0.34213770745558614,0.34213770745558614,0.34213770745558614,0.34213770745558614,0.34213770745558614,0.34213770745558614,0.34213770745558614,0.34213770745558614,0.34213770745558614,0.34213770745558614,0.34213770745558614,0.34213770745558614,0.34213770745558614,0.34213770745558614,0.34213770745558614,0.34213770745558614,0.34213770745558614,0.34213770745558614,0.34213770745558614,0.34213770745558614,0.34213770745558614,0.34213770745558614,0.34213770745558614,0.34213770745558614,0.34213770745558614,0.34213770745558614,0.34213770745558614,0.34213770745558614,0.34213770745558614,0.34213770745558614,0.34213770745558614,0.34213770745558614,0.34213770745558614,0.34213770745558614,0.34213770745558614,0.34213770745558614,0.34213770745558614,0.34213770745558614,0.34213770745558614,0.34213770745558614,0.34213770745558614,0.34213770745558614,0.34213770745558614,0.34213770745558614,0.34213770745558614,0.34213770745558614,0.34213770745558614,0.34213770745558614,0.34213770745558614,0.34213770745558614,0.34213770745558614,0.34213770745558614,0.34213770745558614,0.34213770745558614,0.34213770745558614,0.34213770745558614,0.34213770745558614,0.34213770745558614,0.34213770745558614,0.34213770745558614,0.34213770745558614,0.34213770745558614,0.34213770745558614,0.34213770745558614,0.34213770745558614,0.34213770745558614,0.34213770745558614,0.34213770745558614,0.34213770745558614,0.34213770745558614,0.34213770745558614,0.34213770745558614,0.34213770745558614,0.34213770745558614,0.34213770745558614,0.34213770745558614,0.34213770745558614,0.34213770745558614,0.34213770745558614,0.3329628069954601,0.3329628069954601,0.3329628069954601,0.3329628069954601,0.3329628069954601,0.3329628069954601,0.3329628069954601,0.3329628069954601,0.3329628069954601,0.3329628069954601,0.3329628069954601,0.3329628069954601,0.3329628069954601,0.3329628069954601,0.3329628069954601,0.3329628069954601,0.3329628069954601,0.3329628069954601,0.3329628069954601,0.3329628069954601,0.3329628069954601,0.3329628069954601,0.3329628069954601,0.3329628069954601,0.3329628069954601,0.3329628069954601,0.3329628069954601,0.3329628069954601,0.3329628069954601,0.3329628069954601,0.3329628069954601,0.3329628069954601,0.3329628069954601,0.3329628069954601,0.3329628069954601,0.3329628069954601,0.3329628069954601,0.3329628069954601,0.3329628069954601,0.3329628069954601,0.3329628069954601,0.3329628069954601,0.3329628069954601,0.3329628069954601,0.3329628069954601,0.3329628069954601,0.3329628069954601,0.3329628069954601,0.3329628069954601,0.3329628069954601,0.3329628069954601,0.3329628069954601,0.3329628069954601,0.3329628069954601,0.3329628069954601,0.3329628069954601,0.3329628069954601,0.3329628069954601,0.3329628069954601,0.3329628069954601,0.3329628069954601,0.3329628069954601,0.3329628069954601,0.3329628069954601,0.3329628069954601,0.3329628069954601,0.3329628069954601,0.3329628069954601,0.3329628069954601,0.3329628069954601,0.3329628069954601,0.3329628069954601,0.3329628069954601,0.3329628069954601,0.3329628069954601,0.3329628069954601,0.3329628069954601,0.3329628069954601,0.3329628069954601,0.3329628069954601,0.3329628069954601,0.3329628069954601,0.3329628069954601,0.3329628069954601,0.3329628069954601,0.3329628069954601,0.3329628069954601,0.3329628069954601,0.3329628069954601,0.3329628069954601,0.3329628069954601,0.3329628069954601,0.3329628069954601,0.3329628069954601,0.3329628069954601,0.3329628069954601,0.3329628069954601,0.3329628069954601,0.3329628069954601,0.3329628069954601,0.3190619494199942,0.3190619494199942,0.3190619494199942,0.3190619494199942,0.3190619494199942,0.3190619494199942,0.3190619494199942,0.3190619494199942,0.3190619494199942,0.3190619494199942,0.3190619494199942,0.3190619494199942,0.3190619494199942,0.3190619494199942,0.3190619494199942,0.3190619494199942,0.3190619494199942,0.3190619494199942,0.3190619494199942,0.3190619494199942,0.3190619494199942,0.3190619494199942,0.3190619494199942,0.3190619494199942,0.3190619494199942,0.3190619494199942,0.3190619494199942,0.3190619494199942,0.3190619494199942,0.3190619494199942,0.3190619494199942,0.3190619494199942,0.3190619494199942,0.3190619494199942,0.3190619494199942,0.3190619494199942,0.3190619494199942,0.3190619494199942,0.3190619494199942,0.3190619494199942,0.3190619494199942,0.3190619494199942,0.3190619494199942,0.3190619494199942,0.3190619494199942,0.3190619494199942,0.3190619494199942,0.3190619494199942,0.3190619494199942,0.3190619494199942,0.3190619494199942,0.3190619494199942,0.3190619494199942,0.3190619494199942,0.3190619494199942,0.3190619494199942,0.3190619494199942,0.3190619494199942,0.3190619494199942,0.3190619494199942,0.3190619494199942,0.3190619494199942,0.3190619494199942,0.3190619494199942,0.3190619494199942,0.3190619494199942,0.3190619494199942,0.3190619494199942,0.3190619494199942,0.3190619494199942,0.3190619494199942,0.3190619494199942,0.3190619494199942,0.3190619494199942,0.3190619494199942,0.3190619494199942,0.3190619494199942,0.3190619494199942,0.3190619494199942,0.3190619494199942,0.3190619494199942,0.3190619494199942,0.3190619494199942,0.3190619494199942,0.3190619494199942,0.3190619494199942,0.3190619494199942,0.3190619494199942,0.3190619494199942,0.3190619494199942,0.3190619494199942,0.3190619494199942,0.3190619494199942,0.3190619494199942,0.3190619494199942,0.3190619494199942,0.3190619494199942,0.3190619494199942,0.3190619494199942,0.3190619494199942,0.31280468402345457,0.31280468402345457,0.31280468402345457,0.31280468402345457,0.31280468402345457,0.31280468402345457,0.31280468402345457,0.31280468402345457,0.31280468402345457,0.31280468402345457,0.31280468402345457,0.31280468402345457,0.31280468402345457,0.31280468402345457,0.31280468402345457,0.31280468402345457,0.31280468402345457,0.31280468402345457,0.31280468402345457,0.31280468402345457,0.31280468402345457,0.31280468402345457,0.31280468402345457,0.31280468402345457,0.31280468402345457,0.31280468402345457,0.31280468402345457,0.31280468402345457,0.31280468402345457,0.31280468402345457,0.31280468402345457,0.31280468402345457,0.31280468402345457,0.31280468402345457,0.31280468402345457,0.31280468402345457,0.31280468402345457,0.31280468402345457,0.31280468402345457,0.31280468402345457,0.31280468402345457,0.31280468402345457,0.31280468402345457,0.31280468402345457,0.31280468402345457,0.31280468402345457,0.31280468402345457,0.31280468402345457,0.31280468402345457,0.31280468402345457,0.31280468402345457,0.31280468402345457,0.31280468402345457,0.31280468402345457,0.31280468402345457,0.31280468402345457,0.31280468402345457,0.31280468402345457,0.31280468402345457,0.31280468402345457,0.31280468402345457,0.31280468402345457,0.31280468402345457,0.31280468402345457,0.31280468402345457,0.31280468402345457,0.31280468402345457,0.31280468402345457,0.31280468402345457,0.31280468402345457,0.31280468402345457,0.31280468402345457,0.31280468402345457,0.31280468402345457,0.31280468402345457,0.31280468402345457,0.31280468402345457,0.31280468402345457,0.31280468402345457,0.31280468402345457,0.31280468402345457,0.31280468402345457,0.31280468402345457,0.31280468402345457,0.31280468402345457,0.31280468402345457,0.31280468402345457,0.31280468402345457,0.31280468402345457,0.31280468402345457,0.31280468402345457,0.31280468402345457,0.31280468402345457,0.31280468402345457,0.31280468402345457,0.31280468402345457,0.31280468402345457,0.31280468402345457,0.31280468402345457,0.31280468402345457,0.3074320829401411,0.3074320829401411,0.3074320829401411,0.3074320829401411,0.3074320829401411,0.3074320829401411,0.3074320829401411,0.3074320829401411,0.3074320829401411,0.3074320829401411,0.3074320829401411,0.3074320829401411,0.3074320829401411,0.3074320829401411,0.3074320829401411,0.3074320829401411,0.3074320829401411,0.3074320829401411,0.3074320829401411,0.3074320829401411,0.3074320829401411,0.3074320829401411,0.3074320829401411,0.3074320829401411,0.3074320829401411,0.3074320829401411,0.3074320829401411,0.3074320829401411,0.3074320829401411,0.3074320829401411,0.3074320829401411,0.3074320829401411,0.3074320829401411,0.3074320829401411,0.3074320829401411,0.3074320829401411,0.3074320829401411,0.3074320829401411,0.3074320829401411,0.3074320829401411,0.3074320829401411,0.3074320829401411,0.3074320829401411,0.3074320829401411,0.3074320829401411,0.3074320829401411,0.3074320829401411,0.3074320829401411,0.3074320829401411,0.3074320829401411,0.3074320829401411,0.3074320829401411,0.3074320829401411,0.3074320829401411,0.3074320829401411,0.3074320829401411,0.3074320829401411,0.3074320829401411,0.3074320829401411,0.3074320829401411,0.3074320829401411,0.3074320829401411,0.3074320829401411,0.3074320829401411,0.3074320829401411,0.3074320829401411,0.3074320829401411,0.3074320829401411,0.3074320829401411,0.3074320829401411,0.3074320829401411,0.3074320829401411,0.3074320829401411,0.3074320829401411,0.3074320829401411,0.3074320829401411,0.3074320829401411,0.3074320829401411,0.3074320829401411,0.3074320829401411,0.3074320829401411,0.3074320829401411,0.3074320829401411,0.3074320829401411,0.3074320829401411,0.3074320829401411,0.3074320829401411,0.3074320829401411,0.3074320829401411,0.3074320829401411,0.3074320829401411,0.3074320829401411,0.3074320829401411,0.3074320829401411,0.3074320829401411,0.3074320829401411,0.3074320829401411,0.3074320829401411,0.3074320829401411,0.3074320829401411,0.30537392003826985,0.30537392003826985,0.30537392003826985,0.30537392003826985,0.30537392003826985,0.30537392003826985,0.30537392003826985,0.30537392003826985,0.30537392003826985,0.30537392003826985,0.30537392003826985,0.30537392003826985,0.30537392003826985,0.30537392003826985,0.30537392003826985,0.30537392003826985,0.30537392003826985,0.30537392003826985,0.30537392003826985,0.30537392003826985,0.30537392003826985,0.30537392003826985,0.30537392003826985,0.30537392003826985,0.30537392003826985,0.30537392003826985,0.30537392003826985,0.30537392003826985,0.30537392003826985,0.30537392003826985,0.30537392003826985,0.30537392003826985,0.30537392003826985,0.30537392003826985,0.30537392003826985,0.30537392003826985,0.30537392003826985,0.30537392003826985,0.30537392003826985,0.30537392003826985,0.30537392003826985,0.30537392003826985,0.30537392003826985,0.30537392003826985,0.30537392003826985,0.30537392003826985,0.30537392003826985,0.30537392003826985,0.30537392003826985,0.30537392003826985,0.30537392003826985,0.30537392003826985,0.30537392003826985,0.30537392003826985,0.30537392003826985,0.30537392003826985,0.30537392003826985,0.30537392003826985,0.30537392003826985,0.30537392003826985,0.30537392003826985,0.30537392003826985,0.30537392003826985,0.30537392003826985,0.30537392003826985,0.30537392003826985,0.30537392003826985,0.30537392003826985,0.30537392003826985,0.30537392003826985,0.30537392003826985,0.30537392003826985,0.30537392003826985,0.30537392003826985,0.30537392003826985,0.30537392003826985,0.30537392003826985,0.30537392003826985,0.30537392003826985,0.30537392003826985,0.30537392003826985,0.30537392003826985,0.30537392003826985,0.30537392003826985,0.30537392003826985,0.30537392003826985,0.30537392003826985,0.30537392003826985,0.30537392003826985,0.30537392003826985,0.30537392003826985,0.30537392003826985,0.30537392003826985,0.30537392003826985,0.30537392003826985,0.30537392003826985,0.30537392003826985,0.30537392003826985,0.30537392003826985,0.30537392003826985,0.3051408066478531,0.3051408066478531,0.3051408066478531,0.3051408066478531,0.3051408066478531,0.3051408066478531,0.3051408066478531,0.3051408066478531,0.3051408066478531,0.3051408066478531,0.3051408066478531,0.3051408066478531,0.3051408066478531,0.3051408066478531,0.3051408066478531,0.3051408066478531,0.3051408066478531,0.3051408066478531,0.3051408066478531,0.3051408066478531,0.3051408066478531,0.3051408066478531,0.3051408066478531,0.3051408066478531,0.3051408066478531,0.3051408066478531,0.3051408066478531,0.3051408066478531,0.3051408066478531,0.3051408066478531,0.3051408066478531,0.3051408066478531,0.3051408066478531,0.3051408066478531,0.3051408066478531,0.3051408066478531,0.3051408066478531,0.3051408066478531,0.3051408066478531,0.3051408066478531,0.3051408066478531,0.3051408066478531,0.3051408066478531,0.3051408066478531,0.3051408066478531,0.3051408066478531,0.3051408066478531,0.3051408066478531,0.3051408066478531,0.3051408066478531,0.3051408066478531,0.3051408066478531,0.3051408066478531,0.3051408066478531,0.3051408066478531,0.3051408066478531,0.3051408066478531,0.3051408066478531,0.3051408066478531,0.3051408066478531,0.3051408066478531,0.3051408066478531,0.3051408066478531,0.3051408066478531,0.3051408066478531,0.3051408066478531,0.3051408066478531,0.3051408066478531,0.3051408066478531,0.3051408066478531,0.3051408066478531,0.3051408066478531,0.3051408066478531,0.3051408066478531,0.3051408066478531,0.3051408066478531,0.3051408066478531,0.3051408066478531,0.3051408066478531,0.3051408066478531,0.3051408066478531,0.3051408066478531,0.3051408066478531,0.3051408066478531,0.3051408066478531,0.3051408066478531,0.3051408066478531,0.3051408066478531,0.3051408066478531,0.3051408066478531,0.3051408066478531,0.3051408066478531,0.3051408066478531,0.3051408066478531,0.3051408066478531,0.3051408066478531,0.3051408066478531,0.3051408066478531,0.3051408066478531,0.3051408066478531,0.3040876231926365,0.3040876231926365,0.3040876231926365,0.3040876231926365,0.3040876231926365,0.3040876231926365,0.3040876231926365,0.3040876231926365,0.3040876231926365,0.3040876231926365,0.3040876231926365,0.3040876231926365,0.3040876231926365,0.3040876231926365,0.3040876231926365,0.3040876231926365,0.3040876231926365,0.3040876231926365,0.3040876231926365,0.3040876231926365,0.3040876231926365,0.3040876231926365,0.3040876231926365,0.3040876231926365,0.3040876231926365,0.3040876231926365,0.3040876231926365,0.3040876231926365,0.3040876231926365,0.3040876231926365,0.3040876231926365,0.3040876231926365,0.3040876231926365,0.3040876231926365,0.3040876231926365,0.3040876231926365,0.3040876231926365,0.3040876231926365,0.3040876231926365,0.3040876231926365,0.3040876231926365,0.3040876231926365,0.3040876231926365,0.3040876231926365,0.3040876231926365,0.3040876231926365,0.3040876231926365,0.3040876231926365,0.3040876231926365,0.3040876231926365,0.3040876231926365,0.3040876231926365,0.3040876231926365,0.3040876231926365,0.3040876231926365,0.3040876231926365,0.3040876231926365,0.3040876231926365,0.3040876231926365,0.3040876231926365,0.3040876231926365,0.3040876231926365,0.3040876231926365,0.3040876231926365,0.3040876231926365,0.3040876231926365,0.3040876231926365,0.3040876231926365,0.3040876231926365,0.3040876231926365,0.3040876231926365,0.3040876231926365,0.3040876231926365,0.3040876231926365,0.3040876231926365,0.3040876231926365,0.3040876231926365,0.3040876231926365,0.3040876231926365,0.3040876231926365,0.3040876231926365,0.3040876231926365,0.3040876231926365,0.3040876231926365,0.3040876231926365,0.3040876231926365,0.3040876231926365,0.3040876231926365,0.3040876231926365,0.3040876231926365,0.3040876231926365,0.3040876231926365,0.3040876231926365,0.3040876231926365,0.3040876231926365,0.3040876231926365,0.3040876231926365,0.3040876231926365,0.3040876231926365,0.3040876231926365,0.30356331191095054,0.30356331191095054,0.30356331191095054,0.30356331191095054,0.30356331191095054,0.30356331191095054,0.30356331191095054,0.30356331191095054,0.30356331191095054,0.30356331191095054,0.30356331191095054,0.30356331191095054,0.30356331191095054,0.30356331191095054,0.30356331191095054,0.30356331191095054,0.30356331191095054,0.30356331191095054,0.30356331191095054,0.30356331191095054,0.30356331191095054,0.30356331191095054,0.30356331191095054,0.30356331191095054,0.30356331191095054,0.30356331191095054,0.30356331191095054,0.30356331191095054,0.30356331191095054,0.30356331191095054,0.30356331191095054,0.30356331191095054,0.30356331191095054,0.30356331191095054,0.30356331191095054,0.30356331191095054,0.30356331191095054,0.30356331191095054,0.30356331191095054,0.30356331191095054,0.30356331191095054,0.30356331191095054,0.30356331191095054,0.30356331191095054,0.30356331191095054,0.30356331191095054,0.30356331191095054,0.30356331191095054,0.30356331191095054,0.30356331191095054,0.30356331191095054,0.30356331191095054,0.30356331191095054,0.30356331191095054,0.30356331191095054,0.30356331191095054,0.30356331191095054,0.30356331191095054,0.30356331191095054,0.30356331191095054,0.30356331191095054,0.30356331191095054,0.30356331191095054,0.30356331191095054,0.30356331191095054,0.30356331191095054,0.30356331191095054,0.30356331191095054,0.30356331191095054,0.30356331191095054,0.30356331191095054,0.30356331191095054,0.30356331191095054,0.30356331191095054,0.30356331191095054,0.30356331191095054,0.30356331191095054,0.30356331191095054,0.30356331191095054,0.30356331191095054,0.30356331191095054,0.30356331191095054,0.30356331191095054,0.30356331191095054,0.30356331191095054,0.30356331191095054,0.30356331191095054,0.30356331191095054,0.30356331191095054,0.30356331191095054,0.30356331191095054,0.30356331191095054,0.30356331191095054,0.30356331191095054,0.30356331191095054,0.30356331191095054,0.30356331191095054,0.30356331191095054,0.30356331191095054,0.30356331191095054,0.3040799501968741,0.3040799501968741,0.3040799501968741,0.3040799501968741,0.3040799501968741,0.3040799501968741,0.3040799501968741,0.3040799501968741,0.3040799501968741,0.3040799501968741,0.3040799501968741,0.3040799501968741,0.3040799501968741,0.3040799501968741,0.3040799501968741,0.3040799501968741,0.3040799501968741,0.3040799501968741,0.3040799501968741,0.3040799501968741,0.3040799501968741,0.3040799501968741,0.3040799501968741,0.3040799501968741,0.3040799501968741,0.3040799501968741,0.3040799501968741,0.3040799501968741,0.3040799501968741,0.3040799501968741,0.3040799501968741,0.3040799501968741,0.3040799501968741,0.3040799501968741,0.3040799501968741,0.3040799501968741,0.3040799501968741,0.3040799501968741,0.3040799501968741,0.3040799501968741,0.3040799501968741,0.3040799501968741,0.3040799501968741,0.3040799501968741,0.3040799501968741,0.3040799501968741,0.3040799501968741,0.3040799501968741,0.3040799501968741,0.3040799501968741,0.3040799501968741,0.3040799501968741,0.3040799501968741,0.3040799501968741,0.3040799501968741,0.3040799501968741,0.3040799501968741,0.3040799501968741,0.3040799501968741,0.3040799501968741,0.3040799501968741,0.3040799501968741,0.3040799501968741,0.3040799501968741,0.3040799501968741,0.3040799501968741,0.3040799501968741,0.3040799501968741,0.3040799501968741,0.3040799501968741,0.3040799501968741,0.3040799501968741,0.3040799501968741,0.3040799501968741,0.3040799501968741,0.3040799501968741,0.3040799501968741,0.3040799501968741,0.3040799501968741,0.3040799501968741,0.3040799501968741,0.3040799501968741,0.3040799501968741,0.3040799501968741,0.3040799501968741,0.3040799501968741,0.3040799501968741,0.3040799501968741,0.3040799501968741,0.3040799501968741,0.3040799501968741,0.3040799501968741,0.3040799501968741,0.3040799501968741,0.3040799501968741,0.3040799501968741,0.3040799501968741,0.3040799501968741,0.3040799501968741,0.3040799501968741,0.3037078626269323,0.3037078626269323,0.3037078626269323,0.3037078626269323,0.3037078626269323,0.3037078626269323,0.3037078626269323,0.3037078626269323,0.3037078626269323,0.3037078626269323,0.3037078626269323,0.3037078626269323,0.3037078626269323,0.3037078626269323,0.3037078626269323,0.3037078626269323,0.3037078626269323,0.3037078626269323,0.3037078626269323,0.3037078626269323,0.3037078626269323,0.3037078626269323,0.3037078626269323,0.3037078626269323,0.3037078626269323,0.3037078626269323,0.3037078626269323,0.3037078626269323,0.3037078626269323,0.3037078626269323,0.3037078626269323,0.3037078626269323,0.3037078626269323,0.3037078626269323,0.3037078626269323,0.3037078626269323,0.3037078626269323,0.3037078626269323,0.3037078626269323,0.3037078626269323,0.3037078626269323,0.3037078626269323,0.3037078626269323,0.3037078626269323,0.3037078626269323,0.3037078626269323,0.3037078626269323,0.3037078626269323,0.3037078626269323,0.3037078626269323,0.3037078626269323,0.3037078626269323,0.3037078626269323,0.3037078626269323,0.3037078626269323,0.3037078626269323,0.3037078626269323,0.3037078626269323,0.3037078626269323,0.3037078626269323,0.3037078626269323,0.3037078626269323,0.3037078626269323,0.3037078626269323,0.3037078626269323,0.3037078626269323,0.3037078626269323,0.3037078626269323,0.3037078626269323,0.3037078626269323,0.3037078626269323,0.3037078626269323,0.3037078626269323,0.3037078626269323,0.3037078626269323,0.3037078626269323,0.3037078626269323,0.3037078626269323,0.3037078626269323,0.3037078626269323,0.3037078626269323,0.3037078626269323,0.3037078626269323,0.3037078626269323,0.3037078626269323,0.3037078626269323,0.3037078626269323,0.3037078626269323,0.3037078626269323,0.3037078626269323,0.3037078626269323,0.3037078626269323,0.3037078626269323,0.3037078626269323,0.3037078626269323,0.3037078626269323,0.3037078626269323,0.3037078626269323,0.3037078626269323,0.3037078626269323,0.3074746711799568,0.3074746711799568,0.3074746711799568,0.3074746711799568,0.3074746711799568,0.3074746711799568,0.3074746711799568,0.3074746711799568,0.3074746711799568,0.3074746711799568,0.3074746711799568,0.3074746711799568,0.3074746711799568,0.3074746711799568,0.3074746711799568,0.3074746711799568,0.3074746711799568,0.3074746711799568,0.3074746711799568,0.3074746711799568,0.3074746711799568,0.3074746711799568,0.3074746711799568,0.3074746711799568,0.3074746711799568,0.3074746711799568,0.3074746711799568,0.3074746711799568,0.3074746711799568,0.3074746711799568,0.3074746711799568,0.3074746711799568,0.3074746711799568,0.3074746711799568,0.3074746711799568,0.3074746711799568,0.3074746711799568,0.3074746711799568,0.3074746711799568,0.3074746711799568,0.3074746711799568,0.3074746711799568,0.3074746711799568,0.3074746711799568,0.3074746711799568,0.3074746711799568,0.3074746711799568,0.3074746711799568,0.3074746711799568,0.3074746711799568,0.3074746711799568,0.3074746711799568,0.3074746711799568,0.3074746711799568,0.3074746711799568,0.3074746711799568,0.3074746711799568,0.3074746711799568,0.3074746711799568,0.3074746711799568,0.3074746711799568,0.3074746711799568,0.3074746711799568,0.3074746711799568,0.3074746711799568,0.3074746711799568,0.3074746711799568,0.3074746711799568,0.3074746711799568,0.3074746711799568,0.3074746711799568,0.3074746711799568,0.3074746711799568,0.3074746711799568,0.3074746711799568,0.3074746711799568,0.3074746711799568,0.3074746711799568,0.3074746711799568,0.3074746711799568,0.3074746711799568,0.3074746711799568,0.3074746711799568,0.3074746711799568,0.3074746711799568,0.3074746711799568,0.3074746711799568,0.3074746711799568,0.3074746711799568,0.3074746711799568,0.3074746711799568,0.3074746711799568,0.3074746711799568,0.3074746711799568,0.3074746711799568,0.3074746711799568,0.3074746711799568,0.3074746711799568,0.3074746711799568,0.3074746711799568,0.309084055062631,0.309084055062631,0.309084055062631,0.309084055062631,0.309084055062631,0.309084055062631,0.309084055062631,0.309084055062631,0.309084055062631,0.309084055062631,0.309084055062631,0.309084055062631,0.309084055062631,0.309084055062631,0.309084055062631,0.309084055062631,0.309084055062631,0.309084055062631,0.309084055062631,0.309084055062631,0.309084055062631,0.309084055062631,0.309084055062631,0.309084055062631,0.309084055062631,0.309084055062631,0.309084055062631,0.309084055062631,0.309084055062631,0.309084055062631,0.309084055062631,0.309084055062631,0.309084055062631,0.309084055062631,0.309084055062631,0.309084055062631,0.309084055062631,0.309084055062631,0.309084055062631,0.309084055062631,0.309084055062631,0.309084055062631,0.309084055062631,0.309084055062631,0.309084055062631,0.309084055062631,0.309084055062631,0.309084055062631,0.309084055062631,0.309084055062631,0.309084055062631,0.309084055062631,0.309084055062631,0.309084055062631,0.309084055062631,0.309084055062631,0.309084055062631,0.309084055062631,0.309084055062631,0.309084055062631,0.309084055062631,0.309084055062631,0.309084055062631,0.309084055062631,0.309084055062631,0.309084055062631,0.309084055062631,0.309084055062631,0.309084055062631,0.309084055062631,0.309084055062631,0.309084055062631,0.309084055062631,0.309084055062631,0.309084055062631,0.309084055062631,0.309084055062631,0.309084055062631,0.309084055062631,0.309084055062631,0.309084055062631,0.309084055062631,0.309084055062631,0.309084055062631,0.309084055062631,0.309084055062631,0.309084055062631,0.309084055062631,0.309084055062631,0.309084055062631,0.309084055062631,0.309084055062631,0.309084055062631,0.309084055062631,0.309084055062631,0.309084055062631,0.309084055062631,0.309084055062631,0.309084055062631,0.309084055062631,0.3087129370178583,0.3087129370178583,0.3087129370178583,0.3087129370178583,0.3087129370178583,0.3087129370178583,0.3087129370178583,0.3087129370178583,0.3087129370178583,0.3087129370178583,0.3087129370178583,0.3087129370178583,0.3087129370178583,0.3087129370178583,0.3087129370178583,0.3087129370178583,0.3087129370178583,0.3087129370178583,0.3087129370178583,0.3087129370178583,0.3087129370178583,0.3087129370178583,0.3087129370178583,0.3087129370178583,0.3087129370178583,0.3087129370178583,0.3087129370178583,0.3087129370178583,0.3087129370178583,0.3087129370178583,0.3087129370178583,0.3087129370178583,0.3087129370178583,0.3087129370178583,0.3087129370178583,0.3087129370178583,0.3087129370178583,0.3087129370178583,0.3087129370178583,0.3087129370178583,0.3087129370178583,0.3087129370178583,0.3087129370178583,0.3087129370178583,0.3087129370178583,0.3087129370178583,0.3087129370178583,0.3087129370178583,0.3087129370178583,0.3087129370178583,0.3087129370178583,0.3087129370178583,0.3087129370178583,0.3087129370178583,0.3087129370178583,0.3087129370178583,0.3087129370178583,0.3087129370178583,0.3087129370178583,0.3087129370178583,0.3087129370178583,0.3087129370178583,0.3087129370178583,0.3087129370178583,0.3087129370178583,0.3087129370178583,0.3087129370178583,0.3087129370178583,0.3087129370178583,0.3087129370178583,0.3087129370178583,0.3087129370178583,0.3087129370178583,0.3087129370178583,0.3087129370178583,0.3087129370178583,0.3087129370178583,0.3087129370178583,0.3087129370178583,0.3087129370178583,0.3087129370178583,0.3087129370178583,0.3087129370178583,0.3087129370178583,0.3087129370178583,0.3087129370178583,0.3087129370178583,0.3087129370178583,0.3087129370178583,0.3087129370178583,0.3087129370178583,0.3087129370178583,0.3087129370178583,0.3087129370178583,0.3087129370178583,0.3087129370178583,0.3087129370178583,0.3087129370178583,0.3087129370178583,0.3087129370178583,0.30855018111436044,0.30855018111436044,0.30855018111436044,0.30855018111436044,0.30855018111436044,0.30855018111436044,0.30855018111436044,0.30855018111436044,0.30855018111436044,0.30855018111436044,0.30855018111436044,0.30855018111436044,0.30855018111436044,0.30855018111436044,0.30855018111436044,0.30855018111436044,0.30855018111436044,0.30855018111436044,0.30855018111436044,0.30855018111436044,0.30855018111436044,0.30855018111436044,0.30855018111436044,0.30855018111436044,0.30855018111436044,0.30855018111436044,0.30855018111436044,0.30855018111436044,0.30855018111436044,0.30855018111436044,0.30855018111436044,0.30855018111436044,0.30855018111436044,0.30855018111436044,0.30855018111436044,0.30855018111436044,0.30855018111436044,0.30855018111436044,0.30855018111436044,0.30855018111436044,0.30855018111436044,0.30855018111436044,0.30855018111436044,0.30855018111436044,0.30855018111436044,0.30855018111436044,0.30855018111436044,0.30855018111436044,0.30855018111436044,0.30855018111436044,0.30855018111436044,0.30855018111436044,0.30855018111436044,0.30855018111436044,0.30855018111436044,0.30855018111436044,0.30855018111436044,0.30855018111436044,0.30855018111436044,0.30855018111436044,0.30855018111436044,0.30855018111436044,0.30855018111436044,0.30855018111436044,0.30855018111436044,0.30855018111436044,0.30855018111436044,0.30855018111436044,0.30855018111436044,0.30855018111436044,0.30855018111436044,0.30855018111436044,0.30855018111436044,0.30855018111436044,0.30855018111436044,0.30855018111436044,0.30855018111436044,0.30855018111436044,0.30855018111436044,0.30855018111436044,0.30855018111436044,0.30855018111436044,0.30855018111436044,0.30855018111436044,0.30855018111436044,0.30855018111436044,0.30855018111436044,0.30855018111436044,0.30855018111436044,0.30855018111436044,0.30855018111436044,0.30855018111436044,0.30855018111436044,0.30855018111436044,0.30855018111436044,0.30855018111436044,0.30855018111436044,0.30855018111436044,0.30855018111436044,0.30855018111436044,0.3109475322290194,0.3109475322290194,0.3109475322290194,0.3109475322290194,0.3109475322290194,0.3109475322290194,0.3109475322290194,0.3109475322290194,0.3109475322290194,0.3109475322290194,0.3109475322290194,0.3109475322290194,0.3109475322290194,0.3109475322290194,0.3109475322290194,0.3109475322290194,0.3109475322290194,0.3109475322290194,0.3109475322290194,0.3109475322290194,0.3109475322290194,0.3109475322290194,0.3109475322290194,0.3109475322290194,0.3109475322290194,0.3109475322290194,0.3109475322290194,0.3109475322290194,0.3109475322290194,0.3109475322290194,0.3109475322290194,0.3109475322290194,0.3109475322290194,0.3109475322290194,0.3109475322290194,0.3109475322290194,0.3109475322290194,0.3109475322290194,0.3109475322290194,0.3109475322290194,0.3109475322290194,0.3109475322290194,0.3109475322290194,0.3109475322290194,0.3109475322290194,0.3109475322290194,0.3109475322290194,0.3109475322290194,0.3109475322290194,0.3109475322290194,0.3109475322290194,0.3109475322290194,0.3109475322290194,0.3109475322290194,0.3109475322290194,0.3109475322290194,0.3109475322290194,0.3109475322290194,0.3109475322290194,0.3109475322290194,0.3109475322290194,0.3109475322290194,0.3109475322290194,0.3109475322290194,0.3109475322290194,0.3109475322290194,0.3109475322290194,0.3109475322290194,0.3109475322290194,0.3109475322290194,0.3109475322290194,0.3109475322290194,0.3109475322290194,0.3109475322290194,0.3109475322290194,0.3109475322290194,0.3109475322290194,0.3109475322290194,0.3109475322290194,0.3109475322290194,0.3109475322290194,0.3109475322290194,0.3109475322290194,0.3109475322290194,0.3109475322290194,0.3109475322290194,0.3109475322290194,0.3109475322290194,0.3109475322290194,0.3109475322290194,0.3109475322290194,0.3109475322290194,0.3109475322290194,0.3109475322290194,0.3109475322290194,0.3109475322290194,0.3109475322290194,0.3109475322290194,0.3109475322290194,0.3109475322290194,0.3105107950723598,0.3105107950723598,0.3105107950723598,0.3105107950723598,0.3105107950723598,0.3105107950723598,0.3105107950723598,0.3105107950723598,0.3105107950723598,0.3105107950723598,0.3105107950723598,0.3105107950723598,0.3105107950723598,0.3105107950723598,0.3105107950723598,0.3105107950723598,0.3105107950723598,0.3105107950723598,0.3105107950723598,0.3105107950723598,0.3105107950723598,0.3105107950723598,0.3105107950723598,0.3105107950723598,0.3105107950723598,0.3105107950723598,0.3105107950723598,0.3105107950723598,0.3105107950723598,0.3105107950723598,0.3105107950723598,0.3105107950723598,0.3105107950723598,0.3105107950723598,0.3105107950723598,0.3105107950723598,0.3105107950723598,0.3105107950723598,0.3105107950723598,0.3105107950723598,0.3105107950723598,0.3105107950723598,0.3105107950723598,0.3105107950723598,0.3105107950723598,0.3105107950723598,0.3105107950723598,0.3105107950723598,0.3105107950723598,0.3105107950723598,0.3105107950723598,0.3105107950723598,0.3105107950723598,0.3105107950723598,0.3105107950723598,0.3105107950723598,0.3105107950723598,0.3105107950723598,0.3105107950723598,0.3105107950723598,0.3105107950723598,0.3105107950723598,0.3105107950723598,0.3105107950723598,0.3105107950723598,0.3105107950723598,0.3105107950723598,0.3105107950723598,0.3105107950723598,0.3105107950723598,0.3105107950723598,0.3105107950723598,0.3105107950723598,0.3105107950723598,0.3105107950723598,0.3105107950723598,0.3105107950723598,0.3105107950723598,0.3105107950723598,0.3105107950723598,0.3105107950723598,0.3105107950723598,0.3105107950723598,0.3105107950723598,0.3105107950723598,0.3105107950723598,0.3105107950723598,0.3105107950723598,0.3105107950723598,0.3105107950723598,0.3105107950723598,0.3105107950723598,0.3105107950723598,0.3105107950723598,0.3105107950723598,0.3105107950723598,0.3105107950723598,0.3105107950723598,0.3105107950723598,0.3105107950723598,0.3140126884712822,0.3140126884712822,0.3140126884712822,0.3140126884712822,0.3140126884712822,0.3140126884712822,0.3140126884712822,0.3140126884712822,0.3140126884712822,0.3140126884712822,0.3140126884712822,0.3140126884712822,0.3140126884712822,0.3140126884712822,0.3140126884712822,0.3140126884712822,0.3140126884712822,0.3140126884712822,0.3140126884712822,0.3140126884712822,0.3140126884712822,0.3140126884712822,0.3140126884712822,0.3140126884712822,0.3140126884712822,0.3140126884712822,0.3140126884712822,0.3140126884712822,0.3140126884712822,0.3140126884712822,0.3140126884712822,0.3140126884712822,0.3140126884712822,0.3140126884712822,0.3140126884712822,0.3140126884712822,0.3140126884712822,0.3140126884712822,0.3140126884712822,0.3140126884712822,0.3140126884712822,0.3140126884712822,0.3140126884712822,0.3140126884712822,0.3140126884712822,0.3140126884712822,0.3140126884712822,0.3140126884712822,0.3140126884712822,0.3140126884712822,0.3140126884712822,0.3140126884712822,0.3140126884712822,0.3140126884712822,0.3140126884712822,0.3140126884712822,0.3140126884712822,0.3140126884712822,0.3140126884712822,0.3140126884712822,0.3140126884712822,0.3140126884712822,0.3140126884712822,0.3140126884712822,0.3140126884712822,0.3140126884712822,0.3140126884712822,0.3140126884712822,0.3140126884712822,0.3140126884712822,0.3140126884712822,0.3140126884712822,0.3140126884712822,0.3140126884712822,0.3140126884712822,0.3140126884712822,0.3140126884712822,0.3140126884712822,0.3140126884712822,0.3140126884712822,0.3140126884712822,0.3140126884712822,0.3140126884712822,0.3140126884712822,0.3140126884712822,0.3140126884712822,0.3140126884712822,0.3140126884712822,0.3140126884712822,0.3140126884712822,0.3140126884712822,0.3140126884712822,0.3140126884712822,0.3140126884712822,0.3140126884712822,0.3140126884712822,0.3140126884712822,0.3140126884712822,0.3140126884712822,0.3140126884712822,0.3165825681736331,0.3165825681736331,0.3165825681736331,0.3165825681736331,0.3165825681736331,0.3165825681736331,0.3165825681736331,0.3165825681736331,0.3165825681736331,0.3165825681736331,0.3165825681736331,0.3165825681736331,0.3165825681736331,0.3165825681736331,0.3165825681736331,0.3165825681736331,0.3165825681736331,0.3165825681736331,0.3165825681736331,0.3165825681736331,0.3165825681736331,0.3165825681736331,0.3165825681736331,0.3165825681736331,0.3165825681736331,0.3165825681736331,0.3165825681736331,0.3165825681736331,0.3165825681736331,0.3165825681736331,0.3165825681736331,0.3165825681736331,0.3165825681736331,0.3165825681736331,0.3165825681736331,0.3165825681736331,0.3165825681736331,0.3165825681736331,0.3165825681736331,0.3165825681736331,0.3165825681736331,0.3165825681736331,0.3165825681736331,0.3165825681736331,0.3165825681736331,0.3165825681736331,0.3165825681736331,0.3165825681736331,0.3165825681736331,0.3165825681736331,0.3165825681736331,0.3165825681736331,0.3165825681736331,0.3165825681736331,0.3165825681736331,0.3165825681736331,0.3165825681736331,0.3165825681736331,0.3165825681736331,0.3165825681736331,0.3165825681736331,0.3165825681736331,0.3165825681736331,0.3165825681736331,0.3165825681736331,0.3165825681736331,0.3165825681736331,0.3165825681736331,0.3165825681736331,0.3165825681736331,0.3165825681736331,0.3165825681736331,0.3165825681736331,0.3165825681736331,0.3165825681736331,0.3165825681736331,0.3165825681736331,0.3165825681736331,0.3165825681736331,0.3165825681736331,0.3165825681736331,0.3165825681736331,0.3165825681736331,0.3165825681736331,0.3165825681736331,0.3165825681736331,0.3165825681736331,0.3165825681736331,0.3165825681736331,0.3165825681736331,0.3165825681736331,0.3165825681736331,0.3165825681736331,0.3165825681736331,0.3165825681736331,0.3165825681736331,0.3165825681736331,0.3165825681736331,0.3165825681736331,0.3165825681736331,0.3180817809204307,0.3180817809204307,0.3180817809204307,0.3180817809204307,0.3180817809204307,0.3180817809204307,0.3180817809204307,0.3180817809204307,0.3180817809204307,0.3180817809204307,0.3180817809204307,0.3180817809204307,0.3180817809204307,0.3180817809204307,0.3180817809204307,0.3180817809204307,0.3180817809204307,0.3180817809204307,0.3180817809204307,0.3180817809204307,0.3180817809204307,0.3180817809204307,0.3180817809204307,0.3180817809204307,0.3180817809204307,0.3180817809204307,0.3180817809204307,0.3180817809204307,0.3180817809204307,0.3180817809204307,0.3180817809204307,0.3180817809204307,0.3180817809204307,0.3180817809204307,0.3180817809204307,0.3180817809204307,0.3180817809204307,0.3180817809204307,0.3180817809204307,0.3180817809204307,0.3180817809204307,0.3180817809204307,0.3180817809204307,0.3180817809204307,0.3180817809204307,0.3180817809204307,0.3180817809204307,0.3180817809204307,0.3180817809204307,0.3180817809204307,0.3180817809204307,0.3180817809204307,0.3180817809204307,0.3180817809204307,0.3180817809204307,0.3180817809204307,0.3180817809204307,0.3180817809204307,0.3180817809204307,0.3180817809204307,0.3180817809204307,0.3180817809204307,0.3180817809204307,0.3180817809204307,0.3180817809204307,0.3180817809204307,0.3180817809204307,0.3180817809204307,0.3180817809204307,0.3180817809204307,0.3180817809204307,0.3180817809204307,0.3180817809204307,0.3180817809204307,0.3180817809204307,0.3180817809204307,0.3180817809204307,0.3180817809204307,0.3180817809204307,0.3180817809204307,0.3180817809204307,0.3180817809204307,0.3180817809204307,0.3180817809204307,0.3180817809204307,0.3180817809204307,0.3180817809204307,0.3180817809204307,0.3180817809204307,0.3180817809204307,0.3180817809204307,0.3180817809204307,0.3180817809204307,0.3180817809204307,0.3180817809204307,0.3180817809204307,0.3180817809204307,0.3180817809204307,0.3180817809204307,0.3180817809204307,0.31696801337124464,0.31696801337124464,0.31696801337124464,0.31696801337124464,0.31696801337124464,0.31696801337124464,0.31696801337124464,0.31696801337124464,0.31696801337124464,0.31696801337124464,0.31696801337124464,0.31696801337124464,0.31696801337124464,0.31696801337124464,0.31696801337124464,0.31696801337124464,0.31696801337124464,0.31696801337124464,0.31696801337124464,0.31696801337124464,0.31696801337124464,0.31696801337124464,0.31696801337124464,0.31696801337124464,0.31696801337124464,0.31696801337124464,0.31696801337124464,0.31696801337124464,0.31696801337124464,0.31696801337124464,0.31696801337124464,0.31696801337124464,0.31696801337124464,0.31696801337124464,0.31696801337124464,0.31696801337124464,0.31696801337124464,0.31696801337124464,0.31696801337124464,0.31696801337124464,0.31696801337124464,0.31696801337124464,0.31696801337124464,0.31696801337124464,0.31696801337124464,0.31696801337124464,0.31696801337124464,0.31696801337124464,0.31696801337124464,0.31696801337124464,0.31696801337124464,0.31696801337124464,0.31696801337124464,0.31696801337124464,0.31696801337124464,0.31696801337124464,0.31696801337124464,0.31696801337124464,0.31696801337124464,0.31696801337124464,0.31696801337124464,0.31696801337124464,0.31696801337124464,0.31696801337124464,0.31696801337124464,0.31696801337124464,0.31696801337124464,0.31696801337124464,0.31696801337124464,0.31696801337124464,0.31696801337124464,0.31696801337124464,0.31696801337124464,0.31696801337124464,0.31696801337124464,0.31696801337124464,0.31696801337124464,0.31696801337124464,0.31696801337124464,0.31696801337124464,0.31696801337124464,0.31696801337124464,0.31696801337124464,0.31696801337124464,0.31696801337124464,0.31696801337124464,0.31696801337124464,0.31696801337124464,0.31696801337124464,0.31696801337124464,0.31696801337124464,0.31696801337124464,0.31696801337124464,0.31696801337124464,0.31696801337124464,0.31696801337124464,0.31696801337124464,0.31696801337124464,0.31696801337124464,0.31696801337124464,0.3210769454669353,0.3210769454669353,0.3210769454669353,0.3210769454669353,0.3210769454669353,0.3210769454669353,0.3210769454669353,0.3210769454669353,0.3210769454669353,0.3210769454669353,0.3210769454669353,0.3210769454669353,0.3210769454669353,0.3210769454669353,0.3210769454669353,0.3210769454669353,0.3210769454669353,0.3210769454669353,0.3210769454669353,0.3210769454669353,0.3210769454669353,0.3210769454669353,0.3210769454669353,0.3210769454669353,0.3210769454669353,0.3210769454669353,0.3210769454669353,0.3210769454669353,0.3210769454669353,0.3210769454669353,0.3210769454669353,0.3210769454669353,0.3210769454669353,0.3210769454669353,0.3210769454669353,0.3210769454669353,0.3210769454669353,0.3210769454669353,0.3210769454669353,0.3210769454669353,0.3210769454669353,0.3210769454669353,0.3210769454669353,0.3210769454669353,0.3210769454669353,0.3210769454669353,0.3210769454669353,0.3210769454669353,0.3210769454669353,0.3210769454669353,0.3210769454669353,0.3210769454669353,0.3210769454669353,0.3210769454669353,0.3210769454669353,0.3210769454669353,0.3210769454669353,0.3210769454669353,0.3210769454669353,0.3210769454669353,0.3210769454669353,0.3210769454669353,0.3210769454669353,0.3210769454669353,0.3210769454669353,0.3210769454669353,0.3210769454669353,0.3210769454669353,0.3210769454669353,0.3210769454669353,0.3210769454669353,0.3210769454669353,0.3210769454669353,0.3210769454669353,0.3210769454669353,0.3210769454669353,0.3210769454669353,0.3210769454669353,0.3210769454669353,0.3210769454669353,0.3210769454669353,0.3210769454669353,0.3210769454669353,0.3210769454669353,0.3210769454669353,0.3210769454669353,0.3210769454669353,0.3210769454669353,0.3210769454669353,0.3210769454669353,0.3210769454669353,0.3210769454669353,0.3210769454669353,0.3210769454669353,0.3210769454669353,0.3210769454669353,0.3210769454669353,0.3210769454669353,0.3210769454669353,0.3210769454669353,0.32455743800271236,0.32455743800271236,0.32455743800271236,0.32455743800271236,0.32455743800271236,0.32455743800271236,0.32455743800271236,0.32455743800271236,0.32455743800271236,0.32455743800271236,0.32455743800271236,0.32455743800271236,0.32455743800271236,0.32455743800271236,0.32455743800271236,0.32455743800271236,0.32455743800271236,0.32455743800271236,0.32455743800271236,0.32455743800271236,0.32455743800271236,0.32455743800271236,0.32455743800271236,0.32455743800271236,0.32455743800271236,0.32455743800271236,0.32455743800271236,0.32455743800271236,0.32455743800271236,0.32455743800271236,0.32455743800271236,0.32455743800271236,0.32455743800271236,0.32455743800271236,0.32455743800271236,0.32455743800271236,0.32455743800271236,0.32455743800271236,0.32455743800271236,0.32455743800271236,0.32455743800271236,0.32455743800271236,0.32455743800271236,0.32455743800271236,0.32455743800271236,0.32455743800271236,0.32455743800271236,0.32455743800271236,0.32455743800271236,0.32455743800271236,0.32455743800271236,0.32455743800271236,0.32455743800271236,0.32455743800271236,0.32455743800271236,0.32455743800271236,0.32455743800271236,0.32455743800271236,0.32455743800271236,0.32455743800271236,0.32455743800271236,0.32455743800271236,0.32455743800271236,0.32455743800271236,0.32455743800271236,0.32455743800271236,0.32455743800271236,0.32455743800271236,0.32455743800271236,0.32455743800271236,0.32455743800271236,0.32455743800271236,0.32455743800271236,0.32455743800271236,0.32455743800271236,0.32455743800271236,0.32455743800271236,0.32455743800271236,0.32455743800271236,0.32455743800271236,0.32455743800271236,0.32455743800271236,0.32455743800271236,0.32455743800271236,0.32455743800271236,0.32455743800271236,0.32455743800271236,0.32455743800271236,0.32455743800271236,0.32455743800271236,0.32455743800271236,0.32455743800271236,0.32455743800271236,0.32455743800271236,0.32455743800271236,0.32455743800271236,0.32455743800271236,0.32455743800271236,0.32455743800271236,0.32455743800271236,0.3296116043684269,0.3296116043684269,0.3296116043684269,0.3296116043684269,0.3296116043684269,0.3296116043684269,0.3296116043684269,0.3296116043684269,0.3296116043684269,0.3296116043684269,0.3296116043684269,0.3296116043684269,0.3296116043684269,0.3296116043684269,0.3296116043684269,0.3296116043684269,0.3296116043684269,0.3296116043684269,0.3296116043684269,0.3296116043684269,0.3296116043684269,0.3296116043684269,0.3296116043684269,0.3296116043684269,0.3296116043684269,0.3296116043684269,0.3296116043684269,0.3296116043684269,0.3296116043684269,0.3296116043684269,0.3296116043684269,0.3296116043684269,0.3296116043684269,0.3296116043684269,0.3296116043684269,0.3296116043684269,0.3296116043684269,0.3296116043684269,0.3296116043684269,0.3296116043684269,0.3296116043684269,0.3296116043684269,0.3296116043684269,0.3296116043684269,0.3296116043684269,0.3296116043684269,0.3296116043684269,0.3296116043684269,0.3296116043684269,0.3296116043684269,0.3296116043684269,0.3296116043684269,0.3296116043684269,0.3296116043684269,0.3296116043684269,0.3296116043684269,0.3296116043684269,0.3296116043684269,0.3296116043684269,0.3296116043684269,0.3296116043684269,0.3296116043684269,0.3296116043684269,0.3296116043684269,0.3296116043684269,0.3296116043684269,0.3296116043684269,0.3296116043684269,0.3296116043684269,0.3296116043684269,0.3296116043684269,0.3296116043684269,0.3296116043684269,0.3296116043684269,0.3296116043684269,0.3296116043684269,0.3296116043684269,0.3296116043684269,0.3296116043684269,0.3296116043684269,0.3296116043684269,0.3296116043684269,0.3296116043684269,0.3296116043684269,0.3296116043684269,0.3296116043684269,0.3296116043684269,0.3296116043684269,0.3296116043684269,0.3296116043684269,0.3296116043684269,0.3296116043684269,0.3296116043684269,0.3296116043684269,0.3296116043684269,0.3296116043684269,0.3296116043684269,0.3296116043684269,0.3296116043684269,0.3296116043684269,0.3292791443450242,0.3292791443450242,0.3292791443450242,0.3292791443450242,0.3292791443450242,0.3292791443450242,0.3292791443450242,0.3292791443450242,0.3292791443450242,0.3292791443450242,0.3292791443450242,0.3292791443450242,0.3292791443450242,0.3292791443450242,0.3292791443450242,0.3292791443450242,0.3292791443450242,0.3292791443450242,0.3292791443450242,0.3292791443450242,0.3292791443450242,0.3292791443450242,0.3292791443450242,0.3292791443450242,0.3292791443450242,0.3292791443450242,0.3292791443450242,0.3292791443450242,0.3292791443450242,0.3292791443450242,0.3292791443450242,0.3292791443450242,0.3292791443450242,0.3292791443450242,0.3292791443450242,0.3292791443450242,0.3292791443450242,0.3292791443450242,0.3292791443450242,0.3292791443450242,0.3292791443450242,0.3292791443450242,0.3292791443450242,0.3292791443450242,0.3292791443450242,0.3292791443450242,0.3292791443450242,0.3292791443450242,0.3292791443450242,0.3292791443450242,0.3292791443450242,0.3292791443450242,0.3292791443450242,0.3292791443450242,0.3292791443450242,0.3292791443450242,0.3292791443450242,0.3292791443450242,0.3292791443450242,0.3292791443450242,0.3292791443450242,0.3292791443450242,0.3292791443450242,0.3292791443450242,0.3292791443450242,0.3292791443450242,0.3292791443450242,0.3292791443450242,0.3292791443450242,0.3292791443450242,0.3292791443450242,0.3292791443450242,0.3292791443450242,0.3292791443450242,0.3292791443450242,0.3292791443450242,0.3292791443450242,0.3292791443450242,0.3292791443450242,0.3292791443450242,0.3292791443450242,0.3292791443450242,0.3292791443450242,0.3292791443450242,0.3292791443450242,0.3292791443450242,0.3292791443450242,0.3292791443450242,0.3292791443450242,0.3292791443450242,0.3292791443450242,0.3292791443450242,0.3292791443450242,0.3292791443450242,0.3292791443450242,0.3292791443450242,0.3292791443450242,0.3292791443450242,0.3292791443450242,0.3292791443450242,0.3260905738993216,0.3260905738993216,0.3260905738993216,0.3260905738993216,0.3260905738993216,0.3260905738993216,0.3260905738993216,0.3260905738993216,0.3260905738993216,0.3260905738993216,0.3260905738993216,0.3260905738993216,0.3260905738993216,0.3260905738993216,0.3260905738993216,0.3260905738993216,0.3260905738993216,0.3260905738993216,0.3260905738993216,0.3260905738993216,0.3260905738993216,0.3260905738993216,0.3260905738993216,0.3260905738993216,0.3260905738993216,0.3260905738993216,0.3260905738993216,0.3260905738993216,0.3260905738993216,0.3260905738993216,0.3260905738993216,0.3260905738993216,0.3260905738993216,0.3260905738993216,0.3260905738993216,0.3260905738993216,0.3260905738993216,0.3260905738993216,0.3260905738993216,0.3260905738993216,0.3260905738993216,0.3260905738993216,0.3260905738993216,0.3260905738993216,0.3260905738993216,0.3260905738993216,0.3260905738993216,0.3260905738993216,0.3260905738993216,0.3260905738993216,0.3260905738993216,0.3260905738993216,0.3260905738993216,0.3260905738993216,0.3260905738993216,0.3260905738993216,0.3260905738993216,0.3260905738993216,0.3260905738993216,0.3260905738993216,0.3260905738993216,0.3260905738993216,0.3260905738993216,0.3260905738993216,0.3260905738993216,0.3260905738993216,0.3260905738993216,0.3260905738993216,0.3260905738993216,0.3260905738993216,0.3260905738993216,0.3260905738993216,0.3260905738993216,0.3260905738993216,0.3260905738993216,0.3260905738993216,0.3260905738993216,0.3260905738993216,0.3260905738993216,0.3260905738993216,0.3260905738993216,0.3260905738993216,0.3260905738993216,0.3260905738993216,0.3260905738993216,0.3260905738993216,0.3260905738993216,0.3260905738993216,0.3260905738993216,0.3260905738993216,0.3260905738993216,0.3260905738993216,0.3260905738993216,0.3260905738993216,0.3260905738993216,0.3260905738993216,0.3260905738993216,0.3260905738993216,0.3260905738993216,0.3260905738993216,0.3297554861235345,0.3297554861235345,0.3297554861235345,0.3297554861235345,0.3297554861235345,0.3297554861235345,0.3297554861235345,0.3297554861235345,0.3297554861235345,0.3297554861235345,0.3297554861235345,0.3297554861235345,0.3297554861235345,0.3297554861235345,0.3297554861235345,0.3297554861235345,0.3297554861235345,0.3297554861235345,0.3297554861235345,0.3297554861235345,0.3297554861235345,0.3297554861235345,0.3297554861235345,0.3297554861235345,0.3297554861235345,0.3297554861235345,0.3297554861235345,0.3297554861235345,0.3297554861235345,0.3297554861235345,0.3297554861235345,0.3297554861235345,0.3297554861235345,0.3297554861235345,0.3297554861235345,0.3297554861235345,0.3297554861235345,0.3297554861235345,0.3297554861235345,0.3297554861235345,0.3297554861235345,0.3297554861235345,0.3297554861235345,0.3297554861235345,0.3297554861235345,0.3297554861235345,0.3297554861235345,0.3297554861235345,0.3297554861235345,0.3297554861235345,0.3297554861235345,0.3297554861235345,0.3297554861235345,0.3297554861235345,0.3297554861235345,0.3297554861235345,0.3297554861235345,0.3297554861235345,0.3297554861235345,0.3297554861235345,0.3297554861235345,0.3297554861235345,0.3297554861235345,0.3297554861235345,0.3297554861235345,0.3297554861235345,0.3297554861235345,0.3297554861235345,0.3297554861235345,0.3297554861235345,0.3297554861235345,0.3297554861235345,0.3297554861235345,0.3297554861235345,0.3297554861235345,0.3297554861235345,0.3297554861235345,0.3297554861235345,0.3297554861235345,0.3297554861235345,0.3297554861235345,0.3297554861235345,0.3297554861235345,0.3297554861235345,0.3297554861235345,0.3297554861235345,0.3297554861235345,0.3297554861235345,0.3297554861235345,0.3297554861235345,0.3297554861235345,0.3297554861235345,0.3297554861235345,0.3297554861235345,0.3297554861235345,0.3297554861235345,0.3297554861235345,0.3297554861235345,0.3297554861235345,0.3297554861235345],\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"title\":{\"text\":\"Training and Test Loss\"},\"xaxis\":{\"title\":{\"text\":\"Epoch\"}},\"yaxis\":{\"title\":{\"text\":\"BCEWithLogitsLoss\"}}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('66e5a385-9fad-46c4-9e97-776b6896bc92');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "global_config = {\n",
    "    \"seed\": seed,\n",
    "    \"dataset\": dataset_config,\n",
    "    \"hidden_channels\": 64,\n",
    "    \"optimizer\": \"adam\",\n",
    "    \"learning_rate\": 0.0003,\n",
    "    \"epochs\": 3200,\n",
    "    \"layers\": \"4\",\n",
    "    \"architecture\": \"GAT\",\n",
    "    \"batch\": \"yes\",\n",
    "    \"solutions\": \"one\",\n",
    "}\n",
    "run, model = main(global_config)\n",
    "#torch.save(model, '/home/jovyan/models/42000_lr-0001_lf-multi_8f_lay-4.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, '/home/jovyan/models/10_do_15.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('/home/jovyan/models/10_i_20.pth')\n",
    "\n",
    "\n",
    "def get_highest_n_positions(array, n):\n",
    "    # Convert the array to a numpy array for easy manipulation\n",
    "    array = np.array(array)\n",
    "    \n",
    "    # Get the indices of the n highest values\n",
    "    highest_indices = np.argsort(array)[-n:]\n",
    "    \n",
    "    # Create a new array of zeros with the same length\n",
    "    result = np.zeros_like(array)\n",
    "    \n",
    "    # Set ones at the positions of the highest values\n",
    "    result[highest_indices] = 1\n",
    "    \n",
    "    return result\n",
    "    \n",
    "\n",
    "def check_MIDS_test(A, candidate, target_value, out):\n",
    "    n = len(candidate)\n",
    "    loss = 0\n",
    "    # Candidate set is not minimal\n",
    "    if sum(candidate) > target_value:\n",
    "        return False# not minimal\n",
    "\n",
    "    # Candidate set is not dominating and independent\n",
    "    if not all((A + np.eye(n)) @ candidate >= 1): # domination \n",
    "        return False\n",
    "    \n",
    "    for el in ((A + np.eye(n)) @ candidate):\n",
    "        if el < 1: \n",
    "            loss += 1\n",
    "\n",
    "    for i in range(n):\n",
    "        for j in range(i+1, n):\n",
    "            if candidate[i] and candidate[j] and A[i,j]: # independancy\n",
    "                return False # TODO: zbrajati koliko ih ima koji ispunjavaju uvijet - iz tog dobiti mjeru (LOSS) nezavisnosti\n",
    "                \n",
    "    if sum(candidate) < target_value:\n",
    "        print(f\"Somehow we found an even smaller MIDS: {sum(candidate)}, {target_value}\")\n",
    "        pass\n",
    "\n",
    "    return True\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(loader):\n",
    "    model.eval()\n",
    "    flag = 0\n",
    "    correct = 0\n",
    "    correct_checkMIDS = 0\n",
    "    correct_checkMIDS_new = 0\n",
    "    not_min = 0\n",
    "    one_less = 0\n",
    "    off_by_one = 0\n",
    "    for i, data in enumerate(loader):\n",
    "        for idx in range(data.num_graphs):\n",
    "            out = model(data.get_example(idx).x.type(torch.FloatTensor).to(device), data.get_example(idx).edge_index.to(device))\n",
    "            #print(out)\n",
    "            pred = torch.where(out > 0, 1.0, 0.0)\n",
    "            #print(data.edge_index)\n",
    "\n",
    "            #correct += int(torch.equal(pred.to(device),data.get_example(idx).y.type(torch.LongTensor).to(device)))  # Derive ratio of correct predictions.\n",
    "\n",
    "            num_nodes = data.get_example(idx).num_nodes\n",
    "            adjacency = SparseTensor(row=data.get_example(idx).edge_index[0], col=data.get_example(idx).edge_index[1], sparse_sizes=(num_nodes, num_nodes))\n",
    "            adjacency_matrix = adjacency.to_dense()\n",
    "            correct = check_MIDS_test(adjacency_matrix.numpy(),\n",
    "                                pred.cpu().numpy(),\n",
    "                                sum(torch.split(data.get_example(idx).y, data.num_nodes)[0].cpu().numpy()), out)\n",
    "            correct_new = check_MIDS_test(adjacency_matrix.numpy(),\n",
    "                                get_highest_n_positions(out.cpu(), int(sum(torch.split(data.get_example(idx).y, data.num_nodes)[0].cpu().numpy()))),\n",
    "                                sum(torch.split(data.get_example(idx).y, data.num_nodes)[0].cpu().numpy()), out)\n",
    "\n",
    "            correct_checkMIDS_new += int(correct_new)\n",
    "            if correct == True:\n",
    "                correct_checkMIDS += int(correct)\n",
    "            else:\n",
    "                if correct == -5: # not minimal\n",
    "                    not_min += 1\n",
    "                if correct == -4: # 1 less\n",
    "                    one_less += 1\n",
    "                    #print(get_highest_n_positions(out.cpu(), int(sum(pred).cpu())+1))\n",
    "                    off_by_one += check_MIDS_test(adjacency_matrix.numpy(),\n",
    "                                get_highest_n_positions(out.cpu(), int(sum(pred).cpu())+1),\n",
    "                                sum(torch.split(data.get_example(idx).y, data.num_nodes)[0].cpu().numpy()), out)\n",
    "                    \n",
    "\n",
    "    #print(f'{correct_checkMIDS/len(loader.dataset)*100}%')\n",
    "    print(correct_checkMIDS)\n",
    "    print(len(loader.dataset))\n",
    "    return correct_checkMIDS/len(loader.dataset)*100, correct_checkMIDS_new/len(loader.dataset)*100#, not_min/len(loader.dataset)*100, one_less/len(loader.dataset)*100, off_by_one/len(loader.dataset)*100\n",
    "\n",
    "\n",
    "root = \"/home/jovyan/MIDS-GNN/Dataset\"\n",
    "graphs_loader = GraphDataset(selection=selected_graph_sizes)\n",
    "dataset = MIDSdataset(root, graphs_loader)\n",
    "\n",
    "loader = DataLoader(dataset, batch_size=1, shuffle=False)\n",
    "test(loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def examine_pred(data, pred):\n",
    "    G = pygUtils.to_networkx(data, to_undirected=True)\n",
    "    nx.draw(G, with_labels=True, node_color=pred, cmap=matplotlib.colormaps[\"bwr\"])\n",
    "    plt.show()\n",
    "    print(f'prediction: {pred}')\n",
    "    print(f'data.y:     {torch.split(data.y, data.num_nodes)}')\n",
    "\n",
    "for i in range(50):\n",
    "    d = dataset[i]\n",
    "    out = model(d.x.type(torch.FloatTensor).to(device), d.edge_index.to(device))\n",
    "    pred = torch.where(out > 0, 1.0, 0.0)\n",
    "    num_nodes = d.num_nodes\n",
    "    adjacency = SparseTensor(row=d.edge_index[0], col=d.edge_index[1], sparse_sizes=(num_nodes, num_nodes))\n",
    "    adjacency_matrix = adjacency.to_dense()\n",
    "    correct = check_MIDS_test(adjacency_matrix.numpy(),\n",
    "                                get_highest_n_positions(out.cpu(), int(sum(torch.split(d.y, d.num_nodes)[0].cpu()))),\n",
    "                                sum(torch.split(d.y, data.num_nodes)[0].cpu()), out)\n",
    "\n",
    "    if correct == False:\n",
    "        examine_pred(d.cpu(), pred.cpu())\n",
    "        print(model(d.x.type(torch.FloatTensor).to(device), d.edge_index.to(device)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### W&B sweep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%env WANDB_SILENT=True\n",
    "\n",
    "import time\n",
    "time.sleep(2)\n",
    "\n",
    "# TODO: How to include seed and dataset configuration?\n",
    "\n",
    "full_sweep_configuration = {\n",
    "    \"name\": \"full_first_sweep\",\n",
    "    \"method\": \"grid\",  # grid, random or Bayesian\n",
    "    \"metric\": {\"goal\": \"minimize\", \"name\": \"test_loss\"},\n",
    "    \"parameters\": {\n",
    "        \"architecture\": {\"value\": \"GAT\"},\n",
    "        \"hidden_channels\": {\"values\": [256]},\n",
    "        \"optimizer\": {\"value\": \"adam\"},\n",
    "        \"learning_rate\": {\"values\": [0.0002, 0.0004, 0.0006]},\n",
    "        \"epochs\": {\"value\": 150}\n",
    "    },\n",
    "    \"early_terminate\": {\n",
    "        \"type\": \"hyperband\",\n",
    "        \"eta\": 3,\n",
    "        \"min_iter\": 150\n",
    "    }\n",
    "}\n",
    "\n",
    "test_sweep_configuration = {\n",
    "    \"name\": \"test_sweep\",\n",
    "    \"method\": \"grid\",  # grid, random or Bayesian\n",
    "    \"metric\": {\"goal\": \"minimize\", \"name\": \"test_loss\"},\n",
    "    \"parameters\": {\n",
    "        \"architecture\": {\"values\": [\"GCN\", \"GAT\"]},\n",
    "        \"hidden_channels\": {\"values\": [8, 16]},\n",
    "        \"num_layers\": {\"values\": [2, 5]},\n",
    "        \"optimizer\": {\"value\": \"adam\"},\n",
    "        \"learning_rate\": {\"values\": [0.01, 0.001]},\n",
    "        \"epochs\": {\"value\": 1000}\n",
    "    },\n",
    "}\n",
    "\n",
    "sweep_id = wandb.sweep(sweep=full_sweep_configuration, project=\"GNN_MIDS\")\n",
    "\n",
    "wandb.agent(sweep_id, function=main, count=3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.agent(sweep_id, function=main, count=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop the W&B run.\n",
    "run.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Housekeeping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(model.state_dict(), \"model.pth\")\n",
    "# print(\"Saved PyTorch Model State to model.pth\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make predictions with loaded model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = NeuralNetwork().to(device)\n",
    "# model.load_state_dict(torch.load(\"model.pth\"))\n",
    "\n",
    "# classes = [\n",
    "#     \"T-shirt/top\",\n",
    "#     \"Trouser\",\n",
    "#     \"Pullover\",\n",
    "#     \"Dress\",\n",
    "#     \"Coat\",\n",
    "#     \"Sandal\",\n",
    "#     \"Shirt\",\n",
    "#     \"Sneaker\",\n",
    "#     \"Bag\",\n",
    "#     \"Ankle boot\",\n",
    "# ]\n",
    "\n",
    "# model.eval()\n",
    "# x, y = test_data[0][0], test_data[0][1]\n",
    "# with torch.no_grad():\n",
    "#     x = x.to(device)\n",
    "#     pred = model(x)\n",
    "#     predicted, actual = classes[pred[0].argmax(0)], classes[y]\n",
    "#     print(f'Predicted: \"{predicted}\", Actual: \"{actual}\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional W&B APIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# api = wandb.Api()\n",
    "\n",
    "# # Access attributes directly from the run object\n",
    "# # or from the W&B App\n",
    "# username = \"marko-krizmancic\"\n",
    "# project = \"gnn_fiedler_approx\"\n",
    "# run_id = [\"nrcdc1y4\", \"11l94b1a\", \"ptj7b0vx\"]\n",
    "\n",
    "# for id in run_id:\n",
    "#     run = api.run(f\"{username}/{project}/{id}\")\n",
    "#     run.config[\"model\"] = \"GCN\"\n",
    "#     run.update()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
