{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8J8yE5_XswuN"
   },
   "source": [
    "Install packages and mount google drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rzsRazYTsldP",
    "outputId": "535f6879-5217-4a0c-d0c3-b5410a9d4ce7"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "!pip install torch torchvision torchaudio\n",
    "\n",
    "import torch\n",
    "os.environ['TORCH'] = torch.__version__\n",
    "print(torch.__version__)\n",
    "\n",
    "#!pip install torch-sparse #-f https://data.pyg.org/whl/torch-${TORCH}.html\n",
    "#!pip install torch-scatter #-f https://data.pyg.org/whl/torch-${TORCH}.html\n",
    "#!pip install torch-sparse -f https://data.pyg.org/whl/torch-2.3.0+cu121.html\n",
    "#!pip install torch-scatter -f https://data.pyg.org/whl/torch-2.3.0+cu121.html\n",
    "\n",
    "!pip uninstall torch-scatter torch-sparse torch-geometric torch-cluster  --y\n",
    "!pip install torch-scatter -f https://data.pyg.org/whl/torch-{torch.__version__}.html\n",
    "!pip install torch-sparse -f https://data.pyg.org/whl/torch-{torch.__version__}.html\n",
    "#!pip install torch-cluster -f https://data.pyg.org/whl/torch-{torch.__version__}.html\n",
    "!pip install git+https://github.com/pyg-team/pytorch_geometric.git\n",
    "\n",
    "!pip install torch-geometric\n",
    "!pip install codetiming\n",
    "!pip install wandb\n",
    "!pip install plotly\n",
    "!pip install line-profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# provjera jel se sve dobro instaliralo\n",
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(device)\n",
    "tensor = torch.rand(3, 3).to(device)\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RdYsYt_0tR9o"
   },
   "source": [
    "Initialize dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip3 install codetiming\n",
    "%run -i '/home/jovyan/MIDS-GNN/pyg_dataset_second.py'\n",
    "#%run -i '/home/jovyan/MIDS_collection/PyTorch Geometric/Dataset/raw_file_snapshot.py'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QZ1L4gykthXN"
   },
   "source": [
    "Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "USVP6QoBtju6",
    "outputId": "759a26ff-cafc-4c34-aa05-1b3132dab672"
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "os.chdir('/home/jovyan/MIDS-GNN')\n",
    "root =\"/home/jovyan/MIDS-GNN/Dataset\"\n",
    "\n",
    "selected_graph_sizes =     {\n",
    "                            #3: -1,\n",
    "                            #4: -1,\n",
    "                            #5: -1,\n",
    "                            #6: -1,\n",
    "                            #7: -1,\n",
    "                            #8:  10000,\n",
    "                            #9:  10000,\n",
    "                            #10: 10000,\n",
    "                            #11: 10000,\n",
    "                            #12: 10000,\n",
    "                            #13: 10000,\n",
    "                            #14: 10000,\n",
    "                            #15: 10000,\n",
    "                            #20: 10000,\n",
    "                            50: 2000,\n",
    "                        }\n",
    "loader = GraphDataset(selection=selected_graph_sizes)\n",
    "\n",
    "#import zipfile\n",
    "#with zipfile.ZipFile('/home/jovyan/MIDS_collection/PyTorch Geometric/Dataset/raw_data.zip', 'r') as zip_ref:\n",
    "#    zip_ref.extractall('/home/jovyan/MIDS_collection/PyTorch Geometric/Dataset/raw_data')\n",
    "    \n",
    "raw_included_subdirs = None\n",
    "\n",
    "dataset = MIDSdataset(root, loader)\n",
    "\n",
    "print()\n",
    "print(f\"Dataset: {dataset}:\")\n",
    "print(\"====================\")\n",
    "print(f\"Number of graphs: {len(dataset)}\")\n",
    "print(f\"Number of features: {dataset.num_features}\")\n",
    "#print(f\"Number of classes: {dataset.num_classes}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "id": "P-WNHT2PtuEO",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Define GNN structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OqyebxRztxHT"
   },
   "outputs": [],
   "source": [
    "import os.path as osp\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from torch_geometric.datasets import PPI\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn import GATConv\n",
    "\n",
    "torch.manual_seed(12345)\n",
    "dataset = dataset.shuffle()\n",
    "\n",
    "# split dataset into train and test\n",
    "train_dataset = dataset[:int(len(dataset)*0.8)] # train 80\n",
    "print(len(train_dataset))\n",
    "test_dataset = dataset[int(len(dataset)*0.8):] # test 20\n",
    "print(len(test_dataset))\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = GATConv(train_dataset.num_features, 256, heads=4)\n",
    "        self.lin1 = torch.nn.Linear(train_dataset.num_features, 4 * 256)\n",
    "        self.conv2 = GATConv(4 * 256, 256, heads=4)\n",
    "        self.lin2 = torch.nn.Linear(4 * 256, 4 * 256)\n",
    "        self.conv3 = GATConv(4 * 256, 256, heads=4)\n",
    "        self.lin3 = torch.nn.Linear(4 * 256, 4 * 256)\n",
    "        self.conv4 = GATConv(4 * 256, 1, heads=6,\n",
    "                             concat=False)\n",
    "        self.lin4 = torch.nn.Linear(4 * 256, 1)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = F.elu(self.conv1(x, edge_index) + self.lin1(x))\n",
    "        x = F.elu(self.conv2(x, edge_index) + self.lin2(x))\n",
    "        x = F.elu(self.conv3(x, edge_index) + self.lin3(x))\n",
    "        x = self.conv4(x, edge_index) + self.lin4(x)\n",
    "        return x.squeeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "awfSuqHJt3Nm"
   },
   "source": [
    "Train a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "ttsmINo4t7rB",
    "outputId": "d0deec1b-44a4-47e5-8094-47d7d1d829df"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "\n",
    "from math import inf\n",
    "import torch.nn.functional as F\n",
    "from torch import Tensor\n",
    "from typing import Optional\n",
    "\n",
    "class CustomLossFunction(torch.nn.BCEWithLogitsLoss):\n",
    "  def forward(self, input: Tensor, target: Tensor) -> Tensor:\n",
    "      tens = torch.split(target, input.size(dim=0))[0]\n",
    "      loss = F.binary_cross_entropy_with_logits(input, tens, self.weight, pos_weight=self.pos_weight, reduction=self.reduction)\n",
    "      \n",
    "      for tens in torch.split(target, input.size(dim=0)):\n",
    "          new = F.binary_cross_entropy_with_logits(input, tens, self.weight, pos_weight=self.pos_weight, reduction=self.reduction)\n",
    "          if new.item() < loss.item():\n",
    "              loss = new\n",
    "      return loss\n",
    "\n",
    "from torch_sparse import SparseTensor\n",
    "\n",
    "def check_MIDS(A, candidate, target_value):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        - A: adjacency matrix\n",
    "        - candidate: node labels that are candidate for MIDS (data.y)\n",
    "        - target_value: known size of the MIDS\n",
    "    \"\"\"\n",
    "    # TODO: This function needs to be adjusted.\n",
    "    #   - Instead of adjacency matrix, we may pass the edgelist and convert it here\n",
    "\n",
    "    n = len(candidate)\n",
    "\n",
    "    # Candidate set is not minimal\n",
    "    if sum(candidate) > target_value:\n",
    "        return False\n",
    "\n",
    "    # Candidate set is not dominating and independent\n",
    "    if not all((A + np.eye(n)) @ candidate >= 1):\n",
    "        return False\n",
    "\n",
    "    for i in range(n):\n",
    "        for j in range(i+1, n):\n",
    "            if candidate[i] and candidate[j] and A[i,j]:\n",
    "                return False\n",
    "\n",
    "\n",
    "\n",
    "    if sum(candidate) < target_value:\n",
    "        print(f\"Somehow we found an even smaller MIDS: {sum(candidate)}, {target_value}\")\n",
    "        pass\n",
    "\n",
    "    return True\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "print(torch.cuda.device_count())\n",
    "model = Net().to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.00004)\n",
    "#loss_op = torch.nn.CrossEntropyLoss()\n",
    "#loss_op = torch.nn.BCEWithLogitsLoss()\n",
    "loss_op = CustomLossFunction()\n",
    "\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "\n",
    "    total_loss = 0\n",
    "    for i, data in enumerate(train_loader):\n",
    "        data = data.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(data.x.type(torch.FloatTensor).to(device), data.edge_index)\n",
    "        real = data.y.type(torch.LongTensor)\n",
    "        loss = loss_op(pred.to(device), data.y.to(device))\n",
    "\n",
    "        total_loss += loss.item() * data.num_graphs\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    return total_loss / len(train_loader.dataset)\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(loader):\n",
    "    model.eval()\n",
    "    flag = 0\n",
    "    correct = 0\n",
    "    correct_checkMIDS = 0\n",
    "    for i, data in enumerate(loader):\n",
    "        for idx in range(data.num_graphs):\n",
    "            out = model(data.get_example(idx).x.type(torch.FloatTensor).to(device), data.get_example(idx).edge_index.to(device))\n",
    "            #print(out)\n",
    "          \n",
    "            pred = torch.where(out > 0, 1.0, 0.0)\n",
    "            #print(data.edge_index)\n",
    "            pred_2 = torch.round(out)\n",
    "            #correct += int(torch.equal(pred.to(device),data.get_example(idx).y.type(torch.LongTensor).to(device)))  # Derive ratio of correct predictions.\n",
    "\n",
    "            num_nodes = data.get_example(idx).num_nodes\n",
    "            adjacency = SparseTensor(row=data.get_example(idx).edge_index[0], col=data.get_example(idx).edge_index[1], sparse_sizes=(num_nodes, num_nodes))\n",
    "            adjacency_matrix = adjacency.to_dense()\n",
    "            #print(torch.split(data.get_example(idx).y, data.num_nodes))\n",
    "            correct_checkMIDS += int(check_MIDS(adjacency_matrix.numpy(),\n",
    "                                              pred.cpu().numpy(),\n",
    "                                              sum(torch.split(data.get_example(idx).y, data.num_nodes)[0].cpu().numpy())))\n",
    "\n",
    "    #print(f'{correct_checkMIDS/len(loader.dataset)*100}%')\n",
    "    return correct_checkMIDS/len(loader.dataset)*100\n",
    "\n",
    "\n",
    "times = []\n",
    "losses = []\n",
    "trains = []\n",
    "tests = []\n",
    "\n",
    "for epoch in range(1, 201):\n",
    "    start = time.time()\n",
    "\n",
    "    loss = train()\n",
    "    losses.append(loss)\n",
    "    if epoch == 1 or epoch % 1 == 0:\n",
    "      #train_f1 = test(train_loader)\n",
    "      #trains.append(train_f1)\n",
    "\n",
    "      test_f1 = test(test_loader)\n",
    "      tests.append(test_f1)\n",
    "\n",
    "      print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}, '\n",
    "            f'Test: {test_f1:.4f}%, Time: {(time.time() - start):.1f} sec')\n",
    "    else:\n",
    "      print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}, '\n",
    "            f'Time: {(time.time() - start):.1f} sec')\n",
    "    times.append(time.time() - start)\n",
    "print(f\"Median time per epoch: {torch.tensor(times).median():.4f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0zqfSuWwuEmQ"
   },
   "source": [
    "Plot loss and train and test accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 430
    },
    "id": "30OqhJAduMvo",
    "outputId": "e87f4d18-8583-43e1-fd45-8336c91e68ba"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as pp\n",
    "pp.plot(losses)\n",
    "pp.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 430
    },
    "id": "03bjo1QIuNRt",
    "outputId": "f4a5a255-6e33-4cc5-eb3f-0f7f75b860ec"
   },
   "outputs": [],
   "source": [
    "pp.plot(trains)\n",
    "pp.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 431
    },
    "id": "RdSq6NBJuWue",
    "outputId": "b1079410-3a18-44a1-d238-6e65480614e6"
   },
   "outputs": [],
   "source": [
    "pp.plot(tests)\n",
    "pp.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a6-p8CPEuaex"
   },
   "source": [
    "Save/Load a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yQUkToEKuZ-Q"
   },
   "outputs": [],
   "source": [
    "torch.save(model, '/home/jovyan/models/model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ks1S9NoMue7W"
   },
   "outputs": [],
   "source": [
    "loaded = torch.load('/home/jovyan/models/3-30_with_real_probabilities_23epochs.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xCcdIFqcunqR"
   },
   "source": [
    "Testing a loaded model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EmYdUa3wuqco",
    "outputId": "ceaa3e7e-4ece-464d-ab47-fffb9d03f68a"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(loader):\n",
    "    loaded.eval()\n",
    "    flag = 0\n",
    "    correct = 0\n",
    "    correct_checkMIDS = 0\n",
    "    for i, data in enumerate(loader):\n",
    "        for idx in range(data.num_graphs):\n",
    "          out = loaded(data.get_example(idx).x.type(torch.FloatTensor).to(device), data.get_example(idx).edge_index.to(device))\n",
    "          #print(out)\n",
    "          pred = torch.where(out > 0, 1.0, 0.0)\n",
    "          #print(data.edge_index)\n",
    "\n",
    "          #correct += int(torch.equal(pred.to(device),data.get_example(idx).y.type(torch.LongTensor).to(device)))  # Derive ratio of correct predictions.\n",
    "\n",
    "          num_nodes = data.get_example(idx).num_nodes\n",
    "          adjacency = SparseTensor(row=data.get_example(idx).edge_index[0], col=data.get_example(idx).edge_index[1], sparse_sizes=(num_nodes, num_nodes))\n",
    "          adjacency_matrix = adjacency.to_dense()\n",
    "          correct_checkMIDS += int(check_MIDS(adjacency_matrix.numpy(),\n",
    "                                              pred.cpu().numpy(),\n",
    "                                              sum(torch.split(data.get_example(idx).y, data.num_nodes)[0].cpu().numpy())))\n",
    "\n",
    "    #print(f'{correct_checkMIDS/len(loader.dataset)*100}%')\n",
    "    return correct_checkMIDS/len(loader.dataset)*100\n",
    "\n",
    "loader = DataLoader(dataset, batch_size=1, shuffle=False)\n",
    "test(loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9PmnNH6euynZ"
   },
   "source": [
    "Visualize wrong predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "2-Aobouxu1KB",
    "outputId": "b69601be-d021-411d-9f3f-f58729819852"
   },
   "outputs": [],
   "source": [
    "def check_MIDS(A, candidate, target_value):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        - A: adjacency matrix\n",
    "        - candidate: node labels that are candidate for MIDS (data.y)\n",
    "        - target_value: known size of the MIDS\n",
    "    \"\"\"\n",
    "    # TODO: This function needs to be adjusted.\n",
    "    #   - Instead of adjacency matrix, we may pass the edgelist and convert it here\n",
    "\n",
    "    n = len(candidate)\n",
    "\n",
    "    # Candidate set is not minimal\n",
    "    if sum(candidate) > target_value:\n",
    "        return False\n",
    "\n",
    "    # Candidate set is not dominating and independent\n",
    "    if not all((A + np.eye(n)) @ candidate >= 1):\n",
    "        return False\n",
    "\n",
    "    for i in range(n):\n",
    "        for j in range(i+1, n):\n",
    "            if candidate[i] and candidate[j] and A[i,j]:\n",
    "                return False\n",
    "\n",
    "\n",
    "\n",
    "    if sum(candidate) < target_value:\n",
    "        print(f\"Somehow we found an even smaller MIDS: {sum(candidate)}, {target_value}\")\n",
    "        pass\n",
    "\n",
    "    return True\n",
    "\n",
    "def examine_pred(data, pred):\n",
    "    G = pygUtils.to_networkx(data, to_undirected=True)\n",
    "    nx.draw(G, with_labels=True, node_color=pred, cmap=matplotlib.colormaps[\"bwr\"])\n",
    "    plt.show()\n",
    "    print(f'prediction: {pred}')\n",
    "    print(f'data.y:     {data.y.type(torch.LongTensor)}')\n",
    "\n",
    "for i in range(500):\n",
    "    data = dataset[i]\n",
    "    predik = loaded(data.x.to(device), data.edge_index.to(device))#.argmax(dim=1)\n",
    "    pred = torch.where(predik > 0, 1.0, 0.0).to(device='cpu')\n",
    "    num_nodes = data.num_nodes\n",
    "    adjacency = SparseTensor(row=data.edge_index[0], col=data.edge_index[1], sparse_sizes=(num_nodes, num_nodes))\n",
    "    adjacency_matrix = adjacency.to_dense()\n",
    "    is_mids = check_MIDS(adjacency_matrix.numpy(),\n",
    "                                              pred.cpu().numpy(),\n",
    "                                              sum(torch.split(data.y, data.num_nodes)[0].cpu().numpy()))\n",
    "    if not is_mids:\n",
    "        examine_pred(data.to(device), pred)\n",
    "        print(f'Prediction: {loaded(data.x.to(device), data.edge_index.to(device)).detach()}')\n",
    "        #print(data.feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
